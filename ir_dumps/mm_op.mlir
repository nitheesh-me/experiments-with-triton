// -----// IR Dump Before Inliner (inline) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc86 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc1)
    %1 = tt.call @"cdiv__i32__(1,)cconstexpr_32_"(%arg3) : (i32) -> i32 loc(#loc2)
    %2 = tt.call @"cdiv__i32__(1,)cconstexpr_32_"(%arg4) : (i32) -> i32 loc(#loc3)
    %c4_i32 = arith.constant 4 : i32 loc(#loc4)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc4)
    %3 = arith.extsi %c4_i32_0 : i32 to i64 loc(#loc4)
    %4 = arith.extsi %2 : i32 to i64 loc(#loc4)
    %5 = arith.muli %3, %4 : i64 loc(#loc4)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc4)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc4)
    %6 = arith.cmpi sle, %5, %c2147483647_i64 : i64 loc(#loc4)
    %7 = arith.cmpi sge, %5, %c-2147483648_i64 : i64 loc(#loc4)
    %8 = arith.andi %6, %7 : i1 loc(#loc4)
    %9 = arith.muli %c4_i32_0, %2 : i32 loc(#loc4)
    %10 = arith.divsi %0, %9 : i32 loc(#loc5)
    %c4_i32_1 = arith.constant 4 : i32 loc(#loc6)
    %c4_i32_2 = arith.constant 4 : i32 loc(#loc6)
    %11 = arith.extsi %10 : i32 to i64 loc(#loc6)
    %12 = arith.extsi %c4_i32_2 : i32 to i64 loc(#loc6)
    %13 = arith.muli %11, %12 : i64 loc(#loc6)
    %c2147483647_i64_3 = arith.constant 2147483647 : i64 loc(#loc6)
    %c-2147483648_i64_4 = arith.constant -2147483648 : i64 loc(#loc6)
    %14 = arith.cmpi sle, %13, %c2147483647_i64_3 : i64 loc(#loc6)
    %15 = arith.cmpi sge, %13, %c-2147483648_i64_4 : i64 loc(#loc6)
    %16 = arith.andi %14, %15 : i1 loc(#loc6)
    %17 = arith.muli %10, %c4_i32_2 : i32 loc(#loc6)
    %18 = arith.extsi %1 : i32 to i64 loc(#loc7)
    %19 = arith.extsi %17 : i32 to i64 loc(#loc7)
    %20 = arith.subi %18, %19 : i64 loc(#loc7)
    %c2147483647_i64_5 = arith.constant 2147483647 : i64 loc(#loc7)
    %c-2147483648_i64_6 = arith.constant -2147483648 : i64 loc(#loc7)
    %21 = arith.cmpi sle, %20, %c2147483647_i64_5 : i64 loc(#loc7)
    %22 = arith.cmpi sge, %20, %c-2147483648_i64_6 : i64 loc(#loc7)
    %23 = arith.andi %21, %22 : i1 loc(#loc7)
    %24 = arith.subi %1, %17 : i32 loc(#loc7)
    %c4_i32_7 = arith.constant 4 : i32 loc(#loc8)
    %25 = arith.minsi %24, %c4_i32_7 : i32 loc(#loc8)
    %26 = arith.remsi %0, %9 : i32 loc(#loc9)
    %27 = arith.remsi %26, %25 : i32 loc(#loc10)
    %28 = arith.extsi %17 : i32 to i64 loc(#loc11)
    %29 = arith.extsi %27 : i32 to i64 loc(#loc11)
    %30 = arith.addi %28, %29 : i64 loc(#loc11)
    %c2147483647_i64_8 = arith.constant 2147483647 : i64 loc(#loc11)
    %c-2147483648_i64_9 = arith.constant -2147483648 : i64 loc(#loc11)
    %31 = arith.cmpi sle, %30, %c2147483647_i64_8 : i64 loc(#loc11)
    %32 = arith.cmpi sge, %30, %c-2147483648_i64_9 : i64 loc(#loc11)
    %33 = arith.andi %31, %32 : i1 loc(#loc11)
    %34 = arith.addi %17, %27 : i32 loc(#loc11)
    %35 = arith.remsi %0, %9 : i32 loc(#loc12)
    %36 = arith.divsi %35, %25 : i32 loc(#loc13)
    %c0_i32 = arith.constant 0 : i32 loc(#loc14)
    %37 = arith.cmpi sge, %34, %c0_i32 : i32 loc(#loc14)
    llvm.intr.assume %37 : i1 loc(#loc15)
    %c0_i32_10 = arith.constant 0 : i32 loc(#loc16)
    %38 = arith.cmpi sge, %36, %c0_i32_10 : i32 loc(#loc16)
    llvm.intr.assume %38 : i1 loc(#loc17)
    %c0_i32_11 = arith.constant 0 : i32 loc(#loc18)
    %39 = arith.cmpi sgt, %arg6, %c0_i32_11 : i32 loc(#loc18)
    llvm.intr.assume %39 : i1 loc(#loc19)
    %true = arith.constant true loc(#loc20)
    llvm.intr.assume %true : i1 loc(#loc20)
    %true_12 = arith.constant true loc(#loc21)
    llvm.intr.assume %true_12 : i1 loc(#loc21)
    %c0_i32_13 = arith.constant 0 : i32 loc(#loc22)
    %40 = arith.cmpi sgt, %arg7, %c0_i32_13 : i32 loc(#loc22)
    llvm.intr.assume %40 : i1 loc(#loc23)
    %c0_i32_14 = arith.constant 0 : i32 loc(#loc24)
    %41 = arith.cmpi sgt, %arg8, %c0_i32_14 : i32 loc(#loc24)
    llvm.intr.assume %41 : i1 loc(#loc25)
    %true_15 = arith.constant true loc(#loc26)
    llvm.intr.assume %true_15 : i1 loc(#loc26)
    %c32_i32 = arith.constant 32 : i32 loc(#loc27)
    %c32_i32_16 = arith.constant 32 : i32 loc(#loc27)
    %42 = arith.extsi %34 : i32 to i64 loc(#loc27)
    %43 = arith.extsi %c32_i32_16 : i32 to i64 loc(#loc27)
    %44 = arith.muli %42, %43 : i64 loc(#loc27)
    %c2147483647_i64_17 = arith.constant 2147483647 : i64 loc(#loc27)
    %c-2147483648_i64_18 = arith.constant -2147483648 : i64 loc(#loc27)
    %45 = arith.cmpi sle, %44, %c2147483647_i64_17 : i64 loc(#loc27)
    %46 = arith.cmpi sge, %44, %c-2147483648_i64_18 : i64 loc(#loc27)
    %47 = arith.andi %45, %46 : i1 loc(#loc27)
    %48 = arith.muli %34, %c32_i32_16 : i32 loc(#loc27)
    %49 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc28)
    %50 = tt.splat %48 : i32 -> tensor<32xi32> loc(#loc29)
    %51 = arith.extsi %50 : tensor<32xi32> to tensor<32xi64> loc(#loc29)
    %52 = arith.extsi %49 : tensor<32xi32> to tensor<32xi64> loc(#loc29)
    %53 = arith.addi %51, %52 : tensor<32xi64> loc(#loc29)
    %c2147483647_i64_19 = arith.constant 2147483647 : i64 loc(#loc29)
    %c-2147483648_i64_20 = arith.constant -2147483648 : i64 loc(#loc29)
    %cst = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc29)
    %54 = arith.cmpi sle, %53, %cst : tensor<32xi64> loc(#loc29)
    %cst_21 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc29)
    %55 = arith.cmpi sge, %53, %cst_21 : tensor<32xi64> loc(#loc29)
    %56 = arith.andi %54, %55 : tensor<32xi1> loc(#loc29)
    %57 = arith.addi %50, %49 : tensor<32xi32> loc(#loc29)
    %58 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc30)
    %59 = arith.remsi %57, %58 : tensor<32xi32> loc(#loc30)
    %c32_i32_22 = arith.constant 32 : i32 loc(#loc31)
    %c32_i32_23 = arith.constant 32 : i32 loc(#loc31)
    %60 = arith.extsi %36 : i32 to i64 loc(#loc31)
    %61 = arith.extsi %c32_i32_23 : i32 to i64 loc(#loc31)
    %62 = arith.muli %60, %61 : i64 loc(#loc31)
    %c2147483647_i64_24 = arith.constant 2147483647 : i64 loc(#loc31)
    %c-2147483648_i64_25 = arith.constant -2147483648 : i64 loc(#loc31)
    %63 = arith.cmpi sle, %62, %c2147483647_i64_24 : i64 loc(#loc31)
    %64 = arith.cmpi sge, %62, %c-2147483648_i64_25 : i64 loc(#loc31)
    %65 = arith.andi %63, %64 : i1 loc(#loc31)
    %66 = arith.muli %36, %c32_i32_23 : i32 loc(#loc31)
    %67 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc32)
    %68 = tt.splat %66 : i32 -> tensor<32xi32> loc(#loc33)
    %69 = arith.extsi %68 : tensor<32xi32> to tensor<32xi64> loc(#loc33)
    %70 = arith.extsi %67 : tensor<32xi32> to tensor<32xi64> loc(#loc33)
    %71 = arith.addi %69, %70 : tensor<32xi64> loc(#loc33)
    %c2147483647_i64_26 = arith.constant 2147483647 : i64 loc(#loc33)
    %c-2147483648_i64_27 = arith.constant -2147483648 : i64 loc(#loc33)
    %cst_28 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc33)
    %72 = arith.cmpi sle, %71, %cst_28 : tensor<32xi64> loc(#loc33)
    %cst_29 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc33)
    %73 = arith.cmpi sge, %71, %cst_29 : tensor<32xi64> loc(#loc33)
    %74 = arith.andi %72, %73 : tensor<32xi1> loc(#loc33)
    %75 = arith.addi %68, %67 : tensor<32xi32> loc(#loc33)
    %76 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc34)
    %77 = arith.remsi %75, %76 : tensor<32xi32> loc(#loc34)
    %78 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc35)
    %79 = tt.expand_dims %59 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc36)
    %80 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc37)
    %81 = arith.extsi %79 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc37)
    %82 = arith.extsi %80 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc37)
    %83 = arith.muli %81, %82 : tensor<32x1xi64> loc(#loc37)
    %c2147483647_i64_30 = arith.constant 2147483647 : i64 loc(#loc37)
    %c-2147483648_i64_31 = arith.constant -2147483648 : i64 loc(#loc37)
    %cst_32 = arith.constant dense<2147483647> : tensor<32x1xi64> loc(#loc37)
    %84 = arith.cmpi sle, %83, %cst_32 : tensor<32x1xi64> loc(#loc37)
    %cst_33 = arith.constant dense<-2147483648> : tensor<32x1xi64> loc(#loc37)
    %85 = arith.cmpi sge, %83, %cst_33 : tensor<32x1xi64> loc(#loc37)
    %86 = arith.andi %84, %85 : tensor<32x1xi1> loc(#loc37)
    %87 = arith.muli %79, %80 : tensor<32x1xi32> loc(#loc37)
    %88 = tt.expand_dims %78 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc38)
    %c1_i32 = arith.constant 1 : i32 loc(#loc39)
    %c1_i32_34 = arith.constant 1 : i32 loc(#loc39)
    %cst_35 = arith.constant dense<1> : tensor<1x16xi32> loc(#loc39)
    %89 = arith.extsi %88 : tensor<1x16xi32> to tensor<1x16xi64> loc(#loc39)
    %90 = arith.extsi %cst_35 : tensor<1x16xi32> to tensor<1x16xi64> loc(#loc39)
    %91 = arith.muli %89, %90 : tensor<1x16xi64> loc(#loc39)
    %c2147483647_i64_36 = arith.constant 2147483647 : i64 loc(#loc39)
    %c-2147483648_i64_37 = arith.constant -2147483648 : i64 loc(#loc39)
    %cst_38 = arith.constant dense<2147483647> : tensor<1x16xi64> loc(#loc39)
    %92 = arith.cmpi sle, %91, %cst_38 : tensor<1x16xi64> loc(#loc39)
    %cst_39 = arith.constant dense<-2147483648> : tensor<1x16xi64> loc(#loc39)
    %93 = arith.cmpi sge, %91, %cst_39 : tensor<1x16xi64> loc(#loc39)
    %94 = arith.andi %92, %93 : tensor<1x16xi1> loc(#loc39)
    %95 = arith.muli %88, %cst_35 : tensor<1x16xi32> loc(#loc39)
    %96 = tt.broadcast %87 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc40)
    %97 = tt.broadcast %95 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc40)
    %98 = arith.extsi %96 : tensor<32x16xi32> to tensor<32x16xi64> loc(#loc40)
    %99 = arith.extsi %97 : tensor<32x16xi32> to tensor<32x16xi64> loc(#loc40)
    %100 = arith.addi %98, %99 : tensor<32x16xi64> loc(#loc40)
    %c2147483647_i64_40 = arith.constant 2147483647 : i64 loc(#loc40)
    %c-2147483648_i64_41 = arith.constant -2147483648 : i64 loc(#loc40)
    %cst_42 = arith.constant dense<2147483647> : tensor<32x16xi64> loc(#loc40)
    %101 = arith.cmpi sle, %100, %cst_42 : tensor<32x16xi64> loc(#loc40)
    %cst_43 = arith.constant dense<-2147483648> : tensor<32x16xi64> loc(#loc40)
    %102 = arith.cmpi sge, %100, %cst_43 : tensor<32x16xi64> loc(#loc40)
    %103 = arith.andi %101, %102 : tensor<32x16xi1> loc(#loc40)
    %104 = arith.addi %96, %97 : tensor<32x16xi32> loc(#loc40)
    %105 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc41)
    %106 = tt.addptr %105, %104 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc41)
    %107 = tt.expand_dims %78 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc42)
    %108 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc43)
    %109 = arith.extsi %107 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc43)
    %110 = arith.extsi %108 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc43)
    %111 = arith.muli %109, %110 : tensor<16x1xi64> loc(#loc43)
    %c2147483647_i64_44 = arith.constant 2147483647 : i64 loc(#loc43)
    %c-2147483648_i64_45 = arith.constant -2147483648 : i64 loc(#loc43)
    %cst_46 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc43)
    %112 = arith.cmpi sle, %111, %cst_46 : tensor<16x1xi64> loc(#loc43)
    %cst_47 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc43)
    %113 = arith.cmpi sge, %111, %cst_47 : tensor<16x1xi64> loc(#loc43)
    %114 = arith.andi %112, %113 : tensor<16x1xi1> loc(#loc43)
    %115 = arith.muli %107, %108 : tensor<16x1xi32> loc(#loc43)
    %116 = tt.expand_dims %77 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc44)
    %c1_i32_48 = arith.constant 1 : i32 loc(#loc45)
    %c1_i32_49 = arith.constant 1 : i32 loc(#loc45)
    %cst_50 = arith.constant dense<1> : tensor<1x32xi32> loc(#loc45)
    %117 = arith.extsi %116 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc45)
    %118 = arith.extsi %cst_50 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc45)
    %119 = arith.muli %117, %118 : tensor<1x32xi64> loc(#loc45)
    %c2147483647_i64_51 = arith.constant 2147483647 : i64 loc(#loc45)
    %c-2147483648_i64_52 = arith.constant -2147483648 : i64 loc(#loc45)
    %cst_53 = arith.constant dense<2147483647> : tensor<1x32xi64> loc(#loc45)
    %120 = arith.cmpi sle, %119, %cst_53 : tensor<1x32xi64> loc(#loc45)
    %cst_54 = arith.constant dense<-2147483648> : tensor<1x32xi64> loc(#loc45)
    %121 = arith.cmpi sge, %119, %cst_54 : tensor<1x32xi64> loc(#loc45)
    %122 = arith.andi %120, %121 : tensor<1x32xi1> loc(#loc45)
    %123 = arith.muli %116, %cst_50 : tensor<1x32xi32> loc(#loc45)
    %124 = tt.broadcast %115 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc46)
    %125 = tt.broadcast %123 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc46)
    %126 = arith.extsi %124 : tensor<16x32xi32> to tensor<16x32xi64> loc(#loc46)
    %127 = arith.extsi %125 : tensor<16x32xi32> to tensor<16x32xi64> loc(#loc46)
    %128 = arith.addi %126, %127 : tensor<16x32xi64> loc(#loc46)
    %c2147483647_i64_55 = arith.constant 2147483647 : i64 loc(#loc46)
    %c-2147483648_i64_56 = arith.constant -2147483648 : i64 loc(#loc46)
    %cst_57 = arith.constant dense<2147483647> : tensor<16x32xi64> loc(#loc46)
    %129 = arith.cmpi sle, %128, %cst_57 : tensor<16x32xi64> loc(#loc46)
    %cst_58 = arith.constant dense<-2147483648> : tensor<16x32xi64> loc(#loc46)
    %130 = arith.cmpi sge, %128, %cst_58 : tensor<16x32xi64> loc(#loc46)
    %131 = arith.andi %129, %130 : tensor<16x32xi1> loc(#loc46)
    %132 = arith.addi %124, %125 : tensor<16x32xi32> loc(#loc46)
    %133 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc47)
    %134 = tt.addptr %133, %132 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc47)
    %135 = tt.call @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() : () -> tensor<32x32xf32> loc(#loc48)
    %136 = tt.call @"cdiv__i32__(1,)cconstexpr_16_"(%arg5) : (i32) -> i32 loc(#loc49)
    %c0_i32_59 = arith.constant 0 : i32 loc(#loc50)
    %c1_i32_60 = arith.constant 1 : i32 loc(#loc50)
    %137 = arith.bitcast %c0_i32_59 : i32 to i32 loc(#loc50)
    %138 = arith.bitcast %136 : i32 to i32 loc(#loc50)
    %139 = arith.bitcast %c1_i32_60 : i32 to i32 loc(#loc50)
    %140 = ub.poison : i32 loc(#loc50)
    %141:3 = scf.for %arg9 = %137 to %138 step %139 iter_args(%arg10 = %135, %arg11 = %106, %arg12 = %134) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %206 = tt.expand_dims %78 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc51)
      %c16_i32 = arith.constant 16 : i32 loc(#loc52)
      %c16_i32_88 = arith.constant 16 : i32 loc(#loc52)
      %207 = arith.extsi %arg9 : i32 to i64 loc(#loc52)
      %208 = arith.extsi %c16_i32_88 : i32 to i64 loc(#loc52)
      %209 = arith.muli %207, %208 : i64 loc(#loc52)
      %c2147483647_i64_89 = arith.constant 2147483647 : i64 loc(#loc52)
      %c-2147483648_i64_90 = arith.constant -2147483648 : i64 loc(#loc52)
      %210 = arith.cmpi sle, %209, %c2147483647_i64_89 : i64 loc(#loc52)
      %211 = arith.cmpi sge, %209, %c-2147483648_i64_90 : i64 loc(#loc52)
      %212 = arith.andi %210, %211 : i1 loc(#loc52)
      %213 = arith.muli %arg9, %c16_i32_88 : i32 loc(#loc52)
      %214 = arith.extsi %arg5 : i32 to i64 loc(#loc53)
      %215 = arith.extsi %213 : i32 to i64 loc(#loc53)
      %216 = arith.subi %214, %215 : i64 loc(#loc53)
      %c2147483647_i64_91 = arith.constant 2147483647 : i64 loc(#loc53)
      %c-2147483648_i64_92 = arith.constant -2147483648 : i64 loc(#loc53)
      %217 = arith.cmpi sle, %216, %c2147483647_i64_91 : i64 loc(#loc53)
      %218 = arith.cmpi sge, %216, %c-2147483648_i64_92 : i64 loc(#loc53)
      %219 = arith.andi %217, %218 : i1 loc(#loc53)
      %220 = arith.subi %arg5, %213 : i32 loc(#loc53)
      %221 = tt.splat %220 : i32 -> tensor<1x16xi32> loc(#loc54)
      %222 = arith.cmpi slt, %206, %221 : tensor<1x16xi32> loc(#loc54)
      %cst_93 = arith.constant 0.000000e+00 : f32 loc(#loc55)
      %223 = tt.broadcast %222 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc55)
      %cst_94 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc55)
      %224 = tt.load %arg11, %223, %cst_94 : tensor<32x16x!tt.ptr<f32>> loc(#loc55)
      %225 = tt.expand_dims %78 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc56)
      %c16_i32_95 = arith.constant 16 : i32 loc(#loc57)
      %c16_i32_96 = arith.constant 16 : i32 loc(#loc57)
      %226 = arith.extsi %arg9 : i32 to i64 loc(#loc57)
      %227 = arith.extsi %c16_i32_96 : i32 to i64 loc(#loc57)
      %228 = arith.muli %226, %227 : i64 loc(#loc57)
      %c2147483647_i64_97 = arith.constant 2147483647 : i64 loc(#loc57)
      %c-2147483648_i64_98 = arith.constant -2147483648 : i64 loc(#loc57)
      %229 = arith.cmpi sle, %228, %c2147483647_i64_97 : i64 loc(#loc57)
      %230 = arith.cmpi sge, %228, %c-2147483648_i64_98 : i64 loc(#loc57)
      %231 = arith.andi %229, %230 : i1 loc(#loc57)
      %232 = arith.muli %arg9, %c16_i32_96 : i32 loc(#loc57)
      %233 = arith.extsi %arg5 : i32 to i64 loc(#loc58)
      %234 = arith.extsi %232 : i32 to i64 loc(#loc58)
      %235 = arith.subi %233, %234 : i64 loc(#loc58)
      %c2147483647_i64_99 = arith.constant 2147483647 : i64 loc(#loc58)
      %c-2147483648_i64_100 = arith.constant -2147483648 : i64 loc(#loc58)
      %236 = arith.cmpi sle, %235, %c2147483647_i64_99 : i64 loc(#loc58)
      %237 = arith.cmpi sge, %235, %c-2147483648_i64_100 : i64 loc(#loc58)
      %238 = arith.andi %236, %237 : i1 loc(#loc58)
      %239 = arith.subi %arg5, %232 : i32 loc(#loc58)
      %240 = tt.splat %239 : i32 -> tensor<16x1xi32> loc(#loc59)
      %241 = arith.cmpi slt, %225, %240 : tensor<16x1xi32> loc(#loc59)
      %cst_101 = arith.constant 0.000000e+00 : f32 loc(#loc60)
      %242 = tt.broadcast %241 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc60)
      %cst_102 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc60)
      %243 = tt.load %arg12, %242, %cst_102 : tensor<16x32x!tt.ptr<f32>> loc(#loc60)
      %cst_103 = arith.constant 0.000000e+00 : f32 loc(#loc61)
      %244 = tt.dot %224, %243, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc61)
      %c16_i32_104 = arith.constant 16 : i32 loc(#loc62)
      %cst_105 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc62)
      %245 = tt.addptr %arg11, %cst_105 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc62)
      %c16_i32_106 = arith.constant 16 : i32 loc(#loc63)
      %c16_i32_107 = arith.constant 16 : i32 loc(#loc63)
      %246 = arith.extsi %c16_i32_107 : i32 to i64 loc(#loc63)
      %247 = arith.extsi %arg7 : i32 to i64 loc(#loc63)
      %248 = arith.muli %246, %247 : i64 loc(#loc63)
      %c2147483647_i64_108 = arith.constant 2147483647 : i64 loc(#loc63)
      %c-2147483648_i64_109 = arith.constant -2147483648 : i64 loc(#loc63)
      %249 = arith.cmpi sle, %248, %c2147483647_i64_108 : i64 loc(#loc63)
      %250 = arith.cmpi sge, %248, %c-2147483648_i64_109 : i64 loc(#loc63)
      %251 = arith.andi %249, %250 : i1 loc(#loc63)
      %252 = arith.muli %c16_i32_107, %arg7 : i32 loc(#loc63)
      %253 = tt.splat %252 : i32 -> tensor<16x32xi32> loc(#loc64)
      %254 = tt.addptr %arg12, %253 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc64)
      scf.yield %244, %245, %254 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc65)
    } loc(#loc50)
    %142 = arith.truncf %141#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc66)
    %c32_i32_61 = arith.constant 32 : i32 loc(#loc67)
    %c32_i32_62 = arith.constant 32 : i32 loc(#loc67)
    %143 = arith.extsi %34 : i32 to i64 loc(#loc67)
    %144 = arith.extsi %c32_i32_62 : i32 to i64 loc(#loc67)
    %145 = arith.muli %143, %144 : i64 loc(#loc67)
    %c2147483647_i64_63 = arith.constant 2147483647 : i64 loc(#loc67)
    %c-2147483648_i64_64 = arith.constant -2147483648 : i64 loc(#loc67)
    %146 = arith.cmpi sle, %145, %c2147483647_i64_63 : i64 loc(#loc67)
    %147 = arith.cmpi sge, %145, %c-2147483648_i64_64 : i64 loc(#loc67)
    %148 = arith.andi %146, %147 : i1 loc(#loc67)
    %149 = arith.muli %34, %c32_i32_62 : i32 loc(#loc67)
    %150 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc68)
    %151 = tt.splat %149 : i32 -> tensor<32xi32> loc(#loc69)
    %152 = arith.extsi %151 : tensor<32xi32> to tensor<32xi64> loc(#loc69)
    %153 = arith.extsi %150 : tensor<32xi32> to tensor<32xi64> loc(#loc69)
    %154 = arith.addi %152, %153 : tensor<32xi64> loc(#loc69)
    %c2147483647_i64_65 = arith.constant 2147483647 : i64 loc(#loc69)
    %c-2147483648_i64_66 = arith.constant -2147483648 : i64 loc(#loc69)
    %cst_67 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc69)
    %155 = arith.cmpi sle, %154, %cst_67 : tensor<32xi64> loc(#loc69)
    %cst_68 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc69)
    %156 = arith.cmpi sge, %154, %cst_68 : tensor<32xi64> loc(#loc69)
    %157 = arith.andi %155, %156 : tensor<32xi1> loc(#loc69)
    %158 = arith.addi %151, %150 : tensor<32xi32> loc(#loc69)
    %c32_i32_69 = arith.constant 32 : i32 loc(#loc70)
    %c32_i32_70 = arith.constant 32 : i32 loc(#loc70)
    %159 = arith.extsi %36 : i32 to i64 loc(#loc70)
    %160 = arith.extsi %c32_i32_70 : i32 to i64 loc(#loc70)
    %161 = arith.muli %159, %160 : i64 loc(#loc70)
    %c2147483647_i64_71 = arith.constant 2147483647 : i64 loc(#loc70)
    %c-2147483648_i64_72 = arith.constant -2147483648 : i64 loc(#loc70)
    %162 = arith.cmpi sle, %161, %c2147483647_i64_71 : i64 loc(#loc70)
    %163 = arith.cmpi sge, %161, %c-2147483648_i64_72 : i64 loc(#loc70)
    %164 = arith.andi %162, %163 : i1 loc(#loc70)
    %165 = arith.muli %36, %c32_i32_70 : i32 loc(#loc70)
    %166 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc71)
    %167 = tt.splat %165 : i32 -> tensor<32xi32> loc(#loc72)
    %168 = arith.extsi %167 : tensor<32xi32> to tensor<32xi64> loc(#loc72)
    %169 = arith.extsi %166 : tensor<32xi32> to tensor<32xi64> loc(#loc72)
    %170 = arith.addi %168, %169 : tensor<32xi64> loc(#loc72)
    %c2147483647_i64_73 = arith.constant 2147483647 : i64 loc(#loc72)
    %c-2147483648_i64_74 = arith.constant -2147483648 : i64 loc(#loc72)
    %cst_75 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc72)
    %171 = arith.cmpi sle, %170, %cst_75 : tensor<32xi64> loc(#loc72)
    %cst_76 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc72)
    %172 = arith.cmpi sge, %170, %cst_76 : tensor<32xi64> loc(#loc72)
    %173 = arith.andi %171, %172 : tensor<32xi1> loc(#loc72)
    %174 = arith.addi %167, %166 : tensor<32xi32> loc(#loc72)
    %175 = tt.expand_dims %158 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc73)
    %176 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc74)
    %177 = arith.extsi %176 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc74)
    %178 = arith.extsi %175 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc74)
    %179 = arith.muli %177, %178 : tensor<32x1xi64> loc(#loc74)
    %c2147483647_i64_77 = arith.constant 2147483647 : i64 loc(#loc74)
    %c-2147483648_i64_78 = arith.constant -2147483648 : i64 loc(#loc74)
    %cst_79 = arith.constant dense<2147483647> : tensor<32x1xi64> loc(#loc74)
    %180 = arith.cmpi sle, %179, %cst_79 : tensor<32x1xi64> loc(#loc74)
    %cst_80 = arith.constant dense<-2147483648> : tensor<32x1xi64> loc(#loc74)
    %181 = arith.cmpi sge, %179, %cst_80 : tensor<32x1xi64> loc(#loc74)
    %182 = arith.andi %180, %181 : tensor<32x1xi1> loc(#loc74)
    %183 = arith.muli %176, %175 : tensor<32x1xi32> loc(#loc74)
    %184 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc75)
    %185 = tt.addptr %184, %183 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc75)
    %186 = tt.expand_dims %174 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc76)
    %c1_i32_81 = arith.constant 1 : i32 loc(#loc77)
    %c1_i32_82 = arith.constant 1 : i32 loc(#loc77)
    %cst_83 = arith.constant dense<1> : tensor<1x32xi32> loc(#loc77)
    %187 = arith.extsi %cst_83 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc77)
    %188 = arith.extsi %186 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc77)
    %189 = arith.muli %187, %188 : tensor<1x32xi64> loc(#loc77)
    %c2147483647_i64_84 = arith.constant 2147483647 : i64 loc(#loc77)
    %c-2147483648_i64_85 = arith.constant -2147483648 : i64 loc(#loc77)
    %cst_86 = arith.constant dense<2147483647> : tensor<1x32xi64> loc(#loc77)
    %190 = arith.cmpi sle, %189, %cst_86 : tensor<1x32xi64> loc(#loc77)
    %cst_87 = arith.constant dense<-2147483648> : tensor<1x32xi64> loc(#loc77)
    %191 = arith.cmpi sge, %189, %cst_87 : tensor<1x32xi64> loc(#loc77)
    %192 = arith.andi %190, %191 : tensor<1x32xi1> loc(#loc77)
    %193 = arith.muli %cst_83, %186 : tensor<1x32xi32> loc(#loc77)
    %194 = tt.broadcast %185 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc78)
    %195 = tt.broadcast %193 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc78)
    %196 = tt.addptr %194, %195 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc78)
    %197 = tt.expand_dims %158 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc79)
    %198 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc80)
    %199 = arith.cmpi slt, %197, %198 : tensor<32x1xi32> loc(#loc80)
    %200 = tt.expand_dims %174 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc81)
    %201 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc82)
    %202 = arith.cmpi slt, %200, %201 : tensor<1x32xi32> loc(#loc82)
    %203 = tt.broadcast %199 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc83)
    %204 = tt.broadcast %202 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc83)
    %205 = arith.andi %203, %204 : tensor<32x32xi1> loc(#loc83)
    tt.store %196, %142, %205 : tensor<32x32x!tt.ptr<f16>> loc(#loc84)
    tt.return loc(#loc85)
  } loc(#loc)
  tt.func private @"cdiv__i32__(1,)cconstexpr_32_"(%arg0: i32 loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)) -> i32 attributes {noinline = false} {
    %c32_i32 = arith.constant 32 : i32 loc(#loc87)
    %c32_i32_0 = arith.constant 32 : i32 loc(#loc87)
    %0 = arith.extsi %arg0 : i32 to i64 loc(#loc87)
    %1 = arith.extsi %c32_i32_0 : i32 to i64 loc(#loc87)
    %2 = arith.addi %0, %1 : i64 loc(#loc87)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc87)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc87)
    %3 = arith.cmpi sle, %2, %c2147483647_i64 : i64 loc(#loc87)
    %4 = arith.cmpi sge, %2, %c-2147483648_i64 : i64 loc(#loc87)
    %5 = arith.andi %3, %4 : i1 loc(#loc87)
    %6 = arith.addi %arg0, %c32_i32_0 : i32 loc(#loc87)
    %c1_i32 = arith.constant 1 : i32 loc(#loc88)
    %c1_i32_1 = arith.constant 1 : i32 loc(#loc88)
    %7 = arith.extsi %6 : i32 to i64 loc(#loc88)
    %8 = arith.extsi %c1_i32_1 : i32 to i64 loc(#loc88)
    %9 = arith.subi %7, %8 : i64 loc(#loc88)
    %c2147483647_i64_2 = arith.constant 2147483647 : i64 loc(#loc88)
    %c-2147483648_i64_3 = arith.constant -2147483648 : i64 loc(#loc88)
    %10 = arith.cmpi sle, %9, %c2147483647_i64_2 : i64 loc(#loc88)
    %11 = arith.cmpi sge, %9, %c-2147483648_i64_3 : i64 loc(#loc88)
    %12 = arith.andi %10, %11 : i1 loc(#loc88)
    %13 = arith.subi %6, %c1_i32_1 : i32 loc(#loc88)
    %c32_i32_4 = arith.constant 32 : i32 loc(#loc89)
    %c32_i32_5 = arith.constant 32 : i32 loc(#loc89)
    %14 = arith.divsi %13, %c32_i32_5 : i32 loc(#loc89)
    tt.return %14 : i32 loc(#loc90)
  ^bb1:  // no predecessors
    %15 = ub.poison : i32 loc(#loc91)
    tt.return %15 : i32 loc(#loc91)
  } loc(#loc86)
  tt.func private @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() -> tensor<32x32xf32> attributes {noinline = false} {
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc93)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc93)
    tt.return %cst_0 : tensor<32x32xf32> loc(#loc94)
  ^bb1:  // no predecessors
    %0 = ub.poison : tensor<32x32xf32> loc(#loc95)
    tt.return %0 : tensor<32x32xf32> loc(#loc95)
  } loc(#loc92)
  tt.func private @"cdiv__i32__(1,)cconstexpr_16_"(%arg0: i32 loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)) -> i32 attributes {noinline = false} {
    %c16_i32 = arith.constant 16 : i32 loc(#loc87)
    %c16_i32_0 = arith.constant 16 : i32 loc(#loc87)
    %0 = arith.extsi %arg0 : i32 to i64 loc(#loc87)
    %1 = arith.extsi %c16_i32_0 : i32 to i64 loc(#loc87)
    %2 = arith.addi %0, %1 : i64 loc(#loc87)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc87)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc87)
    %3 = arith.cmpi sle, %2, %c2147483647_i64 : i64 loc(#loc87)
    %4 = arith.cmpi sge, %2, %c-2147483648_i64 : i64 loc(#loc87)
    %5 = arith.andi %3, %4 : i1 loc(#loc87)
    %6 = arith.addi %arg0, %c16_i32_0 : i32 loc(#loc87)
    %c1_i32 = arith.constant 1 : i32 loc(#loc88)
    %c1_i32_1 = arith.constant 1 : i32 loc(#loc88)
    %7 = arith.extsi %6 : i32 to i64 loc(#loc88)
    %8 = arith.extsi %c1_i32_1 : i32 to i64 loc(#loc88)
    %9 = arith.subi %7, %8 : i64 loc(#loc88)
    %c2147483647_i64_2 = arith.constant 2147483647 : i64 loc(#loc88)
    %c-2147483648_i64_3 = arith.constant -2147483648 : i64 loc(#loc88)
    %10 = arith.cmpi sle, %9, %c2147483647_i64_2 : i64 loc(#loc88)
    %11 = arith.cmpi sge, %9, %c-2147483648_i64_3 : i64 loc(#loc88)
    %12 = arith.andi %10, %11 : i1 loc(#loc88)
    %13 = arith.subi %6, %c1_i32_1 : i32 loc(#loc88)
    %c16_i32_4 = arith.constant 16 : i32 loc(#loc89)
    %c16_i32_5 = arith.constant 16 : i32 loc(#loc89)
    %14 = arith.divsi %13, %c16_i32_5 : i32 loc(#loc89)
    tt.return %14 : i32 loc(#loc90)
  ^bb1:  // no predecessors
    %15 = ub.poison : i32 loc(#loc91)
    tt.return %15 : i32 loc(#loc91)
  } loc(#loc86)
} loc(#loc)
#loc1 = loc("examples/kernels/binary_ops.py":126:24)
#loc2 = loc("examples/kernels/binary_ops.py":127:27)
#loc3 = loc("examples/kernels/binary_ops.py":128:27)
#loc4 = loc("examples/kernels/binary_ops.py":129:38)
#loc5 = loc("examples/kernels/binary_ops.py":130:22)
#loc6 = loc("examples/kernels/binary_ops.py":131:29)
#loc7 = loc("examples/kernels/binary_ops.py":132:35)
#loc8 = loc("examples/kernels/binary_ops.py":132:48)
#loc9 = loc("examples/kernels/binary_ops.py":133:34)
#loc10 = loc("examples/kernels/binary_ops.py":133:54)
#loc11 = loc("examples/kernels/binary_ops.py":133:27)
#loc12 = loc("examples/kernels/binary_ops.py":134:19)
#loc13 = loc("examples/kernels/binary_ops.py":134:40)
#loc14 = loc("examples/kernels/binary_ops.py":140:23)
#loc15 = loc("examples/kernels/binary_ops.py":140:14)
#loc16 = loc("examples/kernels/binary_ops.py":141:23)
#loc17 = loc("examples/kernels/binary_ops.py":141:14)
#loc18 = loc("examples/kernels/binary_ops.py":142:26)
#loc19 = loc("examples/kernels/binary_ops.py":142:14)
#loc20 = loc("examples/kernels/binary_ops.py":143:14)
#loc21 = loc("examples/kernels/binary_ops.py":144:14)
#loc22 = loc("examples/kernels/binary_ops.py":145:26)
#loc23 = loc("examples/kernels/binary_ops.py":145:14)
#loc24 = loc("examples/kernels/binary_ops.py":146:26)
#loc25 = loc("examples/kernels/binary_ops.py":146:14)
#loc26 = loc("examples/kernels/binary_ops.py":147:14)
#loc27 = loc("examples/kernels/binary_ops.py":156:23)
#loc28 = loc("examples/kernels/binary_ops.py":156:51)
#loc29 = loc("examples/kernels/binary_ops.py":156:38)
#loc30 = loc("examples/kernels/binary_ops.py":156:68)
#loc31 = loc("examples/kernels/binary_ops.py":157:23)
#loc32 = loc("examples/kernels/binary_ops.py":157:51)
#loc33 = loc("examples/kernels/binary_ops.py":157:38)
#loc34 = loc("examples/kernels/binary_ops.py":157:68)
#loc35 = loc("examples/kernels/binary_ops.py":158:26)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:71)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:71)
#loc46 = loc("examples/kernels/binary_ops.py":160:52)
#loc47 = loc("examples/kernels/binary_ops.py":160:22)
#loc48 = loc("examples/kernels/binary_ops.py":167:27)
#loc49 = loc("examples/kernels/binary_ops.py":168:33)
#loc50 = loc("examples/kernels/binary_ops.py":168:22)
#loc51 = loc("examples/kernels/binary_ops.py":171:40)
#loc52 = loc("examples/kernels/binary_ops.py":171:59)
#loc53 = loc("examples/kernels/binary_ops.py":171:55)
#loc54 = loc("examples/kernels/binary_ops.py":171:51)
#loc55 = loc("examples/kernels/binary_ops.py":171:20)
#loc56 = loc("examples/kernels/binary_ops.py":172:40)
#loc57 = loc("examples/kernels/binary_ops.py":172:59)
#loc58 = loc("examples/kernels/binary_ops.py":172:55)
#loc59 = loc("examples/kernels/binary_ops.py":172:51)
#loc60 = loc("examples/kernels/binary_ops.py":172:20)
#loc61 = loc("examples/kernels/binary_ops.py":174:35)
#loc62 = loc("examples/kernels/binary_ops.py":176:18)
#loc63 = loc("examples/kernels/binary_ops.py":177:33)
#loc64 = loc("examples/kernels/binary_ops.py":177:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:8)
#loc66 = loc("examples/kernels/binary_ops.py":182:23)
#loc67 = loc("examples/kernels/binary_ops.py":186:22)
#loc68 = loc("examples/kernels/binary_ops.py":186:50)
#loc69 = loc("examples/kernels/binary_ops.py":186:37)
#loc70 = loc("examples/kernels/binary_ops.py":187:22)
#loc71 = loc("examples/kernels/binary_ops.py":187:50)
#loc72 = loc("examples/kernels/binary_ops.py":187:37)
#loc73 = loc("examples/kernels/binary_ops.py":188:41)
#loc74 = loc("examples/kernels/binary_ops.py":188:33)
#loc75 = loc("examples/kernels/binary_ops.py":188:21)
#loc76 = loc("examples/kernels/binary_ops.py":188:72)
#loc77 = loc("examples/kernels/binary_ops.py":188:64)
#loc78 = loc("examples/kernels/binary_ops.py":188:52)
#loc79 = loc("examples/kernels/binary_ops.py":189:22)
#loc80 = loc("examples/kernels/binary_ops.py":189:33)
#loc81 = loc("examples/kernels/binary_ops.py":189:47)
#loc82 = loc("examples/kernels/binary_ops.py":189:58)
#loc83 = loc("examples/kernels/binary_ops.py":189:39)
#loc84 = loc("examples/kernels/binary_ops.py":190:21)
#loc85 = loc("examples/kernels/binary_ops.py":190:4)
#loc87 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:16)
#loc88 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc89 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc90 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:11)
#loc91 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:4)
#loc92 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":113:0)
#loc93 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:31)
#loc94 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:11)
#loc95 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:4)


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @cdiv__i32__(1,)cconstexpr_32_) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc86 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc1)
    %1 = tt.call @"cdiv__i32__(1,)cconstexpr_32_"(%arg3) : (i32) -> i32 loc(#loc2)
    %2 = tt.call @"cdiv__i32__(1,)cconstexpr_32_"(%arg4) : (i32) -> i32 loc(#loc3)
    %c4_i32 = arith.constant 4 : i32 loc(#loc4)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc4)
    %3 = arith.extsi %c4_i32_0 : i32 to i64 loc(#loc4)
    %4 = arith.extsi %2 : i32 to i64 loc(#loc4)
    %5 = arith.muli %3, %4 : i64 loc(#loc4)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc4)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc4)
    %6 = arith.cmpi sle, %5, %c2147483647_i64 : i64 loc(#loc4)
    %7 = arith.cmpi sge, %5, %c-2147483648_i64 : i64 loc(#loc4)
    %8 = arith.andi %6, %7 : i1 loc(#loc4)
    %9 = arith.muli %c4_i32_0, %2 : i32 loc(#loc4)
    %10 = arith.divsi %0, %9 : i32 loc(#loc5)
    %c4_i32_1 = arith.constant 4 : i32 loc(#loc6)
    %c4_i32_2 = arith.constant 4 : i32 loc(#loc6)
    %11 = arith.extsi %10 : i32 to i64 loc(#loc6)
    %12 = arith.extsi %c4_i32_2 : i32 to i64 loc(#loc6)
    %13 = arith.muli %11, %12 : i64 loc(#loc6)
    %c2147483647_i64_3 = arith.constant 2147483647 : i64 loc(#loc6)
    %c-2147483648_i64_4 = arith.constant -2147483648 : i64 loc(#loc6)
    %14 = arith.cmpi sle, %13, %c2147483647_i64_3 : i64 loc(#loc6)
    %15 = arith.cmpi sge, %13, %c-2147483648_i64_4 : i64 loc(#loc6)
    %16 = arith.andi %14, %15 : i1 loc(#loc6)
    %17 = arith.muli %10, %c4_i32_2 : i32 loc(#loc6)
    %18 = arith.extsi %1 : i32 to i64 loc(#loc7)
    %19 = arith.extsi %17 : i32 to i64 loc(#loc7)
    %20 = arith.subi %18, %19 : i64 loc(#loc7)
    %c2147483647_i64_5 = arith.constant 2147483647 : i64 loc(#loc7)
    %c-2147483648_i64_6 = arith.constant -2147483648 : i64 loc(#loc7)
    %21 = arith.cmpi sle, %20, %c2147483647_i64_5 : i64 loc(#loc7)
    %22 = arith.cmpi sge, %20, %c-2147483648_i64_6 : i64 loc(#loc7)
    %23 = arith.andi %21, %22 : i1 loc(#loc7)
    %24 = arith.subi %1, %17 : i32 loc(#loc7)
    %c4_i32_7 = arith.constant 4 : i32 loc(#loc8)
    %25 = arith.minsi %24, %c4_i32_7 : i32 loc(#loc8)
    %26 = arith.remsi %0, %9 : i32 loc(#loc9)
    %27 = arith.remsi %26, %25 : i32 loc(#loc10)
    %28 = arith.extsi %17 : i32 to i64 loc(#loc11)
    %29 = arith.extsi %27 : i32 to i64 loc(#loc11)
    %30 = arith.addi %28, %29 : i64 loc(#loc11)
    %c2147483647_i64_8 = arith.constant 2147483647 : i64 loc(#loc11)
    %c-2147483648_i64_9 = arith.constant -2147483648 : i64 loc(#loc11)
    %31 = arith.cmpi sle, %30, %c2147483647_i64_8 : i64 loc(#loc11)
    %32 = arith.cmpi sge, %30, %c-2147483648_i64_9 : i64 loc(#loc11)
    %33 = arith.andi %31, %32 : i1 loc(#loc11)
    %34 = arith.addi %17, %27 : i32 loc(#loc11)
    %35 = arith.remsi %0, %9 : i32 loc(#loc12)
    %36 = arith.divsi %35, %25 : i32 loc(#loc13)
    %c0_i32 = arith.constant 0 : i32 loc(#loc14)
    %37 = arith.cmpi sge, %34, %c0_i32 : i32 loc(#loc14)
    llvm.intr.assume %37 : i1 loc(#loc15)
    %c0_i32_10 = arith.constant 0 : i32 loc(#loc16)
    %38 = arith.cmpi sge, %36, %c0_i32_10 : i32 loc(#loc16)
    llvm.intr.assume %38 : i1 loc(#loc17)
    %c0_i32_11 = arith.constant 0 : i32 loc(#loc18)
    %39 = arith.cmpi sgt, %arg6, %c0_i32_11 : i32 loc(#loc18)
    llvm.intr.assume %39 : i1 loc(#loc19)
    %true = arith.constant true loc(#loc20)
    llvm.intr.assume %true : i1 loc(#loc20)
    %true_12 = arith.constant true loc(#loc21)
    llvm.intr.assume %true_12 : i1 loc(#loc21)
    %c0_i32_13 = arith.constant 0 : i32 loc(#loc22)
    %40 = arith.cmpi sgt, %arg7, %c0_i32_13 : i32 loc(#loc22)
    llvm.intr.assume %40 : i1 loc(#loc23)
    %c0_i32_14 = arith.constant 0 : i32 loc(#loc24)
    %41 = arith.cmpi sgt, %arg8, %c0_i32_14 : i32 loc(#loc24)
    llvm.intr.assume %41 : i1 loc(#loc25)
    %true_15 = arith.constant true loc(#loc26)
    llvm.intr.assume %true_15 : i1 loc(#loc26)
    %c32_i32 = arith.constant 32 : i32 loc(#loc27)
    %c32_i32_16 = arith.constant 32 : i32 loc(#loc27)
    %42 = arith.extsi %34 : i32 to i64 loc(#loc27)
    %43 = arith.extsi %c32_i32_16 : i32 to i64 loc(#loc27)
    %44 = arith.muli %42, %43 : i64 loc(#loc27)
    %c2147483647_i64_17 = arith.constant 2147483647 : i64 loc(#loc27)
    %c-2147483648_i64_18 = arith.constant -2147483648 : i64 loc(#loc27)
    %45 = arith.cmpi sle, %44, %c2147483647_i64_17 : i64 loc(#loc27)
    %46 = arith.cmpi sge, %44, %c-2147483648_i64_18 : i64 loc(#loc27)
    %47 = arith.andi %45, %46 : i1 loc(#loc27)
    %48 = arith.muli %34, %c32_i32_16 : i32 loc(#loc27)
    %49 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc28)
    %50 = tt.splat %48 : i32 -> tensor<32xi32> loc(#loc29)
    %51 = arith.extsi %50 : tensor<32xi32> to tensor<32xi64> loc(#loc29)
    %52 = arith.extsi %49 : tensor<32xi32> to tensor<32xi64> loc(#loc29)
    %53 = arith.addi %51, %52 : tensor<32xi64> loc(#loc29)
    %c2147483647_i64_19 = arith.constant 2147483647 : i64 loc(#loc29)
    %c-2147483648_i64_20 = arith.constant -2147483648 : i64 loc(#loc29)
    %cst = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc29)
    %54 = arith.cmpi sle, %53, %cst : tensor<32xi64> loc(#loc29)
    %cst_21 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc29)
    %55 = arith.cmpi sge, %53, %cst_21 : tensor<32xi64> loc(#loc29)
    %56 = arith.andi %54, %55 : tensor<32xi1> loc(#loc29)
    %57 = arith.addi %50, %49 : tensor<32xi32> loc(#loc29)
    %58 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc30)
    %59 = arith.remsi %57, %58 : tensor<32xi32> loc(#loc30)
    %c32_i32_22 = arith.constant 32 : i32 loc(#loc31)
    %c32_i32_23 = arith.constant 32 : i32 loc(#loc31)
    %60 = arith.extsi %36 : i32 to i64 loc(#loc31)
    %61 = arith.extsi %c32_i32_23 : i32 to i64 loc(#loc31)
    %62 = arith.muli %60, %61 : i64 loc(#loc31)
    %c2147483647_i64_24 = arith.constant 2147483647 : i64 loc(#loc31)
    %c-2147483648_i64_25 = arith.constant -2147483648 : i64 loc(#loc31)
    %63 = arith.cmpi sle, %62, %c2147483647_i64_24 : i64 loc(#loc31)
    %64 = arith.cmpi sge, %62, %c-2147483648_i64_25 : i64 loc(#loc31)
    %65 = arith.andi %63, %64 : i1 loc(#loc31)
    %66 = arith.muli %36, %c32_i32_23 : i32 loc(#loc31)
    %67 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc32)
    %68 = tt.splat %66 : i32 -> tensor<32xi32> loc(#loc33)
    %69 = arith.extsi %68 : tensor<32xi32> to tensor<32xi64> loc(#loc33)
    %70 = arith.extsi %67 : tensor<32xi32> to tensor<32xi64> loc(#loc33)
    %71 = arith.addi %69, %70 : tensor<32xi64> loc(#loc33)
    %c2147483647_i64_26 = arith.constant 2147483647 : i64 loc(#loc33)
    %c-2147483648_i64_27 = arith.constant -2147483648 : i64 loc(#loc33)
    %cst_28 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc33)
    %72 = arith.cmpi sle, %71, %cst_28 : tensor<32xi64> loc(#loc33)
    %cst_29 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc33)
    %73 = arith.cmpi sge, %71, %cst_29 : tensor<32xi64> loc(#loc33)
    %74 = arith.andi %72, %73 : tensor<32xi1> loc(#loc33)
    %75 = arith.addi %68, %67 : tensor<32xi32> loc(#loc33)
    %76 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc34)
    %77 = arith.remsi %75, %76 : tensor<32xi32> loc(#loc34)
    %78 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc35)
    %79 = tt.expand_dims %59 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc36)
    %80 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc37)
    %81 = arith.extsi %79 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc37)
    %82 = arith.extsi %80 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc37)
    %83 = arith.muli %81, %82 : tensor<32x1xi64> loc(#loc37)
    %c2147483647_i64_30 = arith.constant 2147483647 : i64 loc(#loc37)
    %c-2147483648_i64_31 = arith.constant -2147483648 : i64 loc(#loc37)
    %cst_32 = arith.constant dense<2147483647> : tensor<32x1xi64> loc(#loc37)
    %84 = arith.cmpi sle, %83, %cst_32 : tensor<32x1xi64> loc(#loc37)
    %cst_33 = arith.constant dense<-2147483648> : tensor<32x1xi64> loc(#loc37)
    %85 = arith.cmpi sge, %83, %cst_33 : tensor<32x1xi64> loc(#loc37)
    %86 = arith.andi %84, %85 : tensor<32x1xi1> loc(#loc37)
    %87 = arith.muli %79, %80 : tensor<32x1xi32> loc(#loc37)
    %88 = tt.expand_dims %78 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc38)
    %c1_i32 = arith.constant 1 : i32 loc(#loc39)
    %c1_i32_34 = arith.constant 1 : i32 loc(#loc39)
    %cst_35 = arith.constant dense<1> : tensor<1x16xi32> loc(#loc39)
    %89 = arith.extsi %88 : tensor<1x16xi32> to tensor<1x16xi64> loc(#loc39)
    %90 = arith.extsi %cst_35 : tensor<1x16xi32> to tensor<1x16xi64> loc(#loc39)
    %91 = arith.muli %89, %90 : tensor<1x16xi64> loc(#loc39)
    %c2147483647_i64_36 = arith.constant 2147483647 : i64 loc(#loc39)
    %c-2147483648_i64_37 = arith.constant -2147483648 : i64 loc(#loc39)
    %cst_38 = arith.constant dense<2147483647> : tensor<1x16xi64> loc(#loc39)
    %92 = arith.cmpi sle, %91, %cst_38 : tensor<1x16xi64> loc(#loc39)
    %cst_39 = arith.constant dense<-2147483648> : tensor<1x16xi64> loc(#loc39)
    %93 = arith.cmpi sge, %91, %cst_39 : tensor<1x16xi64> loc(#loc39)
    %94 = arith.andi %92, %93 : tensor<1x16xi1> loc(#loc39)
    %95 = arith.muli %88, %cst_35 : tensor<1x16xi32> loc(#loc39)
    %96 = tt.broadcast %87 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc40)
    %97 = tt.broadcast %95 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc40)
    %98 = arith.extsi %96 : tensor<32x16xi32> to tensor<32x16xi64> loc(#loc40)
    %99 = arith.extsi %97 : tensor<32x16xi32> to tensor<32x16xi64> loc(#loc40)
    %100 = arith.addi %98, %99 : tensor<32x16xi64> loc(#loc40)
    %c2147483647_i64_40 = arith.constant 2147483647 : i64 loc(#loc40)
    %c-2147483648_i64_41 = arith.constant -2147483648 : i64 loc(#loc40)
    %cst_42 = arith.constant dense<2147483647> : tensor<32x16xi64> loc(#loc40)
    %101 = arith.cmpi sle, %100, %cst_42 : tensor<32x16xi64> loc(#loc40)
    %cst_43 = arith.constant dense<-2147483648> : tensor<32x16xi64> loc(#loc40)
    %102 = arith.cmpi sge, %100, %cst_43 : tensor<32x16xi64> loc(#loc40)
    %103 = arith.andi %101, %102 : tensor<32x16xi1> loc(#loc40)
    %104 = arith.addi %96, %97 : tensor<32x16xi32> loc(#loc40)
    %105 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc41)
    %106 = tt.addptr %105, %104 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc41)
    %107 = tt.expand_dims %78 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc42)
    %108 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc43)
    %109 = arith.extsi %107 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc43)
    %110 = arith.extsi %108 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc43)
    %111 = arith.muli %109, %110 : tensor<16x1xi64> loc(#loc43)
    %c2147483647_i64_44 = arith.constant 2147483647 : i64 loc(#loc43)
    %c-2147483648_i64_45 = arith.constant -2147483648 : i64 loc(#loc43)
    %cst_46 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc43)
    %112 = arith.cmpi sle, %111, %cst_46 : tensor<16x1xi64> loc(#loc43)
    %cst_47 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc43)
    %113 = arith.cmpi sge, %111, %cst_47 : tensor<16x1xi64> loc(#loc43)
    %114 = arith.andi %112, %113 : tensor<16x1xi1> loc(#loc43)
    %115 = arith.muli %107, %108 : tensor<16x1xi32> loc(#loc43)
    %116 = tt.expand_dims %77 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc44)
    %c1_i32_48 = arith.constant 1 : i32 loc(#loc45)
    %c1_i32_49 = arith.constant 1 : i32 loc(#loc45)
    %cst_50 = arith.constant dense<1> : tensor<1x32xi32> loc(#loc45)
    %117 = arith.extsi %116 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc45)
    %118 = arith.extsi %cst_50 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc45)
    %119 = arith.muli %117, %118 : tensor<1x32xi64> loc(#loc45)
    %c2147483647_i64_51 = arith.constant 2147483647 : i64 loc(#loc45)
    %c-2147483648_i64_52 = arith.constant -2147483648 : i64 loc(#loc45)
    %cst_53 = arith.constant dense<2147483647> : tensor<1x32xi64> loc(#loc45)
    %120 = arith.cmpi sle, %119, %cst_53 : tensor<1x32xi64> loc(#loc45)
    %cst_54 = arith.constant dense<-2147483648> : tensor<1x32xi64> loc(#loc45)
    %121 = arith.cmpi sge, %119, %cst_54 : tensor<1x32xi64> loc(#loc45)
    %122 = arith.andi %120, %121 : tensor<1x32xi1> loc(#loc45)
    %123 = arith.muli %116, %cst_50 : tensor<1x32xi32> loc(#loc45)
    %124 = tt.broadcast %115 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc46)
    %125 = tt.broadcast %123 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc46)
    %126 = arith.extsi %124 : tensor<16x32xi32> to tensor<16x32xi64> loc(#loc46)
    %127 = arith.extsi %125 : tensor<16x32xi32> to tensor<16x32xi64> loc(#loc46)
    %128 = arith.addi %126, %127 : tensor<16x32xi64> loc(#loc46)
    %c2147483647_i64_55 = arith.constant 2147483647 : i64 loc(#loc46)
    %c-2147483648_i64_56 = arith.constant -2147483648 : i64 loc(#loc46)
    %cst_57 = arith.constant dense<2147483647> : tensor<16x32xi64> loc(#loc46)
    %129 = arith.cmpi sle, %128, %cst_57 : tensor<16x32xi64> loc(#loc46)
    %cst_58 = arith.constant dense<-2147483648> : tensor<16x32xi64> loc(#loc46)
    %130 = arith.cmpi sge, %128, %cst_58 : tensor<16x32xi64> loc(#loc46)
    %131 = arith.andi %129, %130 : tensor<16x32xi1> loc(#loc46)
    %132 = arith.addi %124, %125 : tensor<16x32xi32> loc(#loc46)
    %133 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc47)
    %134 = tt.addptr %133, %132 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc47)
    %135 = tt.call @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() : () -> tensor<32x32xf32> loc(#loc48)
    %136 = tt.call @"cdiv__i32__(1,)cconstexpr_16_"(%arg5) : (i32) -> i32 loc(#loc49)
    %c0_i32_59 = arith.constant 0 : i32 loc(#loc50)
    %c1_i32_60 = arith.constant 1 : i32 loc(#loc50)
    %137 = arith.bitcast %c0_i32_59 : i32 to i32 loc(#loc50)
    %138 = arith.bitcast %136 : i32 to i32 loc(#loc50)
    %139 = arith.bitcast %c1_i32_60 : i32 to i32 loc(#loc50)
    %140 = ub.poison : i32 loc(#loc50)
    %141:3 = scf.for %arg9 = %137 to %138 step %139 iter_args(%arg10 = %135, %arg11 = %106, %arg12 = %134) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %206 = tt.expand_dims %78 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc51)
      %c16_i32 = arith.constant 16 : i32 loc(#loc52)
      %c16_i32_88 = arith.constant 16 : i32 loc(#loc52)
      %207 = arith.extsi %arg9 : i32 to i64 loc(#loc52)
      %208 = arith.extsi %c16_i32_88 : i32 to i64 loc(#loc52)
      %209 = arith.muli %207, %208 : i64 loc(#loc52)
      %c2147483647_i64_89 = arith.constant 2147483647 : i64 loc(#loc52)
      %c-2147483648_i64_90 = arith.constant -2147483648 : i64 loc(#loc52)
      %210 = arith.cmpi sle, %209, %c2147483647_i64_89 : i64 loc(#loc52)
      %211 = arith.cmpi sge, %209, %c-2147483648_i64_90 : i64 loc(#loc52)
      %212 = arith.andi %210, %211 : i1 loc(#loc52)
      %213 = arith.muli %arg9, %c16_i32_88 : i32 loc(#loc52)
      %214 = arith.extsi %arg5 : i32 to i64 loc(#loc53)
      %215 = arith.extsi %213 : i32 to i64 loc(#loc53)
      %216 = arith.subi %214, %215 : i64 loc(#loc53)
      %c2147483647_i64_91 = arith.constant 2147483647 : i64 loc(#loc53)
      %c-2147483648_i64_92 = arith.constant -2147483648 : i64 loc(#loc53)
      %217 = arith.cmpi sle, %216, %c2147483647_i64_91 : i64 loc(#loc53)
      %218 = arith.cmpi sge, %216, %c-2147483648_i64_92 : i64 loc(#loc53)
      %219 = arith.andi %217, %218 : i1 loc(#loc53)
      %220 = arith.subi %arg5, %213 : i32 loc(#loc53)
      %221 = tt.splat %220 : i32 -> tensor<1x16xi32> loc(#loc54)
      %222 = arith.cmpi slt, %206, %221 : tensor<1x16xi32> loc(#loc54)
      %cst_93 = arith.constant 0.000000e+00 : f32 loc(#loc55)
      %223 = tt.broadcast %222 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc55)
      %cst_94 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc55)
      %224 = tt.load %arg11, %223, %cst_94 : tensor<32x16x!tt.ptr<f32>> loc(#loc55)
      %225 = tt.expand_dims %78 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc56)
      %c16_i32_95 = arith.constant 16 : i32 loc(#loc57)
      %c16_i32_96 = arith.constant 16 : i32 loc(#loc57)
      %226 = arith.extsi %arg9 : i32 to i64 loc(#loc57)
      %227 = arith.extsi %c16_i32_96 : i32 to i64 loc(#loc57)
      %228 = arith.muli %226, %227 : i64 loc(#loc57)
      %c2147483647_i64_97 = arith.constant 2147483647 : i64 loc(#loc57)
      %c-2147483648_i64_98 = arith.constant -2147483648 : i64 loc(#loc57)
      %229 = arith.cmpi sle, %228, %c2147483647_i64_97 : i64 loc(#loc57)
      %230 = arith.cmpi sge, %228, %c-2147483648_i64_98 : i64 loc(#loc57)
      %231 = arith.andi %229, %230 : i1 loc(#loc57)
      %232 = arith.muli %arg9, %c16_i32_96 : i32 loc(#loc57)
      %233 = arith.extsi %arg5 : i32 to i64 loc(#loc58)
      %234 = arith.extsi %232 : i32 to i64 loc(#loc58)
      %235 = arith.subi %233, %234 : i64 loc(#loc58)
      %c2147483647_i64_99 = arith.constant 2147483647 : i64 loc(#loc58)
      %c-2147483648_i64_100 = arith.constant -2147483648 : i64 loc(#loc58)
      %236 = arith.cmpi sle, %235, %c2147483647_i64_99 : i64 loc(#loc58)
      %237 = arith.cmpi sge, %235, %c-2147483648_i64_100 : i64 loc(#loc58)
      %238 = arith.andi %236, %237 : i1 loc(#loc58)
      %239 = arith.subi %arg5, %232 : i32 loc(#loc58)
      %240 = tt.splat %239 : i32 -> tensor<16x1xi32> loc(#loc59)
      %241 = arith.cmpi slt, %225, %240 : tensor<16x1xi32> loc(#loc59)
      %cst_101 = arith.constant 0.000000e+00 : f32 loc(#loc60)
      %242 = tt.broadcast %241 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc60)
      %cst_102 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc60)
      %243 = tt.load %arg12, %242, %cst_102 : tensor<16x32x!tt.ptr<f32>> loc(#loc60)
      %cst_103 = arith.constant 0.000000e+00 : f32 loc(#loc61)
      %244 = tt.dot %224, %243, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc61)
      %c16_i32_104 = arith.constant 16 : i32 loc(#loc62)
      %cst_105 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc62)
      %245 = tt.addptr %arg11, %cst_105 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc62)
      %c16_i32_106 = arith.constant 16 : i32 loc(#loc63)
      %c16_i32_107 = arith.constant 16 : i32 loc(#loc63)
      %246 = arith.extsi %c16_i32_107 : i32 to i64 loc(#loc63)
      %247 = arith.extsi %arg7 : i32 to i64 loc(#loc63)
      %248 = arith.muli %246, %247 : i64 loc(#loc63)
      %c2147483647_i64_108 = arith.constant 2147483647 : i64 loc(#loc63)
      %c-2147483648_i64_109 = arith.constant -2147483648 : i64 loc(#loc63)
      %249 = arith.cmpi sle, %248, %c2147483647_i64_108 : i64 loc(#loc63)
      %250 = arith.cmpi sge, %248, %c-2147483648_i64_109 : i64 loc(#loc63)
      %251 = arith.andi %249, %250 : i1 loc(#loc63)
      %252 = arith.muli %c16_i32_107, %arg7 : i32 loc(#loc63)
      %253 = tt.splat %252 : i32 -> tensor<16x32xi32> loc(#loc64)
      %254 = tt.addptr %arg12, %253 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc64)
      scf.yield %244, %245, %254 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc65)
    } loc(#loc50)
    %142 = arith.truncf %141#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc66)
    %c32_i32_61 = arith.constant 32 : i32 loc(#loc67)
    %c32_i32_62 = arith.constant 32 : i32 loc(#loc67)
    %143 = arith.extsi %34 : i32 to i64 loc(#loc67)
    %144 = arith.extsi %c32_i32_62 : i32 to i64 loc(#loc67)
    %145 = arith.muli %143, %144 : i64 loc(#loc67)
    %c2147483647_i64_63 = arith.constant 2147483647 : i64 loc(#loc67)
    %c-2147483648_i64_64 = arith.constant -2147483648 : i64 loc(#loc67)
    %146 = arith.cmpi sle, %145, %c2147483647_i64_63 : i64 loc(#loc67)
    %147 = arith.cmpi sge, %145, %c-2147483648_i64_64 : i64 loc(#loc67)
    %148 = arith.andi %146, %147 : i1 loc(#loc67)
    %149 = arith.muli %34, %c32_i32_62 : i32 loc(#loc67)
    %150 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc68)
    %151 = tt.splat %149 : i32 -> tensor<32xi32> loc(#loc69)
    %152 = arith.extsi %151 : tensor<32xi32> to tensor<32xi64> loc(#loc69)
    %153 = arith.extsi %150 : tensor<32xi32> to tensor<32xi64> loc(#loc69)
    %154 = arith.addi %152, %153 : tensor<32xi64> loc(#loc69)
    %c2147483647_i64_65 = arith.constant 2147483647 : i64 loc(#loc69)
    %c-2147483648_i64_66 = arith.constant -2147483648 : i64 loc(#loc69)
    %cst_67 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc69)
    %155 = arith.cmpi sle, %154, %cst_67 : tensor<32xi64> loc(#loc69)
    %cst_68 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc69)
    %156 = arith.cmpi sge, %154, %cst_68 : tensor<32xi64> loc(#loc69)
    %157 = arith.andi %155, %156 : tensor<32xi1> loc(#loc69)
    %158 = arith.addi %151, %150 : tensor<32xi32> loc(#loc69)
    %c32_i32_69 = arith.constant 32 : i32 loc(#loc70)
    %c32_i32_70 = arith.constant 32 : i32 loc(#loc70)
    %159 = arith.extsi %36 : i32 to i64 loc(#loc70)
    %160 = arith.extsi %c32_i32_70 : i32 to i64 loc(#loc70)
    %161 = arith.muli %159, %160 : i64 loc(#loc70)
    %c2147483647_i64_71 = arith.constant 2147483647 : i64 loc(#loc70)
    %c-2147483648_i64_72 = arith.constant -2147483648 : i64 loc(#loc70)
    %162 = arith.cmpi sle, %161, %c2147483647_i64_71 : i64 loc(#loc70)
    %163 = arith.cmpi sge, %161, %c-2147483648_i64_72 : i64 loc(#loc70)
    %164 = arith.andi %162, %163 : i1 loc(#loc70)
    %165 = arith.muli %36, %c32_i32_70 : i32 loc(#loc70)
    %166 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc71)
    %167 = tt.splat %165 : i32 -> tensor<32xi32> loc(#loc72)
    %168 = arith.extsi %167 : tensor<32xi32> to tensor<32xi64> loc(#loc72)
    %169 = arith.extsi %166 : tensor<32xi32> to tensor<32xi64> loc(#loc72)
    %170 = arith.addi %168, %169 : tensor<32xi64> loc(#loc72)
    %c2147483647_i64_73 = arith.constant 2147483647 : i64 loc(#loc72)
    %c-2147483648_i64_74 = arith.constant -2147483648 : i64 loc(#loc72)
    %cst_75 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc72)
    %171 = arith.cmpi sle, %170, %cst_75 : tensor<32xi64> loc(#loc72)
    %cst_76 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc72)
    %172 = arith.cmpi sge, %170, %cst_76 : tensor<32xi64> loc(#loc72)
    %173 = arith.andi %171, %172 : tensor<32xi1> loc(#loc72)
    %174 = arith.addi %167, %166 : tensor<32xi32> loc(#loc72)
    %175 = tt.expand_dims %158 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc73)
    %176 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc74)
    %177 = arith.extsi %176 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc74)
    %178 = arith.extsi %175 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc74)
    %179 = arith.muli %177, %178 : tensor<32x1xi64> loc(#loc74)
    %c2147483647_i64_77 = arith.constant 2147483647 : i64 loc(#loc74)
    %c-2147483648_i64_78 = arith.constant -2147483648 : i64 loc(#loc74)
    %cst_79 = arith.constant dense<2147483647> : tensor<32x1xi64> loc(#loc74)
    %180 = arith.cmpi sle, %179, %cst_79 : tensor<32x1xi64> loc(#loc74)
    %cst_80 = arith.constant dense<-2147483648> : tensor<32x1xi64> loc(#loc74)
    %181 = arith.cmpi sge, %179, %cst_80 : tensor<32x1xi64> loc(#loc74)
    %182 = arith.andi %180, %181 : tensor<32x1xi1> loc(#loc74)
    %183 = arith.muli %176, %175 : tensor<32x1xi32> loc(#loc74)
    %184 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc75)
    %185 = tt.addptr %184, %183 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc75)
    %186 = tt.expand_dims %174 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc76)
    %c1_i32_81 = arith.constant 1 : i32 loc(#loc77)
    %c1_i32_82 = arith.constant 1 : i32 loc(#loc77)
    %cst_83 = arith.constant dense<1> : tensor<1x32xi32> loc(#loc77)
    %187 = arith.extsi %cst_83 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc77)
    %188 = arith.extsi %186 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc77)
    %189 = arith.muli %187, %188 : tensor<1x32xi64> loc(#loc77)
    %c2147483647_i64_84 = arith.constant 2147483647 : i64 loc(#loc77)
    %c-2147483648_i64_85 = arith.constant -2147483648 : i64 loc(#loc77)
    %cst_86 = arith.constant dense<2147483647> : tensor<1x32xi64> loc(#loc77)
    %190 = arith.cmpi sle, %189, %cst_86 : tensor<1x32xi64> loc(#loc77)
    %cst_87 = arith.constant dense<-2147483648> : tensor<1x32xi64> loc(#loc77)
    %191 = arith.cmpi sge, %189, %cst_87 : tensor<1x32xi64> loc(#loc77)
    %192 = arith.andi %190, %191 : tensor<1x32xi1> loc(#loc77)
    %193 = arith.muli %cst_83, %186 : tensor<1x32xi32> loc(#loc77)
    %194 = tt.broadcast %185 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc78)
    %195 = tt.broadcast %193 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc78)
    %196 = tt.addptr %194, %195 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc78)
    %197 = tt.expand_dims %158 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc79)
    %198 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc80)
    %199 = arith.cmpi slt, %197, %198 : tensor<32x1xi32> loc(#loc80)
    %200 = tt.expand_dims %174 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc81)
    %201 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc82)
    %202 = arith.cmpi slt, %200, %201 : tensor<1x32xi32> loc(#loc82)
    %203 = tt.broadcast %199 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc83)
    %204 = tt.broadcast %202 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc83)
    %205 = arith.andi %203, %204 : tensor<32x32xi1> loc(#loc83)
    tt.store %196, %142, %205 : tensor<32x32x!tt.ptr<f16>> loc(#loc84)
    tt.return loc(#loc85)
  } loc(#loc)
  tt.func private @"cdiv__i32__(1,)cconstexpr_32_"(%arg0: i32 loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)) -> i32 attributes {noinline = false} {
    %c32_i32 = arith.constant 32 : i32 loc(#loc87)
    %c32_i32_0 = arith.constant 32 : i32 loc(#loc87)
    %0 = arith.extsi %arg0 : i32 to i64 loc(#loc87)
    %1 = arith.extsi %c32_i32_0 : i32 to i64 loc(#loc87)
    %2 = arith.addi %0, %1 : i64 loc(#loc87)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc87)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc87)
    %3 = arith.cmpi sle, %2, %c2147483647_i64 : i64 loc(#loc87)
    %4 = arith.cmpi sge, %2, %c-2147483648_i64 : i64 loc(#loc87)
    %5 = arith.andi %3, %4 : i1 loc(#loc87)
    %6 = arith.addi %arg0, %c32_i32_0 : i32 loc(#loc87)
    %c1_i32 = arith.constant 1 : i32 loc(#loc88)
    %c1_i32_1 = arith.constant 1 : i32 loc(#loc88)
    %7 = arith.extsi %6 : i32 to i64 loc(#loc88)
    %8 = arith.extsi %c1_i32_1 : i32 to i64 loc(#loc88)
    %9 = arith.subi %7, %8 : i64 loc(#loc88)
    %c2147483647_i64_2 = arith.constant 2147483647 : i64 loc(#loc88)
    %c-2147483648_i64_3 = arith.constant -2147483648 : i64 loc(#loc88)
    %10 = arith.cmpi sle, %9, %c2147483647_i64_2 : i64 loc(#loc88)
    %11 = arith.cmpi sge, %9, %c-2147483648_i64_3 : i64 loc(#loc88)
    %12 = arith.andi %10, %11 : i1 loc(#loc88)
    %13 = arith.subi %6, %c1_i32_1 : i32 loc(#loc88)
    %c32_i32_4 = arith.constant 32 : i32 loc(#loc89)
    %c32_i32_5 = arith.constant 32 : i32 loc(#loc89)
    %14 = arith.divsi %13, %c32_i32_5 : i32 loc(#loc89)
    tt.return %14 : i32 loc(#loc90)
  ^bb1:  // no predecessors
    %15 = ub.poison : i32 loc(#loc91)
    tt.return %15 : i32 loc(#loc91)
  } loc(#loc86)
  tt.func private @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() -> tensor<32x32xf32> attributes {noinline = false} {
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc93)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc93)
    tt.return %cst_0 : tensor<32x32xf32> loc(#loc94)
  ^bb1:  // no predecessors
    %0 = ub.poison : tensor<32x32xf32> loc(#loc95)
    tt.return %0 : tensor<32x32xf32> loc(#loc95)
  } loc(#loc92)
  tt.func private @"cdiv__i32__(1,)cconstexpr_16_"(%arg0: i32 loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)) -> i32 attributes {noinline = false} {
    %c16_i32 = arith.constant 16 : i32 loc(#loc87)
    %c16_i32_0 = arith.constant 16 : i32 loc(#loc87)
    %0 = arith.extsi %arg0 : i32 to i64 loc(#loc87)
    %1 = arith.extsi %c16_i32_0 : i32 to i64 loc(#loc87)
    %2 = arith.addi %0, %1 : i64 loc(#loc87)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc87)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc87)
    %3 = arith.cmpi sle, %2, %c2147483647_i64 : i64 loc(#loc87)
    %4 = arith.cmpi sge, %2, %c-2147483648_i64 : i64 loc(#loc87)
    %5 = arith.andi %3, %4 : i1 loc(#loc87)
    %6 = arith.addi %arg0, %c16_i32_0 : i32 loc(#loc87)
    %c1_i32 = arith.constant 1 : i32 loc(#loc88)
    %c1_i32_1 = arith.constant 1 : i32 loc(#loc88)
    %7 = arith.extsi %6 : i32 to i64 loc(#loc88)
    %8 = arith.extsi %c1_i32_1 : i32 to i64 loc(#loc88)
    %9 = arith.subi %7, %8 : i64 loc(#loc88)
    %c2147483647_i64_2 = arith.constant 2147483647 : i64 loc(#loc88)
    %c-2147483648_i64_3 = arith.constant -2147483648 : i64 loc(#loc88)
    %10 = arith.cmpi sle, %9, %c2147483647_i64_2 : i64 loc(#loc88)
    %11 = arith.cmpi sge, %9, %c-2147483648_i64_3 : i64 loc(#loc88)
    %12 = arith.andi %10, %11 : i1 loc(#loc88)
    %13 = arith.subi %6, %c1_i32_1 : i32 loc(#loc88)
    %c16_i32_4 = arith.constant 16 : i32 loc(#loc89)
    %c16_i32_5 = arith.constant 16 : i32 loc(#loc89)
    %14 = arith.divsi %13, %c16_i32_5 : i32 loc(#loc89)
    tt.return %14 : i32 loc(#loc90)
  ^bb1:  // no predecessors
    %15 = ub.poison : i32 loc(#loc91)
    tt.return %15 : i32 loc(#loc91)
  } loc(#loc86)
} loc(#loc)
#loc1 = loc("examples/kernels/binary_ops.py":126:24)
#loc2 = loc("examples/kernels/binary_ops.py":127:27)
#loc3 = loc("examples/kernels/binary_ops.py":128:27)
#loc4 = loc("examples/kernels/binary_ops.py":129:38)
#loc5 = loc("examples/kernels/binary_ops.py":130:22)
#loc6 = loc("examples/kernels/binary_ops.py":131:29)
#loc7 = loc("examples/kernels/binary_ops.py":132:35)
#loc8 = loc("examples/kernels/binary_ops.py":132:48)
#loc9 = loc("examples/kernels/binary_ops.py":133:34)
#loc10 = loc("examples/kernels/binary_ops.py":133:54)
#loc11 = loc("examples/kernels/binary_ops.py":133:27)
#loc12 = loc("examples/kernels/binary_ops.py":134:19)
#loc13 = loc("examples/kernels/binary_ops.py":134:40)
#loc14 = loc("examples/kernels/binary_ops.py":140:23)
#loc15 = loc("examples/kernels/binary_ops.py":140:14)
#loc16 = loc("examples/kernels/binary_ops.py":141:23)
#loc17 = loc("examples/kernels/binary_ops.py":141:14)
#loc18 = loc("examples/kernels/binary_ops.py":142:26)
#loc19 = loc("examples/kernels/binary_ops.py":142:14)
#loc20 = loc("examples/kernels/binary_ops.py":143:14)
#loc21 = loc("examples/kernels/binary_ops.py":144:14)
#loc22 = loc("examples/kernels/binary_ops.py":145:26)
#loc23 = loc("examples/kernels/binary_ops.py":145:14)
#loc24 = loc("examples/kernels/binary_ops.py":146:26)
#loc25 = loc("examples/kernels/binary_ops.py":146:14)
#loc26 = loc("examples/kernels/binary_ops.py":147:14)
#loc27 = loc("examples/kernels/binary_ops.py":156:23)
#loc28 = loc("examples/kernels/binary_ops.py":156:51)
#loc29 = loc("examples/kernels/binary_ops.py":156:38)
#loc30 = loc("examples/kernels/binary_ops.py":156:68)
#loc31 = loc("examples/kernels/binary_ops.py":157:23)
#loc32 = loc("examples/kernels/binary_ops.py":157:51)
#loc33 = loc("examples/kernels/binary_ops.py":157:38)
#loc34 = loc("examples/kernels/binary_ops.py":157:68)
#loc35 = loc("examples/kernels/binary_ops.py":158:26)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:71)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:71)
#loc46 = loc("examples/kernels/binary_ops.py":160:52)
#loc47 = loc("examples/kernels/binary_ops.py":160:22)
#loc48 = loc("examples/kernels/binary_ops.py":167:27)
#loc49 = loc("examples/kernels/binary_ops.py":168:33)
#loc50 = loc("examples/kernels/binary_ops.py":168:22)
#loc51 = loc("examples/kernels/binary_ops.py":171:40)
#loc52 = loc("examples/kernels/binary_ops.py":171:59)
#loc53 = loc("examples/kernels/binary_ops.py":171:55)
#loc54 = loc("examples/kernels/binary_ops.py":171:51)
#loc55 = loc("examples/kernels/binary_ops.py":171:20)
#loc56 = loc("examples/kernels/binary_ops.py":172:40)
#loc57 = loc("examples/kernels/binary_ops.py":172:59)
#loc58 = loc("examples/kernels/binary_ops.py":172:55)
#loc59 = loc("examples/kernels/binary_ops.py":172:51)
#loc60 = loc("examples/kernels/binary_ops.py":172:20)
#loc61 = loc("examples/kernels/binary_ops.py":174:35)
#loc62 = loc("examples/kernels/binary_ops.py":176:18)
#loc63 = loc("examples/kernels/binary_ops.py":177:33)
#loc64 = loc("examples/kernels/binary_ops.py":177:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:8)
#loc66 = loc("examples/kernels/binary_ops.py":182:23)
#loc67 = loc("examples/kernels/binary_ops.py":186:22)
#loc68 = loc("examples/kernels/binary_ops.py":186:50)
#loc69 = loc("examples/kernels/binary_ops.py":186:37)
#loc70 = loc("examples/kernels/binary_ops.py":187:22)
#loc71 = loc("examples/kernels/binary_ops.py":187:50)
#loc72 = loc("examples/kernels/binary_ops.py":187:37)
#loc73 = loc("examples/kernels/binary_ops.py":188:41)
#loc74 = loc("examples/kernels/binary_ops.py":188:33)
#loc75 = loc("examples/kernels/binary_ops.py":188:21)
#loc76 = loc("examples/kernels/binary_ops.py":188:72)
#loc77 = loc("examples/kernels/binary_ops.py":188:64)
#loc78 = loc("examples/kernels/binary_ops.py":188:52)
#loc79 = loc("examples/kernels/binary_ops.py":189:22)
#loc80 = loc("examples/kernels/binary_ops.py":189:33)
#loc81 = loc("examples/kernels/binary_ops.py":189:47)
#loc82 = loc("examples/kernels/binary_ops.py":189:58)
#loc83 = loc("examples/kernels/binary_ops.py":189:39)
#loc84 = loc("examples/kernels/binary_ops.py":190:21)
#loc85 = loc("examples/kernels/binary_ops.py":190:4)
#loc87 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:16)
#loc88 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc89 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc90 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:11)
#loc91 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:4)
#loc92 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":113:0)
#loc93 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:31)
#loc94 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:11)
#loc95 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:4)


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc86 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc1)
    %1 = tt.call @"cdiv__i32__(1,)cconstexpr_32_"(%arg3) : (i32) -> i32 loc(#loc2)
    %2 = tt.call @"cdiv__i32__(1,)cconstexpr_32_"(%arg4) : (i32) -> i32 loc(#loc3)
    %c4_i32 = arith.constant 4 : i32 loc(#loc4)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc4)
    %3 = arith.extsi %c4_i32_0 : i32 to i64 loc(#loc4)
    %4 = arith.extsi %2 : i32 to i64 loc(#loc4)
    %5 = arith.muli %3, %4 : i64 loc(#loc4)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc4)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc4)
    %6 = arith.cmpi sle, %5, %c2147483647_i64 : i64 loc(#loc4)
    %7 = arith.cmpi sge, %5, %c-2147483648_i64 : i64 loc(#loc4)
    %8 = arith.andi %6, %7 : i1 loc(#loc4)
    %9 = arith.muli %c4_i32_0, %2 : i32 loc(#loc4)
    %10 = arith.divsi %0, %9 : i32 loc(#loc5)
    %c4_i32_1 = arith.constant 4 : i32 loc(#loc6)
    %c4_i32_2 = arith.constant 4 : i32 loc(#loc6)
    %11 = arith.extsi %10 : i32 to i64 loc(#loc6)
    %12 = arith.extsi %c4_i32_2 : i32 to i64 loc(#loc6)
    %13 = arith.muli %11, %12 : i64 loc(#loc6)
    %c2147483647_i64_3 = arith.constant 2147483647 : i64 loc(#loc6)
    %c-2147483648_i64_4 = arith.constant -2147483648 : i64 loc(#loc6)
    %14 = arith.cmpi sle, %13, %c2147483647_i64_3 : i64 loc(#loc6)
    %15 = arith.cmpi sge, %13, %c-2147483648_i64_4 : i64 loc(#loc6)
    %16 = arith.andi %14, %15 : i1 loc(#loc6)
    %17 = arith.muli %10, %c4_i32_2 : i32 loc(#loc6)
    %18 = arith.extsi %1 : i32 to i64 loc(#loc7)
    %19 = arith.extsi %17 : i32 to i64 loc(#loc7)
    %20 = arith.subi %18, %19 : i64 loc(#loc7)
    %c2147483647_i64_5 = arith.constant 2147483647 : i64 loc(#loc7)
    %c-2147483648_i64_6 = arith.constant -2147483648 : i64 loc(#loc7)
    %21 = arith.cmpi sle, %20, %c2147483647_i64_5 : i64 loc(#loc7)
    %22 = arith.cmpi sge, %20, %c-2147483648_i64_6 : i64 loc(#loc7)
    %23 = arith.andi %21, %22 : i1 loc(#loc7)
    %24 = arith.subi %1, %17 : i32 loc(#loc7)
    %c4_i32_7 = arith.constant 4 : i32 loc(#loc8)
    %25 = arith.minsi %24, %c4_i32_7 : i32 loc(#loc8)
    %26 = arith.remsi %0, %9 : i32 loc(#loc9)
    %27 = arith.remsi %26, %25 : i32 loc(#loc10)
    %28 = arith.extsi %17 : i32 to i64 loc(#loc11)
    %29 = arith.extsi %27 : i32 to i64 loc(#loc11)
    %30 = arith.addi %28, %29 : i64 loc(#loc11)
    %c2147483647_i64_8 = arith.constant 2147483647 : i64 loc(#loc11)
    %c-2147483648_i64_9 = arith.constant -2147483648 : i64 loc(#loc11)
    %31 = arith.cmpi sle, %30, %c2147483647_i64_8 : i64 loc(#loc11)
    %32 = arith.cmpi sge, %30, %c-2147483648_i64_9 : i64 loc(#loc11)
    %33 = arith.andi %31, %32 : i1 loc(#loc11)
    %34 = arith.addi %17, %27 : i32 loc(#loc11)
    %35 = arith.remsi %0, %9 : i32 loc(#loc12)
    %36 = arith.divsi %35, %25 : i32 loc(#loc13)
    %c0_i32 = arith.constant 0 : i32 loc(#loc14)
    %37 = arith.cmpi sge, %34, %c0_i32 : i32 loc(#loc14)
    llvm.intr.assume %37 : i1 loc(#loc15)
    %c0_i32_10 = arith.constant 0 : i32 loc(#loc16)
    %38 = arith.cmpi sge, %36, %c0_i32_10 : i32 loc(#loc16)
    llvm.intr.assume %38 : i1 loc(#loc17)
    %c0_i32_11 = arith.constant 0 : i32 loc(#loc18)
    %39 = arith.cmpi sgt, %arg6, %c0_i32_11 : i32 loc(#loc18)
    llvm.intr.assume %39 : i1 loc(#loc19)
    %true = arith.constant true loc(#loc20)
    llvm.intr.assume %true : i1 loc(#loc20)
    %true_12 = arith.constant true loc(#loc21)
    llvm.intr.assume %true_12 : i1 loc(#loc21)
    %c0_i32_13 = arith.constant 0 : i32 loc(#loc22)
    %40 = arith.cmpi sgt, %arg7, %c0_i32_13 : i32 loc(#loc22)
    llvm.intr.assume %40 : i1 loc(#loc23)
    %c0_i32_14 = arith.constant 0 : i32 loc(#loc24)
    %41 = arith.cmpi sgt, %arg8, %c0_i32_14 : i32 loc(#loc24)
    llvm.intr.assume %41 : i1 loc(#loc25)
    %true_15 = arith.constant true loc(#loc26)
    llvm.intr.assume %true_15 : i1 loc(#loc26)
    %c32_i32 = arith.constant 32 : i32 loc(#loc27)
    %c32_i32_16 = arith.constant 32 : i32 loc(#loc27)
    %42 = arith.extsi %34 : i32 to i64 loc(#loc27)
    %43 = arith.extsi %c32_i32_16 : i32 to i64 loc(#loc27)
    %44 = arith.muli %42, %43 : i64 loc(#loc27)
    %c2147483647_i64_17 = arith.constant 2147483647 : i64 loc(#loc27)
    %c-2147483648_i64_18 = arith.constant -2147483648 : i64 loc(#loc27)
    %45 = arith.cmpi sle, %44, %c2147483647_i64_17 : i64 loc(#loc27)
    %46 = arith.cmpi sge, %44, %c-2147483648_i64_18 : i64 loc(#loc27)
    %47 = arith.andi %45, %46 : i1 loc(#loc27)
    %48 = arith.muli %34, %c32_i32_16 : i32 loc(#loc27)
    %49 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc28)
    %50 = tt.splat %48 : i32 -> tensor<32xi32> loc(#loc29)
    %51 = arith.extsi %50 : tensor<32xi32> to tensor<32xi64> loc(#loc29)
    %52 = arith.extsi %49 : tensor<32xi32> to tensor<32xi64> loc(#loc29)
    %53 = arith.addi %51, %52 : tensor<32xi64> loc(#loc29)
    %c2147483647_i64_19 = arith.constant 2147483647 : i64 loc(#loc29)
    %c-2147483648_i64_20 = arith.constant -2147483648 : i64 loc(#loc29)
    %cst = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc29)
    %54 = arith.cmpi sle, %53, %cst : tensor<32xi64> loc(#loc29)
    %cst_21 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc29)
    %55 = arith.cmpi sge, %53, %cst_21 : tensor<32xi64> loc(#loc29)
    %56 = arith.andi %54, %55 : tensor<32xi1> loc(#loc29)
    %57 = arith.addi %50, %49 : tensor<32xi32> loc(#loc29)
    %58 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc30)
    %59 = arith.remsi %57, %58 : tensor<32xi32> loc(#loc30)
    %c32_i32_22 = arith.constant 32 : i32 loc(#loc31)
    %c32_i32_23 = arith.constant 32 : i32 loc(#loc31)
    %60 = arith.extsi %36 : i32 to i64 loc(#loc31)
    %61 = arith.extsi %c32_i32_23 : i32 to i64 loc(#loc31)
    %62 = arith.muli %60, %61 : i64 loc(#loc31)
    %c2147483647_i64_24 = arith.constant 2147483647 : i64 loc(#loc31)
    %c-2147483648_i64_25 = arith.constant -2147483648 : i64 loc(#loc31)
    %63 = arith.cmpi sle, %62, %c2147483647_i64_24 : i64 loc(#loc31)
    %64 = arith.cmpi sge, %62, %c-2147483648_i64_25 : i64 loc(#loc31)
    %65 = arith.andi %63, %64 : i1 loc(#loc31)
    %66 = arith.muli %36, %c32_i32_23 : i32 loc(#loc31)
    %67 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc32)
    %68 = tt.splat %66 : i32 -> tensor<32xi32> loc(#loc33)
    %69 = arith.extsi %68 : tensor<32xi32> to tensor<32xi64> loc(#loc33)
    %70 = arith.extsi %67 : tensor<32xi32> to tensor<32xi64> loc(#loc33)
    %71 = arith.addi %69, %70 : tensor<32xi64> loc(#loc33)
    %c2147483647_i64_26 = arith.constant 2147483647 : i64 loc(#loc33)
    %c-2147483648_i64_27 = arith.constant -2147483648 : i64 loc(#loc33)
    %cst_28 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc33)
    %72 = arith.cmpi sle, %71, %cst_28 : tensor<32xi64> loc(#loc33)
    %cst_29 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc33)
    %73 = arith.cmpi sge, %71, %cst_29 : tensor<32xi64> loc(#loc33)
    %74 = arith.andi %72, %73 : tensor<32xi1> loc(#loc33)
    %75 = arith.addi %68, %67 : tensor<32xi32> loc(#loc33)
    %76 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc34)
    %77 = arith.remsi %75, %76 : tensor<32xi32> loc(#loc34)
    %78 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc35)
    %79 = tt.expand_dims %59 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc36)
    %80 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc37)
    %81 = arith.extsi %79 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc37)
    %82 = arith.extsi %80 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc37)
    %83 = arith.muli %81, %82 : tensor<32x1xi64> loc(#loc37)
    %c2147483647_i64_30 = arith.constant 2147483647 : i64 loc(#loc37)
    %c-2147483648_i64_31 = arith.constant -2147483648 : i64 loc(#loc37)
    %cst_32 = arith.constant dense<2147483647> : tensor<32x1xi64> loc(#loc37)
    %84 = arith.cmpi sle, %83, %cst_32 : tensor<32x1xi64> loc(#loc37)
    %cst_33 = arith.constant dense<-2147483648> : tensor<32x1xi64> loc(#loc37)
    %85 = arith.cmpi sge, %83, %cst_33 : tensor<32x1xi64> loc(#loc37)
    %86 = arith.andi %84, %85 : tensor<32x1xi1> loc(#loc37)
    %87 = arith.muli %79, %80 : tensor<32x1xi32> loc(#loc37)
    %88 = tt.expand_dims %78 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc38)
    %c1_i32 = arith.constant 1 : i32 loc(#loc39)
    %c1_i32_34 = arith.constant 1 : i32 loc(#loc39)
    %cst_35 = arith.constant dense<1> : tensor<1x16xi32> loc(#loc39)
    %89 = arith.extsi %88 : tensor<1x16xi32> to tensor<1x16xi64> loc(#loc39)
    %90 = arith.extsi %cst_35 : tensor<1x16xi32> to tensor<1x16xi64> loc(#loc39)
    %91 = arith.muli %89, %90 : tensor<1x16xi64> loc(#loc39)
    %c2147483647_i64_36 = arith.constant 2147483647 : i64 loc(#loc39)
    %c-2147483648_i64_37 = arith.constant -2147483648 : i64 loc(#loc39)
    %cst_38 = arith.constant dense<2147483647> : tensor<1x16xi64> loc(#loc39)
    %92 = arith.cmpi sle, %91, %cst_38 : tensor<1x16xi64> loc(#loc39)
    %cst_39 = arith.constant dense<-2147483648> : tensor<1x16xi64> loc(#loc39)
    %93 = arith.cmpi sge, %91, %cst_39 : tensor<1x16xi64> loc(#loc39)
    %94 = arith.andi %92, %93 : tensor<1x16xi1> loc(#loc39)
    %95 = arith.muli %88, %cst_35 : tensor<1x16xi32> loc(#loc39)
    %96 = tt.broadcast %87 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc40)
    %97 = tt.broadcast %95 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc40)
    %98 = arith.extsi %96 : tensor<32x16xi32> to tensor<32x16xi64> loc(#loc40)
    %99 = arith.extsi %97 : tensor<32x16xi32> to tensor<32x16xi64> loc(#loc40)
    %100 = arith.addi %98, %99 : tensor<32x16xi64> loc(#loc40)
    %c2147483647_i64_40 = arith.constant 2147483647 : i64 loc(#loc40)
    %c-2147483648_i64_41 = arith.constant -2147483648 : i64 loc(#loc40)
    %cst_42 = arith.constant dense<2147483647> : tensor<32x16xi64> loc(#loc40)
    %101 = arith.cmpi sle, %100, %cst_42 : tensor<32x16xi64> loc(#loc40)
    %cst_43 = arith.constant dense<-2147483648> : tensor<32x16xi64> loc(#loc40)
    %102 = arith.cmpi sge, %100, %cst_43 : tensor<32x16xi64> loc(#loc40)
    %103 = arith.andi %101, %102 : tensor<32x16xi1> loc(#loc40)
    %104 = arith.addi %96, %97 : tensor<32x16xi32> loc(#loc40)
    %105 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc41)
    %106 = tt.addptr %105, %104 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc41)
    %107 = tt.expand_dims %78 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc42)
    %108 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc43)
    %109 = arith.extsi %107 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc43)
    %110 = arith.extsi %108 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc43)
    %111 = arith.muli %109, %110 : tensor<16x1xi64> loc(#loc43)
    %c2147483647_i64_44 = arith.constant 2147483647 : i64 loc(#loc43)
    %c-2147483648_i64_45 = arith.constant -2147483648 : i64 loc(#loc43)
    %cst_46 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc43)
    %112 = arith.cmpi sle, %111, %cst_46 : tensor<16x1xi64> loc(#loc43)
    %cst_47 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc43)
    %113 = arith.cmpi sge, %111, %cst_47 : tensor<16x1xi64> loc(#loc43)
    %114 = arith.andi %112, %113 : tensor<16x1xi1> loc(#loc43)
    %115 = arith.muli %107, %108 : tensor<16x1xi32> loc(#loc43)
    %116 = tt.expand_dims %77 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc44)
    %c1_i32_48 = arith.constant 1 : i32 loc(#loc45)
    %c1_i32_49 = arith.constant 1 : i32 loc(#loc45)
    %cst_50 = arith.constant dense<1> : tensor<1x32xi32> loc(#loc45)
    %117 = arith.extsi %116 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc45)
    %118 = arith.extsi %cst_50 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc45)
    %119 = arith.muli %117, %118 : tensor<1x32xi64> loc(#loc45)
    %c2147483647_i64_51 = arith.constant 2147483647 : i64 loc(#loc45)
    %c-2147483648_i64_52 = arith.constant -2147483648 : i64 loc(#loc45)
    %cst_53 = arith.constant dense<2147483647> : tensor<1x32xi64> loc(#loc45)
    %120 = arith.cmpi sle, %119, %cst_53 : tensor<1x32xi64> loc(#loc45)
    %cst_54 = arith.constant dense<-2147483648> : tensor<1x32xi64> loc(#loc45)
    %121 = arith.cmpi sge, %119, %cst_54 : tensor<1x32xi64> loc(#loc45)
    %122 = arith.andi %120, %121 : tensor<1x32xi1> loc(#loc45)
    %123 = arith.muli %116, %cst_50 : tensor<1x32xi32> loc(#loc45)
    %124 = tt.broadcast %115 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc46)
    %125 = tt.broadcast %123 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc46)
    %126 = arith.extsi %124 : tensor<16x32xi32> to tensor<16x32xi64> loc(#loc46)
    %127 = arith.extsi %125 : tensor<16x32xi32> to tensor<16x32xi64> loc(#loc46)
    %128 = arith.addi %126, %127 : tensor<16x32xi64> loc(#loc46)
    %c2147483647_i64_55 = arith.constant 2147483647 : i64 loc(#loc46)
    %c-2147483648_i64_56 = arith.constant -2147483648 : i64 loc(#loc46)
    %cst_57 = arith.constant dense<2147483647> : tensor<16x32xi64> loc(#loc46)
    %129 = arith.cmpi sle, %128, %cst_57 : tensor<16x32xi64> loc(#loc46)
    %cst_58 = arith.constant dense<-2147483648> : tensor<16x32xi64> loc(#loc46)
    %130 = arith.cmpi sge, %128, %cst_58 : tensor<16x32xi64> loc(#loc46)
    %131 = arith.andi %129, %130 : tensor<16x32xi1> loc(#loc46)
    %132 = arith.addi %124, %125 : tensor<16x32xi32> loc(#loc46)
    %133 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc47)
    %134 = tt.addptr %133, %132 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc47)
    %135 = tt.call @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() : () -> tensor<32x32xf32> loc(#loc48)
    %136 = tt.call @"cdiv__i32__(1,)cconstexpr_16_"(%arg5) : (i32) -> i32 loc(#loc49)
    %c0_i32_59 = arith.constant 0 : i32 loc(#loc50)
    %c1_i32_60 = arith.constant 1 : i32 loc(#loc50)
    %137 = arith.bitcast %c0_i32_59 : i32 to i32 loc(#loc50)
    %138 = arith.bitcast %136 : i32 to i32 loc(#loc50)
    %139 = arith.bitcast %c1_i32_60 : i32 to i32 loc(#loc50)
    %140 = ub.poison : i32 loc(#loc50)
    %141:3 = scf.for %arg9 = %137 to %138 step %139 iter_args(%arg10 = %135, %arg11 = %106, %arg12 = %134) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %206 = tt.expand_dims %78 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc51)
      %c16_i32 = arith.constant 16 : i32 loc(#loc52)
      %c16_i32_88 = arith.constant 16 : i32 loc(#loc52)
      %207 = arith.extsi %arg9 : i32 to i64 loc(#loc52)
      %208 = arith.extsi %c16_i32_88 : i32 to i64 loc(#loc52)
      %209 = arith.muli %207, %208 : i64 loc(#loc52)
      %c2147483647_i64_89 = arith.constant 2147483647 : i64 loc(#loc52)
      %c-2147483648_i64_90 = arith.constant -2147483648 : i64 loc(#loc52)
      %210 = arith.cmpi sle, %209, %c2147483647_i64_89 : i64 loc(#loc52)
      %211 = arith.cmpi sge, %209, %c-2147483648_i64_90 : i64 loc(#loc52)
      %212 = arith.andi %210, %211 : i1 loc(#loc52)
      %213 = arith.muli %arg9, %c16_i32_88 : i32 loc(#loc52)
      %214 = arith.extsi %arg5 : i32 to i64 loc(#loc53)
      %215 = arith.extsi %213 : i32 to i64 loc(#loc53)
      %216 = arith.subi %214, %215 : i64 loc(#loc53)
      %c2147483647_i64_91 = arith.constant 2147483647 : i64 loc(#loc53)
      %c-2147483648_i64_92 = arith.constant -2147483648 : i64 loc(#loc53)
      %217 = arith.cmpi sle, %216, %c2147483647_i64_91 : i64 loc(#loc53)
      %218 = arith.cmpi sge, %216, %c-2147483648_i64_92 : i64 loc(#loc53)
      %219 = arith.andi %217, %218 : i1 loc(#loc53)
      %220 = arith.subi %arg5, %213 : i32 loc(#loc53)
      %221 = tt.splat %220 : i32 -> tensor<1x16xi32> loc(#loc54)
      %222 = arith.cmpi slt, %206, %221 : tensor<1x16xi32> loc(#loc54)
      %cst_93 = arith.constant 0.000000e+00 : f32 loc(#loc55)
      %223 = tt.broadcast %222 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc55)
      %cst_94 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc55)
      %224 = tt.load %arg11, %223, %cst_94 : tensor<32x16x!tt.ptr<f32>> loc(#loc55)
      %225 = tt.expand_dims %78 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc56)
      %c16_i32_95 = arith.constant 16 : i32 loc(#loc57)
      %c16_i32_96 = arith.constant 16 : i32 loc(#loc57)
      %226 = arith.extsi %arg9 : i32 to i64 loc(#loc57)
      %227 = arith.extsi %c16_i32_96 : i32 to i64 loc(#loc57)
      %228 = arith.muli %226, %227 : i64 loc(#loc57)
      %c2147483647_i64_97 = arith.constant 2147483647 : i64 loc(#loc57)
      %c-2147483648_i64_98 = arith.constant -2147483648 : i64 loc(#loc57)
      %229 = arith.cmpi sle, %228, %c2147483647_i64_97 : i64 loc(#loc57)
      %230 = arith.cmpi sge, %228, %c-2147483648_i64_98 : i64 loc(#loc57)
      %231 = arith.andi %229, %230 : i1 loc(#loc57)
      %232 = arith.muli %arg9, %c16_i32_96 : i32 loc(#loc57)
      %233 = arith.extsi %arg5 : i32 to i64 loc(#loc58)
      %234 = arith.extsi %232 : i32 to i64 loc(#loc58)
      %235 = arith.subi %233, %234 : i64 loc(#loc58)
      %c2147483647_i64_99 = arith.constant 2147483647 : i64 loc(#loc58)
      %c-2147483648_i64_100 = arith.constant -2147483648 : i64 loc(#loc58)
      %236 = arith.cmpi sle, %235, %c2147483647_i64_99 : i64 loc(#loc58)
      %237 = arith.cmpi sge, %235, %c-2147483648_i64_100 : i64 loc(#loc58)
      %238 = arith.andi %236, %237 : i1 loc(#loc58)
      %239 = arith.subi %arg5, %232 : i32 loc(#loc58)
      %240 = tt.splat %239 : i32 -> tensor<16x1xi32> loc(#loc59)
      %241 = arith.cmpi slt, %225, %240 : tensor<16x1xi32> loc(#loc59)
      %cst_101 = arith.constant 0.000000e+00 : f32 loc(#loc60)
      %242 = tt.broadcast %241 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc60)
      %cst_102 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc60)
      %243 = tt.load %arg12, %242, %cst_102 : tensor<16x32x!tt.ptr<f32>> loc(#loc60)
      %cst_103 = arith.constant 0.000000e+00 : f32 loc(#loc61)
      %244 = tt.dot %224, %243, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc61)
      %c16_i32_104 = arith.constant 16 : i32 loc(#loc62)
      %cst_105 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc62)
      %245 = tt.addptr %arg11, %cst_105 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc62)
      %c16_i32_106 = arith.constant 16 : i32 loc(#loc63)
      %c16_i32_107 = arith.constant 16 : i32 loc(#loc63)
      %246 = arith.extsi %c16_i32_107 : i32 to i64 loc(#loc63)
      %247 = arith.extsi %arg7 : i32 to i64 loc(#loc63)
      %248 = arith.muli %246, %247 : i64 loc(#loc63)
      %c2147483647_i64_108 = arith.constant 2147483647 : i64 loc(#loc63)
      %c-2147483648_i64_109 = arith.constant -2147483648 : i64 loc(#loc63)
      %249 = arith.cmpi sle, %248, %c2147483647_i64_108 : i64 loc(#loc63)
      %250 = arith.cmpi sge, %248, %c-2147483648_i64_109 : i64 loc(#loc63)
      %251 = arith.andi %249, %250 : i1 loc(#loc63)
      %252 = arith.muli %c16_i32_107, %arg7 : i32 loc(#loc63)
      %253 = tt.splat %252 : i32 -> tensor<16x32xi32> loc(#loc64)
      %254 = tt.addptr %arg12, %253 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc64)
      scf.yield %244, %245, %254 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc65)
    } loc(#loc50)
    %142 = arith.truncf %141#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc66)
    %c32_i32_61 = arith.constant 32 : i32 loc(#loc67)
    %c32_i32_62 = arith.constant 32 : i32 loc(#loc67)
    %143 = arith.extsi %34 : i32 to i64 loc(#loc67)
    %144 = arith.extsi %c32_i32_62 : i32 to i64 loc(#loc67)
    %145 = arith.muli %143, %144 : i64 loc(#loc67)
    %c2147483647_i64_63 = arith.constant 2147483647 : i64 loc(#loc67)
    %c-2147483648_i64_64 = arith.constant -2147483648 : i64 loc(#loc67)
    %146 = arith.cmpi sle, %145, %c2147483647_i64_63 : i64 loc(#loc67)
    %147 = arith.cmpi sge, %145, %c-2147483648_i64_64 : i64 loc(#loc67)
    %148 = arith.andi %146, %147 : i1 loc(#loc67)
    %149 = arith.muli %34, %c32_i32_62 : i32 loc(#loc67)
    %150 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc68)
    %151 = tt.splat %149 : i32 -> tensor<32xi32> loc(#loc69)
    %152 = arith.extsi %151 : tensor<32xi32> to tensor<32xi64> loc(#loc69)
    %153 = arith.extsi %150 : tensor<32xi32> to tensor<32xi64> loc(#loc69)
    %154 = arith.addi %152, %153 : tensor<32xi64> loc(#loc69)
    %c2147483647_i64_65 = arith.constant 2147483647 : i64 loc(#loc69)
    %c-2147483648_i64_66 = arith.constant -2147483648 : i64 loc(#loc69)
    %cst_67 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc69)
    %155 = arith.cmpi sle, %154, %cst_67 : tensor<32xi64> loc(#loc69)
    %cst_68 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc69)
    %156 = arith.cmpi sge, %154, %cst_68 : tensor<32xi64> loc(#loc69)
    %157 = arith.andi %155, %156 : tensor<32xi1> loc(#loc69)
    %158 = arith.addi %151, %150 : tensor<32xi32> loc(#loc69)
    %c32_i32_69 = arith.constant 32 : i32 loc(#loc70)
    %c32_i32_70 = arith.constant 32 : i32 loc(#loc70)
    %159 = arith.extsi %36 : i32 to i64 loc(#loc70)
    %160 = arith.extsi %c32_i32_70 : i32 to i64 loc(#loc70)
    %161 = arith.muli %159, %160 : i64 loc(#loc70)
    %c2147483647_i64_71 = arith.constant 2147483647 : i64 loc(#loc70)
    %c-2147483648_i64_72 = arith.constant -2147483648 : i64 loc(#loc70)
    %162 = arith.cmpi sle, %161, %c2147483647_i64_71 : i64 loc(#loc70)
    %163 = arith.cmpi sge, %161, %c-2147483648_i64_72 : i64 loc(#loc70)
    %164 = arith.andi %162, %163 : i1 loc(#loc70)
    %165 = arith.muli %36, %c32_i32_70 : i32 loc(#loc70)
    %166 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc71)
    %167 = tt.splat %165 : i32 -> tensor<32xi32> loc(#loc72)
    %168 = arith.extsi %167 : tensor<32xi32> to tensor<32xi64> loc(#loc72)
    %169 = arith.extsi %166 : tensor<32xi32> to tensor<32xi64> loc(#loc72)
    %170 = arith.addi %168, %169 : tensor<32xi64> loc(#loc72)
    %c2147483647_i64_73 = arith.constant 2147483647 : i64 loc(#loc72)
    %c-2147483648_i64_74 = arith.constant -2147483648 : i64 loc(#loc72)
    %cst_75 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc72)
    %171 = arith.cmpi sle, %170, %cst_75 : tensor<32xi64> loc(#loc72)
    %cst_76 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc72)
    %172 = arith.cmpi sge, %170, %cst_76 : tensor<32xi64> loc(#loc72)
    %173 = arith.andi %171, %172 : tensor<32xi1> loc(#loc72)
    %174 = arith.addi %167, %166 : tensor<32xi32> loc(#loc72)
    %175 = tt.expand_dims %158 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc73)
    %176 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc74)
    %177 = arith.extsi %176 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc74)
    %178 = arith.extsi %175 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc74)
    %179 = arith.muli %177, %178 : tensor<32x1xi64> loc(#loc74)
    %c2147483647_i64_77 = arith.constant 2147483647 : i64 loc(#loc74)
    %c-2147483648_i64_78 = arith.constant -2147483648 : i64 loc(#loc74)
    %cst_79 = arith.constant dense<2147483647> : tensor<32x1xi64> loc(#loc74)
    %180 = arith.cmpi sle, %179, %cst_79 : tensor<32x1xi64> loc(#loc74)
    %cst_80 = arith.constant dense<-2147483648> : tensor<32x1xi64> loc(#loc74)
    %181 = arith.cmpi sge, %179, %cst_80 : tensor<32x1xi64> loc(#loc74)
    %182 = arith.andi %180, %181 : tensor<32x1xi1> loc(#loc74)
    %183 = arith.muli %176, %175 : tensor<32x1xi32> loc(#loc74)
    %184 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc75)
    %185 = tt.addptr %184, %183 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc75)
    %186 = tt.expand_dims %174 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc76)
    %c1_i32_81 = arith.constant 1 : i32 loc(#loc77)
    %c1_i32_82 = arith.constant 1 : i32 loc(#loc77)
    %cst_83 = arith.constant dense<1> : tensor<1x32xi32> loc(#loc77)
    %187 = arith.extsi %cst_83 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc77)
    %188 = arith.extsi %186 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc77)
    %189 = arith.muli %187, %188 : tensor<1x32xi64> loc(#loc77)
    %c2147483647_i64_84 = arith.constant 2147483647 : i64 loc(#loc77)
    %c-2147483648_i64_85 = arith.constant -2147483648 : i64 loc(#loc77)
    %cst_86 = arith.constant dense<2147483647> : tensor<1x32xi64> loc(#loc77)
    %190 = arith.cmpi sle, %189, %cst_86 : tensor<1x32xi64> loc(#loc77)
    %cst_87 = arith.constant dense<-2147483648> : tensor<1x32xi64> loc(#loc77)
    %191 = arith.cmpi sge, %189, %cst_87 : tensor<1x32xi64> loc(#loc77)
    %192 = arith.andi %190, %191 : tensor<1x32xi1> loc(#loc77)
    %193 = arith.muli %cst_83, %186 : tensor<1x32xi32> loc(#loc77)
    %194 = tt.broadcast %185 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc78)
    %195 = tt.broadcast %193 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc78)
    %196 = tt.addptr %194, %195 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc78)
    %197 = tt.expand_dims %158 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc79)
    %198 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc80)
    %199 = arith.cmpi slt, %197, %198 : tensor<32x1xi32> loc(#loc80)
    %200 = tt.expand_dims %174 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc81)
    %201 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc82)
    %202 = arith.cmpi slt, %200, %201 : tensor<1x32xi32> loc(#loc82)
    %203 = tt.broadcast %199 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc83)
    %204 = tt.broadcast %202 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc83)
    %205 = arith.andi %203, %204 : tensor<32x32xi1> loc(#loc83)
    tt.store %196, %142, %205 : tensor<32x32x!tt.ptr<f16>> loc(#loc84)
    tt.return loc(#loc85)
  } loc(#loc)
  tt.func private @"cdiv__i32__(1,)cconstexpr_32_"(%arg0: i32 loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)) -> i32 attributes {noinline = false} {
    %c32_i32 = arith.constant 32 : i32 loc(#loc87)
    %c31_i32 = arith.constant 31 : i32 loc(#loc88)
    %0 = arith.addi %arg0, %c31_i32 : i32 loc(#loc88)
    %1 = arith.divsi %0, %c32_i32 : i32 loc(#loc89)
    tt.return %1 : i32 loc(#loc90)
  } loc(#loc86)
  tt.func private @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() -> tensor<32x32xf32> attributes {noinline = false} {
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc92)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc92)
    tt.return %cst_0 : tensor<32x32xf32> loc(#loc93)
  ^bb1:  // no predecessors
    %0 = ub.poison : tensor<32x32xf32> loc(#loc94)
    tt.return %0 : tensor<32x32xf32> loc(#loc94)
  } loc(#loc91)
  tt.func private @"cdiv__i32__(1,)cconstexpr_16_"(%arg0: i32 loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)) -> i32 attributes {noinline = false} {
    %c16_i32 = arith.constant 16 : i32 loc(#loc95)
    %c16_i32_0 = arith.constant 16 : i32 loc(#loc95)
    %0 = arith.extsi %arg0 : i32 to i64 loc(#loc95)
    %1 = arith.extsi %c16_i32_0 : i32 to i64 loc(#loc95)
    %2 = arith.addi %0, %1 : i64 loc(#loc95)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc95)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc95)
    %3 = arith.cmpi sle, %2, %c2147483647_i64 : i64 loc(#loc95)
    %4 = arith.cmpi sge, %2, %c-2147483648_i64 : i64 loc(#loc95)
    %5 = arith.andi %3, %4 : i1 loc(#loc95)
    %6 = arith.addi %arg0, %c16_i32_0 : i32 loc(#loc95)
    %c1_i32 = arith.constant 1 : i32 loc(#loc88)
    %c1_i32_1 = arith.constant 1 : i32 loc(#loc88)
    %7 = arith.extsi %6 : i32 to i64 loc(#loc88)
    %8 = arith.extsi %c1_i32_1 : i32 to i64 loc(#loc88)
    %9 = arith.subi %7, %8 : i64 loc(#loc88)
    %c2147483647_i64_2 = arith.constant 2147483647 : i64 loc(#loc88)
    %c-2147483648_i64_3 = arith.constant -2147483648 : i64 loc(#loc88)
    %10 = arith.cmpi sle, %9, %c2147483647_i64_2 : i64 loc(#loc88)
    %11 = arith.cmpi sge, %9, %c-2147483648_i64_3 : i64 loc(#loc88)
    %12 = arith.andi %10, %11 : i1 loc(#loc88)
    %13 = arith.subi %6, %c1_i32_1 : i32 loc(#loc88)
    %c16_i32_4 = arith.constant 16 : i32 loc(#loc89)
    %c16_i32_5 = arith.constant 16 : i32 loc(#loc89)
    %14 = arith.divsi %13, %c16_i32_5 : i32 loc(#loc89)
    tt.return %14 : i32 loc(#loc90)
  ^bb1:  // no predecessors
    %15 = ub.poison : i32 loc(#loc96)
    tt.return %15 : i32 loc(#loc96)
  } loc(#loc86)
} loc(#loc)
#loc1 = loc("examples/kernels/binary_ops.py":126:24)
#loc2 = loc("examples/kernels/binary_ops.py":127:27)
#loc3 = loc("examples/kernels/binary_ops.py":128:27)
#loc4 = loc("examples/kernels/binary_ops.py":129:38)
#loc5 = loc("examples/kernels/binary_ops.py":130:22)
#loc6 = loc("examples/kernels/binary_ops.py":131:29)
#loc7 = loc("examples/kernels/binary_ops.py":132:35)
#loc8 = loc("examples/kernels/binary_ops.py":132:48)
#loc9 = loc("examples/kernels/binary_ops.py":133:34)
#loc10 = loc("examples/kernels/binary_ops.py":133:54)
#loc11 = loc("examples/kernels/binary_ops.py":133:27)
#loc12 = loc("examples/kernels/binary_ops.py":134:19)
#loc13 = loc("examples/kernels/binary_ops.py":134:40)
#loc14 = loc("examples/kernels/binary_ops.py":140:23)
#loc15 = loc("examples/kernels/binary_ops.py":140:14)
#loc16 = loc("examples/kernels/binary_ops.py":141:23)
#loc17 = loc("examples/kernels/binary_ops.py":141:14)
#loc18 = loc("examples/kernels/binary_ops.py":142:26)
#loc19 = loc("examples/kernels/binary_ops.py":142:14)
#loc20 = loc("examples/kernels/binary_ops.py":143:14)
#loc21 = loc("examples/kernels/binary_ops.py":144:14)
#loc22 = loc("examples/kernels/binary_ops.py":145:26)
#loc23 = loc("examples/kernels/binary_ops.py":145:14)
#loc24 = loc("examples/kernels/binary_ops.py":146:26)
#loc25 = loc("examples/kernels/binary_ops.py":146:14)
#loc26 = loc("examples/kernels/binary_ops.py":147:14)
#loc27 = loc("examples/kernels/binary_ops.py":156:23)
#loc28 = loc("examples/kernels/binary_ops.py":156:51)
#loc29 = loc("examples/kernels/binary_ops.py":156:38)
#loc30 = loc("examples/kernels/binary_ops.py":156:68)
#loc31 = loc("examples/kernels/binary_ops.py":157:23)
#loc32 = loc("examples/kernels/binary_ops.py":157:51)
#loc33 = loc("examples/kernels/binary_ops.py":157:38)
#loc34 = loc("examples/kernels/binary_ops.py":157:68)
#loc35 = loc("examples/kernels/binary_ops.py":158:26)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:71)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:71)
#loc46 = loc("examples/kernels/binary_ops.py":160:52)
#loc47 = loc("examples/kernels/binary_ops.py":160:22)
#loc48 = loc("examples/kernels/binary_ops.py":167:27)
#loc49 = loc("examples/kernels/binary_ops.py":168:33)
#loc50 = loc("examples/kernels/binary_ops.py":168:22)
#loc51 = loc("examples/kernels/binary_ops.py":171:40)
#loc52 = loc("examples/kernels/binary_ops.py":171:59)
#loc53 = loc("examples/kernels/binary_ops.py":171:55)
#loc54 = loc("examples/kernels/binary_ops.py":171:51)
#loc55 = loc("examples/kernels/binary_ops.py":171:20)
#loc56 = loc("examples/kernels/binary_ops.py":172:40)
#loc57 = loc("examples/kernels/binary_ops.py":172:59)
#loc58 = loc("examples/kernels/binary_ops.py":172:55)
#loc59 = loc("examples/kernels/binary_ops.py":172:51)
#loc60 = loc("examples/kernels/binary_ops.py":172:20)
#loc61 = loc("examples/kernels/binary_ops.py":174:35)
#loc62 = loc("examples/kernels/binary_ops.py":176:18)
#loc63 = loc("examples/kernels/binary_ops.py":177:33)
#loc64 = loc("examples/kernels/binary_ops.py":177:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:8)
#loc66 = loc("examples/kernels/binary_ops.py":182:23)
#loc67 = loc("examples/kernels/binary_ops.py":186:22)
#loc68 = loc("examples/kernels/binary_ops.py":186:50)
#loc69 = loc("examples/kernels/binary_ops.py":186:37)
#loc70 = loc("examples/kernels/binary_ops.py":187:22)
#loc71 = loc("examples/kernels/binary_ops.py":187:50)
#loc72 = loc("examples/kernels/binary_ops.py":187:37)
#loc73 = loc("examples/kernels/binary_ops.py":188:41)
#loc74 = loc("examples/kernels/binary_ops.py":188:33)
#loc75 = loc("examples/kernels/binary_ops.py":188:21)
#loc76 = loc("examples/kernels/binary_ops.py":188:72)
#loc77 = loc("examples/kernels/binary_ops.py":188:64)
#loc78 = loc("examples/kernels/binary_ops.py":188:52)
#loc79 = loc("examples/kernels/binary_ops.py":189:22)
#loc80 = loc("examples/kernels/binary_ops.py":189:33)
#loc81 = loc("examples/kernels/binary_ops.py":189:47)
#loc82 = loc("examples/kernels/binary_ops.py":189:58)
#loc83 = loc("examples/kernels/binary_ops.py":189:39)
#loc84 = loc("examples/kernels/binary_ops.py":190:21)
#loc85 = loc("examples/kernels/binary_ops.py":190:4)
#loc87 = loc(unknown)
#loc88 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc89 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc90 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:11)
#loc91 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":113:0)
#loc92 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:31)
#loc93 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:11)
#loc94 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:4)
#loc95 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:16)
#loc96 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:4)


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @cdiv__i32__(1,)cconstexpr_16_) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc86 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc1)
    %1 = tt.call @"cdiv__i32__(1,)cconstexpr_32_"(%arg3) : (i32) -> i32 loc(#loc2)
    %2 = tt.call @"cdiv__i32__(1,)cconstexpr_32_"(%arg4) : (i32) -> i32 loc(#loc3)
    %c4_i32 = arith.constant 4 : i32 loc(#loc4)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc4)
    %3 = arith.extsi %c4_i32_0 : i32 to i64 loc(#loc4)
    %4 = arith.extsi %2 : i32 to i64 loc(#loc4)
    %5 = arith.muli %3, %4 : i64 loc(#loc4)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc4)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc4)
    %6 = arith.cmpi sle, %5, %c2147483647_i64 : i64 loc(#loc4)
    %7 = arith.cmpi sge, %5, %c-2147483648_i64 : i64 loc(#loc4)
    %8 = arith.andi %6, %7 : i1 loc(#loc4)
    %9 = arith.muli %c4_i32_0, %2 : i32 loc(#loc4)
    %10 = arith.divsi %0, %9 : i32 loc(#loc5)
    %c4_i32_1 = arith.constant 4 : i32 loc(#loc6)
    %c4_i32_2 = arith.constant 4 : i32 loc(#loc6)
    %11 = arith.extsi %10 : i32 to i64 loc(#loc6)
    %12 = arith.extsi %c4_i32_2 : i32 to i64 loc(#loc6)
    %13 = arith.muli %11, %12 : i64 loc(#loc6)
    %c2147483647_i64_3 = arith.constant 2147483647 : i64 loc(#loc6)
    %c-2147483648_i64_4 = arith.constant -2147483648 : i64 loc(#loc6)
    %14 = arith.cmpi sle, %13, %c2147483647_i64_3 : i64 loc(#loc6)
    %15 = arith.cmpi sge, %13, %c-2147483648_i64_4 : i64 loc(#loc6)
    %16 = arith.andi %14, %15 : i1 loc(#loc6)
    %17 = arith.muli %10, %c4_i32_2 : i32 loc(#loc6)
    %18 = arith.extsi %1 : i32 to i64 loc(#loc7)
    %19 = arith.extsi %17 : i32 to i64 loc(#loc7)
    %20 = arith.subi %18, %19 : i64 loc(#loc7)
    %c2147483647_i64_5 = arith.constant 2147483647 : i64 loc(#loc7)
    %c-2147483648_i64_6 = arith.constant -2147483648 : i64 loc(#loc7)
    %21 = arith.cmpi sle, %20, %c2147483647_i64_5 : i64 loc(#loc7)
    %22 = arith.cmpi sge, %20, %c-2147483648_i64_6 : i64 loc(#loc7)
    %23 = arith.andi %21, %22 : i1 loc(#loc7)
    %24 = arith.subi %1, %17 : i32 loc(#loc7)
    %c4_i32_7 = arith.constant 4 : i32 loc(#loc8)
    %25 = arith.minsi %24, %c4_i32_7 : i32 loc(#loc8)
    %26 = arith.remsi %0, %9 : i32 loc(#loc9)
    %27 = arith.remsi %26, %25 : i32 loc(#loc10)
    %28 = arith.extsi %17 : i32 to i64 loc(#loc11)
    %29 = arith.extsi %27 : i32 to i64 loc(#loc11)
    %30 = arith.addi %28, %29 : i64 loc(#loc11)
    %c2147483647_i64_8 = arith.constant 2147483647 : i64 loc(#loc11)
    %c-2147483648_i64_9 = arith.constant -2147483648 : i64 loc(#loc11)
    %31 = arith.cmpi sle, %30, %c2147483647_i64_8 : i64 loc(#loc11)
    %32 = arith.cmpi sge, %30, %c-2147483648_i64_9 : i64 loc(#loc11)
    %33 = arith.andi %31, %32 : i1 loc(#loc11)
    %34 = arith.addi %17, %27 : i32 loc(#loc11)
    %35 = arith.remsi %0, %9 : i32 loc(#loc12)
    %36 = arith.divsi %35, %25 : i32 loc(#loc13)
    %c0_i32 = arith.constant 0 : i32 loc(#loc14)
    %37 = arith.cmpi sge, %34, %c0_i32 : i32 loc(#loc14)
    llvm.intr.assume %37 : i1 loc(#loc15)
    %c0_i32_10 = arith.constant 0 : i32 loc(#loc16)
    %38 = arith.cmpi sge, %36, %c0_i32_10 : i32 loc(#loc16)
    llvm.intr.assume %38 : i1 loc(#loc17)
    %c0_i32_11 = arith.constant 0 : i32 loc(#loc18)
    %39 = arith.cmpi sgt, %arg6, %c0_i32_11 : i32 loc(#loc18)
    llvm.intr.assume %39 : i1 loc(#loc19)
    %true = arith.constant true loc(#loc20)
    llvm.intr.assume %true : i1 loc(#loc20)
    %true_12 = arith.constant true loc(#loc21)
    llvm.intr.assume %true_12 : i1 loc(#loc21)
    %c0_i32_13 = arith.constant 0 : i32 loc(#loc22)
    %40 = arith.cmpi sgt, %arg7, %c0_i32_13 : i32 loc(#loc22)
    llvm.intr.assume %40 : i1 loc(#loc23)
    %c0_i32_14 = arith.constant 0 : i32 loc(#loc24)
    %41 = arith.cmpi sgt, %arg8, %c0_i32_14 : i32 loc(#loc24)
    llvm.intr.assume %41 : i1 loc(#loc25)
    %true_15 = arith.constant true loc(#loc26)
    llvm.intr.assume %true_15 : i1 loc(#loc26)
    %c32_i32 = arith.constant 32 : i32 loc(#loc27)
    %c32_i32_16 = arith.constant 32 : i32 loc(#loc27)
    %42 = arith.extsi %34 : i32 to i64 loc(#loc27)
    %43 = arith.extsi %c32_i32_16 : i32 to i64 loc(#loc27)
    %44 = arith.muli %42, %43 : i64 loc(#loc27)
    %c2147483647_i64_17 = arith.constant 2147483647 : i64 loc(#loc27)
    %c-2147483648_i64_18 = arith.constant -2147483648 : i64 loc(#loc27)
    %45 = arith.cmpi sle, %44, %c2147483647_i64_17 : i64 loc(#loc27)
    %46 = arith.cmpi sge, %44, %c-2147483648_i64_18 : i64 loc(#loc27)
    %47 = arith.andi %45, %46 : i1 loc(#loc27)
    %48 = arith.muli %34, %c32_i32_16 : i32 loc(#loc27)
    %49 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc28)
    %50 = tt.splat %48 : i32 -> tensor<32xi32> loc(#loc29)
    %51 = arith.extsi %50 : tensor<32xi32> to tensor<32xi64> loc(#loc29)
    %52 = arith.extsi %49 : tensor<32xi32> to tensor<32xi64> loc(#loc29)
    %53 = arith.addi %51, %52 : tensor<32xi64> loc(#loc29)
    %c2147483647_i64_19 = arith.constant 2147483647 : i64 loc(#loc29)
    %c-2147483648_i64_20 = arith.constant -2147483648 : i64 loc(#loc29)
    %cst = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc29)
    %54 = arith.cmpi sle, %53, %cst : tensor<32xi64> loc(#loc29)
    %cst_21 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc29)
    %55 = arith.cmpi sge, %53, %cst_21 : tensor<32xi64> loc(#loc29)
    %56 = arith.andi %54, %55 : tensor<32xi1> loc(#loc29)
    %57 = arith.addi %50, %49 : tensor<32xi32> loc(#loc29)
    %58 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc30)
    %59 = arith.remsi %57, %58 : tensor<32xi32> loc(#loc30)
    %c32_i32_22 = arith.constant 32 : i32 loc(#loc31)
    %c32_i32_23 = arith.constant 32 : i32 loc(#loc31)
    %60 = arith.extsi %36 : i32 to i64 loc(#loc31)
    %61 = arith.extsi %c32_i32_23 : i32 to i64 loc(#loc31)
    %62 = arith.muli %60, %61 : i64 loc(#loc31)
    %c2147483647_i64_24 = arith.constant 2147483647 : i64 loc(#loc31)
    %c-2147483648_i64_25 = arith.constant -2147483648 : i64 loc(#loc31)
    %63 = arith.cmpi sle, %62, %c2147483647_i64_24 : i64 loc(#loc31)
    %64 = arith.cmpi sge, %62, %c-2147483648_i64_25 : i64 loc(#loc31)
    %65 = arith.andi %63, %64 : i1 loc(#loc31)
    %66 = arith.muli %36, %c32_i32_23 : i32 loc(#loc31)
    %67 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc32)
    %68 = tt.splat %66 : i32 -> tensor<32xi32> loc(#loc33)
    %69 = arith.extsi %68 : tensor<32xi32> to tensor<32xi64> loc(#loc33)
    %70 = arith.extsi %67 : tensor<32xi32> to tensor<32xi64> loc(#loc33)
    %71 = arith.addi %69, %70 : tensor<32xi64> loc(#loc33)
    %c2147483647_i64_26 = arith.constant 2147483647 : i64 loc(#loc33)
    %c-2147483648_i64_27 = arith.constant -2147483648 : i64 loc(#loc33)
    %cst_28 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc33)
    %72 = arith.cmpi sle, %71, %cst_28 : tensor<32xi64> loc(#loc33)
    %cst_29 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc33)
    %73 = arith.cmpi sge, %71, %cst_29 : tensor<32xi64> loc(#loc33)
    %74 = arith.andi %72, %73 : tensor<32xi1> loc(#loc33)
    %75 = arith.addi %68, %67 : tensor<32xi32> loc(#loc33)
    %76 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc34)
    %77 = arith.remsi %75, %76 : tensor<32xi32> loc(#loc34)
    %78 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc35)
    %79 = tt.expand_dims %59 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc36)
    %80 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc37)
    %81 = arith.extsi %79 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc37)
    %82 = arith.extsi %80 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc37)
    %83 = arith.muli %81, %82 : tensor<32x1xi64> loc(#loc37)
    %c2147483647_i64_30 = arith.constant 2147483647 : i64 loc(#loc37)
    %c-2147483648_i64_31 = arith.constant -2147483648 : i64 loc(#loc37)
    %cst_32 = arith.constant dense<2147483647> : tensor<32x1xi64> loc(#loc37)
    %84 = arith.cmpi sle, %83, %cst_32 : tensor<32x1xi64> loc(#loc37)
    %cst_33 = arith.constant dense<-2147483648> : tensor<32x1xi64> loc(#loc37)
    %85 = arith.cmpi sge, %83, %cst_33 : tensor<32x1xi64> loc(#loc37)
    %86 = arith.andi %84, %85 : tensor<32x1xi1> loc(#loc37)
    %87 = arith.muli %79, %80 : tensor<32x1xi32> loc(#loc37)
    %88 = tt.expand_dims %78 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc38)
    %c1_i32 = arith.constant 1 : i32 loc(#loc39)
    %c1_i32_34 = arith.constant 1 : i32 loc(#loc39)
    %cst_35 = arith.constant dense<1> : tensor<1x16xi32> loc(#loc39)
    %89 = arith.extsi %88 : tensor<1x16xi32> to tensor<1x16xi64> loc(#loc39)
    %90 = arith.extsi %cst_35 : tensor<1x16xi32> to tensor<1x16xi64> loc(#loc39)
    %91 = arith.muli %89, %90 : tensor<1x16xi64> loc(#loc39)
    %c2147483647_i64_36 = arith.constant 2147483647 : i64 loc(#loc39)
    %c-2147483648_i64_37 = arith.constant -2147483648 : i64 loc(#loc39)
    %cst_38 = arith.constant dense<2147483647> : tensor<1x16xi64> loc(#loc39)
    %92 = arith.cmpi sle, %91, %cst_38 : tensor<1x16xi64> loc(#loc39)
    %cst_39 = arith.constant dense<-2147483648> : tensor<1x16xi64> loc(#loc39)
    %93 = arith.cmpi sge, %91, %cst_39 : tensor<1x16xi64> loc(#loc39)
    %94 = arith.andi %92, %93 : tensor<1x16xi1> loc(#loc39)
    %95 = arith.muli %88, %cst_35 : tensor<1x16xi32> loc(#loc39)
    %96 = tt.broadcast %87 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc40)
    %97 = tt.broadcast %95 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc40)
    %98 = arith.extsi %96 : tensor<32x16xi32> to tensor<32x16xi64> loc(#loc40)
    %99 = arith.extsi %97 : tensor<32x16xi32> to tensor<32x16xi64> loc(#loc40)
    %100 = arith.addi %98, %99 : tensor<32x16xi64> loc(#loc40)
    %c2147483647_i64_40 = arith.constant 2147483647 : i64 loc(#loc40)
    %c-2147483648_i64_41 = arith.constant -2147483648 : i64 loc(#loc40)
    %cst_42 = arith.constant dense<2147483647> : tensor<32x16xi64> loc(#loc40)
    %101 = arith.cmpi sle, %100, %cst_42 : tensor<32x16xi64> loc(#loc40)
    %cst_43 = arith.constant dense<-2147483648> : tensor<32x16xi64> loc(#loc40)
    %102 = arith.cmpi sge, %100, %cst_43 : tensor<32x16xi64> loc(#loc40)
    %103 = arith.andi %101, %102 : tensor<32x16xi1> loc(#loc40)
    %104 = arith.addi %96, %97 : tensor<32x16xi32> loc(#loc40)
    %105 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc41)
    %106 = tt.addptr %105, %104 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc41)
    %107 = tt.expand_dims %78 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc42)
    %108 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc43)
    %109 = arith.extsi %107 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc43)
    %110 = arith.extsi %108 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc43)
    %111 = arith.muli %109, %110 : tensor<16x1xi64> loc(#loc43)
    %c2147483647_i64_44 = arith.constant 2147483647 : i64 loc(#loc43)
    %c-2147483648_i64_45 = arith.constant -2147483648 : i64 loc(#loc43)
    %cst_46 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc43)
    %112 = arith.cmpi sle, %111, %cst_46 : tensor<16x1xi64> loc(#loc43)
    %cst_47 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc43)
    %113 = arith.cmpi sge, %111, %cst_47 : tensor<16x1xi64> loc(#loc43)
    %114 = arith.andi %112, %113 : tensor<16x1xi1> loc(#loc43)
    %115 = arith.muli %107, %108 : tensor<16x1xi32> loc(#loc43)
    %116 = tt.expand_dims %77 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc44)
    %c1_i32_48 = arith.constant 1 : i32 loc(#loc45)
    %c1_i32_49 = arith.constant 1 : i32 loc(#loc45)
    %cst_50 = arith.constant dense<1> : tensor<1x32xi32> loc(#loc45)
    %117 = arith.extsi %116 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc45)
    %118 = arith.extsi %cst_50 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc45)
    %119 = arith.muli %117, %118 : tensor<1x32xi64> loc(#loc45)
    %c2147483647_i64_51 = arith.constant 2147483647 : i64 loc(#loc45)
    %c-2147483648_i64_52 = arith.constant -2147483648 : i64 loc(#loc45)
    %cst_53 = arith.constant dense<2147483647> : tensor<1x32xi64> loc(#loc45)
    %120 = arith.cmpi sle, %119, %cst_53 : tensor<1x32xi64> loc(#loc45)
    %cst_54 = arith.constant dense<-2147483648> : tensor<1x32xi64> loc(#loc45)
    %121 = arith.cmpi sge, %119, %cst_54 : tensor<1x32xi64> loc(#loc45)
    %122 = arith.andi %120, %121 : tensor<1x32xi1> loc(#loc45)
    %123 = arith.muli %116, %cst_50 : tensor<1x32xi32> loc(#loc45)
    %124 = tt.broadcast %115 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc46)
    %125 = tt.broadcast %123 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc46)
    %126 = arith.extsi %124 : tensor<16x32xi32> to tensor<16x32xi64> loc(#loc46)
    %127 = arith.extsi %125 : tensor<16x32xi32> to tensor<16x32xi64> loc(#loc46)
    %128 = arith.addi %126, %127 : tensor<16x32xi64> loc(#loc46)
    %c2147483647_i64_55 = arith.constant 2147483647 : i64 loc(#loc46)
    %c-2147483648_i64_56 = arith.constant -2147483648 : i64 loc(#loc46)
    %cst_57 = arith.constant dense<2147483647> : tensor<16x32xi64> loc(#loc46)
    %129 = arith.cmpi sle, %128, %cst_57 : tensor<16x32xi64> loc(#loc46)
    %cst_58 = arith.constant dense<-2147483648> : tensor<16x32xi64> loc(#loc46)
    %130 = arith.cmpi sge, %128, %cst_58 : tensor<16x32xi64> loc(#loc46)
    %131 = arith.andi %129, %130 : tensor<16x32xi1> loc(#loc46)
    %132 = arith.addi %124, %125 : tensor<16x32xi32> loc(#loc46)
    %133 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc47)
    %134 = tt.addptr %133, %132 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc47)
    %135 = tt.call @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() : () -> tensor<32x32xf32> loc(#loc48)
    %136 = tt.call @"cdiv__i32__(1,)cconstexpr_16_"(%arg5) : (i32) -> i32 loc(#loc49)
    %c0_i32_59 = arith.constant 0 : i32 loc(#loc50)
    %c1_i32_60 = arith.constant 1 : i32 loc(#loc50)
    %137 = arith.bitcast %c0_i32_59 : i32 to i32 loc(#loc50)
    %138 = arith.bitcast %136 : i32 to i32 loc(#loc50)
    %139 = arith.bitcast %c1_i32_60 : i32 to i32 loc(#loc50)
    %140 = ub.poison : i32 loc(#loc50)
    %141:3 = scf.for %arg9 = %137 to %138 step %139 iter_args(%arg10 = %135, %arg11 = %106, %arg12 = %134) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %206 = tt.expand_dims %78 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc51)
      %c16_i32 = arith.constant 16 : i32 loc(#loc52)
      %c16_i32_88 = arith.constant 16 : i32 loc(#loc52)
      %207 = arith.extsi %arg9 : i32 to i64 loc(#loc52)
      %208 = arith.extsi %c16_i32_88 : i32 to i64 loc(#loc52)
      %209 = arith.muli %207, %208 : i64 loc(#loc52)
      %c2147483647_i64_89 = arith.constant 2147483647 : i64 loc(#loc52)
      %c-2147483648_i64_90 = arith.constant -2147483648 : i64 loc(#loc52)
      %210 = arith.cmpi sle, %209, %c2147483647_i64_89 : i64 loc(#loc52)
      %211 = arith.cmpi sge, %209, %c-2147483648_i64_90 : i64 loc(#loc52)
      %212 = arith.andi %210, %211 : i1 loc(#loc52)
      %213 = arith.muli %arg9, %c16_i32_88 : i32 loc(#loc52)
      %214 = arith.extsi %arg5 : i32 to i64 loc(#loc53)
      %215 = arith.extsi %213 : i32 to i64 loc(#loc53)
      %216 = arith.subi %214, %215 : i64 loc(#loc53)
      %c2147483647_i64_91 = arith.constant 2147483647 : i64 loc(#loc53)
      %c-2147483648_i64_92 = arith.constant -2147483648 : i64 loc(#loc53)
      %217 = arith.cmpi sle, %216, %c2147483647_i64_91 : i64 loc(#loc53)
      %218 = arith.cmpi sge, %216, %c-2147483648_i64_92 : i64 loc(#loc53)
      %219 = arith.andi %217, %218 : i1 loc(#loc53)
      %220 = arith.subi %arg5, %213 : i32 loc(#loc53)
      %221 = tt.splat %220 : i32 -> tensor<1x16xi32> loc(#loc54)
      %222 = arith.cmpi slt, %206, %221 : tensor<1x16xi32> loc(#loc54)
      %cst_93 = arith.constant 0.000000e+00 : f32 loc(#loc55)
      %223 = tt.broadcast %222 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc55)
      %cst_94 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc55)
      %224 = tt.load %arg11, %223, %cst_94 : tensor<32x16x!tt.ptr<f32>> loc(#loc55)
      %225 = tt.expand_dims %78 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc56)
      %c16_i32_95 = arith.constant 16 : i32 loc(#loc57)
      %c16_i32_96 = arith.constant 16 : i32 loc(#loc57)
      %226 = arith.extsi %arg9 : i32 to i64 loc(#loc57)
      %227 = arith.extsi %c16_i32_96 : i32 to i64 loc(#loc57)
      %228 = arith.muli %226, %227 : i64 loc(#loc57)
      %c2147483647_i64_97 = arith.constant 2147483647 : i64 loc(#loc57)
      %c-2147483648_i64_98 = arith.constant -2147483648 : i64 loc(#loc57)
      %229 = arith.cmpi sle, %228, %c2147483647_i64_97 : i64 loc(#loc57)
      %230 = arith.cmpi sge, %228, %c-2147483648_i64_98 : i64 loc(#loc57)
      %231 = arith.andi %229, %230 : i1 loc(#loc57)
      %232 = arith.muli %arg9, %c16_i32_96 : i32 loc(#loc57)
      %233 = arith.extsi %arg5 : i32 to i64 loc(#loc58)
      %234 = arith.extsi %232 : i32 to i64 loc(#loc58)
      %235 = arith.subi %233, %234 : i64 loc(#loc58)
      %c2147483647_i64_99 = arith.constant 2147483647 : i64 loc(#loc58)
      %c-2147483648_i64_100 = arith.constant -2147483648 : i64 loc(#loc58)
      %236 = arith.cmpi sle, %235, %c2147483647_i64_99 : i64 loc(#loc58)
      %237 = arith.cmpi sge, %235, %c-2147483648_i64_100 : i64 loc(#loc58)
      %238 = arith.andi %236, %237 : i1 loc(#loc58)
      %239 = arith.subi %arg5, %232 : i32 loc(#loc58)
      %240 = tt.splat %239 : i32 -> tensor<16x1xi32> loc(#loc59)
      %241 = arith.cmpi slt, %225, %240 : tensor<16x1xi32> loc(#loc59)
      %cst_101 = arith.constant 0.000000e+00 : f32 loc(#loc60)
      %242 = tt.broadcast %241 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc60)
      %cst_102 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc60)
      %243 = tt.load %arg12, %242, %cst_102 : tensor<16x32x!tt.ptr<f32>> loc(#loc60)
      %cst_103 = arith.constant 0.000000e+00 : f32 loc(#loc61)
      %244 = tt.dot %224, %243, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc61)
      %c16_i32_104 = arith.constant 16 : i32 loc(#loc62)
      %cst_105 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc62)
      %245 = tt.addptr %arg11, %cst_105 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc62)
      %c16_i32_106 = arith.constant 16 : i32 loc(#loc63)
      %c16_i32_107 = arith.constant 16 : i32 loc(#loc63)
      %246 = arith.extsi %c16_i32_107 : i32 to i64 loc(#loc63)
      %247 = arith.extsi %arg7 : i32 to i64 loc(#loc63)
      %248 = arith.muli %246, %247 : i64 loc(#loc63)
      %c2147483647_i64_108 = arith.constant 2147483647 : i64 loc(#loc63)
      %c-2147483648_i64_109 = arith.constant -2147483648 : i64 loc(#loc63)
      %249 = arith.cmpi sle, %248, %c2147483647_i64_108 : i64 loc(#loc63)
      %250 = arith.cmpi sge, %248, %c-2147483648_i64_109 : i64 loc(#loc63)
      %251 = arith.andi %249, %250 : i1 loc(#loc63)
      %252 = arith.muli %c16_i32_107, %arg7 : i32 loc(#loc63)
      %253 = tt.splat %252 : i32 -> tensor<16x32xi32> loc(#loc64)
      %254 = tt.addptr %arg12, %253 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc64)
      scf.yield %244, %245, %254 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc65)
    } loc(#loc50)
    %142 = arith.truncf %141#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc66)
    %c32_i32_61 = arith.constant 32 : i32 loc(#loc67)
    %c32_i32_62 = arith.constant 32 : i32 loc(#loc67)
    %143 = arith.extsi %34 : i32 to i64 loc(#loc67)
    %144 = arith.extsi %c32_i32_62 : i32 to i64 loc(#loc67)
    %145 = arith.muli %143, %144 : i64 loc(#loc67)
    %c2147483647_i64_63 = arith.constant 2147483647 : i64 loc(#loc67)
    %c-2147483648_i64_64 = arith.constant -2147483648 : i64 loc(#loc67)
    %146 = arith.cmpi sle, %145, %c2147483647_i64_63 : i64 loc(#loc67)
    %147 = arith.cmpi sge, %145, %c-2147483648_i64_64 : i64 loc(#loc67)
    %148 = arith.andi %146, %147 : i1 loc(#loc67)
    %149 = arith.muli %34, %c32_i32_62 : i32 loc(#loc67)
    %150 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc68)
    %151 = tt.splat %149 : i32 -> tensor<32xi32> loc(#loc69)
    %152 = arith.extsi %151 : tensor<32xi32> to tensor<32xi64> loc(#loc69)
    %153 = arith.extsi %150 : tensor<32xi32> to tensor<32xi64> loc(#loc69)
    %154 = arith.addi %152, %153 : tensor<32xi64> loc(#loc69)
    %c2147483647_i64_65 = arith.constant 2147483647 : i64 loc(#loc69)
    %c-2147483648_i64_66 = arith.constant -2147483648 : i64 loc(#loc69)
    %cst_67 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc69)
    %155 = arith.cmpi sle, %154, %cst_67 : tensor<32xi64> loc(#loc69)
    %cst_68 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc69)
    %156 = arith.cmpi sge, %154, %cst_68 : tensor<32xi64> loc(#loc69)
    %157 = arith.andi %155, %156 : tensor<32xi1> loc(#loc69)
    %158 = arith.addi %151, %150 : tensor<32xi32> loc(#loc69)
    %c32_i32_69 = arith.constant 32 : i32 loc(#loc70)
    %c32_i32_70 = arith.constant 32 : i32 loc(#loc70)
    %159 = arith.extsi %36 : i32 to i64 loc(#loc70)
    %160 = arith.extsi %c32_i32_70 : i32 to i64 loc(#loc70)
    %161 = arith.muli %159, %160 : i64 loc(#loc70)
    %c2147483647_i64_71 = arith.constant 2147483647 : i64 loc(#loc70)
    %c-2147483648_i64_72 = arith.constant -2147483648 : i64 loc(#loc70)
    %162 = arith.cmpi sle, %161, %c2147483647_i64_71 : i64 loc(#loc70)
    %163 = arith.cmpi sge, %161, %c-2147483648_i64_72 : i64 loc(#loc70)
    %164 = arith.andi %162, %163 : i1 loc(#loc70)
    %165 = arith.muli %36, %c32_i32_70 : i32 loc(#loc70)
    %166 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc71)
    %167 = tt.splat %165 : i32 -> tensor<32xi32> loc(#loc72)
    %168 = arith.extsi %167 : tensor<32xi32> to tensor<32xi64> loc(#loc72)
    %169 = arith.extsi %166 : tensor<32xi32> to tensor<32xi64> loc(#loc72)
    %170 = arith.addi %168, %169 : tensor<32xi64> loc(#loc72)
    %c2147483647_i64_73 = arith.constant 2147483647 : i64 loc(#loc72)
    %c-2147483648_i64_74 = arith.constant -2147483648 : i64 loc(#loc72)
    %cst_75 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc72)
    %171 = arith.cmpi sle, %170, %cst_75 : tensor<32xi64> loc(#loc72)
    %cst_76 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc72)
    %172 = arith.cmpi sge, %170, %cst_76 : tensor<32xi64> loc(#loc72)
    %173 = arith.andi %171, %172 : tensor<32xi1> loc(#loc72)
    %174 = arith.addi %167, %166 : tensor<32xi32> loc(#loc72)
    %175 = tt.expand_dims %158 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc73)
    %176 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc74)
    %177 = arith.extsi %176 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc74)
    %178 = arith.extsi %175 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc74)
    %179 = arith.muli %177, %178 : tensor<32x1xi64> loc(#loc74)
    %c2147483647_i64_77 = arith.constant 2147483647 : i64 loc(#loc74)
    %c-2147483648_i64_78 = arith.constant -2147483648 : i64 loc(#loc74)
    %cst_79 = arith.constant dense<2147483647> : tensor<32x1xi64> loc(#loc74)
    %180 = arith.cmpi sle, %179, %cst_79 : tensor<32x1xi64> loc(#loc74)
    %cst_80 = arith.constant dense<-2147483648> : tensor<32x1xi64> loc(#loc74)
    %181 = arith.cmpi sge, %179, %cst_80 : tensor<32x1xi64> loc(#loc74)
    %182 = arith.andi %180, %181 : tensor<32x1xi1> loc(#loc74)
    %183 = arith.muli %176, %175 : tensor<32x1xi32> loc(#loc74)
    %184 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc75)
    %185 = tt.addptr %184, %183 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc75)
    %186 = tt.expand_dims %174 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc76)
    %c1_i32_81 = arith.constant 1 : i32 loc(#loc77)
    %c1_i32_82 = arith.constant 1 : i32 loc(#loc77)
    %cst_83 = arith.constant dense<1> : tensor<1x32xi32> loc(#loc77)
    %187 = arith.extsi %cst_83 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc77)
    %188 = arith.extsi %186 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc77)
    %189 = arith.muli %187, %188 : tensor<1x32xi64> loc(#loc77)
    %c2147483647_i64_84 = arith.constant 2147483647 : i64 loc(#loc77)
    %c-2147483648_i64_85 = arith.constant -2147483648 : i64 loc(#loc77)
    %cst_86 = arith.constant dense<2147483647> : tensor<1x32xi64> loc(#loc77)
    %190 = arith.cmpi sle, %189, %cst_86 : tensor<1x32xi64> loc(#loc77)
    %cst_87 = arith.constant dense<-2147483648> : tensor<1x32xi64> loc(#loc77)
    %191 = arith.cmpi sge, %189, %cst_87 : tensor<1x32xi64> loc(#loc77)
    %192 = arith.andi %190, %191 : tensor<1x32xi1> loc(#loc77)
    %193 = arith.muli %cst_83, %186 : tensor<1x32xi32> loc(#loc77)
    %194 = tt.broadcast %185 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc78)
    %195 = tt.broadcast %193 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc78)
    %196 = tt.addptr %194, %195 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc78)
    %197 = tt.expand_dims %158 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc79)
    %198 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc80)
    %199 = arith.cmpi slt, %197, %198 : tensor<32x1xi32> loc(#loc80)
    %200 = tt.expand_dims %174 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc81)
    %201 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc82)
    %202 = arith.cmpi slt, %200, %201 : tensor<1x32xi32> loc(#loc82)
    %203 = tt.broadcast %199 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc83)
    %204 = tt.broadcast %202 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc83)
    %205 = arith.andi %203, %204 : tensor<32x32xi1> loc(#loc83)
    tt.store %196, %142, %205 : tensor<32x32x!tt.ptr<f16>> loc(#loc84)
    tt.return loc(#loc85)
  } loc(#loc)
  tt.func private @"cdiv__i32__(1,)cconstexpr_32_"(%arg0: i32 loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)) -> i32 attributes {noinline = false} {
    %c32_i32 = arith.constant 32 : i32 loc(#loc87)
    %c31_i32 = arith.constant 31 : i32 loc(#loc88)
    %0 = arith.addi %arg0, %c31_i32 : i32 loc(#loc88)
    %1 = arith.divsi %0, %c32_i32 : i32 loc(#loc89)
    tt.return %1 : i32 loc(#loc90)
  } loc(#loc86)
  tt.func private @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() -> tensor<32x32xf32> attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc92)
    tt.return %cst : tensor<32x32xf32> loc(#loc93)
  } loc(#loc91)
  tt.func private @"cdiv__i32__(1,)cconstexpr_16_"(%arg0: i32 loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)) -> i32 attributes {noinline = false} {
    %c16_i32 = arith.constant 16 : i32 loc(#loc94)
    %c16_i32_0 = arith.constant 16 : i32 loc(#loc94)
    %0 = arith.extsi %arg0 : i32 to i64 loc(#loc94)
    %1 = arith.extsi %c16_i32_0 : i32 to i64 loc(#loc94)
    %2 = arith.addi %0, %1 : i64 loc(#loc94)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc94)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc94)
    %3 = arith.cmpi sle, %2, %c2147483647_i64 : i64 loc(#loc94)
    %4 = arith.cmpi sge, %2, %c-2147483648_i64 : i64 loc(#loc94)
    %5 = arith.andi %3, %4 : i1 loc(#loc94)
    %6 = arith.addi %arg0, %c16_i32_0 : i32 loc(#loc94)
    %c1_i32 = arith.constant 1 : i32 loc(#loc88)
    %c1_i32_1 = arith.constant 1 : i32 loc(#loc88)
    %7 = arith.extsi %6 : i32 to i64 loc(#loc88)
    %8 = arith.extsi %c1_i32_1 : i32 to i64 loc(#loc88)
    %9 = arith.subi %7, %8 : i64 loc(#loc88)
    %c2147483647_i64_2 = arith.constant 2147483647 : i64 loc(#loc88)
    %c-2147483648_i64_3 = arith.constant -2147483648 : i64 loc(#loc88)
    %10 = arith.cmpi sle, %9, %c2147483647_i64_2 : i64 loc(#loc88)
    %11 = arith.cmpi sge, %9, %c-2147483648_i64_3 : i64 loc(#loc88)
    %12 = arith.andi %10, %11 : i1 loc(#loc88)
    %13 = arith.subi %6, %c1_i32_1 : i32 loc(#loc88)
    %c16_i32_4 = arith.constant 16 : i32 loc(#loc89)
    %c16_i32_5 = arith.constant 16 : i32 loc(#loc89)
    %14 = arith.divsi %13, %c16_i32_5 : i32 loc(#loc89)
    tt.return %14 : i32 loc(#loc90)
  ^bb1:  // no predecessors
    %15 = ub.poison : i32 loc(#loc95)
    tt.return %15 : i32 loc(#loc95)
  } loc(#loc86)
} loc(#loc)
#loc1 = loc("examples/kernels/binary_ops.py":126:24)
#loc2 = loc("examples/kernels/binary_ops.py":127:27)
#loc3 = loc("examples/kernels/binary_ops.py":128:27)
#loc4 = loc("examples/kernels/binary_ops.py":129:38)
#loc5 = loc("examples/kernels/binary_ops.py":130:22)
#loc6 = loc("examples/kernels/binary_ops.py":131:29)
#loc7 = loc("examples/kernels/binary_ops.py":132:35)
#loc8 = loc("examples/kernels/binary_ops.py":132:48)
#loc9 = loc("examples/kernels/binary_ops.py":133:34)
#loc10 = loc("examples/kernels/binary_ops.py":133:54)
#loc11 = loc("examples/kernels/binary_ops.py":133:27)
#loc12 = loc("examples/kernels/binary_ops.py":134:19)
#loc13 = loc("examples/kernels/binary_ops.py":134:40)
#loc14 = loc("examples/kernels/binary_ops.py":140:23)
#loc15 = loc("examples/kernels/binary_ops.py":140:14)
#loc16 = loc("examples/kernels/binary_ops.py":141:23)
#loc17 = loc("examples/kernels/binary_ops.py":141:14)
#loc18 = loc("examples/kernels/binary_ops.py":142:26)
#loc19 = loc("examples/kernels/binary_ops.py":142:14)
#loc20 = loc("examples/kernels/binary_ops.py":143:14)
#loc21 = loc("examples/kernels/binary_ops.py":144:14)
#loc22 = loc("examples/kernels/binary_ops.py":145:26)
#loc23 = loc("examples/kernels/binary_ops.py":145:14)
#loc24 = loc("examples/kernels/binary_ops.py":146:26)
#loc25 = loc("examples/kernels/binary_ops.py":146:14)
#loc26 = loc("examples/kernels/binary_ops.py":147:14)
#loc27 = loc("examples/kernels/binary_ops.py":156:23)
#loc28 = loc("examples/kernels/binary_ops.py":156:51)
#loc29 = loc("examples/kernels/binary_ops.py":156:38)
#loc30 = loc("examples/kernels/binary_ops.py":156:68)
#loc31 = loc("examples/kernels/binary_ops.py":157:23)
#loc32 = loc("examples/kernels/binary_ops.py":157:51)
#loc33 = loc("examples/kernels/binary_ops.py":157:38)
#loc34 = loc("examples/kernels/binary_ops.py":157:68)
#loc35 = loc("examples/kernels/binary_ops.py":158:26)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:71)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:71)
#loc46 = loc("examples/kernels/binary_ops.py":160:52)
#loc47 = loc("examples/kernels/binary_ops.py":160:22)
#loc48 = loc("examples/kernels/binary_ops.py":167:27)
#loc49 = loc("examples/kernels/binary_ops.py":168:33)
#loc50 = loc("examples/kernels/binary_ops.py":168:22)
#loc51 = loc("examples/kernels/binary_ops.py":171:40)
#loc52 = loc("examples/kernels/binary_ops.py":171:59)
#loc53 = loc("examples/kernels/binary_ops.py":171:55)
#loc54 = loc("examples/kernels/binary_ops.py":171:51)
#loc55 = loc("examples/kernels/binary_ops.py":171:20)
#loc56 = loc("examples/kernels/binary_ops.py":172:40)
#loc57 = loc("examples/kernels/binary_ops.py":172:59)
#loc58 = loc("examples/kernels/binary_ops.py":172:55)
#loc59 = loc("examples/kernels/binary_ops.py":172:51)
#loc60 = loc("examples/kernels/binary_ops.py":172:20)
#loc61 = loc("examples/kernels/binary_ops.py":174:35)
#loc62 = loc("examples/kernels/binary_ops.py":176:18)
#loc63 = loc("examples/kernels/binary_ops.py":177:33)
#loc64 = loc("examples/kernels/binary_ops.py":177:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:8)
#loc66 = loc("examples/kernels/binary_ops.py":182:23)
#loc67 = loc("examples/kernels/binary_ops.py":186:22)
#loc68 = loc("examples/kernels/binary_ops.py":186:50)
#loc69 = loc("examples/kernels/binary_ops.py":186:37)
#loc70 = loc("examples/kernels/binary_ops.py":187:22)
#loc71 = loc("examples/kernels/binary_ops.py":187:50)
#loc72 = loc("examples/kernels/binary_ops.py":187:37)
#loc73 = loc("examples/kernels/binary_ops.py":188:41)
#loc74 = loc("examples/kernels/binary_ops.py":188:33)
#loc75 = loc("examples/kernels/binary_ops.py":188:21)
#loc76 = loc("examples/kernels/binary_ops.py":188:72)
#loc77 = loc("examples/kernels/binary_ops.py":188:64)
#loc78 = loc("examples/kernels/binary_ops.py":188:52)
#loc79 = loc("examples/kernels/binary_ops.py":189:22)
#loc80 = loc("examples/kernels/binary_ops.py":189:33)
#loc81 = loc("examples/kernels/binary_ops.py":189:47)
#loc82 = loc("examples/kernels/binary_ops.py":189:58)
#loc83 = loc("examples/kernels/binary_ops.py":189:39)
#loc84 = loc("examples/kernels/binary_ops.py":190:21)
#loc85 = loc("examples/kernels/binary_ops.py":190:4)
#loc87 = loc(unknown)
#loc88 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc89 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc90 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:11)
#loc91 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":113:0)
#loc92 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:31)
#loc93 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:11)
#loc94 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:16)
#loc95 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:4)


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @matmul_kernel) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc86 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc1)
    %1 = tt.call @"cdiv__i32__(1,)cconstexpr_32_"(%arg3) : (i32) -> i32 loc(#loc2)
    %2 = tt.call @"cdiv__i32__(1,)cconstexpr_32_"(%arg4) : (i32) -> i32 loc(#loc3)
    %c4_i32 = arith.constant 4 : i32 loc(#loc4)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc4)
    %3 = arith.extsi %c4_i32_0 : i32 to i64 loc(#loc4)
    %4 = arith.extsi %2 : i32 to i64 loc(#loc4)
    %5 = arith.muli %3, %4 : i64 loc(#loc4)
    %c2147483647_i64 = arith.constant 2147483647 : i64 loc(#loc4)
    %c-2147483648_i64 = arith.constant -2147483648 : i64 loc(#loc4)
    %6 = arith.cmpi sle, %5, %c2147483647_i64 : i64 loc(#loc4)
    %7 = arith.cmpi sge, %5, %c-2147483648_i64 : i64 loc(#loc4)
    %8 = arith.andi %6, %7 : i1 loc(#loc4)
    %9 = arith.muli %c4_i32_0, %2 : i32 loc(#loc4)
    %10 = arith.divsi %0, %9 : i32 loc(#loc5)
    %c4_i32_1 = arith.constant 4 : i32 loc(#loc6)
    %c4_i32_2 = arith.constant 4 : i32 loc(#loc6)
    %11 = arith.extsi %10 : i32 to i64 loc(#loc6)
    %12 = arith.extsi %c4_i32_2 : i32 to i64 loc(#loc6)
    %13 = arith.muli %11, %12 : i64 loc(#loc6)
    %c2147483647_i64_3 = arith.constant 2147483647 : i64 loc(#loc6)
    %c-2147483648_i64_4 = arith.constant -2147483648 : i64 loc(#loc6)
    %14 = arith.cmpi sle, %13, %c2147483647_i64_3 : i64 loc(#loc6)
    %15 = arith.cmpi sge, %13, %c-2147483648_i64_4 : i64 loc(#loc6)
    %16 = arith.andi %14, %15 : i1 loc(#loc6)
    %17 = arith.muli %10, %c4_i32_2 : i32 loc(#loc6)
    %18 = arith.extsi %1 : i32 to i64 loc(#loc7)
    %19 = arith.extsi %17 : i32 to i64 loc(#loc7)
    %20 = arith.subi %18, %19 : i64 loc(#loc7)
    %c2147483647_i64_5 = arith.constant 2147483647 : i64 loc(#loc7)
    %c-2147483648_i64_6 = arith.constant -2147483648 : i64 loc(#loc7)
    %21 = arith.cmpi sle, %20, %c2147483647_i64_5 : i64 loc(#loc7)
    %22 = arith.cmpi sge, %20, %c-2147483648_i64_6 : i64 loc(#loc7)
    %23 = arith.andi %21, %22 : i1 loc(#loc7)
    %24 = arith.subi %1, %17 : i32 loc(#loc7)
    %c4_i32_7 = arith.constant 4 : i32 loc(#loc8)
    %25 = arith.minsi %24, %c4_i32_7 : i32 loc(#loc8)
    %26 = arith.remsi %0, %9 : i32 loc(#loc9)
    %27 = arith.remsi %26, %25 : i32 loc(#loc10)
    %28 = arith.extsi %17 : i32 to i64 loc(#loc11)
    %29 = arith.extsi %27 : i32 to i64 loc(#loc11)
    %30 = arith.addi %28, %29 : i64 loc(#loc11)
    %c2147483647_i64_8 = arith.constant 2147483647 : i64 loc(#loc11)
    %c-2147483648_i64_9 = arith.constant -2147483648 : i64 loc(#loc11)
    %31 = arith.cmpi sle, %30, %c2147483647_i64_8 : i64 loc(#loc11)
    %32 = arith.cmpi sge, %30, %c-2147483648_i64_9 : i64 loc(#loc11)
    %33 = arith.andi %31, %32 : i1 loc(#loc11)
    %34 = arith.addi %17, %27 : i32 loc(#loc11)
    %35 = arith.remsi %0, %9 : i32 loc(#loc12)
    %36 = arith.divsi %35, %25 : i32 loc(#loc13)
    %c0_i32 = arith.constant 0 : i32 loc(#loc14)
    %37 = arith.cmpi sge, %34, %c0_i32 : i32 loc(#loc14)
    llvm.intr.assume %37 : i1 loc(#loc15)
    %c0_i32_10 = arith.constant 0 : i32 loc(#loc16)
    %38 = arith.cmpi sge, %36, %c0_i32_10 : i32 loc(#loc16)
    llvm.intr.assume %38 : i1 loc(#loc17)
    %c0_i32_11 = arith.constant 0 : i32 loc(#loc18)
    %39 = arith.cmpi sgt, %arg6, %c0_i32_11 : i32 loc(#loc18)
    llvm.intr.assume %39 : i1 loc(#loc19)
    %true = arith.constant true loc(#loc20)
    llvm.intr.assume %true : i1 loc(#loc20)
    %true_12 = arith.constant true loc(#loc21)
    llvm.intr.assume %true_12 : i1 loc(#loc21)
    %c0_i32_13 = arith.constant 0 : i32 loc(#loc22)
    %40 = arith.cmpi sgt, %arg7, %c0_i32_13 : i32 loc(#loc22)
    llvm.intr.assume %40 : i1 loc(#loc23)
    %c0_i32_14 = arith.constant 0 : i32 loc(#loc24)
    %41 = arith.cmpi sgt, %arg8, %c0_i32_14 : i32 loc(#loc24)
    llvm.intr.assume %41 : i1 loc(#loc25)
    %true_15 = arith.constant true loc(#loc26)
    llvm.intr.assume %true_15 : i1 loc(#loc26)
    %c32_i32 = arith.constant 32 : i32 loc(#loc27)
    %c32_i32_16 = arith.constant 32 : i32 loc(#loc27)
    %42 = arith.extsi %34 : i32 to i64 loc(#loc27)
    %43 = arith.extsi %c32_i32_16 : i32 to i64 loc(#loc27)
    %44 = arith.muli %42, %43 : i64 loc(#loc27)
    %c2147483647_i64_17 = arith.constant 2147483647 : i64 loc(#loc27)
    %c-2147483648_i64_18 = arith.constant -2147483648 : i64 loc(#loc27)
    %45 = arith.cmpi sle, %44, %c2147483647_i64_17 : i64 loc(#loc27)
    %46 = arith.cmpi sge, %44, %c-2147483648_i64_18 : i64 loc(#loc27)
    %47 = arith.andi %45, %46 : i1 loc(#loc27)
    %48 = arith.muli %34, %c32_i32_16 : i32 loc(#loc27)
    %49 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc28)
    %50 = tt.splat %48 : i32 -> tensor<32xi32> loc(#loc29)
    %51 = arith.extsi %50 : tensor<32xi32> to tensor<32xi64> loc(#loc29)
    %52 = arith.extsi %49 : tensor<32xi32> to tensor<32xi64> loc(#loc29)
    %53 = arith.addi %51, %52 : tensor<32xi64> loc(#loc29)
    %c2147483647_i64_19 = arith.constant 2147483647 : i64 loc(#loc29)
    %c-2147483648_i64_20 = arith.constant -2147483648 : i64 loc(#loc29)
    %cst = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc29)
    %54 = arith.cmpi sle, %53, %cst : tensor<32xi64> loc(#loc29)
    %cst_21 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc29)
    %55 = arith.cmpi sge, %53, %cst_21 : tensor<32xi64> loc(#loc29)
    %56 = arith.andi %54, %55 : tensor<32xi1> loc(#loc29)
    %57 = arith.addi %50, %49 : tensor<32xi32> loc(#loc29)
    %58 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc30)
    %59 = arith.remsi %57, %58 : tensor<32xi32> loc(#loc30)
    %c32_i32_22 = arith.constant 32 : i32 loc(#loc31)
    %c32_i32_23 = arith.constant 32 : i32 loc(#loc31)
    %60 = arith.extsi %36 : i32 to i64 loc(#loc31)
    %61 = arith.extsi %c32_i32_23 : i32 to i64 loc(#loc31)
    %62 = arith.muli %60, %61 : i64 loc(#loc31)
    %c2147483647_i64_24 = arith.constant 2147483647 : i64 loc(#loc31)
    %c-2147483648_i64_25 = arith.constant -2147483648 : i64 loc(#loc31)
    %63 = arith.cmpi sle, %62, %c2147483647_i64_24 : i64 loc(#loc31)
    %64 = arith.cmpi sge, %62, %c-2147483648_i64_25 : i64 loc(#loc31)
    %65 = arith.andi %63, %64 : i1 loc(#loc31)
    %66 = arith.muli %36, %c32_i32_23 : i32 loc(#loc31)
    %67 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc32)
    %68 = tt.splat %66 : i32 -> tensor<32xi32> loc(#loc33)
    %69 = arith.extsi %68 : tensor<32xi32> to tensor<32xi64> loc(#loc33)
    %70 = arith.extsi %67 : tensor<32xi32> to tensor<32xi64> loc(#loc33)
    %71 = arith.addi %69, %70 : tensor<32xi64> loc(#loc33)
    %c2147483647_i64_26 = arith.constant 2147483647 : i64 loc(#loc33)
    %c-2147483648_i64_27 = arith.constant -2147483648 : i64 loc(#loc33)
    %cst_28 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc33)
    %72 = arith.cmpi sle, %71, %cst_28 : tensor<32xi64> loc(#loc33)
    %cst_29 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc33)
    %73 = arith.cmpi sge, %71, %cst_29 : tensor<32xi64> loc(#loc33)
    %74 = arith.andi %72, %73 : tensor<32xi1> loc(#loc33)
    %75 = arith.addi %68, %67 : tensor<32xi32> loc(#loc33)
    %76 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc34)
    %77 = arith.remsi %75, %76 : tensor<32xi32> loc(#loc34)
    %78 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc35)
    %79 = tt.expand_dims %59 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc36)
    %80 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc37)
    %81 = arith.extsi %79 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc37)
    %82 = arith.extsi %80 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc37)
    %83 = arith.muli %81, %82 : tensor<32x1xi64> loc(#loc37)
    %c2147483647_i64_30 = arith.constant 2147483647 : i64 loc(#loc37)
    %c-2147483648_i64_31 = arith.constant -2147483648 : i64 loc(#loc37)
    %cst_32 = arith.constant dense<2147483647> : tensor<32x1xi64> loc(#loc37)
    %84 = arith.cmpi sle, %83, %cst_32 : tensor<32x1xi64> loc(#loc37)
    %cst_33 = arith.constant dense<-2147483648> : tensor<32x1xi64> loc(#loc37)
    %85 = arith.cmpi sge, %83, %cst_33 : tensor<32x1xi64> loc(#loc37)
    %86 = arith.andi %84, %85 : tensor<32x1xi1> loc(#loc37)
    %87 = arith.muli %79, %80 : tensor<32x1xi32> loc(#loc37)
    %88 = tt.expand_dims %78 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc38)
    %c1_i32 = arith.constant 1 : i32 loc(#loc39)
    %c1_i32_34 = arith.constant 1 : i32 loc(#loc39)
    %cst_35 = arith.constant dense<1> : tensor<1x16xi32> loc(#loc39)
    %89 = arith.extsi %88 : tensor<1x16xi32> to tensor<1x16xi64> loc(#loc39)
    %90 = arith.extsi %cst_35 : tensor<1x16xi32> to tensor<1x16xi64> loc(#loc39)
    %91 = arith.muli %89, %90 : tensor<1x16xi64> loc(#loc39)
    %c2147483647_i64_36 = arith.constant 2147483647 : i64 loc(#loc39)
    %c-2147483648_i64_37 = arith.constant -2147483648 : i64 loc(#loc39)
    %cst_38 = arith.constant dense<2147483647> : tensor<1x16xi64> loc(#loc39)
    %92 = arith.cmpi sle, %91, %cst_38 : tensor<1x16xi64> loc(#loc39)
    %cst_39 = arith.constant dense<-2147483648> : tensor<1x16xi64> loc(#loc39)
    %93 = arith.cmpi sge, %91, %cst_39 : tensor<1x16xi64> loc(#loc39)
    %94 = arith.andi %92, %93 : tensor<1x16xi1> loc(#loc39)
    %95 = arith.muli %88, %cst_35 : tensor<1x16xi32> loc(#loc39)
    %96 = tt.broadcast %87 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc40)
    %97 = tt.broadcast %95 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc40)
    %98 = arith.extsi %96 : tensor<32x16xi32> to tensor<32x16xi64> loc(#loc40)
    %99 = arith.extsi %97 : tensor<32x16xi32> to tensor<32x16xi64> loc(#loc40)
    %100 = arith.addi %98, %99 : tensor<32x16xi64> loc(#loc40)
    %c2147483647_i64_40 = arith.constant 2147483647 : i64 loc(#loc40)
    %c-2147483648_i64_41 = arith.constant -2147483648 : i64 loc(#loc40)
    %cst_42 = arith.constant dense<2147483647> : tensor<32x16xi64> loc(#loc40)
    %101 = arith.cmpi sle, %100, %cst_42 : tensor<32x16xi64> loc(#loc40)
    %cst_43 = arith.constant dense<-2147483648> : tensor<32x16xi64> loc(#loc40)
    %102 = arith.cmpi sge, %100, %cst_43 : tensor<32x16xi64> loc(#loc40)
    %103 = arith.andi %101, %102 : tensor<32x16xi1> loc(#loc40)
    %104 = arith.addi %96, %97 : tensor<32x16xi32> loc(#loc40)
    %105 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc41)
    %106 = tt.addptr %105, %104 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc41)
    %107 = tt.expand_dims %78 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc42)
    %108 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc43)
    %109 = arith.extsi %107 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc43)
    %110 = arith.extsi %108 : tensor<16x1xi32> to tensor<16x1xi64> loc(#loc43)
    %111 = arith.muli %109, %110 : tensor<16x1xi64> loc(#loc43)
    %c2147483647_i64_44 = arith.constant 2147483647 : i64 loc(#loc43)
    %c-2147483648_i64_45 = arith.constant -2147483648 : i64 loc(#loc43)
    %cst_46 = arith.constant dense<2147483647> : tensor<16x1xi64> loc(#loc43)
    %112 = arith.cmpi sle, %111, %cst_46 : tensor<16x1xi64> loc(#loc43)
    %cst_47 = arith.constant dense<-2147483648> : tensor<16x1xi64> loc(#loc43)
    %113 = arith.cmpi sge, %111, %cst_47 : tensor<16x1xi64> loc(#loc43)
    %114 = arith.andi %112, %113 : tensor<16x1xi1> loc(#loc43)
    %115 = arith.muli %107, %108 : tensor<16x1xi32> loc(#loc43)
    %116 = tt.expand_dims %77 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc44)
    %c1_i32_48 = arith.constant 1 : i32 loc(#loc45)
    %c1_i32_49 = arith.constant 1 : i32 loc(#loc45)
    %cst_50 = arith.constant dense<1> : tensor<1x32xi32> loc(#loc45)
    %117 = arith.extsi %116 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc45)
    %118 = arith.extsi %cst_50 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc45)
    %119 = arith.muli %117, %118 : tensor<1x32xi64> loc(#loc45)
    %c2147483647_i64_51 = arith.constant 2147483647 : i64 loc(#loc45)
    %c-2147483648_i64_52 = arith.constant -2147483648 : i64 loc(#loc45)
    %cst_53 = arith.constant dense<2147483647> : tensor<1x32xi64> loc(#loc45)
    %120 = arith.cmpi sle, %119, %cst_53 : tensor<1x32xi64> loc(#loc45)
    %cst_54 = arith.constant dense<-2147483648> : tensor<1x32xi64> loc(#loc45)
    %121 = arith.cmpi sge, %119, %cst_54 : tensor<1x32xi64> loc(#loc45)
    %122 = arith.andi %120, %121 : tensor<1x32xi1> loc(#loc45)
    %123 = arith.muli %116, %cst_50 : tensor<1x32xi32> loc(#loc45)
    %124 = tt.broadcast %115 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc46)
    %125 = tt.broadcast %123 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc46)
    %126 = arith.extsi %124 : tensor<16x32xi32> to tensor<16x32xi64> loc(#loc46)
    %127 = arith.extsi %125 : tensor<16x32xi32> to tensor<16x32xi64> loc(#loc46)
    %128 = arith.addi %126, %127 : tensor<16x32xi64> loc(#loc46)
    %c2147483647_i64_55 = arith.constant 2147483647 : i64 loc(#loc46)
    %c-2147483648_i64_56 = arith.constant -2147483648 : i64 loc(#loc46)
    %cst_57 = arith.constant dense<2147483647> : tensor<16x32xi64> loc(#loc46)
    %129 = arith.cmpi sle, %128, %cst_57 : tensor<16x32xi64> loc(#loc46)
    %cst_58 = arith.constant dense<-2147483648> : tensor<16x32xi64> loc(#loc46)
    %130 = arith.cmpi sge, %128, %cst_58 : tensor<16x32xi64> loc(#loc46)
    %131 = arith.andi %129, %130 : tensor<16x32xi1> loc(#loc46)
    %132 = arith.addi %124, %125 : tensor<16x32xi32> loc(#loc46)
    %133 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc47)
    %134 = tt.addptr %133, %132 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc47)
    %135 = tt.call @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() : () -> tensor<32x32xf32> loc(#loc48)
    %136 = tt.call @"cdiv__i32__(1,)cconstexpr_16_"(%arg5) : (i32) -> i32 loc(#loc49)
    %c0_i32_59 = arith.constant 0 : i32 loc(#loc50)
    %c1_i32_60 = arith.constant 1 : i32 loc(#loc50)
    %137 = arith.bitcast %c0_i32_59 : i32 to i32 loc(#loc50)
    %138 = arith.bitcast %136 : i32 to i32 loc(#loc50)
    %139 = arith.bitcast %c1_i32_60 : i32 to i32 loc(#loc50)
    %140 = ub.poison : i32 loc(#loc50)
    %141:3 = scf.for %arg9 = %137 to %138 step %139 iter_args(%arg10 = %135, %arg11 = %106, %arg12 = %134) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %206 = tt.expand_dims %78 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc51)
      %c16_i32 = arith.constant 16 : i32 loc(#loc52)
      %c16_i32_88 = arith.constant 16 : i32 loc(#loc52)
      %207 = arith.extsi %arg9 : i32 to i64 loc(#loc52)
      %208 = arith.extsi %c16_i32_88 : i32 to i64 loc(#loc52)
      %209 = arith.muli %207, %208 : i64 loc(#loc52)
      %c2147483647_i64_89 = arith.constant 2147483647 : i64 loc(#loc52)
      %c-2147483648_i64_90 = arith.constant -2147483648 : i64 loc(#loc52)
      %210 = arith.cmpi sle, %209, %c2147483647_i64_89 : i64 loc(#loc52)
      %211 = arith.cmpi sge, %209, %c-2147483648_i64_90 : i64 loc(#loc52)
      %212 = arith.andi %210, %211 : i1 loc(#loc52)
      %213 = arith.muli %arg9, %c16_i32_88 : i32 loc(#loc52)
      %214 = arith.extsi %arg5 : i32 to i64 loc(#loc53)
      %215 = arith.extsi %213 : i32 to i64 loc(#loc53)
      %216 = arith.subi %214, %215 : i64 loc(#loc53)
      %c2147483647_i64_91 = arith.constant 2147483647 : i64 loc(#loc53)
      %c-2147483648_i64_92 = arith.constant -2147483648 : i64 loc(#loc53)
      %217 = arith.cmpi sle, %216, %c2147483647_i64_91 : i64 loc(#loc53)
      %218 = arith.cmpi sge, %216, %c-2147483648_i64_92 : i64 loc(#loc53)
      %219 = arith.andi %217, %218 : i1 loc(#loc53)
      %220 = arith.subi %arg5, %213 : i32 loc(#loc53)
      %221 = tt.splat %220 : i32 -> tensor<1x16xi32> loc(#loc54)
      %222 = arith.cmpi slt, %206, %221 : tensor<1x16xi32> loc(#loc54)
      %cst_93 = arith.constant 0.000000e+00 : f32 loc(#loc55)
      %223 = tt.broadcast %222 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc55)
      %cst_94 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc55)
      %224 = tt.load %arg11, %223, %cst_94 : tensor<32x16x!tt.ptr<f32>> loc(#loc55)
      %225 = tt.expand_dims %78 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc56)
      %c16_i32_95 = arith.constant 16 : i32 loc(#loc57)
      %c16_i32_96 = arith.constant 16 : i32 loc(#loc57)
      %226 = arith.extsi %arg9 : i32 to i64 loc(#loc57)
      %227 = arith.extsi %c16_i32_96 : i32 to i64 loc(#loc57)
      %228 = arith.muli %226, %227 : i64 loc(#loc57)
      %c2147483647_i64_97 = arith.constant 2147483647 : i64 loc(#loc57)
      %c-2147483648_i64_98 = arith.constant -2147483648 : i64 loc(#loc57)
      %229 = arith.cmpi sle, %228, %c2147483647_i64_97 : i64 loc(#loc57)
      %230 = arith.cmpi sge, %228, %c-2147483648_i64_98 : i64 loc(#loc57)
      %231 = arith.andi %229, %230 : i1 loc(#loc57)
      %232 = arith.muli %arg9, %c16_i32_96 : i32 loc(#loc57)
      %233 = arith.extsi %arg5 : i32 to i64 loc(#loc58)
      %234 = arith.extsi %232 : i32 to i64 loc(#loc58)
      %235 = arith.subi %233, %234 : i64 loc(#loc58)
      %c2147483647_i64_99 = arith.constant 2147483647 : i64 loc(#loc58)
      %c-2147483648_i64_100 = arith.constant -2147483648 : i64 loc(#loc58)
      %236 = arith.cmpi sle, %235, %c2147483647_i64_99 : i64 loc(#loc58)
      %237 = arith.cmpi sge, %235, %c-2147483648_i64_100 : i64 loc(#loc58)
      %238 = arith.andi %236, %237 : i1 loc(#loc58)
      %239 = arith.subi %arg5, %232 : i32 loc(#loc58)
      %240 = tt.splat %239 : i32 -> tensor<16x1xi32> loc(#loc59)
      %241 = arith.cmpi slt, %225, %240 : tensor<16x1xi32> loc(#loc59)
      %cst_101 = arith.constant 0.000000e+00 : f32 loc(#loc60)
      %242 = tt.broadcast %241 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc60)
      %cst_102 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc60)
      %243 = tt.load %arg12, %242, %cst_102 : tensor<16x32x!tt.ptr<f32>> loc(#loc60)
      %cst_103 = arith.constant 0.000000e+00 : f32 loc(#loc61)
      %244 = tt.dot %224, %243, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc61)
      %c16_i32_104 = arith.constant 16 : i32 loc(#loc62)
      %cst_105 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc62)
      %245 = tt.addptr %arg11, %cst_105 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc62)
      %c16_i32_106 = arith.constant 16 : i32 loc(#loc63)
      %c16_i32_107 = arith.constant 16 : i32 loc(#loc63)
      %246 = arith.extsi %c16_i32_107 : i32 to i64 loc(#loc63)
      %247 = arith.extsi %arg7 : i32 to i64 loc(#loc63)
      %248 = arith.muli %246, %247 : i64 loc(#loc63)
      %c2147483647_i64_108 = arith.constant 2147483647 : i64 loc(#loc63)
      %c-2147483648_i64_109 = arith.constant -2147483648 : i64 loc(#loc63)
      %249 = arith.cmpi sle, %248, %c2147483647_i64_108 : i64 loc(#loc63)
      %250 = arith.cmpi sge, %248, %c-2147483648_i64_109 : i64 loc(#loc63)
      %251 = arith.andi %249, %250 : i1 loc(#loc63)
      %252 = arith.muli %c16_i32_107, %arg7 : i32 loc(#loc63)
      %253 = tt.splat %252 : i32 -> tensor<16x32xi32> loc(#loc64)
      %254 = tt.addptr %arg12, %253 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc64)
      scf.yield %244, %245, %254 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc65)
    } loc(#loc50)
    %142 = arith.truncf %141#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc66)
    %c32_i32_61 = arith.constant 32 : i32 loc(#loc67)
    %c32_i32_62 = arith.constant 32 : i32 loc(#loc67)
    %143 = arith.extsi %34 : i32 to i64 loc(#loc67)
    %144 = arith.extsi %c32_i32_62 : i32 to i64 loc(#loc67)
    %145 = arith.muli %143, %144 : i64 loc(#loc67)
    %c2147483647_i64_63 = arith.constant 2147483647 : i64 loc(#loc67)
    %c-2147483648_i64_64 = arith.constant -2147483648 : i64 loc(#loc67)
    %146 = arith.cmpi sle, %145, %c2147483647_i64_63 : i64 loc(#loc67)
    %147 = arith.cmpi sge, %145, %c-2147483648_i64_64 : i64 loc(#loc67)
    %148 = arith.andi %146, %147 : i1 loc(#loc67)
    %149 = arith.muli %34, %c32_i32_62 : i32 loc(#loc67)
    %150 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc68)
    %151 = tt.splat %149 : i32 -> tensor<32xi32> loc(#loc69)
    %152 = arith.extsi %151 : tensor<32xi32> to tensor<32xi64> loc(#loc69)
    %153 = arith.extsi %150 : tensor<32xi32> to tensor<32xi64> loc(#loc69)
    %154 = arith.addi %152, %153 : tensor<32xi64> loc(#loc69)
    %c2147483647_i64_65 = arith.constant 2147483647 : i64 loc(#loc69)
    %c-2147483648_i64_66 = arith.constant -2147483648 : i64 loc(#loc69)
    %cst_67 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc69)
    %155 = arith.cmpi sle, %154, %cst_67 : tensor<32xi64> loc(#loc69)
    %cst_68 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc69)
    %156 = arith.cmpi sge, %154, %cst_68 : tensor<32xi64> loc(#loc69)
    %157 = arith.andi %155, %156 : tensor<32xi1> loc(#loc69)
    %158 = arith.addi %151, %150 : tensor<32xi32> loc(#loc69)
    %c32_i32_69 = arith.constant 32 : i32 loc(#loc70)
    %c32_i32_70 = arith.constant 32 : i32 loc(#loc70)
    %159 = arith.extsi %36 : i32 to i64 loc(#loc70)
    %160 = arith.extsi %c32_i32_70 : i32 to i64 loc(#loc70)
    %161 = arith.muli %159, %160 : i64 loc(#loc70)
    %c2147483647_i64_71 = arith.constant 2147483647 : i64 loc(#loc70)
    %c-2147483648_i64_72 = arith.constant -2147483648 : i64 loc(#loc70)
    %162 = arith.cmpi sle, %161, %c2147483647_i64_71 : i64 loc(#loc70)
    %163 = arith.cmpi sge, %161, %c-2147483648_i64_72 : i64 loc(#loc70)
    %164 = arith.andi %162, %163 : i1 loc(#loc70)
    %165 = arith.muli %36, %c32_i32_70 : i32 loc(#loc70)
    %166 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc71)
    %167 = tt.splat %165 : i32 -> tensor<32xi32> loc(#loc72)
    %168 = arith.extsi %167 : tensor<32xi32> to tensor<32xi64> loc(#loc72)
    %169 = arith.extsi %166 : tensor<32xi32> to tensor<32xi64> loc(#loc72)
    %170 = arith.addi %168, %169 : tensor<32xi64> loc(#loc72)
    %c2147483647_i64_73 = arith.constant 2147483647 : i64 loc(#loc72)
    %c-2147483648_i64_74 = arith.constant -2147483648 : i64 loc(#loc72)
    %cst_75 = arith.constant dense<2147483647> : tensor<32xi64> loc(#loc72)
    %171 = arith.cmpi sle, %170, %cst_75 : tensor<32xi64> loc(#loc72)
    %cst_76 = arith.constant dense<-2147483648> : tensor<32xi64> loc(#loc72)
    %172 = arith.cmpi sge, %170, %cst_76 : tensor<32xi64> loc(#loc72)
    %173 = arith.andi %171, %172 : tensor<32xi1> loc(#loc72)
    %174 = arith.addi %167, %166 : tensor<32xi32> loc(#loc72)
    %175 = tt.expand_dims %158 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc73)
    %176 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc74)
    %177 = arith.extsi %176 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc74)
    %178 = arith.extsi %175 : tensor<32x1xi32> to tensor<32x1xi64> loc(#loc74)
    %179 = arith.muli %177, %178 : tensor<32x1xi64> loc(#loc74)
    %c2147483647_i64_77 = arith.constant 2147483647 : i64 loc(#loc74)
    %c-2147483648_i64_78 = arith.constant -2147483648 : i64 loc(#loc74)
    %cst_79 = arith.constant dense<2147483647> : tensor<32x1xi64> loc(#loc74)
    %180 = arith.cmpi sle, %179, %cst_79 : tensor<32x1xi64> loc(#loc74)
    %cst_80 = arith.constant dense<-2147483648> : tensor<32x1xi64> loc(#loc74)
    %181 = arith.cmpi sge, %179, %cst_80 : tensor<32x1xi64> loc(#loc74)
    %182 = arith.andi %180, %181 : tensor<32x1xi1> loc(#loc74)
    %183 = arith.muli %176, %175 : tensor<32x1xi32> loc(#loc74)
    %184 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc75)
    %185 = tt.addptr %184, %183 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc75)
    %186 = tt.expand_dims %174 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc76)
    %c1_i32_81 = arith.constant 1 : i32 loc(#loc77)
    %c1_i32_82 = arith.constant 1 : i32 loc(#loc77)
    %cst_83 = arith.constant dense<1> : tensor<1x32xi32> loc(#loc77)
    %187 = arith.extsi %cst_83 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc77)
    %188 = arith.extsi %186 : tensor<1x32xi32> to tensor<1x32xi64> loc(#loc77)
    %189 = arith.muli %187, %188 : tensor<1x32xi64> loc(#loc77)
    %c2147483647_i64_84 = arith.constant 2147483647 : i64 loc(#loc77)
    %c-2147483648_i64_85 = arith.constant -2147483648 : i64 loc(#loc77)
    %cst_86 = arith.constant dense<2147483647> : tensor<1x32xi64> loc(#loc77)
    %190 = arith.cmpi sle, %189, %cst_86 : tensor<1x32xi64> loc(#loc77)
    %cst_87 = arith.constant dense<-2147483648> : tensor<1x32xi64> loc(#loc77)
    %191 = arith.cmpi sge, %189, %cst_87 : tensor<1x32xi64> loc(#loc77)
    %192 = arith.andi %190, %191 : tensor<1x32xi1> loc(#loc77)
    %193 = arith.muli %cst_83, %186 : tensor<1x32xi32> loc(#loc77)
    %194 = tt.broadcast %185 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc78)
    %195 = tt.broadcast %193 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc78)
    %196 = tt.addptr %194, %195 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc78)
    %197 = tt.expand_dims %158 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc79)
    %198 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc80)
    %199 = arith.cmpi slt, %197, %198 : tensor<32x1xi32> loc(#loc80)
    %200 = tt.expand_dims %174 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc81)
    %201 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc82)
    %202 = arith.cmpi slt, %200, %201 : tensor<1x32xi32> loc(#loc82)
    %203 = tt.broadcast %199 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc83)
    %204 = tt.broadcast %202 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc83)
    %205 = arith.andi %203, %204 : tensor<32x32xi1> loc(#loc83)
    tt.store %196, %142, %205 : tensor<32x32x!tt.ptr<f16>> loc(#loc84)
    tt.return loc(#loc85)
  } loc(#loc)
  tt.func private @"cdiv__i32__(1,)cconstexpr_32_"(%arg0: i32 loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)) -> i32 attributes {noinline = false} {
    %c32_i32 = arith.constant 32 : i32 loc(#loc87)
    %c31_i32 = arith.constant 31 : i32 loc(#loc88)
    %0 = arith.addi %arg0, %c31_i32 : i32 loc(#loc88)
    %1 = arith.divsi %0, %c32_i32 : i32 loc(#loc89)
    tt.return %1 : i32 loc(#loc90)
  } loc(#loc86)
  tt.func private @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() -> tensor<32x32xf32> attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc92)
    tt.return %cst : tensor<32x32xf32> loc(#loc93)
  } loc(#loc91)
  tt.func private @"cdiv__i32__(1,)cconstexpr_16_"(%arg0: i32 loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)) -> i32 attributes {noinline = false} {
    %c16_i32 = arith.constant 16 : i32 loc(#loc87)
    %c15_i32 = arith.constant 15 : i32 loc(#loc88)
    %0 = arith.addi %arg0, %c15_i32 : i32 loc(#loc88)
    %1 = arith.divsi %0, %c16_i32 : i32 loc(#loc89)
    tt.return %1 : i32 loc(#loc90)
  } loc(#loc86)
} loc(#loc)
#loc1 = loc("examples/kernels/binary_ops.py":126:24)
#loc2 = loc("examples/kernels/binary_ops.py":127:27)
#loc3 = loc("examples/kernels/binary_ops.py":128:27)
#loc4 = loc("examples/kernels/binary_ops.py":129:38)
#loc5 = loc("examples/kernels/binary_ops.py":130:22)
#loc6 = loc("examples/kernels/binary_ops.py":131:29)
#loc7 = loc("examples/kernels/binary_ops.py":132:35)
#loc8 = loc("examples/kernels/binary_ops.py":132:48)
#loc9 = loc("examples/kernels/binary_ops.py":133:34)
#loc10 = loc("examples/kernels/binary_ops.py":133:54)
#loc11 = loc("examples/kernels/binary_ops.py":133:27)
#loc12 = loc("examples/kernels/binary_ops.py":134:19)
#loc13 = loc("examples/kernels/binary_ops.py":134:40)
#loc14 = loc("examples/kernels/binary_ops.py":140:23)
#loc15 = loc("examples/kernels/binary_ops.py":140:14)
#loc16 = loc("examples/kernels/binary_ops.py":141:23)
#loc17 = loc("examples/kernels/binary_ops.py":141:14)
#loc18 = loc("examples/kernels/binary_ops.py":142:26)
#loc19 = loc("examples/kernels/binary_ops.py":142:14)
#loc20 = loc("examples/kernels/binary_ops.py":143:14)
#loc21 = loc("examples/kernels/binary_ops.py":144:14)
#loc22 = loc("examples/kernels/binary_ops.py":145:26)
#loc23 = loc("examples/kernels/binary_ops.py":145:14)
#loc24 = loc("examples/kernels/binary_ops.py":146:26)
#loc25 = loc("examples/kernels/binary_ops.py":146:14)
#loc26 = loc("examples/kernels/binary_ops.py":147:14)
#loc27 = loc("examples/kernels/binary_ops.py":156:23)
#loc28 = loc("examples/kernels/binary_ops.py":156:51)
#loc29 = loc("examples/kernels/binary_ops.py":156:38)
#loc30 = loc("examples/kernels/binary_ops.py":156:68)
#loc31 = loc("examples/kernels/binary_ops.py":157:23)
#loc32 = loc("examples/kernels/binary_ops.py":157:51)
#loc33 = loc("examples/kernels/binary_ops.py":157:38)
#loc34 = loc("examples/kernels/binary_ops.py":157:68)
#loc35 = loc("examples/kernels/binary_ops.py":158:26)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:71)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:71)
#loc46 = loc("examples/kernels/binary_ops.py":160:52)
#loc47 = loc("examples/kernels/binary_ops.py":160:22)
#loc48 = loc("examples/kernels/binary_ops.py":167:27)
#loc49 = loc("examples/kernels/binary_ops.py":168:33)
#loc50 = loc("examples/kernels/binary_ops.py":168:22)
#loc51 = loc("examples/kernels/binary_ops.py":171:40)
#loc52 = loc("examples/kernels/binary_ops.py":171:59)
#loc53 = loc("examples/kernels/binary_ops.py":171:55)
#loc54 = loc("examples/kernels/binary_ops.py":171:51)
#loc55 = loc("examples/kernels/binary_ops.py":171:20)
#loc56 = loc("examples/kernels/binary_ops.py":172:40)
#loc57 = loc("examples/kernels/binary_ops.py":172:59)
#loc58 = loc("examples/kernels/binary_ops.py":172:55)
#loc59 = loc("examples/kernels/binary_ops.py":172:51)
#loc60 = loc("examples/kernels/binary_ops.py":172:20)
#loc61 = loc("examples/kernels/binary_ops.py":174:35)
#loc62 = loc("examples/kernels/binary_ops.py":176:18)
#loc63 = loc("examples/kernels/binary_ops.py":177:33)
#loc64 = loc("examples/kernels/binary_ops.py":177:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:8)
#loc66 = loc("examples/kernels/binary_ops.py":182:23)
#loc67 = loc("examples/kernels/binary_ops.py":186:22)
#loc68 = loc("examples/kernels/binary_ops.py":186:50)
#loc69 = loc("examples/kernels/binary_ops.py":186:37)
#loc70 = loc("examples/kernels/binary_ops.py":187:22)
#loc71 = loc("examples/kernels/binary_ops.py":187:50)
#loc72 = loc("examples/kernels/binary_ops.py":187:37)
#loc73 = loc("examples/kernels/binary_ops.py":188:41)
#loc74 = loc("examples/kernels/binary_ops.py":188:33)
#loc75 = loc("examples/kernels/binary_ops.py":188:21)
#loc76 = loc("examples/kernels/binary_ops.py":188:72)
#loc77 = loc("examples/kernels/binary_ops.py":188:64)
#loc78 = loc("examples/kernels/binary_ops.py":188:52)
#loc79 = loc("examples/kernels/binary_ops.py":189:22)
#loc80 = loc("examples/kernels/binary_ops.py":189:33)
#loc81 = loc("examples/kernels/binary_ops.py":189:47)
#loc82 = loc("examples/kernels/binary_ops.py":189:58)
#loc83 = loc("examples/kernels/binary_ops.py":189:39)
#loc84 = loc("examples/kernels/binary_ops.py":190:21)
#loc85 = loc("examples/kernels/binary_ops.py":190:4)
#loc87 = loc(unknown)
#loc88 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc89 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc90 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:11)
#loc91 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":113:0)
#loc92 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:31)
#loc93 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:11)


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @matmul_kernel) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst = arith.constant dense<16> : tensor<32x16xi32> loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %c32_i32_2 = arith.constant 32 : i32 loc(#loc89)
    %c31_i32 = arith.constant 31 : i32 loc(#loc90)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc90)
    %2 = arith.divsi %1, %c32_i32_2 : i32 loc(#loc91)
    %c32_i32_3 = arith.constant 32 : i32 loc(#loc92)
    %c31_i32_4 = arith.constant 31 : i32 loc(#loc93)
    %3 = arith.addi %arg4, %c31_i32_4 : i32 loc(#loc93)
    %4 = arith.divsi %3, %c32_i32_3 : i32 loc(#loc94)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.remsi %0, %5 : i32 loc(#loc15)
    %14 = arith.divsi %13, %9 : i32 loc(#loc16)
    %15 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc17)
    llvm.intr.assume %15 : i1 loc(#loc18)
    %16 = arith.cmpi sge, %14, %c0_i32 : i32 loc(#loc19)
    llvm.intr.assume %16 : i1 loc(#loc20)
    %17 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc21)
    llvm.intr.assume %17 : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    llvm.intr.assume %true : i1 loc(#loc24)
    %18 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc25)
    llvm.intr.assume %18 : i1 loc(#loc26)
    %19 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc27)
    llvm.intr.assume %19 : i1 loc(#loc28)
    llvm.intr.assume %true : i1 loc(#loc29)
    %20 = arith.muli %12, %c32_i32 : i32 loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc31)
    %22 = tt.splat %20 : i32 -> tensor<32xi32> loc(#loc32)
    %23 = arith.addi %22, %21 : tensor<32xi32> loc(#loc32)
    %24 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc33)
    %25 = arith.remsi %23, %24 : tensor<32xi32> loc(#loc33)
    %26 = arith.muli %14, %c32_i32 : i32 loc(#loc34)
    %27 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc35)
    %28 = tt.splat %26 : i32 -> tensor<32xi32> loc(#loc36)
    %29 = arith.addi %28, %27 : tensor<32xi32> loc(#loc36)
    %30 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc37)
    %31 = arith.remsi %29, %30 : tensor<32xi32> loc(#loc37)
    %32 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc38)
    %33 = tt.expand_dims %25 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc39)
    %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc40)
    %35 = arith.muli %33, %34 : tensor<32x1xi32> loc(#loc40)
    %36 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc41)
    %37 = tt.broadcast %35 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc42)
    %38 = tt.broadcast %36 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc42)
    %39 = arith.addi %37, %38 : tensor<32x16xi32> loc(#loc42)
    %40 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc43)
    %41 = tt.addptr %40, %39 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc43)
    %42 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc44)
    %43 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc45)
    %44 = arith.muli %42, %43 : tensor<16x1xi32> loc(#loc45)
    %45 = tt.expand_dims %31 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc46)
    %46 = tt.broadcast %44 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc47)
    %47 = tt.broadcast %45 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc47)
    %48 = arith.addi %46, %47 : tensor<16x32xi32> loc(#loc47)
    %49 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc48)
    %50 = tt.addptr %49, %48 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc48)
    %cst_5 = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc95)
    %c16_i32_6 = arith.constant 16 : i32 loc(#loc96)
    %c15_i32 = arith.constant 15 : i32 loc(#loc97)
    %51 = arith.addi %arg5, %c15_i32 : i32 loc(#loc97)
    %52 = arith.divsi %51, %c16_i32_6 : i32 loc(#loc98)
    %53:3 = scf.for %arg9 = %c0_i32 to %52 step %c1_i32 iter_args(%arg10 = %cst_5, %arg11 = %41, %arg12 = %50) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %81 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc53)
      %82 = arith.muli %arg9, %c16_i32 : i32 loc(#loc54)
      %83 = arith.subi %arg5, %82 : i32 loc(#loc55)
      %84 = tt.splat %83 : i32 -> tensor<1x16xi32> loc(#loc56)
      %85 = arith.cmpi slt, %81, %84 : tensor<1x16xi32> loc(#loc56)
      %86 = tt.broadcast %85 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc57)
      %87 = tt.load %arg11, %86, %cst_1 : tensor<32x16x!tt.ptr<f32>> loc(#loc57)
      %88 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc58)
      %89 = arith.muli %arg9, %c16_i32 : i32 loc(#loc59)
      %90 = arith.subi %arg5, %89 : i32 loc(#loc60)
      %91 = tt.splat %90 : i32 -> tensor<16x1xi32> loc(#loc61)
      %92 = arith.cmpi slt, %88, %91 : tensor<16x1xi32> loc(#loc61)
      %93 = tt.broadcast %92 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc62)
      %94 = tt.load %arg12, %93, %cst_0 : tensor<16x32x!tt.ptr<f32>> loc(#loc62)
      %95 = tt.dot %87, %94, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc63)
      %96 = tt.addptr %arg11, %cst : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc64)
      %97 = arith.muli %arg7, %c16_i32 : i32 loc(#loc65)
      %98 = tt.splat %97 : i32 -> tensor<16x32xi32> loc(#loc66)
      %99 = tt.addptr %arg12, %98 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc66)
      scf.yield %95, %96, %99 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc67)
    } loc(#loc52)
    %54 = arith.truncf %53#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc68)
    %55 = arith.muli %12, %c32_i32 : i32 loc(#loc69)
    %56 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc70)
    %57 = tt.splat %55 : i32 -> tensor<32xi32> loc(#loc71)
    %58 = arith.addi %57, %56 : tensor<32xi32> loc(#loc71)
    %59 = arith.muli %14, %c32_i32 : i32 loc(#loc72)
    %60 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc73)
    %61 = tt.splat %59 : i32 -> tensor<32xi32> loc(#loc74)
    %62 = arith.addi %61, %60 : tensor<32xi32> loc(#loc74)
    %63 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc75)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc76)
    %65 = arith.muli %64, %63 : tensor<32x1xi32> loc(#loc76)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc77)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc77)
    %68 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc78)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc79)
    %70 = tt.broadcast %68 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc79)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc79)
    %72 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc80)
    %73 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc81)
    %74 = arith.cmpi slt, %72, %73 : tensor<32x1xi32> loc(#loc81)
    %75 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc82)
    %76 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc83)
    %77 = arith.cmpi slt, %75, %76 : tensor<1x32xi32> loc(#loc83)
    %78 = tt.broadcast %74 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc84)
    %79 = tt.broadcast %77 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc84)
    %80 = arith.andi %78, %79 : tensor<32x32xi1> loc(#loc84)
    tt.store %71, %54, %80 : tensor<32x32x!tt.ptr<f16>> loc(#loc85)
    tt.return loc(#loc86)
  } loc(#loc)
  tt.func private @"cdiv__i32__(1,)cconstexpr_32_"(i32) -> i32 attributes {noinline = false} loc(#loc87)
  tt.func private @"zeros____(0, 0)cconstexpr_32__(0, 1)cconstexpr_32__(1,)cconstexpr_fp32_"() -> tensor<32x32xf32> attributes {noinline = false} loc(#loc88)
  tt.func private @"cdiv__i32__(1,)cconstexpr_16_"(i32) -> i32 attributes {noinline = false} loc(#loc87)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("examples/kernels/binary_ops.py":127:27)
#loc4 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:19)
#loc16 = loc("examples/kernels/binary_ops.py":134:40)
#loc17 = loc("examples/kernels/binary_ops.py":140:23)
#loc18 = loc("examples/kernels/binary_ops.py":140:14)
#loc19 = loc("examples/kernels/binary_ops.py":141:23)
#loc20 = loc("examples/kernels/binary_ops.py":141:14)
#loc21 = loc("examples/kernels/binary_ops.py":142:26)
#loc22 = loc("examples/kernels/binary_ops.py":142:14)
#loc23 = loc("examples/kernels/binary_ops.py":143:14)
#loc24 = loc("examples/kernels/binary_ops.py":144:14)
#loc25 = loc("examples/kernels/binary_ops.py":145:26)
#loc26 = loc("examples/kernels/binary_ops.py":145:14)
#loc27 = loc("examples/kernels/binary_ops.py":146:26)
#loc28 = loc("examples/kernels/binary_ops.py":146:14)
#loc29 = loc("examples/kernels/binary_ops.py":147:14)
#loc30 = loc("examples/kernels/binary_ops.py":156:23)
#loc31 = loc("examples/kernels/binary_ops.py":156:51)
#loc32 = loc("examples/kernels/binary_ops.py":156:38)
#loc33 = loc("examples/kernels/binary_ops.py":156:68)
#loc34 = loc("examples/kernels/binary_ops.py":157:23)
#loc35 = loc("examples/kernels/binary_ops.py":157:51)
#loc36 = loc("examples/kernels/binary_ops.py":157:38)
#loc37 = loc("examples/kernels/binary_ops.py":157:68)
#loc38 = loc("examples/kernels/binary_ops.py":158:26)
#loc39 = loc("examples/kernels/binary_ops.py":159:30)
#loc40 = loc("examples/kernels/binary_ops.py":159:41)
#loc41 = loc("examples/kernels/binary_ops.py":159:60)
#loc42 = loc("examples/kernels/binary_ops.py":159:53)
#loc43 = loc("examples/kernels/binary_ops.py":159:22)
#loc44 = loc("examples/kernels/binary_ops.py":160:29)
#loc45 = loc("examples/kernels/binary_ops.py":160:40)
#loc46 = loc("examples/kernels/binary_ops.py":160:60)
#loc47 = loc("examples/kernels/binary_ops.py":160:52)
#loc48 = loc("examples/kernels/binary_ops.py":160:22)
#loc49 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":122:31)
#loc50 = loc("examples/kernels/binary_ops.py":167:27)
#loc51 = loc("examples/kernels/binary_ops.py":168:33)
#loc52 = loc("examples/kernels/binary_ops.py":168:22)
#loc53 = loc("examples/kernels/binary_ops.py":171:40)
#loc54 = loc("examples/kernels/binary_ops.py":171:59)
#loc55 = loc("examples/kernels/binary_ops.py":171:55)
#loc56 = loc("examples/kernels/binary_ops.py":171:51)
#loc57 = loc("examples/kernels/binary_ops.py":171:20)
#loc58 = loc("examples/kernels/binary_ops.py":172:40)
#loc59 = loc("examples/kernels/binary_ops.py":172:59)
#loc60 = loc("examples/kernels/binary_ops.py":172:55)
#loc61 = loc("examples/kernels/binary_ops.py":172:51)
#loc62 = loc("examples/kernels/binary_ops.py":172:20)
#loc63 = loc("examples/kernels/binary_ops.py":174:35)
#loc64 = loc("examples/kernels/binary_ops.py":176:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:33)
#loc66 = loc("examples/kernels/binary_ops.py":177:18)
#loc67 = loc("examples/kernels/binary_ops.py":177:8)
#loc68 = loc("examples/kernels/binary_ops.py":182:23)
#loc69 = loc("examples/kernels/binary_ops.py":186:22)
#loc70 = loc("examples/kernels/binary_ops.py":186:50)
#loc71 = loc("examples/kernels/binary_ops.py":186:37)
#loc72 = loc("examples/kernels/binary_ops.py":187:22)
#loc73 = loc("examples/kernels/binary_ops.py":187:50)
#loc74 = loc("examples/kernels/binary_ops.py":187:37)
#loc75 = loc("examples/kernels/binary_ops.py":188:41)
#loc76 = loc("examples/kernels/binary_ops.py":188:33)
#loc77 = loc("examples/kernels/binary_ops.py":188:21)
#loc78 = loc("examples/kernels/binary_ops.py":188:72)
#loc79 = loc("examples/kernels/binary_ops.py":188:52)
#loc80 = loc("examples/kernels/binary_ops.py":189:22)
#loc81 = loc("examples/kernels/binary_ops.py":189:33)
#loc82 = loc("examples/kernels/binary_ops.py":189:47)
#loc83 = loc("examples/kernels/binary_ops.py":189:58)
#loc84 = loc("examples/kernels/binary_ops.py":189:39)
#loc85 = loc("examples/kernels/binary_ops.py":190:21)
#loc86 = loc("examples/kernels/binary_ops.py":190:4)
#loc87 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":31:0)
#loc88 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":113:0)
#loc89 = loc(callsite(#loc1 at #loc3))
#loc90 = loc(callsite(#loc4 at #loc3))
#loc91 = loc(callsite(#loc5 at #loc3))
#loc92 = loc(callsite(#loc1 at #loc6))
#loc93 = loc(callsite(#loc4 at #loc6))
#loc94 = loc(callsite(#loc5 at #loc6))
#loc95 = loc(callsite(#loc49 at #loc50))
#loc96 = loc(callsite(#loc1 at #loc51))
#loc97 = loc(callsite(#loc4 at #loc51))
#loc98 = loc(callsite(#loc5 at #loc51))


// -----// IR Dump Before TritonRewriteTensorPointer (triton-rewrite-tensor-pointer) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc85)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc86)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc87)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc88)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.remsi %0, %5 : i32 loc(#loc15)
    %14 = arith.divsi %13, %9 : i32 loc(#loc16)
    %15 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc17)
    llvm.intr.assume %15 : i1 loc(#loc18)
    %16 = arith.cmpi sge, %14, %c0_i32 : i32 loc(#loc19)
    llvm.intr.assume %16 : i1 loc(#loc20)
    %17 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc21)
    llvm.intr.assume %17 : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    llvm.intr.assume %true : i1 loc(#loc24)
    %18 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc25)
    llvm.intr.assume %18 : i1 loc(#loc26)
    %19 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc27)
    llvm.intr.assume %19 : i1 loc(#loc28)
    llvm.intr.assume %true : i1 loc(#loc29)
    %20 = arith.muli %12, %c32_i32 : i32 loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc31)
    %22 = tt.splat %20 : i32 -> tensor<32xi32> loc(#loc32)
    %23 = arith.addi %22, %21 : tensor<32xi32> loc(#loc32)
    %24 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc33)
    %25 = arith.remsi %23, %24 : tensor<32xi32> loc(#loc33)
    %26 = arith.muli %14, %c32_i32 : i32 loc(#loc34)
    %27 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc35)
    %28 = tt.splat %26 : i32 -> tensor<32xi32> loc(#loc36)
    %29 = arith.addi %28, %27 : tensor<32xi32> loc(#loc36)
    %30 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc37)
    %31 = arith.remsi %29, %30 : tensor<32xi32> loc(#loc37)
    %32 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc38)
    %33 = tt.expand_dims %25 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc39)
    %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc40)
    %35 = arith.muli %33, %34 : tensor<32x1xi32> loc(#loc40)
    %36 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc41)
    %37 = tt.broadcast %35 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc42)
    %38 = tt.broadcast %36 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc42)
    %39 = arith.addi %37, %38 : tensor<32x16xi32> loc(#loc42)
    %40 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc43)
    %41 = tt.addptr %40, %39 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc43)
    %42 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc44)
    %43 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc45)
    %44 = arith.muli %42, %43 : tensor<16x1xi32> loc(#loc45)
    %45 = tt.expand_dims %31 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc46)
    %46 = tt.broadcast %44 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc47)
    %47 = tt.broadcast %45 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc47)
    %48 = arith.addi %46, %47 : tensor<16x32xi32> loc(#loc47)
    %49 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc48)
    %50 = tt.addptr %49, %48 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc48)
    %51 = arith.addi %arg5, %c15_i32 : i32 loc(#loc89)
    %52 = arith.divsi %51, %c16_i32 : i32 loc(#loc90)
    %53:3 = scf.for %arg9 = %c0_i32 to %52 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %41, %arg12 = %50) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %81 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc51)
      %82 = arith.muli %arg9, %c16_i32 : i32 loc(#loc52)
      %83 = arith.subi %arg5, %82 : i32 loc(#loc53)
      %84 = tt.splat %83 : i32 -> tensor<1x16xi32> loc(#loc54)
      %85 = arith.cmpi slt, %81, %84 : tensor<1x16xi32> loc(#loc54)
      %86 = tt.broadcast %85 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc55)
      %87 = tt.load %arg11, %86, %cst_2 : tensor<32x16x!tt.ptr<f32>> loc(#loc55)
      %88 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc56)
      %89 = arith.muli %arg9, %c16_i32 : i32 loc(#loc57)
      %90 = arith.subi %arg5, %89 : i32 loc(#loc58)
      %91 = tt.splat %90 : i32 -> tensor<16x1xi32> loc(#loc59)
      %92 = arith.cmpi slt, %88, %91 : tensor<16x1xi32> loc(#loc59)
      %93 = tt.broadcast %92 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc60)
      %94 = tt.load %arg12, %93, %cst_1 : tensor<16x32x!tt.ptr<f32>> loc(#loc60)
      %95 = tt.dot %87, %94, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc61)
      %96 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc62)
      %97 = arith.muli %arg7, %c16_i32 : i32 loc(#loc63)
      %98 = tt.splat %97 : i32 -> tensor<16x32xi32> loc(#loc64)
      %99 = tt.addptr %arg12, %98 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc64)
      scf.yield %95, %96, %99 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc65)
    } loc(#loc50)
    %54 = arith.truncf %53#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc66)
    %55 = arith.muli %12, %c32_i32 : i32 loc(#loc67)
    %56 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc68)
    %57 = tt.splat %55 : i32 -> tensor<32xi32> loc(#loc69)
    %58 = arith.addi %57, %56 : tensor<32xi32> loc(#loc69)
    %59 = arith.muli %14, %c32_i32 : i32 loc(#loc70)
    %60 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc71)
    %61 = tt.splat %59 : i32 -> tensor<32xi32> loc(#loc72)
    %62 = arith.addi %61, %60 : tensor<32xi32> loc(#loc72)
    %63 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc73)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc74)
    %65 = arith.muli %64, %63 : tensor<32x1xi32> loc(#loc74)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc75)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc75)
    %68 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc76)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc77)
    %70 = tt.broadcast %68 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc77)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc77)
    %72 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc78)
    %73 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc79)
    %74 = arith.cmpi slt, %72, %73 : tensor<32x1xi32> loc(#loc79)
    %75 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc80)
    %76 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc81)
    %77 = arith.cmpi slt, %75, %76 : tensor<1x32xi32> loc(#loc81)
    %78 = tt.broadcast %74 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc82)
    %79 = tt.broadcast %77 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc82)
    %80 = arith.andi %78, %79 : tensor<32x32xi1> loc(#loc82)
    tt.store %71, %54, %80 : tensor<32x32x!tt.ptr<f16>> loc(#loc83)
    tt.return loc(#loc84)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:19)
#loc16 = loc("examples/kernels/binary_ops.py":134:40)
#loc17 = loc("examples/kernels/binary_ops.py":140:23)
#loc18 = loc("examples/kernels/binary_ops.py":140:14)
#loc19 = loc("examples/kernels/binary_ops.py":141:23)
#loc20 = loc("examples/kernels/binary_ops.py":141:14)
#loc21 = loc("examples/kernels/binary_ops.py":142:26)
#loc22 = loc("examples/kernels/binary_ops.py":142:14)
#loc23 = loc("examples/kernels/binary_ops.py":143:14)
#loc24 = loc("examples/kernels/binary_ops.py":144:14)
#loc25 = loc("examples/kernels/binary_ops.py":145:26)
#loc26 = loc("examples/kernels/binary_ops.py":145:14)
#loc27 = loc("examples/kernels/binary_ops.py":146:26)
#loc28 = loc("examples/kernels/binary_ops.py":146:14)
#loc29 = loc("examples/kernels/binary_ops.py":147:14)
#loc30 = loc("examples/kernels/binary_ops.py":156:23)
#loc31 = loc("examples/kernels/binary_ops.py":156:51)
#loc32 = loc("examples/kernels/binary_ops.py":156:38)
#loc33 = loc("examples/kernels/binary_ops.py":156:68)
#loc34 = loc("examples/kernels/binary_ops.py":157:23)
#loc35 = loc("examples/kernels/binary_ops.py":157:51)
#loc36 = loc("examples/kernels/binary_ops.py":157:38)
#loc37 = loc("examples/kernels/binary_ops.py":157:68)
#loc38 = loc("examples/kernels/binary_ops.py":158:26)
#loc39 = loc("examples/kernels/binary_ops.py":159:30)
#loc40 = loc("examples/kernels/binary_ops.py":159:41)
#loc41 = loc("examples/kernels/binary_ops.py":159:60)
#loc42 = loc("examples/kernels/binary_ops.py":159:53)
#loc43 = loc("examples/kernels/binary_ops.py":159:22)
#loc44 = loc("examples/kernels/binary_ops.py":160:29)
#loc45 = loc("examples/kernels/binary_ops.py":160:40)
#loc46 = loc("examples/kernels/binary_ops.py":160:60)
#loc47 = loc("examples/kernels/binary_ops.py":160:52)
#loc48 = loc("examples/kernels/binary_ops.py":160:22)
#loc49 = loc("examples/kernels/binary_ops.py":168:33)
#loc50 = loc("examples/kernels/binary_ops.py":168:22)
#loc51 = loc("examples/kernels/binary_ops.py":171:40)
#loc52 = loc("examples/kernels/binary_ops.py":171:59)
#loc53 = loc("examples/kernels/binary_ops.py":171:55)
#loc54 = loc("examples/kernels/binary_ops.py":171:51)
#loc55 = loc("examples/kernels/binary_ops.py":171:20)
#loc56 = loc("examples/kernels/binary_ops.py":172:40)
#loc57 = loc("examples/kernels/binary_ops.py":172:59)
#loc58 = loc("examples/kernels/binary_ops.py":172:55)
#loc59 = loc("examples/kernels/binary_ops.py":172:51)
#loc60 = loc("examples/kernels/binary_ops.py":172:20)
#loc61 = loc("examples/kernels/binary_ops.py":174:35)
#loc62 = loc("examples/kernels/binary_ops.py":176:18)
#loc63 = loc("examples/kernels/binary_ops.py":177:33)
#loc64 = loc("examples/kernels/binary_ops.py":177:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:8)
#loc66 = loc("examples/kernels/binary_ops.py":182:23)
#loc67 = loc("examples/kernels/binary_ops.py":186:22)
#loc68 = loc("examples/kernels/binary_ops.py":186:50)
#loc69 = loc("examples/kernels/binary_ops.py":186:37)
#loc70 = loc("examples/kernels/binary_ops.py":187:22)
#loc71 = loc("examples/kernels/binary_ops.py":187:50)
#loc72 = loc("examples/kernels/binary_ops.py":187:37)
#loc73 = loc("examples/kernels/binary_ops.py":188:41)
#loc74 = loc("examples/kernels/binary_ops.py":188:33)
#loc75 = loc("examples/kernels/binary_ops.py":188:21)
#loc76 = loc("examples/kernels/binary_ops.py":188:72)
#loc77 = loc("examples/kernels/binary_ops.py":188:52)
#loc78 = loc("examples/kernels/binary_ops.py":189:22)
#loc79 = loc("examples/kernels/binary_ops.py":189:33)
#loc80 = loc("examples/kernels/binary_ops.py":189:47)
#loc81 = loc("examples/kernels/binary_ops.py":189:58)
#loc82 = loc("examples/kernels/binary_ops.py":189:39)
#loc83 = loc("examples/kernels/binary_ops.py":190:21)
#loc84 = loc("examples/kernels/binary_ops.py":190:4)
#loc85 = loc(callsite(#loc3 at #loc4))
#loc86 = loc(callsite(#loc5 at #loc4))
#loc87 = loc(callsite(#loc3 at #loc6))
#loc88 = loc(callsite(#loc5 at #loc6))
#loc89 = loc(callsite(#loc3 at #loc49))
#loc90 = loc(callsite(#loc5 at #loc49))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc85)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc86)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc87)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc88)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.remsi %0, %5 : i32 loc(#loc15)
    %14 = arith.divsi %13, %9 : i32 loc(#loc16)
    %15 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc17)
    llvm.intr.assume %15 : i1 loc(#loc18)
    %16 = arith.cmpi sge, %14, %c0_i32 : i32 loc(#loc19)
    llvm.intr.assume %16 : i1 loc(#loc20)
    %17 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc21)
    llvm.intr.assume %17 : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    llvm.intr.assume %true : i1 loc(#loc24)
    %18 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc25)
    llvm.intr.assume %18 : i1 loc(#loc26)
    %19 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc27)
    llvm.intr.assume %19 : i1 loc(#loc28)
    llvm.intr.assume %true : i1 loc(#loc29)
    %20 = arith.muli %12, %c32_i32 : i32 loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc31)
    %22 = tt.splat %20 : i32 -> tensor<32xi32> loc(#loc32)
    %23 = arith.addi %22, %21 : tensor<32xi32> loc(#loc32)
    %24 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc33)
    %25 = arith.remsi %23, %24 : tensor<32xi32> loc(#loc33)
    %26 = arith.muli %14, %c32_i32 : i32 loc(#loc34)
    %27 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc35)
    %28 = tt.splat %26 : i32 -> tensor<32xi32> loc(#loc36)
    %29 = arith.addi %28, %27 : tensor<32xi32> loc(#loc36)
    %30 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc37)
    %31 = arith.remsi %29, %30 : tensor<32xi32> loc(#loc37)
    %32 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc38)
    %33 = tt.expand_dims %25 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc39)
    %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc40)
    %35 = arith.muli %33, %34 : tensor<32x1xi32> loc(#loc40)
    %36 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc41)
    %37 = tt.broadcast %35 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc42)
    %38 = tt.broadcast %36 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc42)
    %39 = arith.addi %37, %38 : tensor<32x16xi32> loc(#loc42)
    %40 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc43)
    %41 = tt.addptr %40, %39 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc43)
    %42 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc44)
    %43 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc45)
    %44 = arith.muli %42, %43 : tensor<16x1xi32> loc(#loc45)
    %45 = tt.expand_dims %31 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc46)
    %46 = tt.broadcast %44 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc47)
    %47 = tt.broadcast %45 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc47)
    %48 = arith.addi %46, %47 : tensor<16x32xi32> loc(#loc47)
    %49 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc48)
    %50 = tt.addptr %49, %48 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc48)
    %51 = arith.addi %arg5, %c15_i32 : i32 loc(#loc89)
    %52 = arith.divsi %51, %c16_i32 : i32 loc(#loc90)
    %53:3 = scf.for %arg9 = %c0_i32 to %52 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %41, %arg12 = %50) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %81 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc51)
      %82 = arith.muli %arg9, %c16_i32 : i32 loc(#loc52)
      %83 = arith.subi %arg5, %82 : i32 loc(#loc53)
      %84 = tt.splat %83 : i32 -> tensor<1x16xi32> loc(#loc54)
      %85 = arith.cmpi slt, %81, %84 : tensor<1x16xi32> loc(#loc54)
      %86 = tt.broadcast %85 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc55)
      %87 = tt.load %arg11, %86, %cst_2 : tensor<32x16x!tt.ptr<f32>> loc(#loc55)
      %88 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc56)
      %89 = arith.muli %arg9, %c16_i32 : i32 loc(#loc57)
      %90 = arith.subi %arg5, %89 : i32 loc(#loc58)
      %91 = tt.splat %90 : i32 -> tensor<16x1xi32> loc(#loc59)
      %92 = arith.cmpi slt, %88, %91 : tensor<16x1xi32> loc(#loc59)
      %93 = tt.broadcast %92 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc60)
      %94 = tt.load %arg12, %93, %cst_1 : tensor<16x32x!tt.ptr<f32>> loc(#loc60)
      %95 = tt.dot %87, %94, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc61)
      %96 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc62)
      %97 = arith.muli %arg7, %c16_i32 : i32 loc(#loc63)
      %98 = tt.splat %97 : i32 -> tensor<16x32xi32> loc(#loc64)
      %99 = tt.addptr %arg12, %98 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc64)
      scf.yield %95, %96, %99 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc65)
    } loc(#loc50)
    %54 = arith.truncf %53#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc66)
    %55 = arith.muli %12, %c32_i32 : i32 loc(#loc67)
    %56 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc68)
    %57 = tt.splat %55 : i32 -> tensor<32xi32> loc(#loc69)
    %58 = arith.addi %57, %56 : tensor<32xi32> loc(#loc69)
    %59 = arith.muli %14, %c32_i32 : i32 loc(#loc70)
    %60 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc71)
    %61 = tt.splat %59 : i32 -> tensor<32xi32> loc(#loc72)
    %62 = arith.addi %61, %60 : tensor<32xi32> loc(#loc72)
    %63 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc73)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc74)
    %65 = arith.muli %64, %63 : tensor<32x1xi32> loc(#loc74)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc75)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc75)
    %68 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc76)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc77)
    %70 = tt.broadcast %68 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc77)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc77)
    %72 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc78)
    %73 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc79)
    %74 = arith.cmpi slt, %72, %73 : tensor<32x1xi32> loc(#loc79)
    %75 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc80)
    %76 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc81)
    %77 = arith.cmpi slt, %75, %76 : tensor<1x32xi32> loc(#loc81)
    %78 = tt.broadcast %74 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc82)
    %79 = tt.broadcast %77 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc82)
    %80 = arith.andi %78, %79 : tensor<32x32xi1> loc(#loc82)
    tt.store %71, %54, %80 : tensor<32x32x!tt.ptr<f16>> loc(#loc83)
    tt.return loc(#loc84)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:19)
#loc16 = loc("examples/kernels/binary_ops.py":134:40)
#loc17 = loc("examples/kernels/binary_ops.py":140:23)
#loc18 = loc("examples/kernels/binary_ops.py":140:14)
#loc19 = loc("examples/kernels/binary_ops.py":141:23)
#loc20 = loc("examples/kernels/binary_ops.py":141:14)
#loc21 = loc("examples/kernels/binary_ops.py":142:26)
#loc22 = loc("examples/kernels/binary_ops.py":142:14)
#loc23 = loc("examples/kernels/binary_ops.py":143:14)
#loc24 = loc("examples/kernels/binary_ops.py":144:14)
#loc25 = loc("examples/kernels/binary_ops.py":145:26)
#loc26 = loc("examples/kernels/binary_ops.py":145:14)
#loc27 = loc("examples/kernels/binary_ops.py":146:26)
#loc28 = loc("examples/kernels/binary_ops.py":146:14)
#loc29 = loc("examples/kernels/binary_ops.py":147:14)
#loc30 = loc("examples/kernels/binary_ops.py":156:23)
#loc31 = loc("examples/kernels/binary_ops.py":156:51)
#loc32 = loc("examples/kernels/binary_ops.py":156:38)
#loc33 = loc("examples/kernels/binary_ops.py":156:68)
#loc34 = loc("examples/kernels/binary_ops.py":157:23)
#loc35 = loc("examples/kernels/binary_ops.py":157:51)
#loc36 = loc("examples/kernels/binary_ops.py":157:38)
#loc37 = loc("examples/kernels/binary_ops.py":157:68)
#loc38 = loc("examples/kernels/binary_ops.py":158:26)
#loc39 = loc("examples/kernels/binary_ops.py":159:30)
#loc40 = loc("examples/kernels/binary_ops.py":159:41)
#loc41 = loc("examples/kernels/binary_ops.py":159:60)
#loc42 = loc("examples/kernels/binary_ops.py":159:53)
#loc43 = loc("examples/kernels/binary_ops.py":159:22)
#loc44 = loc("examples/kernels/binary_ops.py":160:29)
#loc45 = loc("examples/kernels/binary_ops.py":160:40)
#loc46 = loc("examples/kernels/binary_ops.py":160:60)
#loc47 = loc("examples/kernels/binary_ops.py":160:52)
#loc48 = loc("examples/kernels/binary_ops.py":160:22)
#loc49 = loc("examples/kernels/binary_ops.py":168:33)
#loc50 = loc("examples/kernels/binary_ops.py":168:22)
#loc51 = loc("examples/kernels/binary_ops.py":171:40)
#loc52 = loc("examples/kernels/binary_ops.py":171:59)
#loc53 = loc("examples/kernels/binary_ops.py":171:55)
#loc54 = loc("examples/kernels/binary_ops.py":171:51)
#loc55 = loc("examples/kernels/binary_ops.py":171:20)
#loc56 = loc("examples/kernels/binary_ops.py":172:40)
#loc57 = loc("examples/kernels/binary_ops.py":172:59)
#loc58 = loc("examples/kernels/binary_ops.py":172:55)
#loc59 = loc("examples/kernels/binary_ops.py":172:51)
#loc60 = loc("examples/kernels/binary_ops.py":172:20)
#loc61 = loc("examples/kernels/binary_ops.py":174:35)
#loc62 = loc("examples/kernels/binary_ops.py":176:18)
#loc63 = loc("examples/kernels/binary_ops.py":177:33)
#loc64 = loc("examples/kernels/binary_ops.py":177:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:8)
#loc66 = loc("examples/kernels/binary_ops.py":182:23)
#loc67 = loc("examples/kernels/binary_ops.py":186:22)
#loc68 = loc("examples/kernels/binary_ops.py":186:50)
#loc69 = loc("examples/kernels/binary_ops.py":186:37)
#loc70 = loc("examples/kernels/binary_ops.py":187:22)
#loc71 = loc("examples/kernels/binary_ops.py":187:50)
#loc72 = loc("examples/kernels/binary_ops.py":187:37)
#loc73 = loc("examples/kernels/binary_ops.py":188:41)
#loc74 = loc("examples/kernels/binary_ops.py":188:33)
#loc75 = loc("examples/kernels/binary_ops.py":188:21)
#loc76 = loc("examples/kernels/binary_ops.py":188:72)
#loc77 = loc("examples/kernels/binary_ops.py":188:52)
#loc78 = loc("examples/kernels/binary_ops.py":189:22)
#loc79 = loc("examples/kernels/binary_ops.py":189:33)
#loc80 = loc("examples/kernels/binary_ops.py":189:47)
#loc81 = loc("examples/kernels/binary_ops.py":189:58)
#loc82 = loc("examples/kernels/binary_ops.py":189:39)
#loc83 = loc("examples/kernels/binary_ops.py":190:21)
#loc84 = loc("examples/kernels/binary_ops.py":190:4)
#loc85 = loc(callsite(#loc3 at #loc4))
#loc86 = loc(callsite(#loc5 at #loc4))
#loc87 = loc(callsite(#loc3 at #loc6))
#loc88 = loc(callsite(#loc5 at #loc6))
#loc89 = loc(callsite(#loc3 at #loc49))
#loc90 = loc(callsite(#loc5 at #loc49))


// -----// IR Dump Before TritonCombineOps (triton-combine) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc85)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc86)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc87)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc88)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.remsi %0, %5 : i32 loc(#loc15)
    %14 = arith.divsi %13, %9 : i32 loc(#loc16)
    %15 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc17)
    llvm.intr.assume %15 : i1 loc(#loc18)
    %16 = arith.cmpi sge, %14, %c0_i32 : i32 loc(#loc19)
    llvm.intr.assume %16 : i1 loc(#loc20)
    %17 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc21)
    llvm.intr.assume %17 : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    llvm.intr.assume %true : i1 loc(#loc24)
    %18 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc25)
    llvm.intr.assume %18 : i1 loc(#loc26)
    %19 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc27)
    llvm.intr.assume %19 : i1 loc(#loc28)
    llvm.intr.assume %true : i1 loc(#loc29)
    %20 = arith.muli %12, %c32_i32 : i32 loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc31)
    %22 = tt.splat %20 : i32 -> tensor<32xi32> loc(#loc32)
    %23 = arith.addi %22, %21 : tensor<32xi32> loc(#loc32)
    %24 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc33)
    %25 = arith.remsi %23, %24 : tensor<32xi32> loc(#loc33)
    %26 = arith.muli %14, %c32_i32 : i32 loc(#loc34)
    %27 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc35)
    %28 = tt.splat %26 : i32 -> tensor<32xi32> loc(#loc36)
    %29 = arith.addi %28, %27 : tensor<32xi32> loc(#loc36)
    %30 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc37)
    %31 = arith.remsi %29, %30 : tensor<32xi32> loc(#loc37)
    %32 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc38)
    %33 = tt.expand_dims %25 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc39)
    %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc40)
    %35 = arith.muli %33, %34 : tensor<32x1xi32> loc(#loc40)
    %36 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc41)
    %37 = tt.broadcast %35 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc42)
    %38 = tt.broadcast %36 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc42)
    %39 = arith.addi %37, %38 : tensor<32x16xi32> loc(#loc42)
    %40 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc43)
    %41 = tt.addptr %40, %39 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc43)
    %42 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc44)
    %43 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc45)
    %44 = arith.muli %42, %43 : tensor<16x1xi32> loc(#loc45)
    %45 = tt.expand_dims %31 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc46)
    %46 = tt.broadcast %44 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc47)
    %47 = tt.broadcast %45 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc47)
    %48 = arith.addi %46, %47 : tensor<16x32xi32> loc(#loc47)
    %49 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc48)
    %50 = tt.addptr %49, %48 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc48)
    %51 = arith.addi %arg5, %c15_i32 : i32 loc(#loc89)
    %52 = arith.divsi %51, %c16_i32 : i32 loc(#loc90)
    %53:3 = scf.for %arg9 = %c0_i32 to %52 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %41, %arg12 = %50) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %81 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc51)
      %82 = arith.muli %arg9, %c16_i32 : i32 loc(#loc52)
      %83 = arith.subi %arg5, %82 : i32 loc(#loc53)
      %84 = tt.splat %83 : i32 -> tensor<1x16xi32> loc(#loc54)
      %85 = arith.cmpi slt, %81, %84 : tensor<1x16xi32> loc(#loc54)
      %86 = tt.broadcast %85 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc55)
      %87 = tt.load %arg11, %86, %cst_2 : tensor<32x16x!tt.ptr<f32>> loc(#loc55)
      %88 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc56)
      %89 = arith.muli %arg9, %c16_i32 : i32 loc(#loc57)
      %90 = arith.subi %arg5, %89 : i32 loc(#loc58)
      %91 = tt.splat %90 : i32 -> tensor<16x1xi32> loc(#loc59)
      %92 = arith.cmpi slt, %88, %91 : tensor<16x1xi32> loc(#loc59)
      %93 = tt.broadcast %92 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc60)
      %94 = tt.load %arg12, %93, %cst_1 : tensor<16x32x!tt.ptr<f32>> loc(#loc60)
      %95 = tt.dot %87, %94, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc61)
      %96 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc62)
      %97 = arith.muli %arg7, %c16_i32 : i32 loc(#loc63)
      %98 = tt.splat %97 : i32 -> tensor<16x32xi32> loc(#loc64)
      %99 = tt.addptr %arg12, %98 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc64)
      scf.yield %95, %96, %99 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc65)
    } loc(#loc50)
    %54 = arith.truncf %53#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc66)
    %55 = arith.muli %12, %c32_i32 : i32 loc(#loc67)
    %56 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc68)
    %57 = tt.splat %55 : i32 -> tensor<32xi32> loc(#loc69)
    %58 = arith.addi %57, %56 : tensor<32xi32> loc(#loc69)
    %59 = arith.muli %14, %c32_i32 : i32 loc(#loc70)
    %60 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc71)
    %61 = tt.splat %59 : i32 -> tensor<32xi32> loc(#loc72)
    %62 = arith.addi %61, %60 : tensor<32xi32> loc(#loc72)
    %63 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc73)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc74)
    %65 = arith.muli %64, %63 : tensor<32x1xi32> loc(#loc74)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc75)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc75)
    %68 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc76)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc77)
    %70 = tt.broadcast %68 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc77)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc77)
    %72 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc78)
    %73 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc79)
    %74 = arith.cmpi slt, %72, %73 : tensor<32x1xi32> loc(#loc79)
    %75 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc80)
    %76 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc81)
    %77 = arith.cmpi slt, %75, %76 : tensor<1x32xi32> loc(#loc81)
    %78 = tt.broadcast %74 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc82)
    %79 = tt.broadcast %77 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc82)
    %80 = arith.andi %78, %79 : tensor<32x32xi1> loc(#loc82)
    tt.store %71, %54, %80 : tensor<32x32x!tt.ptr<f16>> loc(#loc83)
    tt.return loc(#loc84)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:19)
#loc16 = loc("examples/kernels/binary_ops.py":134:40)
#loc17 = loc("examples/kernels/binary_ops.py":140:23)
#loc18 = loc("examples/kernels/binary_ops.py":140:14)
#loc19 = loc("examples/kernels/binary_ops.py":141:23)
#loc20 = loc("examples/kernels/binary_ops.py":141:14)
#loc21 = loc("examples/kernels/binary_ops.py":142:26)
#loc22 = loc("examples/kernels/binary_ops.py":142:14)
#loc23 = loc("examples/kernels/binary_ops.py":143:14)
#loc24 = loc("examples/kernels/binary_ops.py":144:14)
#loc25 = loc("examples/kernels/binary_ops.py":145:26)
#loc26 = loc("examples/kernels/binary_ops.py":145:14)
#loc27 = loc("examples/kernels/binary_ops.py":146:26)
#loc28 = loc("examples/kernels/binary_ops.py":146:14)
#loc29 = loc("examples/kernels/binary_ops.py":147:14)
#loc30 = loc("examples/kernels/binary_ops.py":156:23)
#loc31 = loc("examples/kernels/binary_ops.py":156:51)
#loc32 = loc("examples/kernels/binary_ops.py":156:38)
#loc33 = loc("examples/kernels/binary_ops.py":156:68)
#loc34 = loc("examples/kernels/binary_ops.py":157:23)
#loc35 = loc("examples/kernels/binary_ops.py":157:51)
#loc36 = loc("examples/kernels/binary_ops.py":157:38)
#loc37 = loc("examples/kernels/binary_ops.py":157:68)
#loc38 = loc("examples/kernels/binary_ops.py":158:26)
#loc39 = loc("examples/kernels/binary_ops.py":159:30)
#loc40 = loc("examples/kernels/binary_ops.py":159:41)
#loc41 = loc("examples/kernels/binary_ops.py":159:60)
#loc42 = loc("examples/kernels/binary_ops.py":159:53)
#loc43 = loc("examples/kernels/binary_ops.py":159:22)
#loc44 = loc("examples/kernels/binary_ops.py":160:29)
#loc45 = loc("examples/kernels/binary_ops.py":160:40)
#loc46 = loc("examples/kernels/binary_ops.py":160:60)
#loc47 = loc("examples/kernels/binary_ops.py":160:52)
#loc48 = loc("examples/kernels/binary_ops.py":160:22)
#loc49 = loc("examples/kernels/binary_ops.py":168:33)
#loc50 = loc("examples/kernels/binary_ops.py":168:22)
#loc51 = loc("examples/kernels/binary_ops.py":171:40)
#loc52 = loc("examples/kernels/binary_ops.py":171:59)
#loc53 = loc("examples/kernels/binary_ops.py":171:55)
#loc54 = loc("examples/kernels/binary_ops.py":171:51)
#loc55 = loc("examples/kernels/binary_ops.py":171:20)
#loc56 = loc("examples/kernels/binary_ops.py":172:40)
#loc57 = loc("examples/kernels/binary_ops.py":172:59)
#loc58 = loc("examples/kernels/binary_ops.py":172:55)
#loc59 = loc("examples/kernels/binary_ops.py":172:51)
#loc60 = loc("examples/kernels/binary_ops.py":172:20)
#loc61 = loc("examples/kernels/binary_ops.py":174:35)
#loc62 = loc("examples/kernels/binary_ops.py":176:18)
#loc63 = loc("examples/kernels/binary_ops.py":177:33)
#loc64 = loc("examples/kernels/binary_ops.py":177:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:8)
#loc66 = loc("examples/kernels/binary_ops.py":182:23)
#loc67 = loc("examples/kernels/binary_ops.py":186:22)
#loc68 = loc("examples/kernels/binary_ops.py":186:50)
#loc69 = loc("examples/kernels/binary_ops.py":186:37)
#loc70 = loc("examples/kernels/binary_ops.py":187:22)
#loc71 = loc("examples/kernels/binary_ops.py":187:50)
#loc72 = loc("examples/kernels/binary_ops.py":187:37)
#loc73 = loc("examples/kernels/binary_ops.py":188:41)
#loc74 = loc("examples/kernels/binary_ops.py":188:33)
#loc75 = loc("examples/kernels/binary_ops.py":188:21)
#loc76 = loc("examples/kernels/binary_ops.py":188:72)
#loc77 = loc("examples/kernels/binary_ops.py":188:52)
#loc78 = loc("examples/kernels/binary_ops.py":189:22)
#loc79 = loc("examples/kernels/binary_ops.py":189:33)
#loc80 = loc("examples/kernels/binary_ops.py":189:47)
#loc81 = loc("examples/kernels/binary_ops.py":189:58)
#loc82 = loc("examples/kernels/binary_ops.py":189:39)
#loc83 = loc("examples/kernels/binary_ops.py":190:21)
#loc84 = loc("examples/kernels/binary_ops.py":190:4)
#loc85 = loc(callsite(#loc3 at #loc4))
#loc86 = loc(callsite(#loc5 at #loc4))
#loc87 = loc(callsite(#loc3 at #loc6))
#loc88 = loc(callsite(#loc5 at #loc6))
#loc89 = loc(callsite(#loc3 at #loc49))
#loc90 = loc(callsite(#loc5 at #loc49))


// -----// IR Dump Before TritonReorderBroadcast (triton-reorder-broadcast) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc85)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc86)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc87)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc88)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.remsi %0, %5 : i32 loc(#loc15)
    %14 = arith.divsi %13, %9 : i32 loc(#loc16)
    %15 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc17)
    llvm.intr.assume %15 : i1 loc(#loc18)
    %16 = arith.cmpi sge, %14, %c0_i32 : i32 loc(#loc19)
    llvm.intr.assume %16 : i1 loc(#loc20)
    %17 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc21)
    llvm.intr.assume %17 : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    llvm.intr.assume %true : i1 loc(#loc24)
    %18 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc25)
    llvm.intr.assume %18 : i1 loc(#loc26)
    %19 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc27)
    llvm.intr.assume %19 : i1 loc(#loc28)
    llvm.intr.assume %true : i1 loc(#loc29)
    %20 = arith.muli %12, %c32_i32 : i32 loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc31)
    %22 = tt.splat %20 : i32 -> tensor<32xi32> loc(#loc32)
    %23 = arith.addi %22, %21 : tensor<32xi32> loc(#loc32)
    %24 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc33)
    %25 = arith.remsi %23, %24 : tensor<32xi32> loc(#loc33)
    %26 = arith.muli %14, %c32_i32 : i32 loc(#loc34)
    %27 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc35)
    %28 = tt.splat %26 : i32 -> tensor<32xi32> loc(#loc36)
    %29 = arith.addi %28, %27 : tensor<32xi32> loc(#loc36)
    %30 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc37)
    %31 = arith.remsi %29, %30 : tensor<32xi32> loc(#loc37)
    %32 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc38)
    %33 = tt.expand_dims %25 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc39)
    %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc40)
    %35 = arith.muli %33, %34 : tensor<32x1xi32> loc(#loc40)
    %36 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc41)
    %37 = tt.broadcast %35 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc42)
    %38 = tt.broadcast %36 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc42)
    %39 = arith.addi %37, %38 : tensor<32x16xi32> loc(#loc42)
    %40 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc43)
    %41 = tt.addptr %40, %39 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc43)
    %42 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc44)
    %43 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc45)
    %44 = arith.muli %42, %43 : tensor<16x1xi32> loc(#loc45)
    %45 = tt.expand_dims %31 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc46)
    %46 = tt.broadcast %44 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc47)
    %47 = tt.broadcast %45 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc47)
    %48 = arith.addi %46, %47 : tensor<16x32xi32> loc(#loc47)
    %49 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc48)
    %50 = tt.addptr %49, %48 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc48)
    %51 = arith.addi %arg5, %c15_i32 : i32 loc(#loc89)
    %52 = arith.divsi %51, %c16_i32 : i32 loc(#loc90)
    %53:3 = scf.for %arg9 = %c0_i32 to %52 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %41, %arg12 = %50) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %81 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc51)
      %82 = arith.muli %arg9, %c16_i32 : i32 loc(#loc52)
      %83 = arith.subi %arg5, %82 : i32 loc(#loc53)
      %84 = tt.splat %83 : i32 -> tensor<1x16xi32> loc(#loc54)
      %85 = arith.cmpi slt, %81, %84 : tensor<1x16xi32> loc(#loc54)
      %86 = tt.broadcast %85 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc55)
      %87 = tt.load %arg11, %86, %cst_2 : tensor<32x16x!tt.ptr<f32>> loc(#loc55)
      %88 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc56)
      %89 = arith.muli %arg9, %c16_i32 : i32 loc(#loc57)
      %90 = arith.subi %arg5, %89 : i32 loc(#loc58)
      %91 = tt.splat %90 : i32 -> tensor<16x1xi32> loc(#loc59)
      %92 = arith.cmpi slt, %88, %91 : tensor<16x1xi32> loc(#loc59)
      %93 = tt.broadcast %92 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc60)
      %94 = tt.load %arg12, %93, %cst_1 : tensor<16x32x!tt.ptr<f32>> loc(#loc60)
      %95 = tt.dot %87, %94, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc61)
      %96 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc62)
      %97 = arith.muli %arg7, %c16_i32 : i32 loc(#loc63)
      %98 = tt.splat %97 : i32 -> tensor<16x32xi32> loc(#loc64)
      %99 = tt.addptr %arg12, %98 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc64)
      scf.yield %95, %96, %99 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc65)
    } loc(#loc50)
    %54 = arith.truncf %53#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc66)
    %55 = arith.muli %12, %c32_i32 : i32 loc(#loc67)
    %56 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc68)
    %57 = tt.splat %55 : i32 -> tensor<32xi32> loc(#loc69)
    %58 = arith.addi %57, %56 : tensor<32xi32> loc(#loc69)
    %59 = arith.muli %14, %c32_i32 : i32 loc(#loc70)
    %60 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc71)
    %61 = tt.splat %59 : i32 -> tensor<32xi32> loc(#loc72)
    %62 = arith.addi %61, %60 : tensor<32xi32> loc(#loc72)
    %63 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc73)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc74)
    %65 = arith.muli %64, %63 : tensor<32x1xi32> loc(#loc74)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc75)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc75)
    %68 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc76)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc77)
    %70 = tt.broadcast %68 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc77)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc77)
    %72 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc78)
    %73 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc79)
    %74 = arith.cmpi slt, %72, %73 : tensor<32x1xi32> loc(#loc79)
    %75 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc80)
    %76 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc81)
    %77 = arith.cmpi slt, %75, %76 : tensor<1x32xi32> loc(#loc81)
    %78 = tt.broadcast %74 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc82)
    %79 = tt.broadcast %77 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc82)
    %80 = arith.andi %78, %79 : tensor<32x32xi1> loc(#loc82)
    tt.store %71, %54, %80 : tensor<32x32x!tt.ptr<f16>> loc(#loc83)
    tt.return loc(#loc84)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:19)
#loc16 = loc("examples/kernels/binary_ops.py":134:40)
#loc17 = loc("examples/kernels/binary_ops.py":140:23)
#loc18 = loc("examples/kernels/binary_ops.py":140:14)
#loc19 = loc("examples/kernels/binary_ops.py":141:23)
#loc20 = loc("examples/kernels/binary_ops.py":141:14)
#loc21 = loc("examples/kernels/binary_ops.py":142:26)
#loc22 = loc("examples/kernels/binary_ops.py":142:14)
#loc23 = loc("examples/kernels/binary_ops.py":143:14)
#loc24 = loc("examples/kernels/binary_ops.py":144:14)
#loc25 = loc("examples/kernels/binary_ops.py":145:26)
#loc26 = loc("examples/kernels/binary_ops.py":145:14)
#loc27 = loc("examples/kernels/binary_ops.py":146:26)
#loc28 = loc("examples/kernels/binary_ops.py":146:14)
#loc29 = loc("examples/kernels/binary_ops.py":147:14)
#loc30 = loc("examples/kernels/binary_ops.py":156:23)
#loc31 = loc("examples/kernels/binary_ops.py":156:51)
#loc32 = loc("examples/kernels/binary_ops.py":156:38)
#loc33 = loc("examples/kernels/binary_ops.py":156:68)
#loc34 = loc("examples/kernels/binary_ops.py":157:23)
#loc35 = loc("examples/kernels/binary_ops.py":157:51)
#loc36 = loc("examples/kernels/binary_ops.py":157:38)
#loc37 = loc("examples/kernels/binary_ops.py":157:68)
#loc38 = loc("examples/kernels/binary_ops.py":158:26)
#loc39 = loc("examples/kernels/binary_ops.py":159:30)
#loc40 = loc("examples/kernels/binary_ops.py":159:41)
#loc41 = loc("examples/kernels/binary_ops.py":159:60)
#loc42 = loc("examples/kernels/binary_ops.py":159:53)
#loc43 = loc("examples/kernels/binary_ops.py":159:22)
#loc44 = loc("examples/kernels/binary_ops.py":160:29)
#loc45 = loc("examples/kernels/binary_ops.py":160:40)
#loc46 = loc("examples/kernels/binary_ops.py":160:60)
#loc47 = loc("examples/kernels/binary_ops.py":160:52)
#loc48 = loc("examples/kernels/binary_ops.py":160:22)
#loc49 = loc("examples/kernels/binary_ops.py":168:33)
#loc50 = loc("examples/kernels/binary_ops.py":168:22)
#loc51 = loc("examples/kernels/binary_ops.py":171:40)
#loc52 = loc("examples/kernels/binary_ops.py":171:59)
#loc53 = loc("examples/kernels/binary_ops.py":171:55)
#loc54 = loc("examples/kernels/binary_ops.py":171:51)
#loc55 = loc("examples/kernels/binary_ops.py":171:20)
#loc56 = loc("examples/kernels/binary_ops.py":172:40)
#loc57 = loc("examples/kernels/binary_ops.py":172:59)
#loc58 = loc("examples/kernels/binary_ops.py":172:55)
#loc59 = loc("examples/kernels/binary_ops.py":172:51)
#loc60 = loc("examples/kernels/binary_ops.py":172:20)
#loc61 = loc("examples/kernels/binary_ops.py":174:35)
#loc62 = loc("examples/kernels/binary_ops.py":176:18)
#loc63 = loc("examples/kernels/binary_ops.py":177:33)
#loc64 = loc("examples/kernels/binary_ops.py":177:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:8)
#loc66 = loc("examples/kernels/binary_ops.py":182:23)
#loc67 = loc("examples/kernels/binary_ops.py":186:22)
#loc68 = loc("examples/kernels/binary_ops.py":186:50)
#loc69 = loc("examples/kernels/binary_ops.py":186:37)
#loc70 = loc("examples/kernels/binary_ops.py":187:22)
#loc71 = loc("examples/kernels/binary_ops.py":187:50)
#loc72 = loc("examples/kernels/binary_ops.py":187:37)
#loc73 = loc("examples/kernels/binary_ops.py":188:41)
#loc74 = loc("examples/kernels/binary_ops.py":188:33)
#loc75 = loc("examples/kernels/binary_ops.py":188:21)
#loc76 = loc("examples/kernels/binary_ops.py":188:72)
#loc77 = loc("examples/kernels/binary_ops.py":188:52)
#loc78 = loc("examples/kernels/binary_ops.py":189:22)
#loc79 = loc("examples/kernels/binary_ops.py":189:33)
#loc80 = loc("examples/kernels/binary_ops.py":189:47)
#loc81 = loc("examples/kernels/binary_ops.py":189:58)
#loc82 = loc("examples/kernels/binary_ops.py":189:39)
#loc83 = loc("examples/kernels/binary_ops.py":190:21)
#loc84 = loc("examples/kernels/binary_ops.py":190:4)
#loc85 = loc(callsite(#loc3 at #loc4))
#loc86 = loc(callsite(#loc5 at #loc4))
#loc87 = loc(callsite(#loc3 at #loc6))
#loc88 = loc(callsite(#loc5 at #loc6))
#loc89 = loc(callsite(#loc3 at #loc49))
#loc90 = loc(callsite(#loc5 at #loc49))


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc85)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc86)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc87)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc88)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.remsi %0, %5 : i32 loc(#loc15)
    %14 = arith.divsi %13, %9 : i32 loc(#loc16)
    %15 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc17)
    llvm.intr.assume %15 : i1 loc(#loc18)
    %16 = arith.cmpi sge, %14, %c0_i32 : i32 loc(#loc19)
    llvm.intr.assume %16 : i1 loc(#loc20)
    %17 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc21)
    llvm.intr.assume %17 : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    llvm.intr.assume %true : i1 loc(#loc24)
    %18 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc25)
    llvm.intr.assume %18 : i1 loc(#loc26)
    %19 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc27)
    llvm.intr.assume %19 : i1 loc(#loc28)
    llvm.intr.assume %true : i1 loc(#loc29)
    %20 = arith.muli %12, %c32_i32 : i32 loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc31)
    %22 = tt.splat %20 : i32 -> tensor<32xi32> loc(#loc32)
    %23 = arith.addi %22, %21 : tensor<32xi32> loc(#loc32)
    %24 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc33)
    %25 = arith.remsi %23, %24 : tensor<32xi32> loc(#loc33)
    %26 = arith.muli %14, %c32_i32 : i32 loc(#loc34)
    %27 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc35)
    %28 = tt.splat %26 : i32 -> tensor<32xi32> loc(#loc36)
    %29 = arith.addi %28, %27 : tensor<32xi32> loc(#loc36)
    %30 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc37)
    %31 = arith.remsi %29, %30 : tensor<32xi32> loc(#loc37)
    %32 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc38)
    %33 = tt.expand_dims %25 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc39)
    %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc40)
    %35 = arith.muli %33, %34 : tensor<32x1xi32> loc(#loc40)
    %36 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc41)
    %37 = tt.broadcast %35 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc42)
    %38 = tt.broadcast %36 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc42)
    %39 = arith.addi %37, %38 : tensor<32x16xi32> loc(#loc42)
    %40 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc43)
    %41 = tt.addptr %40, %39 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc43)
    %42 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc44)
    %43 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc45)
    %44 = arith.muli %42, %43 : tensor<16x1xi32> loc(#loc45)
    %45 = tt.expand_dims %31 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc46)
    %46 = tt.broadcast %44 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc47)
    %47 = tt.broadcast %45 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc47)
    %48 = arith.addi %46, %47 : tensor<16x32xi32> loc(#loc47)
    %49 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc48)
    %50 = tt.addptr %49, %48 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc48)
    %51 = arith.addi %arg5, %c15_i32 : i32 loc(#loc89)
    %52 = arith.divsi %51, %c16_i32 : i32 loc(#loc90)
    %53:3 = scf.for %arg9 = %c0_i32 to %52 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %41, %arg12 = %50) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %81 = tt.expand_dims %32 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc51)
      %82 = arith.muli %arg9, %c16_i32 : i32 loc(#loc52)
      %83 = arith.subi %arg5, %82 : i32 loc(#loc53)
      %84 = tt.splat %83 : i32 -> tensor<1x16xi32> loc(#loc54)
      %85 = arith.cmpi slt, %81, %84 : tensor<1x16xi32> loc(#loc54)
      %86 = tt.broadcast %85 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc55)
      %87 = tt.load %arg11, %86, %cst_2 : tensor<32x16x!tt.ptr<f32>> loc(#loc55)
      %88 = tt.expand_dims %32 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc56)
      %89 = arith.muli %arg9, %c16_i32 : i32 loc(#loc57)
      %90 = arith.subi %arg5, %89 : i32 loc(#loc58)
      %91 = tt.splat %90 : i32 -> tensor<16x1xi32> loc(#loc59)
      %92 = arith.cmpi slt, %88, %91 : tensor<16x1xi32> loc(#loc59)
      %93 = tt.broadcast %92 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc60)
      %94 = tt.load %arg12, %93, %cst_1 : tensor<16x32x!tt.ptr<f32>> loc(#loc60)
      %95 = tt.dot %87, %94, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc61)
      %96 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc62)
      %97 = arith.muli %arg7, %c16_i32 : i32 loc(#loc63)
      %98 = tt.splat %97 : i32 -> tensor<16x32xi32> loc(#loc64)
      %99 = tt.addptr %arg12, %98 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc64)
      scf.yield %95, %96, %99 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc65)
    } loc(#loc50)
    %54 = arith.truncf %53#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc66)
    %55 = arith.muli %12, %c32_i32 : i32 loc(#loc67)
    %56 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc68)
    %57 = tt.splat %55 : i32 -> tensor<32xi32> loc(#loc69)
    %58 = arith.addi %57, %56 : tensor<32xi32> loc(#loc69)
    %59 = arith.muli %14, %c32_i32 : i32 loc(#loc70)
    %60 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc71)
    %61 = tt.splat %59 : i32 -> tensor<32xi32> loc(#loc72)
    %62 = arith.addi %61, %60 : tensor<32xi32> loc(#loc72)
    %63 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc73)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc74)
    %65 = arith.muli %64, %63 : tensor<32x1xi32> loc(#loc74)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc75)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc75)
    %68 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc76)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc77)
    %70 = tt.broadcast %68 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc77)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc77)
    %72 = tt.expand_dims %58 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc78)
    %73 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc79)
    %74 = arith.cmpi slt, %72, %73 : tensor<32x1xi32> loc(#loc79)
    %75 = tt.expand_dims %62 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc80)
    %76 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc81)
    %77 = arith.cmpi slt, %75, %76 : tensor<1x32xi32> loc(#loc81)
    %78 = tt.broadcast %74 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc82)
    %79 = tt.broadcast %77 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc82)
    %80 = arith.andi %78, %79 : tensor<32x32xi1> loc(#loc82)
    tt.store %71, %54, %80 : tensor<32x32x!tt.ptr<f16>> loc(#loc83)
    tt.return loc(#loc84)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:19)
#loc16 = loc("examples/kernels/binary_ops.py":134:40)
#loc17 = loc("examples/kernels/binary_ops.py":140:23)
#loc18 = loc("examples/kernels/binary_ops.py":140:14)
#loc19 = loc("examples/kernels/binary_ops.py":141:23)
#loc20 = loc("examples/kernels/binary_ops.py":141:14)
#loc21 = loc("examples/kernels/binary_ops.py":142:26)
#loc22 = loc("examples/kernels/binary_ops.py":142:14)
#loc23 = loc("examples/kernels/binary_ops.py":143:14)
#loc24 = loc("examples/kernels/binary_ops.py":144:14)
#loc25 = loc("examples/kernels/binary_ops.py":145:26)
#loc26 = loc("examples/kernels/binary_ops.py":145:14)
#loc27 = loc("examples/kernels/binary_ops.py":146:26)
#loc28 = loc("examples/kernels/binary_ops.py":146:14)
#loc29 = loc("examples/kernels/binary_ops.py":147:14)
#loc30 = loc("examples/kernels/binary_ops.py":156:23)
#loc31 = loc("examples/kernels/binary_ops.py":156:51)
#loc32 = loc("examples/kernels/binary_ops.py":156:38)
#loc33 = loc("examples/kernels/binary_ops.py":156:68)
#loc34 = loc("examples/kernels/binary_ops.py":157:23)
#loc35 = loc("examples/kernels/binary_ops.py":157:51)
#loc36 = loc("examples/kernels/binary_ops.py":157:38)
#loc37 = loc("examples/kernels/binary_ops.py":157:68)
#loc38 = loc("examples/kernels/binary_ops.py":158:26)
#loc39 = loc("examples/kernels/binary_ops.py":159:30)
#loc40 = loc("examples/kernels/binary_ops.py":159:41)
#loc41 = loc("examples/kernels/binary_ops.py":159:60)
#loc42 = loc("examples/kernels/binary_ops.py":159:53)
#loc43 = loc("examples/kernels/binary_ops.py":159:22)
#loc44 = loc("examples/kernels/binary_ops.py":160:29)
#loc45 = loc("examples/kernels/binary_ops.py":160:40)
#loc46 = loc("examples/kernels/binary_ops.py":160:60)
#loc47 = loc("examples/kernels/binary_ops.py":160:52)
#loc48 = loc("examples/kernels/binary_ops.py":160:22)
#loc49 = loc("examples/kernels/binary_ops.py":168:33)
#loc50 = loc("examples/kernels/binary_ops.py":168:22)
#loc51 = loc("examples/kernels/binary_ops.py":171:40)
#loc52 = loc("examples/kernels/binary_ops.py":171:59)
#loc53 = loc("examples/kernels/binary_ops.py":171:55)
#loc54 = loc("examples/kernels/binary_ops.py":171:51)
#loc55 = loc("examples/kernels/binary_ops.py":171:20)
#loc56 = loc("examples/kernels/binary_ops.py":172:40)
#loc57 = loc("examples/kernels/binary_ops.py":172:59)
#loc58 = loc("examples/kernels/binary_ops.py":172:55)
#loc59 = loc("examples/kernels/binary_ops.py":172:51)
#loc60 = loc("examples/kernels/binary_ops.py":172:20)
#loc61 = loc("examples/kernels/binary_ops.py":174:35)
#loc62 = loc("examples/kernels/binary_ops.py":176:18)
#loc63 = loc("examples/kernels/binary_ops.py":177:33)
#loc64 = loc("examples/kernels/binary_ops.py":177:18)
#loc65 = loc("examples/kernels/binary_ops.py":177:8)
#loc66 = loc("examples/kernels/binary_ops.py":182:23)
#loc67 = loc("examples/kernels/binary_ops.py":186:22)
#loc68 = loc("examples/kernels/binary_ops.py":186:50)
#loc69 = loc("examples/kernels/binary_ops.py":186:37)
#loc70 = loc("examples/kernels/binary_ops.py":187:22)
#loc71 = loc("examples/kernels/binary_ops.py":187:50)
#loc72 = loc("examples/kernels/binary_ops.py":187:37)
#loc73 = loc("examples/kernels/binary_ops.py":188:41)
#loc74 = loc("examples/kernels/binary_ops.py":188:33)
#loc75 = loc("examples/kernels/binary_ops.py":188:21)
#loc76 = loc("examples/kernels/binary_ops.py":188:72)
#loc77 = loc("examples/kernels/binary_ops.py":188:52)
#loc78 = loc("examples/kernels/binary_ops.py":189:22)
#loc79 = loc("examples/kernels/binary_ops.py":189:33)
#loc80 = loc("examples/kernels/binary_ops.py":189:47)
#loc81 = loc("examples/kernels/binary_ops.py":189:58)
#loc82 = loc("examples/kernels/binary_ops.py":189:39)
#loc83 = loc("examples/kernels/binary_ops.py":190:21)
#loc84 = loc("examples/kernels/binary_ops.py":190:4)
#loc85 = loc(callsite(#loc3 at #loc4))
#loc86 = loc(callsite(#loc5 at #loc4))
#loc87 = loc(callsite(#loc3 at #loc6))
#loc88 = loc(callsite(#loc5 at #loc6))
#loc89 = loc(callsite(#loc3 at #loc49))
#loc90 = loc(callsite(#loc5 at #loc49))


// -----// IR Dump Before SymbolDCE (symbol-dce) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc71)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc72)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc73)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc74)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc30)
    %21 = tt.splat %19 : i32 -> tensor<32xi32> loc(#loc31)
    %22 = arith.addi %21, %20 : tensor<32xi32> loc(#loc31)
    %23 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc32)
    %24 = arith.remsi %22, %23 : tensor<32xi32> loc(#loc32)
    %25 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %26 = tt.splat %25 : i32 -> tensor<32xi32> loc(#loc34)
    %27 = arith.addi %26, %20 : tensor<32xi32> loc(#loc34)
    %28 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc35)
    %29 = arith.remsi %27, %28 : tensor<32xi32> loc(#loc35)
    %30 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc36)
    %31 = tt.expand_dims %24 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc37)
    %32 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc38)
    %33 = arith.muli %31, %32 : tensor<32x1xi32> loc(#loc38)
    %34 = tt.expand_dims %30 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc39)
    %35 = tt.broadcast %33 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc40)
    %36 = tt.broadcast %34 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc40)
    %37 = arith.addi %35, %36 : tensor<32x16xi32> loc(#loc40)
    %38 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc41)
    %39 = tt.addptr %38, %37 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc41)
    %40 = tt.expand_dims %30 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc42)
    %41 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc43)
    %42 = arith.muli %40, %41 : tensor<16x1xi32> loc(#loc43)
    %43 = tt.expand_dims %29 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc44)
    %44 = tt.broadcast %42 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc45)
    %45 = tt.broadcast %43 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc45)
    %46 = arith.addi %44, %45 : tensor<16x32xi32> loc(#loc45)
    %47 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc46)
    %48 = tt.addptr %47, %46 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc46)
    %49 = arith.addi %arg5, %c15_i32 : i32 loc(#loc75)
    %50 = arith.divsi %49, %c16_i32 : i32 loc(#loc76)
    %51:3 = scf.for %arg9 = %c0_i32 to %50 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %39, %arg12 = %48) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %69 = arith.muli %arg9, %c16_i32 : i32 loc(#loc49)
      %70 = arith.subi %arg5, %69 : i32 loc(#loc50)
      %71 = tt.splat %70 : i32 -> tensor<1x16xi32> loc(#loc51)
      %72 = arith.cmpi slt, %34, %71 : tensor<1x16xi32> loc(#loc51)
      %73 = tt.broadcast %72 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc52)
      %74 = tt.load %arg11, %73, %cst_2 : tensor<32x16x!tt.ptr<f32>> loc(#loc52)
      %75 = tt.splat %70 : i32 -> tensor<16x1xi32> loc(#loc53)
      %76 = arith.cmpi slt, %40, %75 : tensor<16x1xi32> loc(#loc53)
      %77 = tt.broadcast %76 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc54)
      %78 = tt.load %arg12, %77, %cst_1 : tensor<16x32x!tt.ptr<f32>> loc(#loc54)
      %79 = tt.dot %74, %78, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc55)
      %80 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc56)
      %81 = arith.muli %arg7, %c16_i32 : i32 loc(#loc57)
      %82 = tt.splat %81 : i32 -> tensor<16x32xi32> loc(#loc58)
      %83 = tt.addptr %arg12, %82 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc58)
      scf.yield %79, %80, %83 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc59)
    } loc(#loc48)
    %52 = arith.truncf %51#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc60)
    %53 = tt.expand_dims %22 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc61)
    %54 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc62)
    %55 = arith.muli %54, %53 : tensor<32x1xi32> loc(#loc62)
    %56 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc63)
    %57 = tt.addptr %56, %55 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc63)
    %58 = tt.expand_dims %27 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc64)
    %59 = tt.broadcast %57 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc65)
    %60 = tt.broadcast %58 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc65)
    %61 = tt.addptr %59, %60 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc65)
    %62 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc66)
    %63 = arith.cmpi slt, %53, %62 : tensor<32x1xi32> loc(#loc66)
    %64 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc67)
    %65 = arith.cmpi slt, %58, %64 : tensor<1x32xi32> loc(#loc67)
    %66 = tt.broadcast %63 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc68)
    %67 = tt.broadcast %65 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc68)
    %68 = arith.andi %66, %67 : tensor<32x32xi1> loc(#loc68)
    tt.store %61, %52, %68 : tensor<32x32x!tt.ptr<f16>> loc(#loc69)
    tt.return loc(#loc70)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":158:26)
#loc37 = loc("examples/kernels/binary_ops.py":159:30)
#loc38 = loc("examples/kernels/binary_ops.py":159:41)
#loc39 = loc("examples/kernels/binary_ops.py":159:60)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:33)
#loc48 = loc("examples/kernels/binary_ops.py":168:22)
#loc49 = loc("examples/kernels/binary_ops.py":171:59)
#loc50 = loc("examples/kernels/binary_ops.py":171:55)
#loc51 = loc("examples/kernels/binary_ops.py":171:51)
#loc52 = loc("examples/kernels/binary_ops.py":171:20)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":172:20)
#loc55 = loc("examples/kernels/binary_ops.py":174:35)
#loc56 = loc("examples/kernels/binary_ops.py":176:18)
#loc57 = loc("examples/kernels/binary_ops.py":177:33)
#loc58 = loc("examples/kernels/binary_ops.py":177:18)
#loc59 = loc("examples/kernels/binary_ops.py":177:8)
#loc60 = loc("examples/kernels/binary_ops.py":182:23)
#loc61 = loc("examples/kernels/binary_ops.py":188:41)
#loc62 = loc("examples/kernels/binary_ops.py":188:33)
#loc63 = loc("examples/kernels/binary_ops.py":188:21)
#loc64 = loc("examples/kernels/binary_ops.py":188:72)
#loc65 = loc("examples/kernels/binary_ops.py":188:52)
#loc66 = loc("examples/kernels/binary_ops.py":189:33)
#loc67 = loc("examples/kernels/binary_ops.py":189:58)
#loc68 = loc("examples/kernels/binary_ops.py":189:39)
#loc69 = loc("examples/kernels/binary_ops.py":190:21)
#loc70 = loc("examples/kernels/binary_ops.py":190:4)
#loc71 = loc(callsite(#loc3 at #loc4))
#loc72 = loc(callsite(#loc5 at #loc4))
#loc73 = loc(callsite(#loc3 at #loc6))
#loc74 = loc(callsite(#loc5 at #loc6))
#loc75 = loc(callsite(#loc3 at #loc47))
#loc76 = loc(callsite(#loc5 at #loc47))


// -----// IR Dump Before TritonLoopUnroll (triton-loop-unroll) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc71)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc72)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc73)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc74)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc30)
    %21 = tt.splat %19 : i32 -> tensor<32xi32> loc(#loc31)
    %22 = arith.addi %21, %20 : tensor<32xi32> loc(#loc31)
    %23 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc32)
    %24 = arith.remsi %22, %23 : tensor<32xi32> loc(#loc32)
    %25 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %26 = tt.splat %25 : i32 -> tensor<32xi32> loc(#loc34)
    %27 = arith.addi %26, %20 : tensor<32xi32> loc(#loc34)
    %28 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc35)
    %29 = arith.remsi %27, %28 : tensor<32xi32> loc(#loc35)
    %30 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc36)
    %31 = tt.expand_dims %24 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc37)
    %32 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc38)
    %33 = arith.muli %31, %32 : tensor<32x1xi32> loc(#loc38)
    %34 = tt.expand_dims %30 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc39)
    %35 = tt.broadcast %33 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc40)
    %36 = tt.broadcast %34 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc40)
    %37 = arith.addi %35, %36 : tensor<32x16xi32> loc(#loc40)
    %38 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc41)
    %39 = tt.addptr %38, %37 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc41)
    %40 = tt.expand_dims %30 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc42)
    %41 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc43)
    %42 = arith.muli %40, %41 : tensor<16x1xi32> loc(#loc43)
    %43 = tt.expand_dims %29 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc44)
    %44 = tt.broadcast %42 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc45)
    %45 = tt.broadcast %43 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc45)
    %46 = arith.addi %44, %45 : tensor<16x32xi32> loc(#loc45)
    %47 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc46)
    %48 = tt.addptr %47, %46 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc46)
    %49 = arith.addi %arg5, %c15_i32 : i32 loc(#loc75)
    %50 = arith.divsi %49, %c16_i32 : i32 loc(#loc76)
    %51:3 = scf.for %arg9 = %c0_i32 to %50 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %39, %arg12 = %48) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %69 = arith.muli %arg9, %c16_i32 : i32 loc(#loc49)
      %70 = arith.subi %arg5, %69 : i32 loc(#loc50)
      %71 = tt.splat %70 : i32 -> tensor<1x16xi32> loc(#loc51)
      %72 = arith.cmpi slt, %34, %71 : tensor<1x16xi32> loc(#loc51)
      %73 = tt.broadcast %72 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc52)
      %74 = tt.load %arg11, %73, %cst_2 : tensor<32x16x!tt.ptr<f32>> loc(#loc52)
      %75 = tt.splat %70 : i32 -> tensor<16x1xi32> loc(#loc53)
      %76 = arith.cmpi slt, %40, %75 : tensor<16x1xi32> loc(#loc53)
      %77 = tt.broadcast %76 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc54)
      %78 = tt.load %arg12, %77, %cst_1 : tensor<16x32x!tt.ptr<f32>> loc(#loc54)
      %79 = tt.dot %74, %78, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc55)
      %80 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc56)
      %81 = arith.muli %arg7, %c16_i32 : i32 loc(#loc57)
      %82 = tt.splat %81 : i32 -> tensor<16x32xi32> loc(#loc58)
      %83 = tt.addptr %arg12, %82 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc58)
      scf.yield %79, %80, %83 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc59)
    } loc(#loc48)
    %52 = arith.truncf %51#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc60)
    %53 = tt.expand_dims %22 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc61)
    %54 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc62)
    %55 = arith.muli %54, %53 : tensor<32x1xi32> loc(#loc62)
    %56 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc63)
    %57 = tt.addptr %56, %55 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc63)
    %58 = tt.expand_dims %27 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc64)
    %59 = tt.broadcast %57 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc65)
    %60 = tt.broadcast %58 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc65)
    %61 = tt.addptr %59, %60 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc65)
    %62 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc66)
    %63 = arith.cmpi slt, %53, %62 : tensor<32x1xi32> loc(#loc66)
    %64 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc67)
    %65 = arith.cmpi slt, %58, %64 : tensor<1x32xi32> loc(#loc67)
    %66 = tt.broadcast %63 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc68)
    %67 = tt.broadcast %65 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc68)
    %68 = arith.andi %66, %67 : tensor<32x32xi1> loc(#loc68)
    tt.store %61, %52, %68 : tensor<32x32x!tt.ptr<f16>> loc(#loc69)
    tt.return loc(#loc70)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":158:26)
#loc37 = loc("examples/kernels/binary_ops.py":159:30)
#loc38 = loc("examples/kernels/binary_ops.py":159:41)
#loc39 = loc("examples/kernels/binary_ops.py":159:60)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:33)
#loc48 = loc("examples/kernels/binary_ops.py":168:22)
#loc49 = loc("examples/kernels/binary_ops.py":171:59)
#loc50 = loc("examples/kernels/binary_ops.py":171:55)
#loc51 = loc("examples/kernels/binary_ops.py":171:51)
#loc52 = loc("examples/kernels/binary_ops.py":171:20)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":172:20)
#loc55 = loc("examples/kernels/binary_ops.py":174:35)
#loc56 = loc("examples/kernels/binary_ops.py":176:18)
#loc57 = loc("examples/kernels/binary_ops.py":177:33)
#loc58 = loc("examples/kernels/binary_ops.py":177:18)
#loc59 = loc("examples/kernels/binary_ops.py":177:8)
#loc60 = loc("examples/kernels/binary_ops.py":182:23)
#loc61 = loc("examples/kernels/binary_ops.py":188:41)
#loc62 = loc("examples/kernels/binary_ops.py":188:33)
#loc63 = loc("examples/kernels/binary_ops.py":188:21)
#loc64 = loc("examples/kernels/binary_ops.py":188:72)
#loc65 = loc("examples/kernels/binary_ops.py":188:52)
#loc66 = loc("examples/kernels/binary_ops.py":189:33)
#loc67 = loc("examples/kernels/binary_ops.py":189:58)
#loc68 = loc("examples/kernels/binary_ops.py":189:39)
#loc69 = loc("examples/kernels/binary_ops.py":190:21)
#loc70 = loc("examples/kernels/binary_ops.py":190:4)
#loc71 = loc(callsite(#loc3 at #loc4))
#loc72 = loc(callsite(#loc5 at #loc4))
#loc73 = loc(callsite(#loc3 at #loc6))
#loc74 = loc(callsite(#loc5 at #loc6))
#loc75 = loc(callsite(#loc3 at #loc47))
#loc76 = loc(callsite(#loc5 at #loc47))


// -----// IR Dump Before ConvertTritonToTritonGPU (convert-triton-to-tritongpu) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
module {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc71)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc72)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc73)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc74)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32> loc(#loc30)
    %21 = tt.splat %19 : i32 -> tensor<32xi32> loc(#loc31)
    %22 = arith.addi %21, %20 : tensor<32xi32> loc(#loc31)
    %23 = tt.splat %arg3 : i32 -> tensor<32xi32> loc(#loc32)
    %24 = arith.remsi %22, %23 : tensor<32xi32> loc(#loc32)
    %25 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %26 = tt.splat %25 : i32 -> tensor<32xi32> loc(#loc34)
    %27 = arith.addi %26, %20 : tensor<32xi32> loc(#loc34)
    %28 = tt.splat %arg4 : i32 -> tensor<32xi32> loc(#loc35)
    %29 = arith.remsi %27, %28 : tensor<32xi32> loc(#loc35)
    %30 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32> loc(#loc36)
    %31 = tt.expand_dims %24 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc37)
    %32 = tt.splat %arg6 : i32 -> tensor<32x1xi32> loc(#loc38)
    %33 = arith.muli %31, %32 : tensor<32x1xi32> loc(#loc38)
    %34 = tt.expand_dims %30 {axis = 0 : i32} : tensor<16xi32> -> tensor<1x16xi32> loc(#loc39)
    %35 = tt.broadcast %33 : tensor<32x1xi32> -> tensor<32x16xi32> loc(#loc40)
    %36 = tt.broadcast %34 : tensor<1x16xi32> -> tensor<32x16xi32> loc(#loc40)
    %37 = arith.addi %35, %36 : tensor<32x16xi32> loc(#loc40)
    %38 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>> loc(#loc41)
    %39 = tt.addptr %38, %37 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc41)
    %40 = tt.expand_dims %30 {axis = 1 : i32} : tensor<16xi32> -> tensor<16x1xi32> loc(#loc42)
    %41 = tt.splat %arg7 : i32 -> tensor<16x1xi32> loc(#loc43)
    %42 = arith.muli %40, %41 : tensor<16x1xi32> loc(#loc43)
    %43 = tt.expand_dims %29 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc44)
    %44 = tt.broadcast %42 : tensor<16x1xi32> -> tensor<16x32xi32> loc(#loc45)
    %45 = tt.broadcast %43 : tensor<1x32xi32> -> tensor<16x32xi32> loc(#loc45)
    %46 = arith.addi %44, %45 : tensor<16x32xi32> loc(#loc45)
    %47 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>> loc(#loc46)
    %48 = tt.addptr %47, %46 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc46)
    %49 = arith.addi %arg5, %c15_i32 : i32 loc(#loc75)
    %50 = arith.divsi %49, %c16_i32 : i32 loc(#loc76)
    %51:3 = scf.for %arg9 = %c0_i32 to %50 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %39, %arg12 = %48) -> (tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>>)  : i32 {
      %69 = arith.muli %arg9, %c16_i32 : i32 loc(#loc49)
      %70 = arith.subi %arg5, %69 : i32 loc(#loc50)
      %71 = tt.splat %70 : i32 -> tensor<1x16xi32> loc(#loc51)
      %72 = arith.cmpi slt, %34, %71 : tensor<1x16xi32> loc(#loc51)
      %73 = tt.broadcast %72 : tensor<1x16xi1> -> tensor<32x16xi1> loc(#loc52)
      %74 = tt.load %arg11, %73, %cst_2 : tensor<32x16x!tt.ptr<f32>> loc(#loc52)
      %75 = tt.splat %70 : i32 -> tensor<16x1xi32> loc(#loc53)
      %76 = arith.cmpi slt, %40, %75 : tensor<16x1xi32> loc(#loc53)
      %77 = tt.broadcast %76 : tensor<16x1xi1> -> tensor<16x32xi1> loc(#loc54)
      %78 = tt.load %arg12, %77, %cst_1 : tensor<16x32x!tt.ptr<f32>> loc(#loc54)
      %79 = tt.dot %74, %78, %arg10, inputPrecision = tf32 : tensor<32x16xf32> * tensor<16x32xf32> -> tensor<32x32xf32> loc(#loc55)
      %80 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>>, tensor<32x16xi32> loc(#loc56)
      %81 = arith.muli %arg7, %c16_i32 : i32 loc(#loc57)
      %82 = tt.splat %81 : i32 -> tensor<16x32xi32> loc(#loc58)
      %83 = tt.addptr %arg12, %82 : tensor<16x32x!tt.ptr<f32>>, tensor<16x32xi32> loc(#loc58)
      scf.yield %79, %80, %83 : tensor<32x32xf32>, tensor<32x16x!tt.ptr<f32>>, tensor<16x32x!tt.ptr<f32>> loc(#loc59)
    } loc(#loc48)
    %52 = arith.truncf %51#0 : tensor<32x32xf32> to tensor<32x32xf16> loc(#loc60)
    %53 = tt.expand_dims %22 {axis = 1 : i32} : tensor<32xi32> -> tensor<32x1xi32> loc(#loc61)
    %54 = tt.splat %arg8 : i32 -> tensor<32x1xi32> loc(#loc62)
    %55 = arith.muli %54, %53 : tensor<32x1xi32> loc(#loc62)
    %56 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>> loc(#loc63)
    %57 = tt.addptr %56, %55 : tensor<32x1x!tt.ptr<f16>>, tensor<32x1xi32> loc(#loc63)
    %58 = tt.expand_dims %27 {axis = 0 : i32} : tensor<32xi32> -> tensor<1x32xi32> loc(#loc64)
    %59 = tt.broadcast %57 : tensor<32x1x!tt.ptr<f16>> -> tensor<32x32x!tt.ptr<f16>> loc(#loc65)
    %60 = tt.broadcast %58 : tensor<1x32xi32> -> tensor<32x32xi32> loc(#loc65)
    %61 = tt.addptr %59, %60 : tensor<32x32x!tt.ptr<f16>>, tensor<32x32xi32> loc(#loc65)
    %62 = tt.splat %arg3 : i32 -> tensor<32x1xi32> loc(#loc66)
    %63 = arith.cmpi slt, %53, %62 : tensor<32x1xi32> loc(#loc66)
    %64 = tt.splat %arg4 : i32 -> tensor<1x32xi32> loc(#loc67)
    %65 = arith.cmpi slt, %58, %64 : tensor<1x32xi32> loc(#loc67)
    %66 = tt.broadcast %63 : tensor<32x1xi1> -> tensor<32x32xi1> loc(#loc68)
    %67 = tt.broadcast %65 : tensor<1x32xi1> -> tensor<32x32xi1> loc(#loc68)
    %68 = arith.andi %66, %67 : tensor<32x32xi1> loc(#loc68)
    tt.store %61, %52, %68 : tensor<32x32x!tt.ptr<f16>> loc(#loc69)
    tt.return loc(#loc70)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":158:26)
#loc37 = loc("examples/kernels/binary_ops.py":159:30)
#loc38 = loc("examples/kernels/binary_ops.py":159:41)
#loc39 = loc("examples/kernels/binary_ops.py":159:60)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:33)
#loc48 = loc("examples/kernels/binary_ops.py":168:22)
#loc49 = loc("examples/kernels/binary_ops.py":171:59)
#loc50 = loc("examples/kernels/binary_ops.py":171:55)
#loc51 = loc("examples/kernels/binary_ops.py":171:51)
#loc52 = loc("examples/kernels/binary_ops.py":171:20)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":172:20)
#loc55 = loc("examples/kernels/binary_ops.py":174:35)
#loc56 = loc("examples/kernels/binary_ops.py":176:18)
#loc57 = loc("examples/kernels/binary_ops.py":177:33)
#loc58 = loc("examples/kernels/binary_ops.py":177:18)
#loc59 = loc("examples/kernels/binary_ops.py":177:8)
#loc60 = loc("examples/kernels/binary_ops.py":182:23)
#loc61 = loc("examples/kernels/binary_ops.py":188:41)
#loc62 = loc("examples/kernels/binary_ops.py":188:33)
#loc63 = loc("examples/kernels/binary_ops.py":188:21)
#loc64 = loc("examples/kernels/binary_ops.py":188:72)
#loc65 = loc("examples/kernels/binary_ops.py":188:52)
#loc66 = loc("examples/kernels/binary_ops.py":189:33)
#loc67 = loc("examples/kernels/binary_ops.py":189:58)
#loc68 = loc("examples/kernels/binary_ops.py":189:39)
#loc69 = loc("examples/kernels/binary_ops.py":190:21)
#loc70 = loc("examples/kernels/binary_ops.py":190:4)
#loc71 = loc(callsite(#loc3 at #loc4))
#loc72 = loc(callsite(#loc5 at #loc4))
#loc73 = loc(callsite(#loc3 at #loc6))
#loc74 = loc(callsite(#loc5 at #loc6))
#loc75 = loc(callsite(#loc3 at #loc47))
#loc76 = loc(callsite(#loc5 at #loc47))


// -----// IR Dump Before TritonGPUCoalesce (tritongpu-coalesce) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked6 = #ttg.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #blocked> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc72)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc73)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc74)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc75)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #blocked2> loc(#loc30)
    %21 = tt.splat %19 : i32 -> tensor<32xi32, #blocked2> loc(#loc31)
    %22 = arith.addi %21, %20 : tensor<32xi32, #blocked2> loc(#loc31)
    %23 = tt.splat %arg3 : i32 -> tensor<32xi32, #blocked2> loc(#loc32)
    %24 = arith.remsi %22, %23 : tensor<32xi32, #blocked2> loc(#loc32)
    %25 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %26 = tt.splat %25 : i32 -> tensor<32xi32, #blocked2> loc(#loc34)
    %27 = arith.addi %26, %20 : tensor<32xi32, #blocked2> loc(#loc34)
    %28 = tt.splat %arg4 : i32 -> tensor<32xi32, #blocked2> loc(#loc35)
    %29 = arith.remsi %27, %28 : tensor<32xi32, #blocked2> loc(#loc35)
    %30 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #blocked2> loc(#loc36)
    %31 = ttg.convert_layout %24 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc37)
    %32 = tt.expand_dims %31 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc37)
    %33 = ttg.convert_layout %32 : tensor<32x1xi32, #blocked3> -> tensor<32x1xi32, #blocked4> loc(#loc38)
    %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc38)
    %35 = arith.muli %33, %34 : tensor<32x1xi32, #blocked4> loc(#loc38)
    %36 = ttg.convert_layout %30 : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc39)
    %37 = tt.expand_dims %36 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x16xi32, #blocked5> loc(#loc39)
    %38 = ttg.convert_layout %37 : tensor<1x16xi32, #blocked5> -> tensor<1x16xi32, #blocked1> loc(#loc40)
    %39 = tt.broadcast %35 : tensor<32x1xi32, #blocked4> -> tensor<32x16xi32, #blocked4> loc(#loc40)
    %40 = ttg.convert_layout %39 : tensor<32x16xi32, #blocked4> -> tensor<32x16xi32, #blocked1> loc(#loc40)
    %41 = tt.broadcast %38 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc40)
    %42 = arith.addi %40, %41 : tensor<32x16xi32, #blocked1> loc(#loc40)
    %43 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc41)
    %44 = tt.addptr %43, %42 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc41)
    %45 = ttg.convert_layout %30 : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc42)
    %46 = tt.expand_dims %45 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi32, #blocked3> loc(#loc42)
    %47 = ttg.convert_layout %46 : tensor<16x1xi32, #blocked3> -> tensor<16x1xi32, #blocked4> loc(#loc43)
    %48 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked4> loc(#loc43)
    %49 = arith.muli %47, %48 : tensor<16x1xi32, #blocked4> loc(#loc43)
    %50 = ttg.convert_layout %29 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc44)
    %51 = tt.expand_dims %50 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x32xi32, #blocked5> loc(#loc44)
    %52 = ttg.convert_layout %51 : tensor<1x32xi32, #blocked5> -> tensor<1x32xi32, #blocked> loc(#loc45)
    %53 = tt.broadcast %49 : tensor<16x1xi32, #blocked4> -> tensor<16x32xi32, #blocked4> loc(#loc45)
    %54 = ttg.convert_layout %53 : tensor<16x32xi32, #blocked4> -> tensor<16x32xi32, #blocked> loc(#loc45)
    %55 = tt.broadcast %52 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc45)
    %56 = arith.addi %54, %55 : tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc46)
    %58 = tt.addptr %57, %56 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc46)
    %59 = arith.addi %arg5, %c15_i32 : i32 loc(#loc76)
    %60 = arith.divsi %59, %c16_i32 : i32 loc(#loc77)
    %61:3 = scf.for %arg9 = %c0_i32 to %60 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %44, %arg12 = %58) -> (tensor<32x32xf32, #blocked>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %85 = arith.muli %arg9, %c16_i32 : i32 loc(#loc49)
      %86 = arith.subi %arg5, %85 : i32 loc(#loc50)
      %87 = tt.splat %86 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc51)
      %88 = arith.cmpi slt, %38, %87 : tensor<1x16xi32, #blocked1> loc(#loc51)
      %89 = tt.broadcast %88 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc52)
      %90 = tt.load %arg11, %89, %cst_2 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc52)
      %91 = tt.splat %86 : i32 -> tensor<16x1xi32, #blocked4> loc(#loc53)
      %92 = arith.cmpi slt, %47, %91 : tensor<16x1xi32, #blocked4> loc(#loc53)
      %93 = tt.broadcast %92 : tensor<16x1xi1, #blocked4> -> tensor<16x32xi1, #blocked4> loc(#loc54)
      %94 = ttg.convert_layout %93 : tensor<16x32xi1, #blocked4> -> tensor<16x32xi1, #blocked> loc(#loc54)
      %95 = tt.load %arg12, %94, %cst_1 : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc54)
      %96 = ttg.convert_layout %90 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked6}>> loc(#loc52)
      %97 = ttg.convert_layout %95 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked6}>> loc(#loc54)
      %98 = ttg.convert_layout %arg10 : tensor<32x32xf32, #blocked> -> tensor<32x32xf32, #blocked6> loc(#loc55)
      %99 = tt.dot %96, %97, %98, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked6}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked6}>> -> tensor<32x32xf32, #blocked6> loc(#loc56)
      %100 = ttg.convert_layout %99 : tensor<32x32xf32, #blocked6> -> tensor<32x32xf32, #blocked> loc(#loc57)
      %101 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc58)
      %102 = arith.muli %arg7, %c16_i32 : i32 loc(#loc59)
      %103 = tt.splat %102 : i32 -> tensor<16x32xi32, #blocked> loc(#loc60)
      %104 = tt.addptr %arg12, %103 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc60)
      scf.yield %100, %101, %104 : tensor<32x32xf32, #blocked>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc57)
    } loc(#loc48)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #blocked> to tensor<32x32xf16, #blocked> loc(#loc61)
    %63 = ttg.convert_layout %22 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc62)
    %64 = tt.expand_dims %63 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc62)
    %65 = ttg.convert_layout %64 : tensor<32x1xi32, #blocked3> -> tensor<32x1xi32, #blocked4> loc(#loc63)
    %66 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc63)
    %67 = arith.muli %66, %65 : tensor<32x1xi32, #blocked4> loc(#loc63)
    %68 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked4> loc(#loc64)
    %69 = tt.addptr %68, %67 : tensor<32x1x!tt.ptr<f16>, #blocked4>, tensor<32x1xi32, #blocked4> loc(#loc64)
    %70 = ttg.convert_layout %27 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc65)
    %71 = tt.expand_dims %70 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x32xi32, #blocked5> loc(#loc65)
    %72 = ttg.convert_layout %71 : tensor<1x32xi32, #blocked5> -> tensor<1x32xi32, #blocked> loc(#loc66)
    %73 = tt.broadcast %69 : tensor<32x1x!tt.ptr<f16>, #blocked4> -> tensor<32x32x!tt.ptr<f16>, #blocked4> loc(#loc66)
    %74 = ttg.convert_layout %73 : tensor<32x32x!tt.ptr<f16>, #blocked4> -> tensor<32x32x!tt.ptr<f16>, #blocked> loc(#loc66)
    %75 = tt.broadcast %72 : tensor<1x32xi32, #blocked> -> tensor<32x32xi32, #blocked> loc(#loc66)
    %76 = tt.addptr %74, %75 : tensor<32x32x!tt.ptr<f16>, #blocked>, tensor<32x32xi32, #blocked> loc(#loc66)
    %77 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc67)
    %78 = arith.cmpi slt, %65, %77 : tensor<32x1xi32, #blocked4> loc(#loc67)
    %79 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked> loc(#loc68)
    %80 = arith.cmpi slt, %72, %79 : tensor<1x32xi32, #blocked> loc(#loc68)
    %81 = tt.broadcast %78 : tensor<32x1xi1, #blocked4> -> tensor<32x32xi1, #blocked4> loc(#loc69)
    %82 = ttg.convert_layout %81 : tensor<32x32xi1, #blocked4> -> tensor<32x32xi1, #blocked> loc(#loc69)
    %83 = tt.broadcast %80 : tensor<1x32xi1, #blocked> -> tensor<32x32xi1, #blocked> loc(#loc69)
    %84 = arith.andi %82, %83 : tensor<32x32xi1, #blocked> loc(#loc69)
    tt.store %76, %62, %84 : tensor<32x32x!tt.ptr<f16>, #blocked> loc(#loc70)
    tt.return loc(#loc71)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":158:26)
#loc37 = loc("examples/kernels/binary_ops.py":159:30)
#loc38 = loc("examples/kernels/binary_ops.py":159:41)
#loc39 = loc("examples/kernels/binary_ops.py":159:60)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:33)
#loc48 = loc("examples/kernels/binary_ops.py":168:22)
#loc49 = loc("examples/kernels/binary_ops.py":171:59)
#loc50 = loc("examples/kernels/binary_ops.py":171:55)
#loc51 = loc("examples/kernels/binary_ops.py":171:51)
#loc52 = loc("examples/kernels/binary_ops.py":171:20)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":172:20)
#loc55 = loc("examples/kernels/binary_ops.py":167:27)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":177:8)
#loc58 = loc("examples/kernels/binary_ops.py":176:18)
#loc59 = loc("examples/kernels/binary_ops.py":177:33)
#loc60 = loc("examples/kernels/binary_ops.py":177:18)
#loc61 = loc("examples/kernels/binary_ops.py":182:23)
#loc62 = loc("examples/kernels/binary_ops.py":188:41)
#loc63 = loc("examples/kernels/binary_ops.py":188:33)
#loc64 = loc("examples/kernels/binary_ops.py":188:21)
#loc65 = loc("examples/kernels/binary_ops.py":188:72)
#loc66 = loc("examples/kernels/binary_ops.py":188:52)
#loc67 = loc("examples/kernels/binary_ops.py":189:33)
#loc68 = loc("examples/kernels/binary_ops.py":189:58)
#loc69 = loc("examples/kernels/binary_ops.py":189:39)
#loc70 = loc("examples/kernels/binary_ops.py":190:21)
#loc71 = loc("examples/kernels/binary_ops.py":190:4)
#loc72 = loc(callsite(#loc3 at #loc4))
#loc73 = loc(callsite(#loc5 at #loc4))
#loc74 = loc(callsite(#loc3 at #loc6))
#loc75 = loc(callsite(#loc5 at #loc6))
#loc76 = loc(callsite(#loc3 at #loc47))
#loc77 = loc(callsite(#loc5 at #loc47))


// -----// IR Dump Before TritonGPUF32DotTC (tritongpu-F32DotTC) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked6 = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked7 = #ttg.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #blocked> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc72)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc73)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc74)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc75)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #blocked2> loc(#loc30)
    %21 = tt.splat %19 : i32 -> tensor<32xi32, #blocked2> loc(#loc31)
    %22 = arith.addi %21, %20 : tensor<32xi32, #blocked2> loc(#loc31)
    %23 = tt.splat %arg3 : i32 -> tensor<32xi32, #blocked2> loc(#loc32)
    %24 = arith.remsi %22, %23 : tensor<32xi32, #blocked2> loc(#loc32)
    %25 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %26 = tt.splat %25 : i32 -> tensor<32xi32, #blocked2> loc(#loc34)
    %27 = arith.addi %26, %20 : tensor<32xi32, #blocked2> loc(#loc34)
    %28 = tt.splat %arg4 : i32 -> tensor<32xi32, #blocked2> loc(#loc35)
    %29 = arith.remsi %27, %28 : tensor<32xi32, #blocked2> loc(#loc35)
    %30 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #blocked2> loc(#loc36)
    %31 = ttg.convert_layout %24 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc37)
    %32 = tt.expand_dims %31 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc37)
    %33 = ttg.convert_layout %32 : tensor<32x1xi32, #blocked3> -> tensor<32x1xi32, #blocked4> loc(#loc38)
    %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc38)
    %35 = arith.muli %33, %34 : tensor<32x1xi32, #blocked4> loc(#loc38)
    %36 = ttg.convert_layout %30 : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc39)
    %37 = tt.expand_dims %36 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x16xi32, #blocked5> loc(#loc39)
    %38 = ttg.convert_layout %37 : tensor<1x16xi32, #blocked5> -> tensor<1x16xi32, #blocked1> loc(#loc40)
    %39 = tt.broadcast %35 : tensor<32x1xi32, #blocked4> -> tensor<32x16xi32, #blocked4> loc(#loc40)
    %40 = ttg.convert_layout %39 : tensor<32x16xi32, #blocked4> -> tensor<32x16xi32, #blocked1> loc(#loc40)
    %41 = tt.broadcast %38 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc40)
    %42 = arith.addi %40, %41 : tensor<32x16xi32, #blocked1> loc(#loc40)
    %43 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc41)
    %44 = tt.addptr %43, %42 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc41)
    %45 = ttg.convert_layout %30 : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc42)
    %46 = tt.expand_dims %45 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi32, #blocked3> loc(#loc42)
    %47 = ttg.convert_layout %46 : tensor<16x1xi32, #blocked3> -> tensor<16x1xi32, #blocked4> loc(#loc43)
    %48 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked4> loc(#loc43)
    %49 = arith.muli %47, %48 : tensor<16x1xi32, #blocked4> loc(#loc43)
    %50 = ttg.convert_layout %29 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc44)
    %51 = tt.expand_dims %50 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x32xi32, #blocked5> loc(#loc44)
    %52 = ttg.convert_layout %51 : tensor<1x32xi32, #blocked5> -> tensor<1x32xi32, #blocked> loc(#loc45)
    %53 = tt.broadcast %49 : tensor<16x1xi32, #blocked4> -> tensor<16x32xi32, #blocked4> loc(#loc45)
    %54 = ttg.convert_layout %53 : tensor<16x32xi32, #blocked4> -> tensor<16x32xi32, #blocked> loc(#loc45)
    %55 = tt.broadcast %52 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc45)
    %56 = arith.addi %54, %55 : tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc46)
    %58 = tt.addptr %57, %56 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc46)
    %59 = arith.addi %arg5, %c15_i32 : i32 loc(#loc76)
    %60 = arith.divsi %59, %c16_i32 : i32 loc(#loc77)
    %61:3 = scf.for %arg9 = %c0_i32 to %60 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %44, %arg12 = %58) -> (tensor<32x32xf32, #blocked>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %88 = arith.muli %arg9, %c16_i32 : i32 loc(#loc49)
      %89 = arith.subi %arg5, %88 : i32 loc(#loc50)
      %90 = tt.splat %89 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc51)
      %91 = arith.cmpi slt, %38, %90 : tensor<1x16xi32, #blocked1> loc(#loc51)
      %92 = tt.broadcast %91 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc52)
      %93 = ttg.convert_layout %arg11 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc52)
      %94 = ttg.convert_layout %92 : tensor<32x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc52)
      %95 = ttg.convert_layout %cst_2 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #blocked1> loc(#loc52)
      %96 = tt.load %93, %94, %95 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc52)
      %97 = tt.splat %89 : i32 -> tensor<16x1xi32, #blocked4> loc(#loc53)
      %98 = arith.cmpi slt, %47, %97 : tensor<16x1xi32, #blocked4> loc(#loc53)
      %99 = tt.broadcast %98 : tensor<16x1xi1, #blocked4> -> tensor<16x32xi1, #blocked4> loc(#loc54)
      %100 = ttg.convert_layout %99 : tensor<16x32xi1, #blocked4> -> tensor<16x32xi1, #blocked> loc(#loc54)
      %101 = ttg.convert_layout %arg12 : tensor<16x32x!tt.ptr<f32>, #blocked> -> tensor<16x32x!tt.ptr<f32>, #blocked6> loc(#loc54)
      %102 = ttg.convert_layout %100 : tensor<16x32xi1, #blocked> -> tensor<16x32xi1, #blocked6> loc(#loc54)
      %103 = ttg.convert_layout %cst_1 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #blocked6> loc(#loc54)
      %104 = tt.load %101, %102, %103 : tensor<16x32x!tt.ptr<f32>, #blocked6> loc(#loc54)
      %105 = ttg.convert_layout %104 : tensor<16x32xf32, #blocked6> -> tensor<16x32xf32, #blocked> loc(#loc54)
      %106 = ttg.convert_layout %96 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked7}>> loc(#loc52)
      %107 = ttg.convert_layout %105 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked7}>> loc(#loc54)
      %108 = ttg.convert_layout %arg10 : tensor<32x32xf32, #blocked> -> tensor<32x32xf32, #blocked7> loc(#loc55)
      %109 = tt.dot %106, %107, %108, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked7}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked7}>> -> tensor<32x32xf32, #blocked7> loc(#loc56)
      %110 = ttg.convert_layout %109 : tensor<32x32xf32, #blocked7> -> tensor<32x32xf32, #blocked> loc(#loc57)
      %111 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc58)
      %112 = arith.muli %arg7, %c16_i32 : i32 loc(#loc59)
      %113 = tt.splat %112 : i32 -> tensor<16x32xi32, #blocked> loc(#loc60)
      %114 = tt.addptr %arg12, %113 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc60)
      scf.yield %110, %111, %114 : tensor<32x32xf32, #blocked>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc57)
    } loc(#loc48)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #blocked> to tensor<32x32xf16, #blocked> loc(#loc61)
    %63 = ttg.convert_layout %22 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc62)
    %64 = tt.expand_dims %63 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc62)
    %65 = ttg.convert_layout %64 : tensor<32x1xi32, #blocked3> -> tensor<32x1xi32, #blocked4> loc(#loc63)
    %66 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc63)
    %67 = arith.muli %66, %65 : tensor<32x1xi32, #blocked4> loc(#loc63)
    %68 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked4> loc(#loc64)
    %69 = tt.addptr %68, %67 : tensor<32x1x!tt.ptr<f16>, #blocked4>, tensor<32x1xi32, #blocked4> loc(#loc64)
    %70 = ttg.convert_layout %27 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc65)
    %71 = tt.expand_dims %70 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x32xi32, #blocked5> loc(#loc65)
    %72 = ttg.convert_layout %71 : tensor<1x32xi32, #blocked5> -> tensor<1x32xi32, #blocked> loc(#loc66)
    %73 = tt.broadcast %69 : tensor<32x1x!tt.ptr<f16>, #blocked4> -> tensor<32x32x!tt.ptr<f16>, #blocked4> loc(#loc66)
    %74 = ttg.convert_layout %73 : tensor<32x32x!tt.ptr<f16>, #blocked4> -> tensor<32x32x!tt.ptr<f16>, #blocked> loc(#loc66)
    %75 = tt.broadcast %72 : tensor<1x32xi32, #blocked> -> tensor<32x32xi32, #blocked> loc(#loc66)
    %76 = tt.addptr %74, %75 : tensor<32x32x!tt.ptr<f16>, #blocked>, tensor<32x32xi32, #blocked> loc(#loc66)
    %77 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc67)
    %78 = arith.cmpi slt, %65, %77 : tensor<32x1xi32, #blocked4> loc(#loc67)
    %79 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked> loc(#loc68)
    %80 = arith.cmpi slt, %72, %79 : tensor<1x32xi32, #blocked> loc(#loc68)
    %81 = tt.broadcast %78 : tensor<32x1xi1, #blocked4> -> tensor<32x32xi1, #blocked4> loc(#loc69)
    %82 = ttg.convert_layout %81 : tensor<32x32xi1, #blocked4> -> tensor<32x32xi1, #blocked> loc(#loc69)
    %83 = tt.broadcast %80 : tensor<1x32xi1, #blocked> -> tensor<32x32xi1, #blocked> loc(#loc69)
    %84 = arith.andi %82, %83 : tensor<32x32xi1, #blocked> loc(#loc69)
    %85 = ttg.convert_layout %76 : tensor<32x32x!tt.ptr<f16>, #blocked> -> tensor<32x32x!tt.ptr<f16>, #blocked8> loc(#loc70)
    %86 = ttg.convert_layout %62 : tensor<32x32xf16, #blocked> -> tensor<32x32xf16, #blocked8> loc(#loc70)
    %87 = ttg.convert_layout %84 : tensor<32x32xi1, #blocked> -> tensor<32x32xi1, #blocked8> loc(#loc70)
    tt.store %85, %86, %87 : tensor<32x32x!tt.ptr<f16>, #blocked8> loc(#loc70)
    tt.return loc(#loc71)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":158:26)
#loc37 = loc("examples/kernels/binary_ops.py":159:30)
#loc38 = loc("examples/kernels/binary_ops.py":159:41)
#loc39 = loc("examples/kernels/binary_ops.py":159:60)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:33)
#loc48 = loc("examples/kernels/binary_ops.py":168:22)
#loc49 = loc("examples/kernels/binary_ops.py":171:59)
#loc50 = loc("examples/kernels/binary_ops.py":171:55)
#loc51 = loc("examples/kernels/binary_ops.py":171:51)
#loc52 = loc("examples/kernels/binary_ops.py":171:20)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":172:20)
#loc55 = loc("examples/kernels/binary_ops.py":167:27)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":177:8)
#loc58 = loc("examples/kernels/binary_ops.py":176:18)
#loc59 = loc("examples/kernels/binary_ops.py":177:33)
#loc60 = loc("examples/kernels/binary_ops.py":177:18)
#loc61 = loc("examples/kernels/binary_ops.py":182:23)
#loc62 = loc("examples/kernels/binary_ops.py":188:41)
#loc63 = loc("examples/kernels/binary_ops.py":188:33)
#loc64 = loc("examples/kernels/binary_ops.py":188:21)
#loc65 = loc("examples/kernels/binary_ops.py":188:72)
#loc66 = loc("examples/kernels/binary_ops.py":188:52)
#loc67 = loc("examples/kernels/binary_ops.py":189:33)
#loc68 = loc("examples/kernels/binary_ops.py":189:58)
#loc69 = loc("examples/kernels/binary_ops.py":189:39)
#loc70 = loc("examples/kernels/binary_ops.py":190:21)
#loc71 = loc("examples/kernels/binary_ops.py":190:4)
#loc72 = loc(callsite(#loc3 at #loc4))
#loc73 = loc(callsite(#loc5 at #loc4))
#loc74 = loc(callsite(#loc3 at #loc6))
#loc75 = loc(callsite(#loc5 at #loc6))
#loc76 = loc(callsite(#loc3 at #loc47))
#loc77 = loc(callsite(#loc5 at #loc47))


// -----// IR Dump Before TritonGPUPlanCTAPass (triton-nvidia-gpu-plan-cta) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked6 = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked7 = #ttg.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #blocked> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc72)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc73)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc74)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc75)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #blocked2> loc(#loc30)
    %21 = tt.splat %19 : i32 -> tensor<32xi32, #blocked2> loc(#loc31)
    %22 = arith.addi %21, %20 : tensor<32xi32, #blocked2> loc(#loc31)
    %23 = tt.splat %arg3 : i32 -> tensor<32xi32, #blocked2> loc(#loc32)
    %24 = arith.remsi %22, %23 : tensor<32xi32, #blocked2> loc(#loc32)
    %25 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %26 = tt.splat %25 : i32 -> tensor<32xi32, #blocked2> loc(#loc34)
    %27 = arith.addi %26, %20 : tensor<32xi32, #blocked2> loc(#loc34)
    %28 = tt.splat %arg4 : i32 -> tensor<32xi32, #blocked2> loc(#loc35)
    %29 = arith.remsi %27, %28 : tensor<32xi32, #blocked2> loc(#loc35)
    %30 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #blocked2> loc(#loc36)
    %31 = ttg.convert_layout %24 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc37)
    %32 = tt.expand_dims %31 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc37)
    %33 = ttg.convert_layout %32 : tensor<32x1xi32, #blocked3> -> tensor<32x1xi32, #blocked4> loc(#loc38)
    %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc38)
    %35 = arith.muli %33, %34 : tensor<32x1xi32, #blocked4> loc(#loc38)
    %36 = ttg.convert_layout %30 : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc39)
    %37 = tt.expand_dims %36 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x16xi32, #blocked5> loc(#loc39)
    %38 = ttg.convert_layout %37 : tensor<1x16xi32, #blocked5> -> tensor<1x16xi32, #blocked1> loc(#loc40)
    %39 = tt.broadcast %35 : tensor<32x1xi32, #blocked4> -> tensor<32x16xi32, #blocked4> loc(#loc40)
    %40 = ttg.convert_layout %39 : tensor<32x16xi32, #blocked4> -> tensor<32x16xi32, #blocked1> loc(#loc40)
    %41 = tt.broadcast %38 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc40)
    %42 = arith.addi %40, %41 : tensor<32x16xi32, #blocked1> loc(#loc40)
    %43 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc41)
    %44 = tt.addptr %43, %42 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc41)
    %45 = ttg.convert_layout %30 : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc42)
    %46 = tt.expand_dims %45 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi32, #blocked3> loc(#loc42)
    %47 = ttg.convert_layout %46 : tensor<16x1xi32, #blocked3> -> tensor<16x1xi32, #blocked4> loc(#loc43)
    %48 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked4> loc(#loc43)
    %49 = arith.muli %47, %48 : tensor<16x1xi32, #blocked4> loc(#loc43)
    %50 = ttg.convert_layout %29 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc44)
    %51 = tt.expand_dims %50 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x32xi32, #blocked5> loc(#loc44)
    %52 = ttg.convert_layout %51 : tensor<1x32xi32, #blocked5> -> tensor<1x32xi32, #blocked> loc(#loc45)
    %53 = tt.broadcast %49 : tensor<16x1xi32, #blocked4> -> tensor<16x32xi32, #blocked4> loc(#loc45)
    %54 = ttg.convert_layout %53 : tensor<16x32xi32, #blocked4> -> tensor<16x32xi32, #blocked> loc(#loc45)
    %55 = tt.broadcast %52 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc45)
    %56 = arith.addi %54, %55 : tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc46)
    %58 = tt.addptr %57, %56 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc46)
    %59 = arith.addi %arg5, %c15_i32 : i32 loc(#loc76)
    %60 = arith.divsi %59, %c16_i32 : i32 loc(#loc77)
    %61:3 = scf.for %arg9 = %c0_i32 to %60 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %44, %arg12 = %58) -> (tensor<32x32xf32, #blocked>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %88 = arith.muli %arg9, %c16_i32 : i32 loc(#loc49)
      %89 = arith.subi %arg5, %88 : i32 loc(#loc50)
      %90 = tt.splat %89 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc51)
      %91 = arith.cmpi slt, %38, %90 : tensor<1x16xi32, #blocked1> loc(#loc51)
      %92 = tt.broadcast %91 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc52)
      %93 = ttg.convert_layout %arg11 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc52)
      %94 = ttg.convert_layout %92 : tensor<32x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc52)
      %95 = ttg.convert_layout %cst_2 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #blocked1> loc(#loc52)
      %96 = tt.load %93, %94, %95 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc52)
      %97 = tt.splat %89 : i32 -> tensor<16x1xi32, #blocked4> loc(#loc53)
      %98 = arith.cmpi slt, %47, %97 : tensor<16x1xi32, #blocked4> loc(#loc53)
      %99 = tt.broadcast %98 : tensor<16x1xi1, #blocked4> -> tensor<16x32xi1, #blocked4> loc(#loc54)
      %100 = ttg.convert_layout %99 : tensor<16x32xi1, #blocked4> -> tensor<16x32xi1, #blocked> loc(#loc54)
      %101 = ttg.convert_layout %arg12 : tensor<16x32x!tt.ptr<f32>, #blocked> -> tensor<16x32x!tt.ptr<f32>, #blocked6> loc(#loc54)
      %102 = ttg.convert_layout %100 : tensor<16x32xi1, #blocked> -> tensor<16x32xi1, #blocked6> loc(#loc54)
      %103 = ttg.convert_layout %cst_1 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #blocked6> loc(#loc54)
      %104 = tt.load %101, %102, %103 : tensor<16x32x!tt.ptr<f32>, #blocked6> loc(#loc54)
      %105 = ttg.convert_layout %104 : tensor<16x32xf32, #blocked6> -> tensor<16x32xf32, #blocked> loc(#loc54)
      %106 = ttg.convert_layout %96 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked7}>> loc(#loc52)
      %107 = ttg.convert_layout %105 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked7}>> loc(#loc54)
      %108 = ttg.convert_layout %arg10 : tensor<32x32xf32, #blocked> -> tensor<32x32xf32, #blocked7> loc(#loc55)
      %109 = tt.dot %106, %107, %108, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked7}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked7}>> -> tensor<32x32xf32, #blocked7> loc(#loc56)
      %110 = ttg.convert_layout %109 : tensor<32x32xf32, #blocked7> -> tensor<32x32xf32, #blocked> loc(#loc57)
      %111 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc58)
      %112 = arith.muli %arg7, %c16_i32 : i32 loc(#loc59)
      %113 = tt.splat %112 : i32 -> tensor<16x32xi32, #blocked> loc(#loc60)
      %114 = tt.addptr %arg12, %113 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc60)
      scf.yield %110, %111, %114 : tensor<32x32xf32, #blocked>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc57)
    } loc(#loc48)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #blocked> to tensor<32x32xf16, #blocked> loc(#loc61)
    %63 = ttg.convert_layout %22 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc62)
    %64 = tt.expand_dims %63 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc62)
    %65 = ttg.convert_layout %64 : tensor<32x1xi32, #blocked3> -> tensor<32x1xi32, #blocked4> loc(#loc63)
    %66 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc63)
    %67 = arith.muli %66, %65 : tensor<32x1xi32, #blocked4> loc(#loc63)
    %68 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked4> loc(#loc64)
    %69 = tt.addptr %68, %67 : tensor<32x1x!tt.ptr<f16>, #blocked4>, tensor<32x1xi32, #blocked4> loc(#loc64)
    %70 = ttg.convert_layout %27 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc65)
    %71 = tt.expand_dims %70 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x32xi32, #blocked5> loc(#loc65)
    %72 = ttg.convert_layout %71 : tensor<1x32xi32, #blocked5> -> tensor<1x32xi32, #blocked> loc(#loc66)
    %73 = tt.broadcast %69 : tensor<32x1x!tt.ptr<f16>, #blocked4> -> tensor<32x32x!tt.ptr<f16>, #blocked4> loc(#loc66)
    %74 = ttg.convert_layout %73 : tensor<32x32x!tt.ptr<f16>, #blocked4> -> tensor<32x32x!tt.ptr<f16>, #blocked> loc(#loc66)
    %75 = tt.broadcast %72 : tensor<1x32xi32, #blocked> -> tensor<32x32xi32, #blocked> loc(#loc66)
    %76 = tt.addptr %74, %75 : tensor<32x32x!tt.ptr<f16>, #blocked>, tensor<32x32xi32, #blocked> loc(#loc66)
    %77 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc67)
    %78 = arith.cmpi slt, %65, %77 : tensor<32x1xi32, #blocked4> loc(#loc67)
    %79 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked> loc(#loc68)
    %80 = arith.cmpi slt, %72, %79 : tensor<1x32xi32, #blocked> loc(#loc68)
    %81 = tt.broadcast %78 : tensor<32x1xi1, #blocked4> -> tensor<32x32xi1, #blocked4> loc(#loc69)
    %82 = ttg.convert_layout %81 : tensor<32x32xi1, #blocked4> -> tensor<32x32xi1, #blocked> loc(#loc69)
    %83 = tt.broadcast %80 : tensor<1x32xi1, #blocked> -> tensor<32x32xi1, #blocked> loc(#loc69)
    %84 = arith.andi %82, %83 : tensor<32x32xi1, #blocked> loc(#loc69)
    %85 = ttg.convert_layout %76 : tensor<32x32x!tt.ptr<f16>, #blocked> -> tensor<32x32x!tt.ptr<f16>, #blocked8> loc(#loc70)
    %86 = ttg.convert_layout %62 : tensor<32x32xf16, #blocked> -> tensor<32x32xf16, #blocked8> loc(#loc70)
    %87 = ttg.convert_layout %84 : tensor<32x32xi1, #blocked> -> tensor<32x32xi1, #blocked8> loc(#loc70)
    tt.store %85, %86, %87 : tensor<32x32x!tt.ptr<f16>, #blocked8> loc(#loc70)
    tt.return loc(#loc71)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":158:26)
#loc37 = loc("examples/kernels/binary_ops.py":159:30)
#loc38 = loc("examples/kernels/binary_ops.py":159:41)
#loc39 = loc("examples/kernels/binary_ops.py":159:60)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:33)
#loc48 = loc("examples/kernels/binary_ops.py":168:22)
#loc49 = loc("examples/kernels/binary_ops.py":171:59)
#loc50 = loc("examples/kernels/binary_ops.py":171:55)
#loc51 = loc("examples/kernels/binary_ops.py":171:51)
#loc52 = loc("examples/kernels/binary_ops.py":171:20)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":172:20)
#loc55 = loc("examples/kernels/binary_ops.py":167:27)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":177:8)
#loc58 = loc("examples/kernels/binary_ops.py":176:18)
#loc59 = loc("examples/kernels/binary_ops.py":177:33)
#loc60 = loc("examples/kernels/binary_ops.py":177:18)
#loc61 = loc("examples/kernels/binary_ops.py":182:23)
#loc62 = loc("examples/kernels/binary_ops.py":188:41)
#loc63 = loc("examples/kernels/binary_ops.py":188:33)
#loc64 = loc("examples/kernels/binary_ops.py":188:21)
#loc65 = loc("examples/kernels/binary_ops.py":188:72)
#loc66 = loc("examples/kernels/binary_ops.py":188:52)
#loc67 = loc("examples/kernels/binary_ops.py":189:33)
#loc68 = loc("examples/kernels/binary_ops.py":189:58)
#loc69 = loc("examples/kernels/binary_ops.py":189:39)
#loc70 = loc("examples/kernels/binary_ops.py":190:21)
#loc71 = loc("examples/kernels/binary_ops.py":190:4)
#loc72 = loc(callsite(#loc3 at #loc4))
#loc73 = loc(callsite(#loc5 at #loc4))
#loc74 = loc(callsite(#loc3 at #loc6))
#loc75 = loc(callsite(#loc5 at #loc6))
#loc76 = loc(callsite(#loc3 at #loc47))
#loc77 = loc(callsite(#loc5 at #loc47))


// -----// IR Dump Before TritonGPURemoveLayoutConversions (tritongpu-remove-layout-conversions) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>
#blocked4 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked5 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [0, 1]}>
#blocked6 = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked7 = #ttg.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked8 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #blocked> loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc72)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc73)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc74)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc75)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #blocked2> loc(#loc30)
    %21 = tt.splat %19 : i32 -> tensor<32xi32, #blocked2> loc(#loc31)
    %22 = arith.addi %21, %20 : tensor<32xi32, #blocked2> loc(#loc31)
    %23 = tt.splat %arg3 : i32 -> tensor<32xi32, #blocked2> loc(#loc32)
    %24 = arith.remsi %22, %23 : tensor<32xi32, #blocked2> loc(#loc32)
    %25 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %26 = tt.splat %25 : i32 -> tensor<32xi32, #blocked2> loc(#loc34)
    %27 = arith.addi %26, %20 : tensor<32xi32, #blocked2> loc(#loc34)
    %28 = tt.splat %arg4 : i32 -> tensor<32xi32, #blocked2> loc(#loc35)
    %29 = arith.remsi %27, %28 : tensor<32xi32, #blocked2> loc(#loc35)
    %30 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #blocked2> loc(#loc36)
    %31 = ttg.convert_layout %24 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc37)
    %32 = tt.expand_dims %31 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc37)
    %33 = ttg.convert_layout %32 : tensor<32x1xi32, #blocked3> -> tensor<32x1xi32, #blocked4> loc(#loc38)
    %34 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc38)
    %35 = arith.muli %33, %34 : tensor<32x1xi32, #blocked4> loc(#loc38)
    %36 = ttg.convert_layout %30 : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc39)
    %37 = tt.expand_dims %36 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x16xi32, #blocked5> loc(#loc39)
    %38 = ttg.convert_layout %37 : tensor<1x16xi32, #blocked5> -> tensor<1x16xi32, #blocked1> loc(#loc40)
    %39 = tt.broadcast %35 : tensor<32x1xi32, #blocked4> -> tensor<32x16xi32, #blocked4> loc(#loc40)
    %40 = ttg.convert_layout %39 : tensor<32x16xi32, #blocked4> -> tensor<32x16xi32, #blocked1> loc(#loc40)
    %41 = tt.broadcast %38 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc40)
    %42 = arith.addi %40, %41 : tensor<32x16xi32, #blocked1> loc(#loc40)
    %43 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc41)
    %44 = tt.addptr %43, %42 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc41)
    %45 = ttg.convert_layout %30 : tensor<16xi32, #blocked2> -> tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc42)
    %46 = tt.expand_dims %45 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<16x1xi32, #blocked3> loc(#loc42)
    %47 = ttg.convert_layout %46 : tensor<16x1xi32, #blocked3> -> tensor<16x1xi32, #blocked4> loc(#loc43)
    %48 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked4> loc(#loc43)
    %49 = arith.muli %47, %48 : tensor<16x1xi32, #blocked4> loc(#loc43)
    %50 = ttg.convert_layout %29 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc44)
    %51 = tt.expand_dims %50 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x32xi32, #blocked5> loc(#loc44)
    %52 = ttg.convert_layout %51 : tensor<1x32xi32, #blocked5> -> tensor<1x32xi32, #blocked> loc(#loc45)
    %53 = tt.broadcast %49 : tensor<16x1xi32, #blocked4> -> tensor<16x32xi32, #blocked4> loc(#loc45)
    %54 = ttg.convert_layout %53 : tensor<16x32xi32, #blocked4> -> tensor<16x32xi32, #blocked> loc(#loc45)
    %55 = tt.broadcast %52 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc45)
    %56 = arith.addi %54, %55 : tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc46)
    %58 = tt.addptr %57, %56 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc46)
    %59 = arith.addi %arg5, %c15_i32 : i32 loc(#loc76)
    %60 = arith.divsi %59, %c16_i32 : i32 loc(#loc77)
    %61:3 = scf.for %arg9 = %c0_i32 to %60 step %c1_i32 iter_args(%arg10 = %cst, %arg11 = %44, %arg12 = %58) -> (tensor<32x32xf32, #blocked>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %88 = arith.muli %arg9, %c16_i32 : i32 loc(#loc49)
      %89 = arith.subi %arg5, %88 : i32 loc(#loc50)
      %90 = tt.splat %89 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc51)
      %91 = arith.cmpi slt, %38, %90 : tensor<1x16xi32, #blocked1> loc(#loc51)
      %92 = tt.broadcast %91 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc52)
      %93 = ttg.convert_layout %arg11 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc52)
      %94 = ttg.convert_layout %92 : tensor<32x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc52)
      %95 = ttg.convert_layout %cst_2 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #blocked1> loc(#loc52)
      %96 = tt.load %93, %94, %95 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc52)
      %97 = tt.splat %89 : i32 -> tensor<16x1xi32, #blocked4> loc(#loc53)
      %98 = arith.cmpi slt, %47, %97 : tensor<16x1xi32, #blocked4> loc(#loc53)
      %99 = tt.broadcast %98 : tensor<16x1xi1, #blocked4> -> tensor<16x32xi1, #blocked4> loc(#loc54)
      %100 = ttg.convert_layout %99 : tensor<16x32xi1, #blocked4> -> tensor<16x32xi1, #blocked> loc(#loc54)
      %101 = ttg.convert_layout %arg12 : tensor<16x32x!tt.ptr<f32>, #blocked> -> tensor<16x32x!tt.ptr<f32>, #blocked6> loc(#loc54)
      %102 = ttg.convert_layout %100 : tensor<16x32xi1, #blocked> -> tensor<16x32xi1, #blocked6> loc(#loc54)
      %103 = ttg.convert_layout %cst_1 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #blocked6> loc(#loc54)
      %104 = tt.load %101, %102, %103 : tensor<16x32x!tt.ptr<f32>, #blocked6> loc(#loc54)
      %105 = ttg.convert_layout %104 : tensor<16x32xf32, #blocked6> -> tensor<16x32xf32, #blocked> loc(#loc54)
      %106 = ttg.convert_layout %96 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked7}>> loc(#loc52)
      %107 = ttg.convert_layout %105 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked7}>> loc(#loc54)
      %108 = ttg.convert_layout %arg10 : tensor<32x32xf32, #blocked> -> tensor<32x32xf32, #blocked7> loc(#loc55)
      %109 = tt.dot %106, %107, %108, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked7}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked7}>> -> tensor<32x32xf32, #blocked7> loc(#loc56)
      %110 = ttg.convert_layout %109 : tensor<32x32xf32, #blocked7> -> tensor<32x32xf32, #blocked> loc(#loc57)
      %111 = tt.addptr %arg11, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc58)
      %112 = arith.muli %arg7, %c16_i32 : i32 loc(#loc59)
      %113 = tt.splat %112 : i32 -> tensor<16x32xi32, #blocked> loc(#loc60)
      %114 = tt.addptr %arg12, %113 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc60)
      scf.yield %110, %111, %114 : tensor<32x32xf32, #blocked>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc57)
    } loc(#loc48)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #blocked> to tensor<32x32xf16, #blocked> loc(#loc61)
    %63 = ttg.convert_layout %22 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc62)
    %64 = tt.expand_dims %63 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc62)
    %65 = ttg.convert_layout %64 : tensor<32x1xi32, #blocked3> -> tensor<32x1xi32, #blocked4> loc(#loc63)
    %66 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc63)
    %67 = arith.muli %66, %65 : tensor<32x1xi32, #blocked4> loc(#loc63)
    %68 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked4> loc(#loc64)
    %69 = tt.addptr %68, %67 : tensor<32x1x!tt.ptr<f16>, #blocked4>, tensor<32x1xi32, #blocked4> loc(#loc64)
    %70 = ttg.convert_layout %27 : tensor<32xi32, #blocked2> -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> loc(#loc65)
    %71 = tt.expand_dims %70 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked5}>> -> tensor<1x32xi32, #blocked5> loc(#loc65)
    %72 = ttg.convert_layout %71 : tensor<1x32xi32, #blocked5> -> tensor<1x32xi32, #blocked> loc(#loc66)
    %73 = tt.broadcast %69 : tensor<32x1x!tt.ptr<f16>, #blocked4> -> tensor<32x32x!tt.ptr<f16>, #blocked4> loc(#loc66)
    %74 = ttg.convert_layout %73 : tensor<32x32x!tt.ptr<f16>, #blocked4> -> tensor<32x32x!tt.ptr<f16>, #blocked> loc(#loc66)
    %75 = tt.broadcast %72 : tensor<1x32xi32, #blocked> -> tensor<32x32xi32, #blocked> loc(#loc66)
    %76 = tt.addptr %74, %75 : tensor<32x32x!tt.ptr<f16>, #blocked>, tensor<32x32xi32, #blocked> loc(#loc66)
    %77 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked4> loc(#loc67)
    %78 = arith.cmpi slt, %65, %77 : tensor<32x1xi32, #blocked4> loc(#loc67)
    %79 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked> loc(#loc68)
    %80 = arith.cmpi slt, %72, %79 : tensor<1x32xi32, #blocked> loc(#loc68)
    %81 = tt.broadcast %78 : tensor<32x1xi1, #blocked4> -> tensor<32x32xi1, #blocked4> loc(#loc69)
    %82 = ttg.convert_layout %81 : tensor<32x32xi1, #blocked4> -> tensor<32x32xi1, #blocked> loc(#loc69)
    %83 = tt.broadcast %80 : tensor<1x32xi1, #blocked> -> tensor<32x32xi1, #blocked> loc(#loc69)
    %84 = arith.andi %82, %83 : tensor<32x32xi1, #blocked> loc(#loc69)
    %85 = ttg.convert_layout %76 : tensor<32x32x!tt.ptr<f16>, #blocked> -> tensor<32x32x!tt.ptr<f16>, #blocked8> loc(#loc70)
    %86 = ttg.convert_layout %62 : tensor<32x32xf16, #blocked> -> tensor<32x32xf16, #blocked8> loc(#loc70)
    %87 = ttg.convert_layout %84 : tensor<32x32xi1, #blocked> -> tensor<32x32xi1, #blocked8> loc(#loc70)
    tt.store %85, %86, %87 : tensor<32x32x!tt.ptr<f16>, #blocked8> loc(#loc70)
    tt.return loc(#loc71)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":158:26)
#loc37 = loc("examples/kernels/binary_ops.py":159:30)
#loc38 = loc("examples/kernels/binary_ops.py":159:41)
#loc39 = loc("examples/kernels/binary_ops.py":159:60)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:33)
#loc48 = loc("examples/kernels/binary_ops.py":168:22)
#loc49 = loc("examples/kernels/binary_ops.py":171:59)
#loc50 = loc("examples/kernels/binary_ops.py":171:55)
#loc51 = loc("examples/kernels/binary_ops.py":171:51)
#loc52 = loc("examples/kernels/binary_ops.py":171:20)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":172:20)
#loc55 = loc("examples/kernels/binary_ops.py":167:27)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":177:8)
#loc58 = loc("examples/kernels/binary_ops.py":176:18)
#loc59 = loc("examples/kernels/binary_ops.py":177:33)
#loc60 = loc("examples/kernels/binary_ops.py":177:18)
#loc61 = loc("examples/kernels/binary_ops.py":182:23)
#loc62 = loc("examples/kernels/binary_ops.py":188:41)
#loc63 = loc("examples/kernels/binary_ops.py":188:33)
#loc64 = loc("examples/kernels/binary_ops.py":188:21)
#loc65 = loc("examples/kernels/binary_ops.py":188:72)
#loc66 = loc("examples/kernels/binary_ops.py":188:52)
#loc67 = loc("examples/kernels/binary_ops.py":189:33)
#loc68 = loc("examples/kernels/binary_ops.py":189:58)
#loc69 = loc("examples/kernels/binary_ops.py":189:39)
#loc70 = loc("examples/kernels/binary_ops.py":190:21)
#loc71 = loc("examples/kernels/binary_ops.py":190:4)
#loc72 = loc(callsite(#loc3 at #loc4))
#loc73 = loc(callsite(#loc5 at #loc4))
#loc74 = loc(callsite(#loc3 at #loc6))
#loc75 = loc(callsite(#loc5 at #loc6))
#loc76 = loc(callsite(#loc3 at #loc47))
#loc77 = loc(callsite(#loc5 at #loc47))


// -----// IR Dump Before TritonGPUOptimizeThreadLocality (tritongpu-optimize-thread-locality) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #blocked2> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %49 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %50 = tt.expand_dims %48 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %51 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %52 = arith.muli %49, %51 : tensor<16x1xi32, #blocked> loc(#loc42)
    %53 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %54 = tt.broadcast %52 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.broadcast %53 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %56 = arith.addi %54, %55 : tensor<16x32xi32, #blocked> loc(#loc44)
    %57 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %58 = tt.addptr %57, %56 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %59 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %60 = arith.divsi %59, %c16_i32 : i32 loc(#loc75)
    %61:3 = scf.for %arg9 = %c0_i32 to %60 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %58) -> (tensor<32x32xf32, #blocked2>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc48)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc49)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc50)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc50)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc51)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc52)
      %87 = arith.cmpi slt, %50, %86 : tensor<16x1xi32, #blocked> loc(#loc52)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc53)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc53)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked2}>> loc(#loc51)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked2}>> loc(#loc53)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked2}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked2}>> -> tensor<32x32xf32, #blocked2> loc(#loc54)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %94 = arith.muli %arg7, %c16_i32 : i32 loc(#loc56)
      %95 = tt.splat %94 : i32 -> tensor<16x32xi32, #blocked> loc(#loc57)
      %96 = tt.addptr %arg12, %95 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc57)
      scf.yield %92, %93, %96 : tensor<32x32xf32, #blocked2>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc47)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #blocked2> to tensor<32x32xf16, #blocked2> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked3> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked3> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked3> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked3>, tensor<32x1xi32, #blocked3> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi32, #blocked3> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked3> -> tensor<32x32x!tt.ptr<f16>, #blocked3> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked3> -> tensor<32x32xi32, #blocked3> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked3>, tensor<32x32xi32, #blocked3> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked3> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked3> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked3> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked3> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked3> -> tensor<32x32xi1, #blocked3> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked3> -> tensor<32x32xi1, #blocked3> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked3> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #blocked2> -> tensor<32x32xf16, #blocked3> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked3> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
#loc48 = loc("examples/kernels/binary_ops.py":171:59)
#loc49 = loc("examples/kernels/binary_ops.py":171:55)
#loc50 = loc("examples/kernels/binary_ops.py":171:51)
#loc51 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":172:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:20)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":177:33)
#loc57 = loc("examples/kernels/binary_ops.py":177:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUAccelerateMatmul (tritongpu-accelerate-matmul) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #blocked2> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %49 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %50 = tt.expand_dims %48 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %51 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %52 = arith.muli %49, %51 : tensor<16x1xi32, #blocked> loc(#loc42)
    %53 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %54 = tt.broadcast %52 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.broadcast %53 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %56 = arith.addi %54, %55 : tensor<16x32xi32, #blocked> loc(#loc44)
    %57 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %58 = tt.addptr %57, %56 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %59 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %60 = arith.divsi %59, %c16_i32 : i32 loc(#loc75)
    %61:3 = scf.for %arg9 = %c0_i32 to %60 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %58) -> (tensor<32x32xf32, #blocked2>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc48)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc49)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc50)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc50)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc51)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc52)
      %87 = arith.cmpi slt, %50, %86 : tensor<16x1xi32, #blocked> loc(#loc52)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc53)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc53)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked2}>> loc(#loc51)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked2}>> loc(#loc53)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked2}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked2}>> -> tensor<32x32xf32, #blocked2> loc(#loc54)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %94 = arith.muli %arg7, %c16_i32 : i32 loc(#loc56)
      %95 = tt.splat %94 : i32 -> tensor<16x32xi32, #blocked> loc(#loc57)
      %96 = tt.addptr %arg12, %95 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc57)
      scf.yield %92, %93, %96 : tensor<32x32xf32, #blocked2>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc47)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #blocked2> to tensor<32x32xf16, #blocked2> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked3> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked3> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked3> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked3>, tensor<32x1xi32, #blocked3> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi32, #blocked3> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked3> -> tensor<32x32x!tt.ptr<f16>, #blocked3> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked3> -> tensor<32x32xi32, #blocked3> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked3>, tensor<32x32xi32, #blocked3> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked3> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked3> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked3> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked3> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked3> -> tensor<32x32xi1, #blocked3> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked3> -> tensor<32x32xi1, #blocked3> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked3> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #blocked2> -> tensor<32x32xf16, #blocked3> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked3> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
#loc48 = loc("examples/kernels/binary_ops.py":171:59)
#loc49 = loc("examples/kernels/binary_ops.py":171:55)
#loc50 = loc("examples/kernels/binary_ops.py":171:51)
#loc51 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":172:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:20)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":177:33)
#loc57 = loc("examples/kernels/binary_ops.py":177:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPURemoveLayoutConversions (tritongpu-remove-layout-conversions) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [2, 2], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked3 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #blocked2> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %49 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %50 = tt.expand_dims %48 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %51 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %52 = arith.muli %49, %51 : tensor<16x1xi32, #blocked> loc(#loc42)
    %53 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %54 = tt.broadcast %52 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.broadcast %53 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %56 = arith.addi %54, %55 : tensor<16x32xi32, #blocked> loc(#loc44)
    %57 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %58 = tt.addptr %57, %56 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %59 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %60 = arith.divsi %59, %c16_i32 : i32 loc(#loc75)
    %61:3 = scf.for %arg9 = %c0_i32 to %60 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %58) -> (tensor<32x32xf32, #blocked2>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc48)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc49)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc50)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc50)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc51)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc52)
      %87 = arith.cmpi slt, %50, %86 : tensor<16x1xi32, #blocked> loc(#loc52)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc53)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc53)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked2}>> loc(#loc51)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked2}>> loc(#loc53)
      %92 = ttg.convert_layout %arg10 : tensor<32x32xf32, #blocked2> -> tensor<32x32xf32, #mma> loc(#loc1)
      %93 = ttg.convert_layout %90 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #blocked2}>> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc51)
      %94 = ttg.convert_layout %91 : tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #blocked2}>> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc53)
      %95 = tt.dot %93, %94, %92, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %96 = ttg.convert_layout %95 : tensor<32x32xf32, #mma> -> tensor<32x32xf32, #blocked2> loc(#loc54)
      %97 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %98 = arith.muli %arg7, %c16_i32 : i32 loc(#loc56)
      %99 = tt.splat %98 : i32 -> tensor<16x32xi32, #blocked> loc(#loc57)
      %100 = tt.addptr %arg12, %99 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc57)
      scf.yield %96, %97, %100 : tensor<32x32xf32, #blocked2>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc47)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #blocked2> to tensor<32x32xf16, #blocked2> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked3}>> -> tensor<32x1xi32, #blocked3> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked3> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked3> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked3> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked3>, tensor<32x1xi32, #blocked3> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked3}>> -> tensor<1x32xi32, #blocked3> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked3> -> tensor<32x32x!tt.ptr<f16>, #blocked3> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked3> -> tensor<32x32xi32, #blocked3> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked3>, tensor<32x32xi32, #blocked3> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked3> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked3> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked3> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked3> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked3> -> tensor<32x32xi1, #blocked3> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked3> -> tensor<32x32xi1, #blocked3> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked3> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #blocked2> -> tensor<32x32xf16, #blocked3> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked3> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
#loc48 = loc("examples/kernels/binary_ops.py":171:59)
#loc49 = loc("examples/kernels/binary_ops.py":171:55)
#loc50 = loc("examples/kernels/binary_ops.py":171:51)
#loc51 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":172:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:20)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":177:33)
#loc57 = loc("examples/kernels/binary_ops.py":177:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUOptimizeDotOperands (tritongpu-optimize-dot-operands) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %49 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %50 = tt.expand_dims %48 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %51 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %52 = arith.muli %49, %51 : tensor<16x1xi32, #blocked> loc(#loc42)
    %53 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %54 = tt.broadcast %52 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.broadcast %53 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %56 = arith.addi %54, %55 : tensor<16x32xi32, #blocked> loc(#loc44)
    %57 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %58 = tt.addptr %57, %56 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %59 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %60 = arith.divsi %59, %c16_i32 : i32 loc(#loc75)
    %61:3 = scf.for %arg9 = %c0_i32 to %60 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %58) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc48)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc49)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc50)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc50)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc51)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc52)
      %87 = arith.cmpi slt, %50, %86 : tensor<16x1xi32, #blocked> loc(#loc52)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc53)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc53)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc51)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc53)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %94 = arith.muli %arg7, %c16_i32 : i32 loc(#loc56)
      %95 = tt.splat %94 : i32 -> tensor<16x32xi32, #blocked> loc(#loc57)
      %96 = tt.addptr %arg12, %95 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc57)
      scf.yield %92, %93, %96 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc47)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
#loc48 = loc("examples/kernels/binary_ops.py":171:59)
#loc49 = loc("examples/kernels/binary_ops.py":171:55)
#loc50 = loc("examples/kernels/binary_ops.py":171:51)
#loc51 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":172:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:20)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":177:33)
#loc57 = loc("examples/kernels/binary_ops.py":177:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %49 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %50 = tt.expand_dims %48 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %51 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %52 = arith.muli %49, %51 : tensor<16x1xi32, #blocked> loc(#loc42)
    %53 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %54 = tt.broadcast %52 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.broadcast %53 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %56 = arith.addi %54, %55 : tensor<16x32xi32, #blocked> loc(#loc44)
    %57 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %58 = tt.addptr %57, %56 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %59 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %60 = arith.divsi %59, %c16_i32 : i32 loc(#loc75)
    %61:3 = scf.for %arg9 = %c0_i32 to %60 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %58) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc48)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc49)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc50)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc50)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc51)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc52)
      %87 = arith.cmpi slt, %50, %86 : tensor<16x1xi32, #blocked> loc(#loc52)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc53)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc53)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc51)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc53)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %94 = arith.muli %arg7, %c16_i32 : i32 loc(#loc56)
      %95 = tt.splat %94 : i32 -> tensor<16x32xi32, #blocked> loc(#loc57)
      %96 = tt.addptr %arg12, %95 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc57)
      scf.yield %92, %93, %96 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc47)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
#loc48 = loc("examples/kernels/binary_ops.py":171:59)
#loc49 = loc("examples/kernels/binary_ops.py":171:55)
#loc50 = loc("examples/kernels/binary_ops.py":171:51)
#loc51 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":172:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:20)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":177:33)
#loc57 = loc("examples/kernels/binary_ops.py":177:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %49 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %50 = tt.expand_dims %48 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %51 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %52 = arith.muli %49, %51 : tensor<16x1xi32, #blocked> loc(#loc42)
    %53 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %54 = tt.broadcast %52 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.broadcast %53 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %56 = arith.addi %54, %55 : tensor<16x32xi32, #blocked> loc(#loc44)
    %57 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %58 = tt.addptr %57, %56 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %59 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %60 = arith.divsi %59, %c16_i32 : i32 loc(#loc75)
    %61:3 = scf.for %arg9 = %c0_i32 to %60 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %58) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc48)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc49)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc50)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc50)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc51)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc52)
      %87 = arith.cmpi slt, %50, %86 : tensor<16x1xi32, #blocked> loc(#loc52)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc53)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc53)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc51)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc53)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %94 = arith.muli %arg7, %c16_i32 : i32 loc(#loc56)
      %95 = tt.splat %94 : i32 -> tensor<16x32xi32, #blocked> loc(#loc57)
      %96 = tt.addptr %arg12, %95 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc57)
      scf.yield %92, %93, %96 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc47)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
#loc48 = loc("examples/kernels/binary_ops.py":171:59)
#loc49 = loc("examples/kernels/binary_ops.py":171:55)
#loc50 = loc("examples/kernels/binary_ops.py":171:51)
#loc51 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":172:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:20)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":177:33)
#loc57 = loc("examples/kernels/binary_ops.py":177:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUFuseNestedLoops (tritongpu-fuse-nested-loops) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %78 = arith.muli %arg9, %c16_i32 : i32 loc(#loc48)
      %79 = arith.subi %arg5, %78 : i32 loc(#loc49)
      %80 = tt.splat %79 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc50)
      %81 = arith.cmpi slt, %41, %80 : tensor<1x16xi32, #blocked1> loc(#loc50)
      %82 = tt.broadcast %81 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %83 = tt.load %arg11, %82, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc51)
      %84 = tt.splat %79 : i32 -> tensor<16x1xi32, #blocked> loc(#loc52)
      %85 = arith.cmpi slt, %48, %84 : tensor<16x1xi32, #blocked> loc(#loc52)
      %86 = tt.broadcast %85 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc53)
      %87 = tt.load %arg12, %86, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc53)
      %88 = ttg.convert_layout %83 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc51)
      %89 = ttg.convert_layout %87 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc53)
      %90 = tt.dot %88, %89, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %91 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %92 = arith.muli %arg7, %c16_i32 : i32 loc(#loc56)
      %93 = tt.splat %92 : i32 -> tensor<16x32xi32, #blocked> loc(#loc57)
      %94 = tt.addptr %arg12, %93 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc57)
      scf.yield %90, %91, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc47)
    %60 = arith.truncf %59#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %61 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %62 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %63 = arith.muli %62, %61 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %64 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %65 = tt.addptr %64, %63 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %66 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %67 = tt.broadcast %65 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %68 = tt.broadcast %66 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %69 = tt.addptr %67, %68 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %70 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %71 = arith.cmpi slt, %61, %70 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %72 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %73 = arith.cmpi slt, %66, %72 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %74 = tt.broadcast %71 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %75 = tt.broadcast %73 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %76 = arith.andi %74, %75 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = ttg.convert_layout %60 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %69, %77, %76 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
#loc48 = loc("examples/kernels/binary_ops.py":171:59)
#loc49 = loc("examples/kernels/binary_ops.py":171:55)
#loc50 = loc("examples/kernels/binary_ops.py":171:51)
#loc51 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":172:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:20)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":177:33)
#loc57 = loc("examples/kernels/binary_ops.py":177:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %78 = arith.muli %arg9, %c16_i32 : i32 loc(#loc48)
      %79 = arith.subi %arg5, %78 : i32 loc(#loc49)
      %80 = tt.splat %79 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc50)
      %81 = arith.cmpi slt, %41, %80 : tensor<1x16xi32, #blocked1> loc(#loc50)
      %82 = tt.broadcast %81 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %83 = tt.load %arg11, %82, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc51)
      %84 = tt.splat %79 : i32 -> tensor<16x1xi32, #blocked> loc(#loc52)
      %85 = arith.cmpi slt, %48, %84 : tensor<16x1xi32, #blocked> loc(#loc52)
      %86 = tt.broadcast %85 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc53)
      %87 = tt.load %arg12, %86, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc53)
      %88 = ttg.convert_layout %83 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc51)
      %89 = ttg.convert_layout %87 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc53)
      %90 = tt.dot %88, %89, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %91 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %92 = arith.muli %arg7, %c16_i32 : i32 loc(#loc56)
      %93 = tt.splat %92 : i32 -> tensor<16x32xi32, #blocked> loc(#loc57)
      %94 = tt.addptr %arg12, %93 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc57)
      scf.yield %90, %91, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc47)
    %60 = arith.truncf %59#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %61 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %62 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %63 = arith.muli %62, %61 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %64 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %65 = tt.addptr %64, %63 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %66 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %67 = tt.broadcast %65 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %68 = tt.broadcast %66 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %69 = tt.addptr %67, %68 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %70 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %71 = arith.cmpi slt, %61, %70 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %72 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %73 = arith.cmpi slt, %66, %72 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %74 = tt.broadcast %71 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %75 = tt.broadcast %73 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %76 = arith.andi %74, %75 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = ttg.convert_layout %60 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %69, %77, %76 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
#loc48 = loc("examples/kernels/binary_ops.py":171:59)
#loc49 = loc("examples/kernels/binary_ops.py":171:55)
#loc50 = loc("examples/kernels/binary_ops.py":171:51)
#loc51 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":172:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:20)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":177:33)
#loc57 = loc("examples/kernels/binary_ops.py":177:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before LoopInvariantCodeMotion (loop-invariant-code-motion) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %78 = arith.muli %arg9, %c16_i32 : i32 loc(#loc48)
      %79 = arith.subi %arg5, %78 : i32 loc(#loc49)
      %80 = tt.splat %79 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc50)
      %81 = arith.cmpi slt, %41, %80 : tensor<1x16xi32, #blocked1> loc(#loc50)
      %82 = tt.broadcast %81 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %83 = tt.load %arg11, %82, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc51)
      %84 = tt.splat %79 : i32 -> tensor<16x1xi32, #blocked> loc(#loc52)
      %85 = arith.cmpi slt, %48, %84 : tensor<16x1xi32, #blocked> loc(#loc52)
      %86 = tt.broadcast %85 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc53)
      %87 = tt.load %arg12, %86, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc53)
      %88 = ttg.convert_layout %83 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc51)
      %89 = ttg.convert_layout %87 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc53)
      %90 = tt.dot %88, %89, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %91 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %92 = arith.muli %arg7, %c16_i32 : i32 loc(#loc56)
      %93 = tt.splat %92 : i32 -> tensor<16x32xi32, #blocked> loc(#loc57)
      %94 = tt.addptr %arg12, %93 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc57)
      scf.yield %90, %91, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc47)
    %60 = arith.truncf %59#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %61 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %62 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %63 = arith.muli %62, %61 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %64 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %65 = tt.addptr %64, %63 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %66 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %67 = tt.broadcast %65 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %68 = tt.broadcast %66 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %69 = tt.addptr %67, %68 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %70 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %71 = arith.cmpi slt, %61, %70 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %72 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %73 = arith.cmpi slt, %66, %72 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %74 = tt.broadcast %71 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %75 = tt.broadcast %73 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %76 = arith.andi %74, %75 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = ttg.convert_layout %60 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %69, %77, %76 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
#loc48 = loc("examples/kernels/binary_ops.py":171:59)
#loc49 = loc("examples/kernels/binary_ops.py":171:55)
#loc50 = loc("examples/kernels/binary_ops.py":171:51)
#loc51 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":172:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:20)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":177:33)
#loc57 = loc("examples/kernels/binary_ops.py":177:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUOptimizeAccumulatorInit (tritongpu-optimize-accumulator-init) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc50)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc51)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc53)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc53)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc54)
      %87 = arith.cmpi slt, %48, %86 : tensor<16x1xi32, #blocked> loc(#loc54)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc55)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc55)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc53)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc55)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc56)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc57)
      %94 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      scf.yield %92, %93, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc49)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":168:22)
#loc50 = loc("examples/kernels/binary_ops.py":171:59)
#loc51 = loc("examples/kernels/binary_ops.py":171:55)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":171:20)
#loc54 = loc("examples/kernels/binary_ops.py":172:51)
#loc55 = loc("examples/kernels/binary_ops.py":172:20)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":176:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc50)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc51)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc53)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc53)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc54)
      %87 = arith.cmpi slt, %48, %86 : tensor<16x1xi32, #blocked> loc(#loc54)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc55)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc55)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc53)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc55)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc56)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc57)
      %94 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      scf.yield %92, %93, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc49)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":168:22)
#loc50 = loc("examples/kernels/binary_ops.py":171:59)
#loc51 = loc("examples/kernels/binary_ops.py":171:55)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":171:20)
#loc54 = loc("examples/kernels/binary_ops.py":172:51)
#loc55 = loc("examples/kernels/binary_ops.py":172:20)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":176:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUCombineTensorSelectAndIf (tritongpu-combine-tensor-select-and-if) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc50)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc51)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc53)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc53)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc54)
      %87 = arith.cmpi slt, %48, %86 : tensor<16x1xi32, #blocked> loc(#loc54)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc55)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc55)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc53)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc55)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc56)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc57)
      %94 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      scf.yield %92, %93, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc49)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":168:22)
#loc50 = loc("examples/kernels/binary_ops.py":171:59)
#loc51 = loc("examples/kernels/binary_ops.py":171:55)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":171:20)
#loc54 = loc("examples/kernels/binary_ops.py":172:51)
#loc55 = loc("examples/kernels/binary_ops.py":172:20)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":176:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUWSTaskPartition (tritongpu-warp-spec-task-partition) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc50)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc51)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc53)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc53)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc54)
      %87 = arith.cmpi slt, %48, %86 : tensor<16x1xi32, #blocked> loc(#loc54)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc55)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc55)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc53)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc55)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc56)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc57)
      %94 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      scf.yield %92, %93, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc49)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":168:22)
#loc50 = loc("examples/kernels/binary_ops.py":171:59)
#loc51 = loc("examples/kernels/binary_ops.py":171:55)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":171:20)
#loc54 = loc("examples/kernels/binary_ops.py":172:51)
#loc55 = loc("examples/kernels/binary_ops.py":172:20)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":176:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUTaskIdPropagate (triton-gpu-taskid-propagate) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc50)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc51)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc53)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc53)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc54)
      %87 = arith.cmpi slt, %48, %86 : tensor<16x1xi32, #blocked> loc(#loc54)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc55)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc55)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc53)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc55)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc56)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc57)
      %94 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      scf.yield %92, %93, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc49)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":168:22)
#loc50 = loc("examples/kernels/binary_ops.py":171:59)
#loc51 = loc("examples/kernels/binary_ops.py":171:55)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":171:20)
#loc54 = loc("examples/kernels/binary_ops.py":172:51)
#loc55 = loc("examples/kernels/binary_ops.py":172:20)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":176:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUWSDataPartition (tritongpu-warp-spec-data-partition) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc50)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc51)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc53)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc53)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc54)
      %87 = arith.cmpi slt, %48, %86 : tensor<16x1xi32, #blocked> loc(#loc54)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc55)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc55)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc53)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc55)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc56)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc57)
      %94 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      scf.yield %92, %93, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc49)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":168:22)
#loc50 = loc("examples/kernels/binary_ops.py":171:59)
#loc51 = loc("examples/kernels/binary_ops.py":171:55)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":171:20)
#loc54 = loc("examples/kernels/binary_ops.py":172:51)
#loc55 = loc("examples/kernels/binary_ops.py":172:20)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":176:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUWSCodePartition (tritongpu-warp-spec-code-partition) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc50)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc51)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc53)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc53)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc54)
      %87 = arith.cmpi slt, %48, %86 : tensor<16x1xi32, #blocked> loc(#loc54)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc55)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc55)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc53)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc55)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc56)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc57)
      %94 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      scf.yield %92, %93, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc49)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":168:22)
#loc50 = loc("examples/kernels/binary_ops.py":171:59)
#loc51 = loc("examples/kernels/binary_ops.py":171:55)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":171:20)
#loc54 = loc("examples/kernels/binary_ops.py":172:51)
#loc55 = loc("examples/kernels/binary_ops.py":172:20)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":176:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUPipeline (tritongpu-pipeline) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc70)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc71)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc72)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc73)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc74)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc75)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32 loc(#loc50)
      %81 = arith.subi %arg5, %80 : i32 loc(#loc51)
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %84 = tt.broadcast %83 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc53)
      %85 = tt.load %arg11, %84, %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc53)
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #blocked> loc(#loc54)
      %87 = arith.cmpi slt, %48, %86 : tensor<16x1xi32, #blocked> loc(#loc54)
      %88 = tt.broadcast %87 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc55)
      %89 = tt.load %arg12, %88, %cst : tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc55)
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc53)
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc55)
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc56)
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc57)
      %94 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      scf.yield %92, %93, %94 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc58)
    } loc(#loc49)
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc59)
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc61)
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #blocked2> loc(#loc61)
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc62)
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc62)
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc63)
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc64)
    %70 = tt.broadcast %68 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc64)
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc64)
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc65)
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #blocked2> loc(#loc65)
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc66)
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #blocked2> loc(#loc66)
    %76 = tt.broadcast %73 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %77 = tt.broadcast %75 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc67)
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #blocked2> loc(#loc67)
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc68)
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc68)
    tt.return loc(#loc69)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":168:22)
#loc50 = loc("examples/kernels/binary_ops.py":171:59)
#loc51 = loc("examples/kernels/binary_ops.py":171:55)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":171:20)
#loc54 = loc("examples/kernels/binary_ops.py":172:51)
#loc55 = loc("examples/kernels/binary_ops.py":172:20)
#loc56 = loc("examples/kernels/binary_ops.py":174:35)
#loc57 = loc("examples/kernels/binary_ops.py":176:18)
#loc58 = loc("examples/kernels/binary_ops.py":177:8)
#loc59 = loc("examples/kernels/binary_ops.py":182:23)
#loc60 = loc("examples/kernels/binary_ops.py":188:41)
#loc61 = loc("examples/kernels/binary_ops.py":188:33)
#loc62 = loc("examples/kernels/binary_ops.py":188:21)
#loc63 = loc("examples/kernels/binary_ops.py":188:72)
#loc64 = loc("examples/kernels/binary_ops.py":188:52)
#loc65 = loc("examples/kernels/binary_ops.py":189:33)
#loc66 = loc("examples/kernels/binary_ops.py":189:58)
#loc67 = loc("examples/kernels/binary_ops.py":189:39)
#loc68 = loc("examples/kernels/binary_ops.py":190:21)
#loc69 = loc("examples/kernels/binary_ops.py":190:4)
#loc70 = loc(callsite(#loc3 at #loc4))
#loc71 = loc(callsite(#loc5 at #loc4))
#loc72 = loc(callsite(#loc3 at #loc6))
#loc73 = loc(callsite(#loc5 at #loc6))
#loc74 = loc(callsite(#loc3 at #loc46))
#loc75 = loc(callsite(#loc5 at #loc46))


// -----// SoftwarePipeliner internal IR Dump After: AssignLatencies
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32, %arg6: i32, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %c4_i32 = arith.constant 4 : i32
    %c0_i32 = arith.constant 0 : i32
    %true = arith.constant true
    %c32_i32 = arith.constant 32 : i32
    %c16_i32 = arith.constant 16 : i32
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %c1_i32 = arith.constant 1 : i32
    %c31_i32 = arith.constant 31 : i32
    %c15_i32 = arith.constant 15 : i32
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %0 = tt.get_program_id x : i32
    %1 = arith.addi %arg3, %c31_i32 : i32
    %2 = arith.divsi %1, %c32_i32 : i32
    %3 = arith.addi %arg4, %c31_i32 : i32
    %4 = arith.divsi %3, %c32_i32 : i32
    %5 = arith.muli %4, %c4_i32 : i32
    %6 = arith.divsi %0, %5 : i32
    %7 = arith.muli %6, %c4_i32 : i32
    %8 = arith.subi %2, %7 : i32
    %9 = arith.minsi %8, %c4_i32 : i32
    %10 = arith.remsi %0, %5 : i32
    %11 = arith.remsi %10, %9 : i32
    %12 = arith.addi %7, %11 : i32
    %13 = arith.divsi %10, %9 : i32
    %14 = arith.cmpi sge, %12, %c0_i32 : i32
    llvm.intr.assume %14 : i1
    %15 = arith.cmpi sge, %13, %c0_i32 : i32
    llvm.intr.assume %15 : i1
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    llvm.intr.assume %16 : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32
    llvm.intr.assume %17 : i1
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32
    llvm.intr.assume %18 : i1
    llvm.intr.assume %true : i1
    %19 = arith.muli %12, %c32_i32 : i32
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %30 = arith.muli %13, %c32_i32 : i32
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %42 = tt.broadcast %39 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %43 = tt.broadcast %41 : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %52 = tt.broadcast %50 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %53 = tt.broadcast %51 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %57 = arith.addi %arg5, %c15_i32 : i32
    %58 = arith.divsi %57, %c16_i32 : i32
    %59 = arith.muli %arg7, %c16_i32 : i32
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %61:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 : i32
      %81 = arith.subi %arg5, %80 : i32
      %82 = tt.splat %81 : i32 -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %83 = arith.cmpi slt, %41, %82 : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %84 = tt.broadcast %83 : tensor<1x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %85 = tt.load %arg11, %84, %cst_0 {tt.latency = 1 : i32} : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %86 = tt.splat %81 : i32 -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %87 = arith.cmpi slt, %48, %86 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %88 = tt.broadcast %87 : tensor<16x1xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %89 = tt.load %arg12, %88, %cst {tt.latency = 1 : i32} : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %90 = ttg.convert_layout %85 : tensor<32x16xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>>
      %91 = ttg.convert_layout %89 : tensor<16x32xf32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>>
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>> -> tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
      %93 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %94 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      scf.yield %92, %93, %94 : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    }
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %70 = tt.broadcast %68 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %76 = tt.broadcast %73 : tensor<32x1xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %77 = tt.broadcast %75 : tensor<1x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.return
  }
}


// -----// SoftwarePipeliner internal IR Dump After: ScheduleLoops
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32, %arg6: i32, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %c4_i32 = arith.constant 4 : i32
    %c0_i32 = arith.constant 0 : i32
    %true = arith.constant true
    %c32_i32 = arith.constant 32 : i32
    %c16_i32 = arith.constant 16 : i32
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %c1_i32 = arith.constant 1 : i32
    %c31_i32 = arith.constant 31 : i32
    %c15_i32 = arith.constant 15 : i32
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %0 = tt.get_program_id x : i32
    %1 = arith.addi %arg3, %c31_i32 : i32
    %2 = arith.divsi %1, %c32_i32 : i32
    %3 = arith.addi %arg4, %c31_i32 : i32
    %4 = arith.divsi %3, %c32_i32 : i32
    %5 = arith.muli %4, %c4_i32 : i32
    %6 = arith.divsi %0, %5 : i32
    %7 = arith.muli %6, %c4_i32 : i32
    %8 = arith.subi %2, %7 : i32
    %9 = arith.minsi %8, %c4_i32 : i32
    %10 = arith.remsi %0, %5 : i32
    %11 = arith.remsi %10, %9 : i32
    %12 = arith.addi %7, %11 : i32
    %13 = arith.divsi %10, %9 : i32
    %14 = arith.cmpi sge, %12, %c0_i32 : i32
    llvm.intr.assume %14 : i1
    %15 = arith.cmpi sge, %13, %c0_i32 : i32
    llvm.intr.assume %15 : i1
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    llvm.intr.assume %16 : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32
    llvm.intr.assume %17 : i1
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32
    llvm.intr.assume %18 : i1
    llvm.intr.assume %true : i1
    %19 = arith.muli %12, %c32_i32 : i32
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %30 = arith.muli %13, %c32_i32 : i32
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %42 = tt.broadcast %39 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %43 = tt.broadcast %41 : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %52 = tt.broadcast %50 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %53 = tt.broadcast %51 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %57 = arith.addi %arg5, %c15_i32 : i32
    %58 = arith.divsi %57, %c16_i32 : i32
    %59 = arith.muli %arg7, %c16_i32 : i32
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %61:3 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56) -> (tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>)  : i32 {
      %80 = arith.muli %arg9, %c16_i32 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %81 = arith.subi %arg5, %80 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %82 = tt.splat %81 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32 -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %83 = arith.cmpi slt, %41, %82 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %84 = tt.broadcast %83 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<1x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %85 = tt.load %arg11, %84, %cst_0 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %86 = tt.splat %81 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32 -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %87 = arith.cmpi slt, %48, %86 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %88 = tt.broadcast %87 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x1xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %89 = tt.load %arg12, %88, %cst {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %90 = ttg.convert_layout %85 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : tensor<32x16xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>>
      %91 = ttg.convert_layout %89 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : tensor<16x32xf32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>>
      %92 = tt.dot %90, %91, %arg10, inputPrecision = tf32 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>> -> tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
      %93 = tt.addptr %arg11, %cst_1 {loop.cluster = 1 : i32, loop.stage = 1 : i32} : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %94 = tt.addptr %arg12, %60 {loop.cluster = 1 : i32, loop.stage = 1 : i32} : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      scf.yield %92, %93, %94 : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    } {tt.scheduled_max_stage = 1 : i32}
    %62 = arith.truncf %61#0 : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %63 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %64 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %65 = arith.muli %64, %63 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %66 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %67 = tt.addptr %66, %65 : tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %68 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %69 = tt.broadcast %67 : tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %70 = tt.broadcast %68 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %71 = tt.addptr %69, %70 : tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %72 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %73 = arith.cmpi slt, %63, %72 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %74 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %75 = arith.cmpi slt, %68, %74 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %76 = tt.broadcast %73 : tensor<32x1xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %77 = tt.broadcast %75 : tensor<1x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %78 = arith.andi %76, %77 : tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %79 = ttg.convert_layout %62 : tensor<32x32xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.store %71, %79, %78 : tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.return
  }
}


// -----// SoftwarePipeliner internal IR Dump After: LowerLoops
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32, %arg6: i32, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %c4_i32 = arith.constant 4 : i32
    %c0_i32 = arith.constant 0 : i32
    %true = arith.constant true
    %c32_i32 = arith.constant 32 : i32
    %c16_i32 = arith.constant 16 : i32
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %c1_i32 = arith.constant 1 : i32
    %c31_i32 = arith.constant 31 : i32
    %c15_i32 = arith.constant 15 : i32
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %0 = tt.get_program_id x : i32
    %1 = arith.addi %arg3, %c31_i32 : i32
    %2 = arith.divsi %1, %c32_i32 : i32
    %3 = arith.addi %arg4, %c31_i32 : i32
    %4 = arith.divsi %3, %c32_i32 : i32
    %5 = arith.muli %4, %c4_i32 : i32
    %6 = arith.divsi %0, %5 : i32
    %7 = arith.muli %6, %c4_i32 : i32
    %8 = arith.subi %2, %7 : i32
    %9 = arith.minsi %8, %c4_i32 : i32
    %10 = arith.remsi %0, %5 : i32
    %11 = arith.remsi %10, %9 : i32
    %12 = arith.addi %7, %11 : i32
    %13 = arith.divsi %10, %9 : i32
    %14 = arith.cmpi sge, %12, %c0_i32 : i32
    llvm.intr.assume %14 : i1
    %15 = arith.cmpi sge, %13, %c0_i32 : i32
    llvm.intr.assume %15 : i1
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    llvm.intr.assume %16 : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32
    llvm.intr.assume %17 : i1
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32
    llvm.intr.assume %18 : i1
    llvm.intr.assume %true : i1
    %19 = arith.muli %12, %c32_i32 : i32
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %30 = arith.muli %13, %c32_i32 : i32
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %42 = tt.broadcast %39 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %43 = tt.broadcast %41 : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %52 = tt.broadcast %50 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %53 = tt.broadcast %51 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %57 = arith.addi %arg5, %c15_i32 : i32
    %58 = arith.divsi %57, %c16_i32 : i32
    %59 = arith.muli %arg7, %c16_i32 : i32
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable>
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable>
    %c-1_i32 = arith.constant -1 : i32
    %c0_i32_3 = arith.constant 0 : i32
    %c1_i32_4 = arith.constant 1 : i32
    %c0_i32_5 = arith.constant 0 : i32
    %c0_i32_6 = arith.constant 0 : i32
    %c0_i32_7 = arith.constant 0 : i32
    %c1_i32_8 = arith.constant 1 : i32
    %c2_i32 = arith.constant 2 : i32
    %63:5 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c-1_i32, %arg14 = %c-1_i32) -> (tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32)  : i32 {
      %c1_i32_9 = arith.constant {loop.cluster = 2 : i32, loop.stage = 0 : i32} 1 : i32
      %83 = arith.addi %arg13, %c1_i32_4 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %84 = arith.cmpi slt, %83, %c1_i32_9 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %85 = arith.select %84, %83, %c0_i32_3 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %86 = arith.addi %arg14, %c1_i32_4 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : i32
      %87 = arith.cmpi slt, %86, %c1_i32_9 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : i32
      %88 = arith.select %87, %86, %c0_i32_3 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : i32
      %89 = arith.muli %arg9, %c16_i32 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %90 = arith.subi %arg5, %89 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %91 = tt.splat %90 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32 -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %92 = arith.cmpi slt, %41, %91 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %93 = tt.broadcast %92 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<1x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %94 = ttg.memdesc_subview %61[%85, %c0_i32_5, %c0_i32_5] {loop.cluster = 2 : i32, loop.stage = 0 : i32} : !ttg.memdesc<1x32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x32x16>
      %95 = ttg.async_copy_global_to_local %arg11, %94 mask %93 other %cst_0 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x32x16>
      %96 = ttg.async_commit_group %95 {loop.cluster = 2 : i32, loop.stage = 0 : i32}
      %97 = ttg.async_wait %96 {loop.cluster = 0 : i32, loop.stage = 1 : i32, num = 0 : i32}
      %98 = ttg.memdesc_subview %61[%88, %c0_i32_5, %c0_i32_5] {loop.cluster = 0 : i32, loop.stage = 1 : i32} : !ttg.memdesc<1x32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x32x16>
      %99 = ttg.local_load %98 token %97 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : !ttg.memdesc<32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %100 = tt.splat %90 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32 -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %101 = arith.cmpi slt, %48, %100 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %102 = tt.broadcast %101 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x1xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %103 = ttg.memdesc_subview %62[%85, %c0_i32_6, %c0_i32_6] {loop.cluster = 2 : i32, loop.stage = 0 : i32} : !ttg.memdesc<1x16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x16x32>
      %104 = ttg.async_copy_global_to_local %arg12, %103 mask %102 other %cst {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x16x32>
      %105 = ttg.async_commit_group %104 {loop.cluster = 2 : i32, loop.stage = 0 : i32}
      %106 = ttg.async_wait %105 {loop.cluster = 0 : i32, loop.stage = 1 : i32, num = 0 : i32}
      %107 = ttg.memdesc_subview %62[%88, %c0_i32_6, %c0_i32_6] {loop.cluster = 0 : i32, loop.stage = 1 : i32} : !ttg.memdesc<1x16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x16x32>
      %108 = ttg.local_load %107 token %106 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : !ttg.memdesc<16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %109 = ttg.convert_layout %99 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : tensor<32x16xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>>
      %110 = ttg.convert_layout %108 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : tensor<16x32xf32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>>
      %111 = tt.dot %109, %110, %arg10, inputPrecision = tf32 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>> -> tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
      %112 = tt.addptr %arg11, %cst_1 {loop.cluster = 1 : i32, loop.stage = 1 : i32} : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %113 = tt.addptr %arg12, %60 {loop.cluster = 1 : i32, loop.stage = 1 : i32} : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      scf.yield %111, %112, %113, %85, %88 : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32
    } {tt.scheduled_max_stage = 1 : i32}
    %64 = ttg.async_wait  {num = 0 : i32}
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable>
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable>
    %65 = arith.truncf %63#0 : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %66 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %67 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %68 = arith.muli %67, %66 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %69 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %70 = tt.addptr %69, %68 : tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %71 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %72 = tt.broadcast %70 : tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %73 = tt.broadcast %71 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %74 = tt.addptr %72, %73 : tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %75 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %76 = arith.cmpi slt, %66, %75 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %77 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %78 = arith.cmpi slt, %71, %77 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %79 = tt.broadcast %76 : tensor<32x1xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %80 = tt.broadcast %78 : tensor<1x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %81 = arith.andi %79, %80 : tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %82 = ttg.convert_layout %65 : tensor<32x32xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.store %74, %82, %81 : tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.return
  }
}


// -----// SoftwarePipeliner internal IR Dump After: ExpandLoops
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32, %arg6: i32, %arg7: i32 {tt.divisibility = 16 : i32}, %arg8: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %c4_i32 = arith.constant 4 : i32
    %c0_i32 = arith.constant 0 : i32
    %true = arith.constant true
    %c32_i32 = arith.constant 32 : i32
    %c16_i32 = arith.constant 16 : i32
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %c1_i32 = arith.constant 1 : i32
    %c31_i32 = arith.constant 31 : i32
    %c15_i32 = arith.constant 15 : i32
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %0 = tt.get_program_id x : i32
    %1 = arith.addi %arg3, %c31_i32 : i32
    %2 = arith.divsi %1, %c32_i32 : i32
    %3 = arith.addi %arg4, %c31_i32 : i32
    %4 = arith.divsi %3, %c32_i32 : i32
    %5 = arith.muli %4, %c4_i32 : i32
    %6 = arith.divsi %0, %5 : i32
    %7 = arith.muli %6, %c4_i32 : i32
    %8 = arith.subi %2, %7 : i32
    %9 = arith.minsi %8, %c4_i32 : i32
    %10 = arith.remsi %0, %5 : i32
    %11 = arith.remsi %10, %9 : i32
    %12 = arith.addi %7, %11 : i32
    %13 = arith.divsi %10, %9 : i32
    %14 = arith.cmpi sge, %12, %c0_i32 : i32
    llvm.intr.assume %14 : i1
    %15 = arith.cmpi sge, %13, %c0_i32 : i32
    llvm.intr.assume %15 : i1
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32
    llvm.intr.assume %16 : i1
    llvm.intr.assume %true : i1
    llvm.intr.assume %true : i1
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32
    llvm.intr.assume %17 : i1
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32
    llvm.intr.assume %18 : i1
    llvm.intr.assume %true : i1
    %19 = arith.muli %12, %c32_i32 : i32
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %30 = arith.muli %13, %c32_i32 : i32
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %42 = tt.broadcast %39 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %43 = tt.broadcast %41 : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>>
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %52 = tt.broadcast %50 : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %53 = tt.broadcast %51 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %57 = arith.addi %arg5, %c15_i32 : i32
    %58 = arith.divsi %57, %c16_i32 : i32
    %59 = arith.muli %arg7, %c16_i32 : i32
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable>
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable>
    %c-1_i32 = arith.constant -1 : i32
    %c0_i32_3 = arith.constant 0 : i32
    %c1_i32_4 = arith.constant 1 : i32
    %c0_i32_5 = arith.constant 0 : i32
    %c0_i32_6 = arith.constant 0 : i32
    %c0_i32_7 = arith.constant 0 : i32
    %c1_i32_8 = arith.constant 1 : i32
    %c2_i32 = arith.constant 2 : i32
    %c0_i32_9 = arith.constant 0 : i32
    %63 = arith.muli %c1_i32, %c0_i32_9 : i32
    %64 = arith.addi %c0_i32, %63 : i32
    %65 = arith.cmpi slt, %64, %58 : i32
    %c1_i32_10 = arith.constant {loop.cluster = 2 : i32, loop.stage = 0 : i32} 1 : i32
    %66 = arith.addi %c-1_i32, %c1_i32_4 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
    %67 = arith.cmpi slt, %66, %c1_i32_10 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
    %68 = arith.select %67, %66, %c0_i32_3 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
    %69 = arith.muli %64, %c16_i32 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
    %70 = arith.subi %arg5, %69 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
    %71 = tt.splat %70 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32 -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %72 = arith.cmpi slt, %41, %71 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %73 = tt.broadcast %72 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<1x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %74 = ttg.memdesc_subview %61[%68, %c0_i32_5, %c0_i32_5] {loop.cluster = 2 : i32, loop.stage = 0 : i32} : !ttg.memdesc<1x32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x32x16>
    %75 = tt.splat %65 : i1 -> tensor<32x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %76 = arith.andi %75, %73 : tensor<32x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %77 = ttg.async_copy_global_to_local %46, %74 mask %76 other %cst_0 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x32x16>
    %78 = ttg.async_commit_group %77 {loop.cluster = 2 : i32, loop.stage = 0 : i32}
    %79 = tt.splat %70 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32 -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %80 = arith.cmpi slt, %48, %79 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %81 = tt.broadcast %80 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x1xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %82 = ttg.memdesc_subview %62[%68, %c0_i32_6, %c0_i32_6] {loop.cluster = 2 : i32, loop.stage = 0 : i32} : !ttg.memdesc<1x16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x16x32>
    %83 = tt.splat %65 : i1 -> tensor<16x32xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %84 = arith.andi %83, %81 : tensor<16x32xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %85 = ttg.async_copy_global_to_local %56, %82 mask %84 other %cst {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x16x32>
    %86 = ttg.async_commit_group %85 {loop.cluster = 2 : i32, loop.stage = 0 : i32}
    %87:8 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %68, %arg14 = %c-1_i32, %arg15 = %c1_i32_10, %arg16 = %78, %arg17 = %86) -> (tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, i32, !ttg.async.token, !ttg.async.token)  : i32 {
      %c1_i32_11 = arith.constant 1 : i32
      %107 = arith.muli %c1_i32, %c1_i32_11 : i32
      %108 = arith.subi %58, %107 : i32
      %109 = arith.cmpi slt, %arg9, %108 : i32
      %110 = arith.addi %arg14, %c1_i32_4 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : i32
      %111 = arith.cmpi slt, %110, %arg15 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : i32
      %112 = arith.select %111, %110, %c0_i32_3 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : i32
      %113 = ttg.async_wait %arg16 {loop.cluster = 0 : i32, loop.stage = 1 : i32, num = 0 : i32}
      %114 = ttg.memdesc_subview %61[%112, %c0_i32_5, %c0_i32_5] {loop.cluster = 0 : i32, loop.stage = 1 : i32} : !ttg.memdesc<1x32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x32x16>
      %115 = ttg.local_load %114 token %113 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : !ttg.memdesc<32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %116 = ttg.async_wait %arg17 {loop.cluster = 0 : i32, loop.stage = 1 : i32, num = 0 : i32}
      %117 = ttg.memdesc_subview %62[%112, %c0_i32_6, %c0_i32_6] {loop.cluster = 0 : i32, loop.stage = 1 : i32} : !ttg.memdesc<1x16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x16x32>
      %118 = ttg.local_load %117 token %116 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : !ttg.memdesc<16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %119 = ttg.convert_layout %115 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : tensor<32x16xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>>
      %120 = ttg.convert_layout %118 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : tensor<16x32xf32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>>
      %121 = tt.dot %119, %120, %arg10, inputPrecision = tf32 {loop.cluster = 0 : i32, loop.stage = 1 : i32} : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>, kWidth = 1}>> -> tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
      %122 = tt.addptr %arg11, %cst_1 {loop.cluster = 1 : i32, loop.stage = 1 : i32} : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %123 = tt.addptr %arg12, %60 {loop.cluster = 1 : i32, loop.stage = 1 : i32} : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %c1_i32_12 = arith.constant {loop.cluster = 2 : i32, loop.stage = 0 : i32} 1 : i32
      %124 = arith.addi %arg13, %c1_i32_4 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %125 = arith.cmpi slt, %124, %c1_i32_12 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %126 = arith.select %125, %124, %c0_i32_3 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %c1_i32_13 = arith.constant 1 : i32
      %127 = arith.muli %c1_i32, %c1_i32_13 : i32
      %128 = arith.addi %arg9, %127 : i32
      %129 = arith.muli %128, %c16_i32 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %130 = arith.subi %arg5, %129 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32
      %131 = tt.splat %130 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32 -> tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %132 = arith.cmpi slt, %41, %131 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<1x16xi32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %133 = tt.broadcast %132 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<1x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %134 = ttg.memdesc_subview %61[%126, %c0_i32_5, %c0_i32_5] {loop.cluster = 2 : i32, loop.stage = 0 : i32} : !ttg.memdesc<1x32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x32x16>
      %135 = tt.splat %109 : i1 -> tensor<32x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %136 = arith.andi %135, %133 : tensor<32x16xi1, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %137 = ttg.async_copy_global_to_local %122, %134 mask %136 other %cst_0 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x32x16>
      %138 = ttg.async_commit_group %137 {loop.cluster = 2 : i32, loop.stage = 0 : i32}
      %139 = tt.splat %130 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : i32 -> tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %140 = arith.cmpi slt, %48, %139 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x1xi32, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %141 = tt.broadcast %140 {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x1xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<16x32xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %142 = ttg.memdesc_subview %62[%126, %c0_i32_6, %c0_i32_6] {loop.cluster = 2 : i32, loop.stage = 0 : i32} : !ttg.memdesc<1x16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x16x32>
      %143 = tt.splat %109 : i1 -> tensor<16x32xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %144 = arith.andi %143, %141 : tensor<16x32xi1, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>
      %145 = ttg.async_copy_global_to_local %123, %142 mask %144 other %cst {loop.cluster = 2 : i32, loop.stage = 0 : i32} : tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>> -> <16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable, 1x16x32>
      %146 = ttg.async_commit_group %145 {loop.cluster = 2 : i32, loop.stage = 0 : i32}
      scf.yield %121, %122, %123, %126, %112, %c1_i32_12, %138, %146 : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>, tensor<32x16x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<16x32x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>>, i32, i32, i32, !ttg.async.token, !ttg.async.token
    } {tt.scheduled_max_stage = 1 : i32}
    %88 = ttg.async_wait  {num = 0 : i32}
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable>
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>, #ttg.shared_memory, mutable>
    %89 = arith.truncf %87#0 : tensor<32x32xf32, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> to tensor<32x32xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>>
    %90 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %91 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %92 = arith.muli %91, %90 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %93 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %94 = tt.addptr %93, %92 : tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %95 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>}>> -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %96 = tt.broadcast %94 : tensor<32x1x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %97 = tt.broadcast %95 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %98 = tt.addptr %96, %97 : tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>, tensor<32x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %99 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %100 = arith.cmpi slt, %90, %99 : tensor<32x1xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %101 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %102 = arith.cmpi slt, %95, %101 : tensor<1x32xi32, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %103 = tt.broadcast %100 : tensor<32x1xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %104 = tt.broadcast %102 : tensor<1x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>> -> tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %105 = arith.andi %103, %104 : tensor<32x32xi1, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    %106 = ttg.convert_layout %89 : tensor<32x32xf16, #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>> -> tensor<32x32xf16, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.store %98, %106, %105 : tensor<32x32x!tt.ptr<f16>, #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>>
    tt.return
  }
}


// -----// IR Dump Before TritonGPUPingPongSync (tritongpu-ping-pong-sync) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:7 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %71, %arg16 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg16 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 token %105 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #blocked1> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 token %105 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #blocked> loc(#loc50)
      %110 = ttg.convert_layout %107 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %111 = ttg.convert_layout %109 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %112 = tt.dot %110, %111, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %113 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %114 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %115 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %116 = arith.cmpi slt, %115, %c1_i32 : i32 loc(#loc51)
      %117 = arith.select %116, %115, %c0_i32 : i32 loc(#loc51)
      %118 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %119 = arith.muli %118, %c16_i32 : i32 loc(#loc56)
      %120 = arith.subi %arg5, %119 : i32 loc(#loc57)
      %121 = tt.splat %120 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %122 = arith.cmpi slt, %41, %121 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %123 = tt.broadcast %122 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %124 = ttg.memdesc_subview %61[%117, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %125 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %126 = arith.andi %125, %123 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %127 = ttg.async_copy_global_to_local %113, %124 mask %126 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %128 = ttg.async_commit_group %127 loc(#loc49)
      %129 = tt.splat %120 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %130 = arith.cmpi slt, %48, %129 : tensor<16x1xi32, #blocked> loc(#loc53)
      %131 = tt.broadcast %130 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %132 = ttg.memdesc_subview %62[%117, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %133 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %134 = arith.andi %133, %131 : tensor<16x32xi1, #blocked> loc(#loc51)
      %135 = ttg.async_copy_global_to_local %114, %132 mask %134 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %136 = ttg.async_commit_group %135 loc(#loc50)
      scf.yield %112, %113, %114, %117, %104, %128, %136 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUWSLowering (tritongpu-warp-spec-lowering) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:7 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %71, %arg16 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg16 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 token %105 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #blocked1> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 token %105 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #blocked> loc(#loc50)
      %110 = ttg.convert_layout %107 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %111 = ttg.convert_layout %109 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %112 = tt.dot %110, %111, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %113 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %114 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %115 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %116 = arith.cmpi slt, %115, %c1_i32 : i32 loc(#loc51)
      %117 = arith.select %116, %115, %c0_i32 : i32 loc(#loc51)
      %118 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %119 = arith.muli %118, %c16_i32 : i32 loc(#loc56)
      %120 = arith.subi %arg5, %119 : i32 loc(#loc57)
      %121 = tt.splat %120 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %122 = arith.cmpi slt, %41, %121 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %123 = tt.broadcast %122 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %124 = ttg.memdesc_subview %61[%117, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %125 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %126 = arith.andi %125, %123 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %127 = ttg.async_copy_global_to_local %113, %124 mask %126 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %128 = ttg.async_commit_group %127 loc(#loc49)
      %129 = tt.splat %120 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %130 = arith.cmpi slt, %48, %129 : tensor<16x1xi32, #blocked> loc(#loc53)
      %131 = tt.broadcast %130 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %132 = ttg.memdesc_subview %62[%117, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %133 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %134 = arith.andi %133, %131 : tensor<16x32xi1, #blocked> loc(#loc51)
      %135 = ttg.async_copy_global_to_local %114, %132 mask %134 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %136 = ttg.async_commit_group %135 loc(#loc50)
      scf.yield %112, %113, %114, %117, %104, %128, %136 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUPrefetch (tritongpu-prefetch) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:7 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %71, %arg16 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg16 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 token %105 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #blocked1> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 token %105 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #blocked> loc(#loc50)
      %110 = ttg.convert_layout %107 : tensor<32x16xf32, #blocked1> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %111 = ttg.convert_layout %109 : tensor<16x32xf32, #blocked> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %112 = tt.dot %110, %111, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %113 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %114 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %115 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %116 = arith.cmpi slt, %115, %c1_i32 : i32 loc(#loc51)
      %117 = arith.select %116, %115, %c0_i32 : i32 loc(#loc51)
      %118 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %119 = arith.muli %118, %c16_i32 : i32 loc(#loc56)
      %120 = arith.subi %arg5, %119 : i32 loc(#loc57)
      %121 = tt.splat %120 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %122 = arith.cmpi slt, %41, %121 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %123 = tt.broadcast %122 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %124 = ttg.memdesc_subview %61[%117, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %125 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %126 = arith.andi %125, %123 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %127 = ttg.async_copy_global_to_local %113, %124 mask %126 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %128 = ttg.async_commit_group %127 loc(#loc49)
      %129 = tt.splat %120 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %130 = arith.cmpi slt, %48, %129 : tensor<16x1xi32, #blocked> loc(#loc53)
      %131 = tt.broadcast %130 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %132 = ttg.memdesc_subview %62[%117, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %133 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %134 = arith.andi %133, %131 : tensor<16x32xi1, #blocked> loc(#loc51)
      %135 = ttg.async_copy_global_to_local %114, %132 mask %134 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %136 = ttg.async_commit_group %135 loc(#loc50)
      scf.yield %112, %113, %114, %117, %104, %128, %136 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUOptimizeDotOperands (tritongpu-optimize-dot-operands) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:7 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %71, %arg16 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg16 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %126, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:7 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %71, %arg16 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg16 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %126, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUCoalesceAsyncCopy (tritongpu-coalesce-async-copy) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPURemoveLayoutConversions (tritongpu-remove-layout-conversions) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUReduceDataDuplication (tritongpu-reduce-data-duplication) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUReorderInstructions (tritongpu-reorder-instructions) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before SymbolDCE (symbol-dce) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonNvidiaGPUMMALoweringPass (triton-nvidia-mma-lowering) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUCombineTensorSelectAndIf (tritongpu-combine-tensor-select-and-if) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUAllocateWarpGroups (tritongpu-allocate-warp-groups) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before SCFToControlFlowPass (convert-scf-to-cf) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    %80:6 = scf.for %arg9 = %c0_i32 to %58 step %c1_i32 iter_args(%arg10 = %cst_2, %arg11 = %46, %arg12 = %56, %arg13 = %c0_i32, %arg14 = %c-1_i32, %arg15 = %79) -> (tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token)  : i32 {
      %100 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
      %101 = arith.cmpi slt, %arg9, %100 : i32 loc(#loc51)
      %102 = arith.addi %arg14, %c1_i32 : i32 loc(#loc51)
      %103 = arith.cmpi slt, %102, %c1_i32 : i32 loc(#loc51)
      %104 = arith.select %103, %102, %c0_i32 : i32 loc(#loc51)
      %105 = ttg.async_wait %arg15 {num = 0 : i32} loc(#loc49)
      %106 = ttg.memdesc_subview %61[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %107 = ttg.local_load %106 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
      %108 = ttg.memdesc_subview %62[%104, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %109 = ttg.local_load %108 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
      %110 = tt.dot %107, %109, %arg10, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
      %111 = tt.addptr %arg11, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
      %112 = tt.addptr %arg12, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
      %113 = arith.addi %arg13, %c1_i32 : i32 loc(#loc51)
      %114 = arith.cmpi slt, %113, %c1_i32 : i32 loc(#loc51)
      %115 = arith.select %114, %113, %c0_i32 : i32 loc(#loc51)
      %116 = arith.addi %arg9, %c1_i32 : i32 loc(#loc51)
      %117 = arith.muli %116, %c16_i32 : i32 loc(#loc56)
      %118 = arith.subi %arg5, %117 : i32 loc(#loc57)
      %119 = tt.splat %118 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
      %120 = arith.cmpi slt, %41, %119 : tensor<1x16xi32, #blocked1> loc(#loc52)
      %121 = tt.broadcast %120 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
      %122 = ttg.memdesc_subview %61[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %123 = tt.splat %101 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
      %124 = arith.andi %123, %121 : tensor<32x16xi1, #blocked1> loc(#loc51)
      %125 = ttg.async_copy_global_to_local %111, %122 mask %124 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
      %126 = ttg.async_commit_group %125 loc(#loc49)
      %127 = tt.splat %118 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
      %128 = arith.cmpi slt, %48, %127 : tensor<16x1xi32, #blocked> loc(#loc53)
      %129 = tt.broadcast %128 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
      %130 = ttg.memdesc_subview %62[%115, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %131 = tt.splat %101 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
      %132 = arith.andi %131, %129 : tensor<16x32xi1, #blocked> loc(#loc51)
      %133 = ttg.async_copy_global_to_local %112, %130 mask %132 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
      %134 = ttg.async_commit_group %133 loc(#loc50)
      scf.yield %110, %111, %112, %115, %104, %134 : tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token loc(#loc51)
    } loc(#loc51)
    %81 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %82 = arith.truncf %80#0 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %83 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %84 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %85 = arith.muli %84, %83 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %86 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %87 = tt.addptr %86, %85 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %88 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %89 = tt.broadcast %87 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %90 = tt.broadcast %88 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %91 = tt.addptr %89, %90 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %92 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %93 = arith.cmpi slt, %83, %92 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %94 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %95 = arith.cmpi slt, %88, %94 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %96 = tt.broadcast %93 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %97 = tt.broadcast %95 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %98 = arith.andi %96, %97 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %99 = ttg.convert_layout %82 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %91, %99, %98 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before AllocateSharedMemory (allocate-shared-memory) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    cf.br ^bb1(%c0_i32, %cst_2, %46, %56, %c0_i32, %c-1_i32, %79 : i32, tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token) loc(#loc51)
  ^bb1(%80: i32 loc("examples/kernels/binary_ops.py":168:22), %81: tensor<32x32xf32, #mma> loc(unknown), %82: tensor<32x16x!tt.ptr<f32>, #blocked1> loc("examples/kernels/binary_ops.py":159:22), %83: tensor<16x32x!tt.ptr<f32>, #blocked> loc("examples/kernels/binary_ops.py":160:22), %84: i32 loc(unknown), %85: i32 loc(unknown), %86: !ttg.async.token loc("examples/kernels/binary_ops.py":172:20)):  // 2 preds: ^bb0, ^bb2
    %87 = arith.cmpi slt, %80, %58 : i32 loc(#loc51)
    cf.cond_br %87, ^bb2, ^bb3 loc(#loc51)
  ^bb2:  // pred: ^bb1
    %88 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
    %89 = arith.cmpi slt, %80, %88 : i32 loc(#loc51)
    %90 = arith.addi %85, %c1_i32 : i32 loc(#loc51)
    %91 = arith.cmpi slt, %90, %c1_i32 : i32 loc(#loc51)
    %92 = arith.select %91, %90, %c0_i32 : i32 loc(#loc51)
    %93 = ttg.async_wait %86 {num = 0 : i32} loc(#loc49)
    %94 = ttg.memdesc_subview %61[%92, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %95 = ttg.local_load %94 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
    %96 = ttg.memdesc_subview %62[%92, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %97 = ttg.local_load %96 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
    %98 = tt.dot %95, %97, %81, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
    %99 = tt.addptr %82, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
    %100 = tt.addptr %83, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
    %101 = arith.addi %84, %c1_i32 : i32 loc(#loc51)
    %102 = arith.cmpi slt, %101, %c1_i32 : i32 loc(#loc51)
    %103 = arith.select %102, %101, %c0_i32 : i32 loc(#loc51)
    %104 = arith.addi %80, %c1_i32 : i32 loc(#loc51)
    %105 = arith.muli %104, %c16_i32 : i32 loc(#loc56)
    %106 = arith.subi %arg5, %105 : i32 loc(#loc57)
    %107 = tt.splat %106 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %108 = arith.cmpi slt, %41, %107 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %109 = tt.broadcast %108 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %110 = ttg.memdesc_subview %61[%103, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %111 = tt.splat %89 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %112 = arith.andi %111, %109 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %113 = ttg.async_copy_global_to_local %99, %110 mask %112 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %114 = ttg.async_commit_group %113 loc(#loc49)
    %115 = tt.splat %106 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %116 = arith.cmpi slt, %48, %115 : tensor<16x1xi32, #blocked> loc(#loc53)
    %117 = tt.broadcast %116 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %118 = ttg.memdesc_subview %62[%103, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %119 = tt.splat %89 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %120 = arith.andi %119, %117 : tensor<16x32xi1, #blocked> loc(#loc51)
    %121 = ttg.async_copy_global_to_local %100, %118 mask %120 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %122 = ttg.async_commit_group %121 loc(#loc50)
    %123 = arith.addi %80, %c1_i32 : i32 loc(#loc51)
    cf.br ^bb1(%123, %98, %99, %100, %103, %92, %122 : i32, tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token) loc(#loc51)
  ^bb3:  // pred: ^bb1
    %124 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %125 = arith.truncf %81 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %126 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %127 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %128 = arith.muli %127, %126 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %129 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %130 = tt.addptr %129, %128 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %131 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %132 = tt.broadcast %130 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %133 = tt.broadcast %131 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %134 = tt.addptr %132, %133 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %135 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %136 = arith.cmpi slt, %126, %135 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %137 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %138 = arith.cmpi slt, %131, %137 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %139 = tt.broadcast %136 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %140 = tt.broadcast %138 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %141 = arith.andi %139, %140 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %142 = ttg.convert_layout %125 : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %134, %142, %141 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritionTensorMemoryAllocationPass (triton-tensor-memory-allocation) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  {allocation.offset = 0 : i32} : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  {allocation.offset = 2048 : i32} : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    cf.br ^bb1(%c0_i32, %cst_2, %46, %56, %c0_i32, %c-1_i32, %79 : i32, tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token) loc(#loc51)
  ^bb1(%80: i32 loc("examples/kernels/binary_ops.py":168:22), %81: tensor<32x32xf32, #mma> loc(unknown), %82: tensor<32x16x!tt.ptr<f32>, #blocked1> loc("examples/kernels/binary_ops.py":159:22), %83: tensor<16x32x!tt.ptr<f32>, #blocked> loc("examples/kernels/binary_ops.py":160:22), %84: i32 loc(unknown), %85: i32 loc(unknown), %86: !ttg.async.token loc("examples/kernels/binary_ops.py":172:20)):  // 2 preds: ^bb0, ^bb2
    %87 = arith.cmpi slt, %80, %58 : i32 loc(#loc51)
    cf.cond_br %87, ^bb2, ^bb3 loc(#loc51)
  ^bb2:  // pred: ^bb1
    %88 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
    %89 = arith.cmpi slt, %80, %88 : i32 loc(#loc51)
    %90 = arith.addi %85, %c1_i32 : i32 loc(#loc51)
    %91 = arith.cmpi slt, %90, %c1_i32 : i32 loc(#loc51)
    %92 = arith.select %91, %90, %c0_i32 : i32 loc(#loc51)
    %93 = ttg.async_wait %86 {num = 0 : i32} loc(#loc49)
    %94 = ttg.memdesc_subview %61[%92, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %95 = ttg.local_load %94 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
    %96 = ttg.memdesc_subview %62[%92, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %97 = ttg.local_load %96 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
    %98 = tt.dot %95, %97, %81, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
    %99 = tt.addptr %82, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
    %100 = tt.addptr %83, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
    %101 = arith.addi %84, %c1_i32 : i32 loc(#loc51)
    %102 = arith.cmpi slt, %101, %c1_i32 : i32 loc(#loc51)
    %103 = arith.select %102, %101, %c0_i32 : i32 loc(#loc51)
    %104 = arith.addi %80, %c1_i32 : i32 loc(#loc51)
    %105 = arith.muli %104, %c16_i32 : i32 loc(#loc56)
    %106 = arith.subi %arg5, %105 : i32 loc(#loc57)
    %107 = tt.splat %106 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %108 = arith.cmpi slt, %41, %107 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %109 = tt.broadcast %108 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %110 = ttg.memdesc_subview %61[%103, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %111 = tt.splat %89 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %112 = arith.andi %111, %109 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %113 = ttg.async_copy_global_to_local %99, %110 mask %112 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %114 = ttg.async_commit_group %113 loc(#loc49)
    %115 = tt.splat %106 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %116 = arith.cmpi slt, %48, %115 : tensor<16x1xi32, #blocked> loc(#loc53)
    %117 = tt.broadcast %116 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %118 = ttg.memdesc_subview %62[%103, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %119 = tt.splat %89 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %120 = arith.andi %119, %117 : tensor<16x32xi1, #blocked> loc(#loc51)
    %121 = ttg.async_copy_global_to_local %100, %118 mask %120 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %122 = ttg.async_commit_group %121 loc(#loc50)
    %123 = arith.addi %80, %c1_i32 : i32 loc(#loc51)
    cf.br ^bb1(%123, %98, %99, %100, %103, %92, %122 : i32, tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token) loc(#loc51)
  ^bb3:  // pred: ^bb1
    %124 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %125 = arith.truncf %81 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %126 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %127 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %128 = arith.muli %127, %126 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %129 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %130 = tt.addptr %129, %128 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %131 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %132 = tt.broadcast %130 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %133 = tt.broadcast %131 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %134 = tt.addptr %132, %133 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %135 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %136 = arith.cmpi slt, %126, %135 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %137 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %138 = arith.cmpi slt, %131, %137 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %139 = tt.broadcast %136 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %140 = tt.broadcast %138 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %141 = arith.andi %139, %140 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %142 = ttg.convert_layout %125 {allocation.offset = 0 : i32} : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %134, %142, %141 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before TritonGPUGlobalScratchAllocationPass (tritongpu-global-scratch-memory-allocation) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  {allocation.offset = 0 : i32} : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  {allocation.offset = 2048 : i32} : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    cf.br ^bb1(%c0_i32, %cst_2, %46, %56, %c0_i32, %c-1_i32, %79 : i32, tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token) loc(#loc51)
  ^bb1(%80: i32 loc("examples/kernels/binary_ops.py":168:22), %81: tensor<32x32xf32, #mma> loc(unknown), %82: tensor<32x16x!tt.ptr<f32>, #blocked1> loc("examples/kernels/binary_ops.py":159:22), %83: tensor<16x32x!tt.ptr<f32>, #blocked> loc("examples/kernels/binary_ops.py":160:22), %84: i32 loc(unknown), %85: i32 loc(unknown), %86: !ttg.async.token loc("examples/kernels/binary_ops.py":172:20)):  // 2 preds: ^bb0, ^bb2
    %87 = arith.cmpi slt, %80, %58 : i32 loc(#loc51)
    cf.cond_br %87, ^bb2, ^bb3 loc(#loc51)
  ^bb2:  // pred: ^bb1
    %88 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
    %89 = arith.cmpi slt, %80, %88 : i32 loc(#loc51)
    %90 = arith.addi %85, %c1_i32 : i32 loc(#loc51)
    %91 = arith.cmpi slt, %90, %c1_i32 : i32 loc(#loc51)
    %92 = arith.select %91, %90, %c0_i32 : i32 loc(#loc51)
    %93 = ttg.async_wait %86 {num = 0 : i32} loc(#loc49)
    %94 = ttg.memdesc_subview %61[%92, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %95 = ttg.local_load %94 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
    %96 = ttg.memdesc_subview %62[%92, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %97 = ttg.local_load %96 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
    %98 = tt.dot %95, %97, %81, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
    %99 = tt.addptr %82, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
    %100 = tt.addptr %83, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
    %101 = arith.addi %84, %c1_i32 : i32 loc(#loc51)
    %102 = arith.cmpi slt, %101, %c1_i32 : i32 loc(#loc51)
    %103 = arith.select %102, %101, %c0_i32 : i32 loc(#loc51)
    %104 = arith.addi %80, %c1_i32 : i32 loc(#loc51)
    %105 = arith.muli %104, %c16_i32 : i32 loc(#loc56)
    %106 = arith.subi %arg5, %105 : i32 loc(#loc57)
    %107 = tt.splat %106 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %108 = arith.cmpi slt, %41, %107 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %109 = tt.broadcast %108 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %110 = ttg.memdesc_subview %61[%103, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %111 = tt.splat %89 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %112 = arith.andi %111, %109 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %113 = ttg.async_copy_global_to_local %99, %110 mask %112 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %114 = ttg.async_commit_group %113 loc(#loc49)
    %115 = tt.splat %106 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %116 = arith.cmpi slt, %48, %115 : tensor<16x1xi32, #blocked> loc(#loc53)
    %117 = tt.broadcast %116 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %118 = ttg.memdesc_subview %62[%103, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %119 = tt.splat %89 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %120 = arith.andi %119, %117 : tensor<16x32xi1, #blocked> loc(#loc51)
    %121 = ttg.async_copy_global_to_local %100, %118 mask %120 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %122 = ttg.async_commit_group %121 loc(#loc50)
    %123 = arith.addi %80, %c1_i32 : i32 loc(#loc51)
    cf.br ^bb1(%123, %98, %99, %100, %103, %92, %122 : i32, tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token) loc(#loc51)
  ^bb3:  // pred: ^bb1
    %124 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %125 = arith.truncf %81 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %126 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %127 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %128 = arith.muli %127, %126 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %129 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %130 = tt.addptr %129, %128 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %131 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %132 = tt.broadcast %130 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %133 = tt.broadcast %131 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %134 = tt.addptr %132, %133 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %135 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %136 = arith.cmpi slt, %126, %135 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %137 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %138 = arith.cmpi slt, %131, %137 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %139 = tt.broadcast %136 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %140 = tt.broadcast %138 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %141 = arith.andi %139, %140 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %142 = ttg.convert_layout %125 {allocation.offset = 0 : i32} : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %134, %142, %141 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before ConvertTritonGPUToLLVM (convert-triton-gpu-to-llvm) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked2 = #ttg.blocked<{sizePerThread = [1, 8], threadsPerWarp = [8, 4], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc40 = loc("examples/kernels/binary_ops.py":159:22)
#loc45 = loc("examples/kernels/binary_ops.py":160:22)
#loc50 = loc("examples/kernels/binary_ops.py":172:20)
#loc51 = loc("examples/kernels/binary_ops.py":168:22)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
#shared = #ttg.swizzled_shared<{vec = 4, perPhase = 2, maxPhase = 4, order = [1, 0]}>
#shared1 = #ttg.swizzled_shared<{vec = 8, perPhase = 1, maxPhase = 4, order = [1, 0]}>
#smem = #ttg.shared_memory
module attributes {ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  tt.func public @matmul_kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !tt.ptr<f16> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %c-1_i32 = arith.constant -1 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<16x32xf32, #blocked> loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %true = arith.constant true loc(#loc1)
    %c32_i32 = arith.constant 32 : i32 loc(#loc1)
    %c16_i32 = arith.constant 16 : i32 loc(#loc1)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x16xf32, #blocked1> loc(#loc1)
    %cst_1 = arith.constant dense<16> : tensor<32x16xi32, #blocked1> loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c31_i32 = arith.constant 31 : i32 loc(#loc1)
    %c15_i32 = arith.constant 15 : i32 loc(#loc1)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<32x32xf32, #mma> loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = arith.addi %arg3, %c31_i32 : i32 loc(#loc69)
    %2 = arith.divsi %1, %c32_i32 : i32 loc(#loc70)
    %3 = arith.addi %arg4, %c31_i32 : i32 loc(#loc71)
    %4 = arith.divsi %3, %c32_i32 : i32 loc(#loc72)
    %5 = arith.muli %4, %c4_i32 : i32 loc(#loc7)
    %6 = arith.divsi %0, %5 : i32 loc(#loc8)
    %7 = arith.muli %6, %c4_i32 : i32 loc(#loc9)
    %8 = arith.subi %2, %7 : i32 loc(#loc10)
    %9 = arith.minsi %8, %c4_i32 : i32 loc(#loc11)
    %10 = arith.remsi %0, %5 : i32 loc(#loc12)
    %11 = arith.remsi %10, %9 : i32 loc(#loc13)
    %12 = arith.addi %7, %11 : i32 loc(#loc14)
    %13 = arith.divsi %10, %9 : i32 loc(#loc15)
    %14 = arith.cmpi sge, %12, %c0_i32 : i32 loc(#loc16)
    llvm.intr.assume %14 : i1 loc(#loc17)
    %15 = arith.cmpi sge, %13, %c0_i32 : i32 loc(#loc18)
    llvm.intr.assume %15 : i1 loc(#loc19)
    %16 = arith.cmpi sgt, %arg6, %c0_i32 : i32 loc(#loc20)
    llvm.intr.assume %16 : i1 loc(#loc21)
    llvm.intr.assume %true : i1 loc(#loc22)
    llvm.intr.assume %true : i1 loc(#loc23)
    %17 = arith.cmpi sgt, %arg7, %c0_i32 : i32 loc(#loc24)
    llvm.intr.assume %17 : i1 loc(#loc25)
    %18 = arith.cmpi sgt, %arg8, %c0_i32 : i32 loc(#loc26)
    llvm.intr.assume %18 : i1 loc(#loc27)
    llvm.intr.assume %true : i1 loc(#loc28)
    %19 = arith.muli %12, %c32_i32 : i32 loc(#loc29)
    %20 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc30)
    %21 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc30)
    %22 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc30)
    %23 = tt.make_range {end = 32 : i32, start = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc30)
    %24 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %25 = tt.splat %19 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %26 = arith.addi %24, %20 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc31)
    %27 = arith.addi %25, %21 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> loc(#loc31)
    %28 = tt.splat %arg3 : i32 -> tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %29 = arith.remsi %26, %28 : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> loc(#loc32)
    %30 = arith.muli %13, %c32_i32 : i32 loc(#loc33)
    %31 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %32 = tt.splat %30 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %33 = arith.addi %31, %22 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc34)
    %34 = arith.addi %32, %23 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> loc(#loc34)
    %35 = tt.splat %arg4 : i32 -> tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %36 = arith.remsi %33, %35 : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> loc(#loc35)
    %37 = tt.expand_dims %29 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked1}>> -> tensor<32x1xi32, #blocked1> loc(#loc36)
    %38 = tt.splat %arg6 : i32 -> tensor<32x1xi32, #blocked1> loc(#loc37)
    %39 = arith.muli %37, %38 : tensor<32x1xi32, #blocked1> loc(#loc37)
    %40 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> loc(#loc38)
    %41 = tt.expand_dims %40 {axis = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 0, parent = #blocked1}>> -> tensor<1x16xi32, #blocked1> loc(#loc38)
    %42 = tt.broadcast %39 : tensor<32x1xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %43 = tt.broadcast %41 : tensor<1x16xi32, #blocked1> -> tensor<32x16xi32, #blocked1> loc(#loc39)
    %44 = arith.addi %42, %43 : tensor<32x16xi32, #blocked1> loc(#loc39)
    %45 = tt.splat %arg0 : !tt.ptr<f32> -> tensor<32x16x!tt.ptr<f32>, #blocked1> loc(#loc40)
    %46 = tt.addptr %45, %44 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc40)
    %47 = tt.make_range {end = 16 : i32, start = 0 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> loc(#loc41)
    %48 = tt.expand_dims %47 {axis = 1 : i32} : tensor<16xi32, #ttg.slice<{dim = 1, parent = #blocked}>> -> tensor<16x1xi32, #blocked> loc(#loc41)
    %49 = tt.splat %arg7 : i32 -> tensor<16x1xi32, #blocked> loc(#loc42)
    %50 = arith.muli %48, %49 : tensor<16x1xi32, #blocked> loc(#loc42)
    %51 = tt.expand_dims %36 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked}>> -> tensor<1x32xi32, #blocked> loc(#loc43)
    %52 = tt.broadcast %50 : tensor<16x1xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %53 = tt.broadcast %51 : tensor<1x32xi32, #blocked> -> tensor<16x32xi32, #blocked> loc(#loc44)
    %54 = arith.addi %52, %53 : tensor<16x32xi32, #blocked> loc(#loc44)
    %55 = tt.splat %arg1 : !tt.ptr<f32> -> tensor<16x32x!tt.ptr<f32>, #blocked> loc(#loc45)
    %56 = tt.addptr %55, %54 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc45)
    %57 = arith.addi %arg5, %c15_i32 : i32 loc(#loc73)
    %58 = arith.divsi %57, %c16_i32 : i32 loc(#loc74)
    %59 = arith.muli %arg7, %c16_i32 : i32 loc(#loc47)
    %60 = tt.splat %59 : i32 -> tensor<16x32xi32, #blocked> loc(#loc48)
    %61 = ttg.local_alloc  {allocation.offset = 0 : i32} : () -> !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc49)
    %62 = ttg.local_alloc  {allocation.offset = 2048 : i32} : () -> !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc50)
    %63 = arith.cmpi sgt, %58, %c0_i32 : i32 loc(#loc51)
    %64 = tt.splat %arg5 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %65 = arith.cmpi slt, %41, %64 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %66 = tt.broadcast %65 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %67 = ttg.memdesc_subview %61[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %68 = tt.splat %63 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %69 = arith.andi %68, %66 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %70 = ttg.async_copy_global_to_local %46, %67 mask %69 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %71 = ttg.async_commit_group %70 loc(#loc49)
    %72 = tt.splat %arg5 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %73 = arith.cmpi slt, %48, %72 : tensor<16x1xi32, #blocked> loc(#loc53)
    %74 = tt.broadcast %73 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %75 = ttg.memdesc_subview %62[%c0_i32, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %76 = tt.splat %63 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %77 = arith.andi %76, %74 : tensor<16x32xi1, #blocked> loc(#loc51)
    %78 = ttg.async_copy_global_to_local %56, %75 mask %77 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %79 = ttg.async_commit_group %78 loc(#loc50)
    cf.br ^bb1(%c0_i32, %cst_2, %46, %56, %c0_i32, %c-1_i32, %79 : i32, tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token) loc(#loc51)
  ^bb1(%80: i32 loc("examples/kernels/binary_ops.py":168:22), %81: tensor<32x32xf32, #mma> loc(unknown), %82: tensor<32x16x!tt.ptr<f32>, #blocked1> loc("examples/kernels/binary_ops.py":159:22), %83: tensor<16x32x!tt.ptr<f32>, #blocked> loc("examples/kernels/binary_ops.py":160:22), %84: i32 loc(unknown), %85: i32 loc(unknown), %86: !ttg.async.token loc("examples/kernels/binary_ops.py":172:20)):  // 2 preds: ^bb0, ^bb2
    %87 = arith.cmpi slt, %80, %58 : i32 loc(#loc51)
    cf.cond_br %87, ^bb2, ^bb3 loc(#loc51)
  ^bb2:  // pred: ^bb1
    %88 = arith.subi %58, %c1_i32 : i32 loc(#loc51)
    %89 = arith.cmpi slt, %80, %88 : i32 loc(#loc51)
    %90 = arith.addi %85, %c1_i32 : i32 loc(#loc51)
    %91 = arith.cmpi slt, %90, %c1_i32 : i32 loc(#loc51)
    %92 = arith.select %91, %90, %c0_i32 : i32 loc(#loc51)
    %93 = ttg.async_wait %86 {num = 0 : i32} loc(#loc49)
    %94 = ttg.memdesc_subview %61[%92, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %95 = ttg.local_load %94 : !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> -> tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> loc(#loc49)
    %96 = ttg.memdesc_subview %62[%92, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %97 = ttg.local_load %96 : !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> -> tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> loc(#loc50)
    %98 = tt.dot %95, %97, %81, inputPrecision = tf32 : tensor<32x16xf32, #ttg.dot_op<{opIdx = 0, parent = #mma, kWidth = 1}>> * tensor<16x32xf32, #ttg.dot_op<{opIdx = 1, parent = #mma, kWidth = 1}>> -> tensor<32x32xf32, #mma> loc(#loc54)
    %99 = tt.addptr %82, %cst_1 : tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<32x16xi32, #blocked1> loc(#loc55)
    %100 = tt.addptr %83, %60 : tensor<16x32x!tt.ptr<f32>, #blocked>, tensor<16x32xi32, #blocked> loc(#loc48)
    %101 = arith.addi %84, %c1_i32 : i32 loc(#loc51)
    %102 = arith.cmpi slt, %101, %c1_i32 : i32 loc(#loc51)
    %103 = arith.select %102, %101, %c0_i32 : i32 loc(#loc51)
    %104 = arith.addi %80, %c1_i32 : i32 loc(#loc51)
    %105 = arith.muli %104, %c16_i32 : i32 loc(#loc56)
    %106 = arith.subi %arg5, %105 : i32 loc(#loc57)
    %107 = tt.splat %106 : i32 -> tensor<1x16xi32, #blocked1> loc(#loc52)
    %108 = arith.cmpi slt, %41, %107 : tensor<1x16xi32, #blocked1> loc(#loc52)
    %109 = tt.broadcast %108 : tensor<1x16xi1, #blocked1> -> tensor<32x16xi1, #blocked1> loc(#loc49)
    %110 = ttg.memdesc_subview %61[%103, %c0_i32, %c0_i32] : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> -> !ttg.memdesc<32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %111 = tt.splat %89 : i1 -> tensor<32x16xi1, #blocked1> loc(#loc51)
    %112 = arith.andi %111, %109 : tensor<32x16xi1, #blocked1> loc(#loc51)
    %113 = ttg.async_copy_global_to_local %99, %110 mask %112 other %cst_0 : tensor<32x16x!tt.ptr<f32>, #blocked1> -> <32x16xf32, #shared, #smem, mutable, 1x32x16> loc(#loc49)
    %114 = ttg.async_commit_group %113 loc(#loc49)
    %115 = tt.splat %106 : i32 -> tensor<16x1xi32, #blocked> loc(#loc53)
    %116 = arith.cmpi slt, %48, %115 : tensor<16x1xi32, #blocked> loc(#loc53)
    %117 = tt.broadcast %116 : tensor<16x1xi1, #blocked> -> tensor<16x32xi1, #blocked> loc(#loc50)
    %118 = ttg.memdesc_subview %62[%103, %c0_i32, %c0_i32] : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> -> !ttg.memdesc<16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %119 = tt.splat %89 : i1 -> tensor<16x32xi1, #blocked> loc(#loc51)
    %120 = arith.andi %119, %117 : tensor<16x32xi1, #blocked> loc(#loc51)
    %121 = ttg.async_copy_global_to_local %100, %118 mask %120 other %cst : tensor<16x32x!tt.ptr<f32>, #blocked> -> <16x32xf32, #shared1, #smem, mutable, 1x16x32> loc(#loc50)
    %122 = ttg.async_commit_group %121 loc(#loc50)
    %123 = arith.addi %80, %c1_i32 : i32 loc(#loc51)
    cf.br ^bb1(%123, %98, %99, %100, %103, %92, %122 : i32, tensor<32x32xf32, #mma>, tensor<32x16x!tt.ptr<f32>, #blocked1>, tensor<16x32x!tt.ptr<f32>, #blocked>, i32, i32, !ttg.async.token) loc(#loc51)
  ^bb3:  // pred: ^bb1
    %124 = ttg.async_wait  {num = 0 : i32} loc(#loc51)
    ttg.local_dealloc %62 : !ttg.memdesc<1x16x32xf32, #shared1, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %61 : !ttg.memdesc<1x32x16xf32, #shared, #smem, mutable> loc(#loc51)
    %125 = arith.truncf %81 : tensor<32x32xf32, #mma> to tensor<32x32xf16, #mma> loc(#loc58)
    %126 = tt.expand_dims %27 {axis = 1 : i32} : tensor<32xi32, #ttg.slice<{dim = 1, parent = #blocked2}>> -> tensor<32x1xi32, #blocked2> loc(#loc59)
    %127 = tt.splat %arg8 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc60)
    %128 = arith.muli %127, %126 : tensor<32x1xi32, #blocked2> loc(#loc60)
    %129 = tt.splat %arg2 : !tt.ptr<f16> -> tensor<32x1x!tt.ptr<f16>, #blocked2> loc(#loc61)
    %130 = tt.addptr %129, %128 : tensor<32x1x!tt.ptr<f16>, #blocked2>, tensor<32x1xi32, #blocked2> loc(#loc61)
    %131 = tt.expand_dims %34 {axis = 0 : i32} : tensor<32xi32, #ttg.slice<{dim = 0, parent = #blocked2}>> -> tensor<1x32xi32, #blocked2> loc(#loc62)
    %132 = tt.broadcast %130 : tensor<32x1x!tt.ptr<f16>, #blocked2> -> tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc63)
    %133 = tt.broadcast %131 : tensor<1x32xi32, #blocked2> -> tensor<32x32xi32, #blocked2> loc(#loc63)
    %134 = tt.addptr %132, %133 : tensor<32x32x!tt.ptr<f16>, #blocked2>, tensor<32x32xi32, #blocked2> loc(#loc63)
    %135 = tt.splat %arg3 : i32 -> tensor<32x1xi32, #blocked2> loc(#loc64)
    %136 = arith.cmpi slt, %126, %135 : tensor<32x1xi32, #blocked2> loc(#loc64)
    %137 = tt.splat %arg4 : i32 -> tensor<1x32xi32, #blocked2> loc(#loc65)
    %138 = arith.cmpi slt, %131, %137 : tensor<1x32xi32, #blocked2> loc(#loc65)
    %139 = tt.broadcast %136 : tensor<32x1xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %140 = tt.broadcast %138 : tensor<1x32xi1, #blocked2> -> tensor<32x32xi1, #blocked2> loc(#loc66)
    %141 = arith.andi %139, %140 : tensor<32x32xi1, #blocked2> loc(#loc66)
    %142 = ttg.convert_layout %125 {allocation.offset = 0 : i32} : tensor<32x32xf16, #mma> -> tensor<32x32xf16, #blocked2> loc(#loc67)
    tt.store %134, %142, %141 : tensor<32x32x!tt.ptr<f16>, #blocked2> loc(#loc67)
    tt.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:30)
#loc37 = loc("examples/kernels/binary_ops.py":159:41)
#loc38 = loc("examples/kernels/binary_ops.py":159:60)
#loc39 = loc("examples/kernels/binary_ops.py":159:53)
#loc41 = loc("examples/kernels/binary_ops.py":160:29)
#loc42 = loc("examples/kernels/binary_ops.py":160:40)
#loc43 = loc("examples/kernels/binary_ops.py":160:60)
#loc44 = loc("examples/kernels/binary_ops.py":160:52)
#loc46 = loc("examples/kernels/binary_ops.py":168:33)
#loc47 = loc("examples/kernels/binary_ops.py":177:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:18)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc3 at #loc4))
#loc70 = loc(callsite(#loc5 at #loc4))
#loc71 = loc(callsite(#loc3 at #loc6))
#loc72 = loc(callsite(#loc5 at #loc6))
#loc73 = loc(callsite(#loc3 at #loc46))
#loc74 = loc(callsite(#loc5 at #loc46))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#blocked = #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [2, 16], warpsPerCTA = [4, 1], order = [1, 0]}>
#blocked1 = #ttg.blocked<{sizePerThread = [1, 4], threadsPerWarp = [4, 8], warpsPerCTA = [4, 1], order = [1, 0]}>
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc2 = loc("examples/kernels/binary_ops.py":168:22)
#loc41 = loc("examples/kernels/binary_ops.py":159:22)
#loc46 = loc("examples/kernels/binary_ops.py":160:22)
#loc51 = loc("examples/kernels/binary_ops.py":172:20)
#mma = #ttg.nvidia_mma<{versionMajor = 2, versionMinor = 0, warpsPerCTA = [2, 2], instrShape = [16, 8]}>
module attributes {ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @matmul_kernel(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg9: !llvm.ptr<1> loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.constant(-1 : i32) : i32 loc(#loc1)
    %1 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %2 = llvm.bitcast %1 : f32 to f32 loc(#loc1)
    %3 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32)> loc(#loc1)
    %4 = llvm.insertvalue %2, %3[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %5 = llvm.insertvalue %2, %4[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %6 = llvm.insertvalue %2, %5[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %7 = llvm.insertvalue %2, %6[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %8 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %10 = llvm.mlir.constant(true) : i1 loc(#loc1)
    %11 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %13 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %14 = llvm.bitcast %13 : f32 to f32 loc(#loc1)
    %15 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32)> loc(#loc1)
    %16 = llvm.insertvalue %14, %15[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %17 = llvm.insertvalue %14, %16[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %18 = llvm.insertvalue %14, %17[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %19 = llvm.insertvalue %14, %18[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc1)
    %20 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %21 = llvm.bitcast %20 : i32 to i32 loc(#loc1)
    %22 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc1)
    %23 = llvm.insertvalue %21, %22[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc1)
    %24 = llvm.insertvalue %21, %23[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc1)
    %25 = llvm.insertvalue %21, %24[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc1)
    %26 = llvm.insertvalue %21, %25[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc1)
    %27 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %28 = llvm.mlir.constant(31 : i32) : i32 loc(#loc1)
    %29 = llvm.mlir.constant(15 : i32) : i32 loc(#loc1)
    %30 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %31 = llvm.bitcast %30 : f32 to f32 loc(#loc1)
    %32 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc1)
    %33 = llvm.insertvalue %31, %32[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %34 = llvm.insertvalue %31, %33[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %35 = llvm.insertvalue %31, %34[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %36 = llvm.insertvalue %31, %35[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %37 = llvm.insertvalue %31, %36[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %38 = llvm.insertvalue %31, %37[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %39 = llvm.insertvalue %31, %38[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %40 = llvm.insertvalue %31, %39[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %41 = builtin.unrealized_conversion_cast %40 : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> to tensor<32x32xf32, #mma> loc(#loc1)
    %42 = builtin.unrealized_conversion_cast %41 : tensor<32x32xf32, #mma> to !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc2)
    %43 = llvm.call_intrinsic "llvm.nvvm.read.ptx.sreg.ctaid.x"() : () -> i32 loc(#loc3)
    %44 = llvm.add %arg3, %28 : i32 loc(#loc69)
    %45 = llvm.sdiv %44, %11 : i32 loc(#loc70)
    %46 = llvm.add %arg4, %28 : i32 loc(#loc71)
    %47 = llvm.sdiv %46, %11 : i32 loc(#loc72)
    %48 = llvm.mul %47, %8 : i32 loc(#loc8)
    %49 = llvm.sdiv %43, %48 : i32 loc(#loc9)
    %50 = llvm.mul %49, %8 : i32 loc(#loc10)
    %51 = llvm.sub %45, %50 : i32 loc(#loc11)
    %52 = llvm.intr.smin(%51, %8) : (i32, i32) -> i32 loc(#loc12)
    %53 = llvm.srem %43, %48 : i32 loc(#loc13)
    %54 = llvm.srem %53, %52 : i32 loc(#loc14)
    %55 = llvm.add %50, %54 : i32 loc(#loc15)
    %56 = llvm.sdiv %53, %52 : i32 loc(#loc16)
    %57 = llvm.icmp "sge" %55, %9 : i32 loc(#loc17)
    llvm.intr.assume %57 : i1 loc(#loc18)
    %58 = llvm.icmp "sge" %56, %9 : i32 loc(#loc19)
    llvm.intr.assume %58 : i1 loc(#loc20)
    %59 = llvm.icmp "sgt" %arg6, %9 : i32 loc(#loc21)
    llvm.intr.assume %59 : i1 loc(#loc22)
    llvm.intr.assume %10 : i1 loc(#loc23)
    llvm.intr.assume %10 : i1 loc(#loc24)
    %60 = llvm.icmp "sgt" %arg7, %9 : i32 loc(#loc25)
    llvm.intr.assume %60 : i1 loc(#loc26)
    %61 = llvm.icmp "sgt" %arg8, %9 : i32 loc(#loc27)
    llvm.intr.assume %61 : i1 loc(#loc28)
    llvm.intr.assume %10 : i1 loc(#loc29)
    %62 = llvm.mul %55, %11 : i32 loc(#loc30)
    %63 = llvm.mlir.constant(0 : index) : i32 loc(#loc31)
    %64 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc31)
    %65 = llvm.mlir.constant(32 : i32) : i32 loc(#loc31)
    %66 = llvm.urem %64, %65 : i32 loc(#loc31)
    %67 = llvm.udiv %64, %65 : i32 loc(#loc31)
    %68 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %69 = nvgpu.cluster_id loc(#loc31)
    %70 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %71 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %72 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %73 = llvm.and %66, %72 : i32 loc(#loc31)
    %74 = llvm.icmp "eq" %73, %71 : i32 loc(#loc31)
    %75 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %76 = llvm.and %66, %75 : i32 loc(#loc31)
    %77 = llvm.icmp "eq" %76, %71 : i32 loc(#loc31)
    %78 = llvm.mlir.constant(4 : i32) : i32 loc(#loc31)
    %79 = llvm.and %66, %78 : i32 loc(#loc31)
    %80 = llvm.icmp "eq" %79, %71 : i32 loc(#loc31)
    %81 = llvm.mlir.constant(8 : i32) : i32 loc(#loc31)
    %82 = llvm.and %66, %81 : i32 loc(#loc31)
    %83 = llvm.icmp "eq" %82, %71 : i32 loc(#loc31)
    %84 = llvm.mlir.constant(16 : i32) : i32 loc(#loc31)
    %85 = llvm.and %66, %84 : i32 loc(#loc31)
    %86 = llvm.icmp "eq" %85, %71 : i32 loc(#loc31)
    %87 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %88 = llvm.select %86, %71, %87 : i1, i32 loc(#loc31)
    %89 = llvm.xor %71, %88 : i32 loc(#loc31)
    %90 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %91 = llvm.and %67, %90 : i32 loc(#loc31)
    %92 = llvm.icmp "eq" %91, %71 : i32 loc(#loc31)
    %93 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %94 = llvm.select %92, %71, %93 : i1, i32 loc(#loc31)
    %95 = llvm.xor %89, %94 : i32 loc(#loc31)
    %96 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %97 = llvm.and %67, %96 : i32 loc(#loc31)
    %98 = llvm.icmp "eq" %97, %71 : i32 loc(#loc31)
    %99 = llvm.mlir.constant(4 : i32) : i32 loc(#loc31)
    %100 = llvm.select %98, %71, %99 : i1, i32 loc(#loc31)
    %101 = llvm.xor %95, %100 : i32 loc(#loc31)
    %102 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %103 = llvm.xor %101, %102 : i32 loc(#loc31)
    %104 = llvm.mlir.constant(8 : i32) : i32 loc(#loc31)
    %105 = llvm.xor %101, %104 : i32 loc(#loc31)
    %106 = llvm.mlir.constant(16 : i32) : i32 loc(#loc31)
    %107 = llvm.xor %101, %106 : i32 loc(#loc31)
    %108 = llvm.mlir.constant(24 : i32) : i32 loc(#loc31)
    %109 = llvm.xor %101, %108 : i32 loc(#loc31)
    %110 = llvm.add %103, %63 : i32 loc(#loc31)
    %111 = llvm.add %105, %63 : i32 loc(#loc31)
    %112 = llvm.add %107, %63 : i32 loc(#loc31)
    %113 = llvm.add %109, %63 : i32 loc(#loc31)
    %114 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc31)
    %115 = llvm.insertvalue %110, %114[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc31)
    %116 = llvm.insertvalue %111, %115[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc31)
    %117 = llvm.insertvalue %112, %116[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc31)
    %118 = llvm.insertvalue %113, %117[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc31)
    %119 = llvm.mlir.constant(0 : index) : i32 loc(#loc31)
    %120 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc31)
    %121 = llvm.mlir.constant(32 : i32) : i32 loc(#loc31)
    %122 = llvm.urem %120, %121 : i32 loc(#loc31)
    %123 = llvm.udiv %120, %121 : i32 loc(#loc31)
    %124 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %125 = nvgpu.cluster_id loc(#loc31)
    %126 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %127 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %128 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %129 = llvm.and %122, %128 : i32 loc(#loc31)
    %130 = llvm.icmp "eq" %129, %127 : i32 loc(#loc31)
    %131 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %132 = llvm.and %122, %131 : i32 loc(#loc31)
    %133 = llvm.icmp "eq" %132, %127 : i32 loc(#loc31)
    %134 = llvm.mlir.constant(4 : i32) : i32 loc(#loc31)
    %135 = llvm.and %122, %134 : i32 loc(#loc31)
    %136 = llvm.icmp "eq" %135, %127 : i32 loc(#loc31)
    %137 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %138 = llvm.select %136, %127, %137 : i1, i32 loc(#loc31)
    %139 = llvm.xor %127, %138 : i32 loc(#loc31)
    %140 = llvm.mlir.constant(8 : i32) : i32 loc(#loc31)
    %141 = llvm.and %122, %140 : i32 loc(#loc31)
    %142 = llvm.icmp "eq" %141, %127 : i32 loc(#loc31)
    %143 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %144 = llvm.select %142, %127, %143 : i1, i32 loc(#loc31)
    %145 = llvm.xor %139, %144 : i32 loc(#loc31)
    %146 = llvm.mlir.constant(16 : i32) : i32 loc(#loc31)
    %147 = llvm.and %122, %146 : i32 loc(#loc31)
    %148 = llvm.icmp "eq" %147, %127 : i32 loc(#loc31)
    %149 = llvm.mlir.constant(4 : i32) : i32 loc(#loc31)
    %150 = llvm.select %148, %127, %149 : i1, i32 loc(#loc31)
    %151 = llvm.xor %145, %150 : i32 loc(#loc31)
    %152 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %153 = llvm.and %123, %152 : i32 loc(#loc31)
    %154 = llvm.icmp "eq" %153, %127 : i32 loc(#loc31)
    %155 = llvm.mlir.constant(8 : i32) : i32 loc(#loc31)
    %156 = llvm.select %154, %127, %155 : i1, i32 loc(#loc31)
    %157 = llvm.xor %151, %156 : i32 loc(#loc31)
    %158 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %159 = llvm.and %123, %158 : i32 loc(#loc31)
    %160 = llvm.icmp "eq" %159, %127 : i32 loc(#loc31)
    %161 = llvm.mlir.constant(16 : i32) : i32 loc(#loc31)
    %162 = llvm.select %160, %127, %161 : i1, i32 loc(#loc31)
    %163 = llvm.xor %157, %162 : i32 loc(#loc31)
    %164 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %165 = llvm.xor %163, %164 : i32 loc(#loc31)
    %166 = llvm.add %165, %119 : i32 loc(#loc31)
    %167 = llvm.mlir.undef : !llvm.struct<(i32)> loc(#loc31)
    %168 = llvm.insertvalue %166, %167[0] : !llvm.struct<(i32)>  loc(#loc31)
    %169 = llvm.mlir.constant(0 : index) : i32 loc(#loc31)
    %170 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc31)
    %171 = llvm.mlir.constant(32 : i32) : i32 loc(#loc31)
    %172 = llvm.urem %170, %171 : i32 loc(#loc31)
    %173 = llvm.udiv %170, %171 : i32 loc(#loc31)
    %174 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %175 = nvgpu.cluster_id loc(#loc31)
    %176 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %177 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %178 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %179 = llvm.and %172, %178 : i32 loc(#loc31)
    %180 = llvm.icmp "eq" %179, %177 : i32 loc(#loc31)
    %181 = llvm.mlir.constant(4 : i32) : i32 loc(#loc31)
    %182 = llvm.select %180, %177, %181 : i1, i32 loc(#loc31)
    %183 = llvm.xor %177, %182 : i32 loc(#loc31)
    %184 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %185 = llvm.and %172, %184 : i32 loc(#loc31)
    %186 = llvm.icmp "eq" %185, %177 : i32 loc(#loc31)
    %187 = llvm.mlir.constant(8 : i32) : i32 loc(#loc31)
    %188 = llvm.select %186, %177, %187 : i1, i32 loc(#loc31)
    %189 = llvm.xor %183, %188 : i32 loc(#loc31)
    %190 = llvm.mlir.constant(4 : i32) : i32 loc(#loc31)
    %191 = llvm.and %172, %190 : i32 loc(#loc31)
    %192 = llvm.icmp "eq" %191, %177 : i32 loc(#loc31)
    %193 = llvm.mlir.constant(16 : i32) : i32 loc(#loc31)
    %194 = llvm.select %192, %177, %193 : i1, i32 loc(#loc31)
    %195 = llvm.xor %189, %194 : i32 loc(#loc31)
    %196 = llvm.mlir.constant(8 : i32) : i32 loc(#loc31)
    %197 = llvm.and %172, %196 : i32 loc(#loc31)
    %198 = llvm.icmp "eq" %197, %177 : i32 loc(#loc31)
    %199 = llvm.mlir.constant(16 : i32) : i32 loc(#loc31)
    %200 = llvm.and %172, %199 : i32 loc(#loc31)
    %201 = llvm.icmp "eq" %200, %177 : i32 loc(#loc31)
    %202 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %203 = llvm.and %173, %202 : i32 loc(#loc31)
    %204 = llvm.icmp "eq" %203, %177 : i32 loc(#loc31)
    %205 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %206 = llvm.and %173, %205 : i32 loc(#loc31)
    %207 = llvm.icmp "eq" %206, %177 : i32 loc(#loc31)
    %208 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %209 = llvm.xor %195, %208 : i32 loc(#loc31)
    %210 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %211 = llvm.xor %195, %210 : i32 loc(#loc31)
    %212 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %213 = llvm.xor %195, %212 : i32 loc(#loc31)
    %214 = llvm.mlir.constant(3 : i32) : i32 loc(#loc31)
    %215 = llvm.xor %195, %214 : i32 loc(#loc31)
    %216 = llvm.add %209, %169 : i32 loc(#loc31)
    %217 = llvm.add %211, %169 : i32 loc(#loc31)
    %218 = llvm.add %213, %169 : i32 loc(#loc31)
    %219 = llvm.add %215, %169 : i32 loc(#loc31)
    %220 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc31)
    %221 = llvm.insertvalue %216, %220[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc31)
    %222 = llvm.insertvalue %217, %221[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc31)
    %223 = llvm.insertvalue %218, %222[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc31)
    %224 = llvm.insertvalue %219, %223[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc31)
    %225 = llvm.mlir.constant(0 : index) : i32 loc(#loc31)
    %226 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc31)
    %227 = llvm.mlir.constant(32 : i32) : i32 loc(#loc31)
    %228 = llvm.urem %226, %227 : i32 loc(#loc31)
    %229 = llvm.udiv %226, %227 : i32 loc(#loc31)
    %230 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %231 = nvgpu.cluster_id loc(#loc31)
    %232 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %233 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %234 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %235 = llvm.and %228, %234 : i32 loc(#loc31)
    %236 = llvm.icmp "eq" %235, %233 : i32 loc(#loc31)
    %237 = llvm.mlir.constant(8 : i32) : i32 loc(#loc31)
    %238 = llvm.select %236, %233, %237 : i1, i32 loc(#loc31)
    %239 = llvm.xor %233, %238 : i32 loc(#loc31)
    %240 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %241 = llvm.and %228, %240 : i32 loc(#loc31)
    %242 = llvm.icmp "eq" %241, %233 : i32 loc(#loc31)
    %243 = llvm.mlir.constant(16 : i32) : i32 loc(#loc31)
    %244 = llvm.select %242, %233, %243 : i1, i32 loc(#loc31)
    %245 = llvm.xor %239, %244 : i32 loc(#loc31)
    %246 = llvm.mlir.constant(4 : i32) : i32 loc(#loc31)
    %247 = llvm.and %228, %246 : i32 loc(#loc31)
    %248 = llvm.icmp "eq" %247, %233 : i32 loc(#loc31)
    %249 = llvm.mlir.constant(8 : i32) : i32 loc(#loc31)
    %250 = llvm.and %228, %249 : i32 loc(#loc31)
    %251 = llvm.icmp "eq" %250, %233 : i32 loc(#loc31)
    %252 = llvm.mlir.constant(16 : i32) : i32 loc(#loc31)
    %253 = llvm.and %228, %252 : i32 loc(#loc31)
    %254 = llvm.icmp "eq" %253, %233 : i32 loc(#loc31)
    %255 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %256 = llvm.and %229, %255 : i32 loc(#loc31)
    %257 = llvm.icmp "eq" %256, %233 : i32 loc(#loc31)
    %258 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %259 = llvm.and %229, %258 : i32 loc(#loc31)
    %260 = llvm.icmp "eq" %259, %233 : i32 loc(#loc31)
    %261 = llvm.mlir.constant(0 : i32) : i32 loc(#loc31)
    %262 = llvm.xor %245, %261 : i32 loc(#loc31)
    %263 = llvm.mlir.constant(1 : i32) : i32 loc(#loc31)
    %264 = llvm.xor %245, %263 : i32 loc(#loc31)
    %265 = llvm.mlir.constant(2 : i32) : i32 loc(#loc31)
    %266 = llvm.xor %245, %265 : i32 loc(#loc31)
    %267 = llvm.mlir.constant(3 : i32) : i32 loc(#loc31)
    %268 = llvm.xor %245, %267 : i32 loc(#loc31)
    %269 = llvm.mlir.constant(4 : i32) : i32 loc(#loc31)
    %270 = llvm.xor %245, %269 : i32 loc(#loc31)
    %271 = llvm.mlir.constant(5 : i32) : i32 loc(#loc31)
    %272 = llvm.xor %245, %271 : i32 loc(#loc31)
    %273 = llvm.mlir.constant(6 : i32) : i32 loc(#loc31)
    %274 = llvm.xor %245, %273 : i32 loc(#loc31)
    %275 = llvm.mlir.constant(7 : i32) : i32 loc(#loc31)
    %276 = llvm.xor %245, %275 : i32 loc(#loc31)
    %277 = llvm.add %262, %225 : i32 loc(#loc31)
    %278 = llvm.add %264, %225 : i32 loc(#loc31)
    %279 = llvm.add %266, %225 : i32 loc(#loc31)
    %280 = llvm.add %268, %225 : i32 loc(#loc31)
    %281 = llvm.add %270, %225 : i32 loc(#loc31)
    %282 = llvm.add %272, %225 : i32 loc(#loc31)
    %283 = llvm.add %274, %225 : i32 loc(#loc31)
    %284 = llvm.add %276, %225 : i32 loc(#loc31)
    %285 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)> loc(#loc31)
    %286 = llvm.insertvalue %277, %285[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc31)
    %287 = llvm.insertvalue %278, %286[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc31)
    %288 = llvm.insertvalue %279, %287[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc31)
    %289 = llvm.insertvalue %280, %288[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc31)
    %290 = llvm.insertvalue %281, %289[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc31)
    %291 = llvm.insertvalue %282, %290[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc31)
    %292 = llvm.insertvalue %283, %291[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc31)
    %293 = llvm.insertvalue %284, %292[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc31)
    %294 = llvm.bitcast %62 : i32 to i32 loc(#loc32)
    %295 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc32)
    %296 = llvm.insertvalue %294, %295[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %297 = llvm.insertvalue %294, %296[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %298 = llvm.insertvalue %294, %297[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %299 = llvm.insertvalue %294, %298[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %300 = llvm.bitcast %62 : i32 to i32 loc(#loc32)
    %301 = llvm.mlir.undef : !llvm.struct<(i32)> loc(#loc32)
    %302 = llvm.insertvalue %300, %301[0] : !llvm.struct<(i32)>  loc(#loc32)
    %303 = llvm.extractvalue %299[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %304 = llvm.extractvalue %299[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %305 = llvm.extractvalue %299[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %306 = llvm.extractvalue %299[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %307 = llvm.extractvalue %118[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %308 = llvm.extractvalue %118[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %309 = llvm.extractvalue %118[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %310 = llvm.extractvalue %118[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %311 = llvm.add %303, %307 : i32 loc(#loc32)
    %312 = llvm.add %304, %308 : i32 loc(#loc32)
    %313 = llvm.add %305, %309 : i32 loc(#loc32)
    %314 = llvm.add %306, %310 : i32 loc(#loc32)
    %315 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc32)
    %316 = llvm.insertvalue %311, %315[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %317 = llvm.insertvalue %312, %316[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %318 = llvm.insertvalue %313, %317[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %319 = llvm.insertvalue %314, %318[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc32)
    %320 = llvm.extractvalue %302[0] : !llvm.struct<(i32)>  loc(#loc32)
    %321 = llvm.extractvalue %168[0] : !llvm.struct<(i32)>  loc(#loc32)
    %322 = llvm.add %320, %321 : i32 loc(#loc32)
    %323 = llvm.mlir.undef : !llvm.struct<(i32)> loc(#loc32)
    %324 = llvm.insertvalue %322, %323[0] : !llvm.struct<(i32)>  loc(#loc32)
    %325 = llvm.bitcast %arg3 : i32 to i32 loc(#loc33)
    %326 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc33)
    %327 = llvm.insertvalue %325, %326[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %328 = llvm.insertvalue %325, %327[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %329 = llvm.insertvalue %325, %328[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %330 = llvm.insertvalue %325, %329[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %331 = llvm.extractvalue %319[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %332 = llvm.extractvalue %319[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %333 = llvm.extractvalue %319[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %334 = llvm.extractvalue %319[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %335 = llvm.extractvalue %330[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %336 = llvm.extractvalue %330[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %337 = llvm.extractvalue %330[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %338 = llvm.extractvalue %330[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %339 = llvm.srem %331, %335 : i32 loc(#loc33)
    %340 = llvm.srem %332, %336 : i32 loc(#loc33)
    %341 = llvm.srem %333, %337 : i32 loc(#loc33)
    %342 = llvm.srem %334, %338 : i32 loc(#loc33)
    %343 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc33)
    %344 = llvm.insertvalue %339, %343[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %345 = llvm.insertvalue %340, %344[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %346 = llvm.insertvalue %341, %345[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %347 = llvm.insertvalue %342, %346[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc33)
    %348 = llvm.mul %56, %11 : i32 loc(#loc34)
    %349 = llvm.bitcast %348 : i32 to i32 loc(#loc35)
    %350 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc35)
    %351 = llvm.insertvalue %349, %350[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %352 = llvm.insertvalue %349, %351[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %353 = llvm.insertvalue %349, %352[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %354 = llvm.insertvalue %349, %353[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %355 = llvm.bitcast %348 : i32 to i32 loc(#loc35)
    %356 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)> loc(#loc35)
    %357 = llvm.insertvalue %355, %356[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %358 = llvm.insertvalue %355, %357[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %359 = llvm.insertvalue %355, %358[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %360 = llvm.insertvalue %355, %359[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %361 = llvm.insertvalue %355, %360[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %362 = llvm.insertvalue %355, %361[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %363 = llvm.insertvalue %355, %362[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %364 = llvm.insertvalue %355, %363[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %365 = llvm.extractvalue %354[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %366 = llvm.extractvalue %354[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %367 = llvm.extractvalue %354[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %368 = llvm.extractvalue %354[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %369 = llvm.extractvalue %224[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %370 = llvm.extractvalue %224[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %371 = llvm.extractvalue %224[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %372 = llvm.extractvalue %224[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %373 = llvm.add %365, %369 : i32 loc(#loc35)
    %374 = llvm.add %366, %370 : i32 loc(#loc35)
    %375 = llvm.add %367, %371 : i32 loc(#loc35)
    %376 = llvm.add %368, %372 : i32 loc(#loc35)
    %377 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc35)
    %378 = llvm.insertvalue %373, %377[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %379 = llvm.insertvalue %374, %378[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %380 = llvm.insertvalue %375, %379[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %381 = llvm.insertvalue %376, %380[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc35)
    %382 = llvm.extractvalue %364[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %383 = llvm.extractvalue %364[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %384 = llvm.extractvalue %364[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %385 = llvm.extractvalue %364[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %386 = llvm.extractvalue %364[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %387 = llvm.extractvalue %364[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %388 = llvm.extractvalue %364[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %389 = llvm.extractvalue %364[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %390 = llvm.extractvalue %293[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %391 = llvm.extractvalue %293[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %392 = llvm.extractvalue %293[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %393 = llvm.extractvalue %293[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %394 = llvm.extractvalue %293[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %395 = llvm.extractvalue %293[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %396 = llvm.extractvalue %293[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %397 = llvm.extractvalue %293[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %398 = llvm.add %382, %390 : i32 loc(#loc35)
    %399 = llvm.add %383, %391 : i32 loc(#loc35)
    %400 = llvm.add %384, %392 : i32 loc(#loc35)
    %401 = llvm.add %385, %393 : i32 loc(#loc35)
    %402 = llvm.add %386, %394 : i32 loc(#loc35)
    %403 = llvm.add %387, %395 : i32 loc(#loc35)
    %404 = llvm.add %388, %396 : i32 loc(#loc35)
    %405 = llvm.add %389, %397 : i32 loc(#loc35)
    %406 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)> loc(#loc35)
    %407 = llvm.insertvalue %398, %406[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %408 = llvm.insertvalue %399, %407[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %409 = llvm.insertvalue %400, %408[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %410 = llvm.insertvalue %401, %409[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %411 = llvm.insertvalue %402, %410[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %412 = llvm.insertvalue %403, %411[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %413 = llvm.insertvalue %404, %412[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %414 = llvm.insertvalue %405, %413[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc35)
    %415 = llvm.bitcast %arg4 : i32 to i32 loc(#loc36)
    %416 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc36)
    %417 = llvm.insertvalue %415, %416[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %418 = llvm.insertvalue %415, %417[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %419 = llvm.insertvalue %415, %418[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %420 = llvm.insertvalue %415, %419[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %421 = llvm.extractvalue %381[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %422 = llvm.extractvalue %381[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %423 = llvm.extractvalue %381[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %424 = llvm.extractvalue %381[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %425 = llvm.extractvalue %420[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %426 = llvm.extractvalue %420[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %427 = llvm.extractvalue %420[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %428 = llvm.extractvalue %420[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %429 = llvm.srem %421, %425 : i32 loc(#loc36)
    %430 = llvm.srem %422, %426 : i32 loc(#loc36)
    %431 = llvm.srem %423, %427 : i32 loc(#loc36)
    %432 = llvm.srem %424, %428 : i32 loc(#loc36)
    %433 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc36)
    %434 = llvm.insertvalue %429, %433[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %435 = llvm.insertvalue %430, %434[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %436 = llvm.insertvalue %431, %435[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %437 = llvm.insertvalue %432, %436[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc36)
    %438 = llvm.extractvalue %347[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc37)
    %439 = llvm.extractvalue %347[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc37)
    %440 = llvm.extractvalue %347[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc37)
    %441 = llvm.extractvalue %347[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc37)
    %442 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc37)
    %443 = llvm.insertvalue %438, %442[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc37)
    %444 = llvm.insertvalue %439, %443[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc37)
    %445 = llvm.insertvalue %440, %444[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc37)
    %446 = llvm.insertvalue %441, %445[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc37)
    %447 = llvm.bitcast %arg6 : i32 to i32 loc(#loc38)
    %448 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc38)
    %449 = llvm.insertvalue %447, %448[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %450 = llvm.insertvalue %447, %449[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %451 = llvm.insertvalue %447, %450[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %452 = llvm.insertvalue %447, %451[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %453 = llvm.extractvalue %446[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %454 = llvm.extractvalue %446[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %455 = llvm.extractvalue %446[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %456 = llvm.extractvalue %446[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %457 = llvm.extractvalue %452[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %458 = llvm.extractvalue %452[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %459 = llvm.extractvalue %452[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %460 = llvm.extractvalue %452[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %461 = llvm.mul %453, %457 : i32 loc(#loc38)
    %462 = llvm.mul %454, %458 : i32 loc(#loc38)
    %463 = llvm.mul %455, %459 : i32 loc(#loc38)
    %464 = llvm.mul %456, %460 : i32 loc(#loc38)
    %465 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc38)
    %466 = llvm.insertvalue %461, %465[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %467 = llvm.insertvalue %462, %466[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %468 = llvm.insertvalue %463, %467[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %469 = llvm.insertvalue %464, %468[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc38)
    %470 = llvm.mlir.constant(0 : index) : i32 loc(#loc39)
    %471 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc39)
    %472 = llvm.mlir.constant(32 : i32) : i32 loc(#loc39)
    %473 = llvm.urem %471, %472 : i32 loc(#loc39)
    %474 = llvm.udiv %471, %472 : i32 loc(#loc39)
    %475 = llvm.mlir.constant(0 : i32) : i32 loc(#loc39)
    %476 = nvgpu.cluster_id loc(#loc39)
    %477 = llvm.mlir.constant(0 : i32) : i32 loc(#loc39)
    %478 = llvm.mlir.constant(0 : i32) : i32 loc(#loc39)
    %479 = llvm.mlir.constant(1 : i32) : i32 loc(#loc39)
    %480 = llvm.and %473, %479 : i32 loc(#loc39)
    %481 = llvm.icmp "eq" %480, %478 : i32 loc(#loc39)
    %482 = llvm.mlir.constant(1 : i32) : i32 loc(#loc39)
    %483 = llvm.select %481, %478, %482 : i1, i32 loc(#loc39)
    %484 = llvm.xor %478, %483 : i32 loc(#loc39)
    %485 = llvm.mlir.constant(2 : i32) : i32 loc(#loc39)
    %486 = llvm.and %473, %485 : i32 loc(#loc39)
    %487 = llvm.icmp "eq" %486, %478 : i32 loc(#loc39)
    %488 = llvm.mlir.constant(2 : i32) : i32 loc(#loc39)
    %489 = llvm.select %487, %478, %488 : i1, i32 loc(#loc39)
    %490 = llvm.xor %484, %489 : i32 loc(#loc39)
    %491 = llvm.mlir.constant(4 : i32) : i32 loc(#loc39)
    %492 = llvm.and %473, %491 : i32 loc(#loc39)
    %493 = llvm.icmp "eq" %492, %478 : i32 loc(#loc39)
    %494 = llvm.mlir.constant(4 : i32) : i32 loc(#loc39)
    %495 = llvm.select %493, %478, %494 : i1, i32 loc(#loc39)
    %496 = llvm.xor %490, %495 : i32 loc(#loc39)
    %497 = llvm.mlir.constant(8 : i32) : i32 loc(#loc39)
    %498 = llvm.and %473, %497 : i32 loc(#loc39)
    %499 = llvm.icmp "eq" %498, %478 : i32 loc(#loc39)
    %500 = llvm.mlir.constant(8 : i32) : i32 loc(#loc39)
    %501 = llvm.select %499, %478, %500 : i1, i32 loc(#loc39)
    %502 = llvm.xor %496, %501 : i32 loc(#loc39)
    %503 = llvm.mlir.constant(16 : i32) : i32 loc(#loc39)
    %504 = llvm.and %473, %503 : i32 loc(#loc39)
    %505 = llvm.icmp "eq" %504, %478 : i32 loc(#loc39)
    %506 = llvm.mlir.constant(1 : i32) : i32 loc(#loc39)
    %507 = llvm.and %474, %506 : i32 loc(#loc39)
    %508 = llvm.icmp "eq" %507, %478 : i32 loc(#loc39)
    %509 = llvm.mlir.constant(2 : i32) : i32 loc(#loc39)
    %510 = llvm.and %474, %509 : i32 loc(#loc39)
    %511 = llvm.icmp "eq" %510, %478 : i32 loc(#loc39)
    %512 = llvm.mlir.constant(0 : i32) : i32 loc(#loc39)
    %513 = llvm.xor %502, %512 : i32 loc(#loc39)
    %514 = llvm.add %513, %470 : i32 loc(#loc39)
    %515 = llvm.mlir.undef : !llvm.struct<(i32)> loc(#loc39)
    %516 = llvm.insertvalue %514, %515[0] : !llvm.struct<(i32)>  loc(#loc39)
    %517 = llvm.extractvalue %516[0] : !llvm.struct<(i32)>  loc(#loc39)
    %518 = llvm.mlir.undef : !llvm.struct<(i32)> loc(#loc39)
    %519 = llvm.insertvalue %517, %518[0] : !llvm.struct<(i32)>  loc(#loc39)
    %520 = llvm.extractvalue %469[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %521 = llvm.extractvalue %469[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %522 = llvm.extractvalue %469[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %523 = llvm.extractvalue %469[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %524 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc40)
    %525 = llvm.insertvalue %520, %524[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %526 = llvm.insertvalue %521, %525[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %527 = llvm.insertvalue %522, %526[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %528 = llvm.insertvalue %523, %527[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %529 = llvm.extractvalue %519[0] : !llvm.struct<(i32)>  loc(#loc40)
    %530 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc40)
    %531 = llvm.insertvalue %529, %530[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %532 = llvm.insertvalue %529, %531[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %533 = llvm.insertvalue %529, %532[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %534 = llvm.insertvalue %529, %533[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %535 = llvm.extractvalue %528[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %536 = llvm.extractvalue %528[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %537 = llvm.extractvalue %528[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %538 = llvm.extractvalue %528[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %539 = llvm.extractvalue %534[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %540 = llvm.extractvalue %534[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %541 = llvm.extractvalue %534[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %542 = llvm.extractvalue %534[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %543 = llvm.add %535, %539 : i32 loc(#loc40)
    %544 = llvm.add %536, %540 : i32 loc(#loc40)
    %545 = llvm.add %537, %541 : i32 loc(#loc40)
    %546 = llvm.add %538, %542 : i32 loc(#loc40)
    %547 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc40)
    %548 = llvm.insertvalue %543, %547[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %549 = llvm.insertvalue %544, %548[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %550 = llvm.insertvalue %545, %549[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %551 = llvm.insertvalue %546, %550[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc40)
    %552 = llvm.bitcast %arg0 : !llvm.ptr<1> to !llvm.ptr<1> loc(#loc41)
    %553 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc41)
    %554 = llvm.insertvalue %552, %553[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %555 = llvm.insertvalue %552, %554[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %556 = llvm.insertvalue %552, %555[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %557 = llvm.insertvalue %552, %556[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %558 = llvm.extractvalue %557[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %559 = llvm.extractvalue %557[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %560 = llvm.extractvalue %557[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %561 = llvm.extractvalue %557[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %562 = llvm.extractvalue %551[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc41)
    %563 = llvm.extractvalue %551[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc41)
    %564 = llvm.extractvalue %551[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc41)
    %565 = llvm.extractvalue %551[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc41)
    %566 = llvm.getelementptr %558[%562] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc41)
    %567 = llvm.getelementptr %559[%563] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc41)
    %568 = llvm.getelementptr %560[%564] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc41)
    %569 = llvm.getelementptr %561[%565] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc41)
    %570 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc41)
    %571 = llvm.insertvalue %566, %570[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %572 = llvm.insertvalue %567, %571[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %573 = llvm.insertvalue %568, %572[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %574 = llvm.insertvalue %569, %573[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc41)
    %575 = builtin.unrealized_conversion_cast %574 : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> to tensor<32x16x!tt.ptr<f32>, #blocked> loc(#loc41)
    %576 = builtin.unrealized_conversion_cast %575 : tensor<32x16x!tt.ptr<f32>, #blocked> to !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc2)
    %577 = llvm.mlir.constant(0 : index) : i32 loc(#loc42)
    %578 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc42)
    %579 = llvm.mlir.constant(32 : i32) : i32 loc(#loc42)
    %580 = llvm.urem %578, %579 : i32 loc(#loc42)
    %581 = llvm.udiv %578, %579 : i32 loc(#loc42)
    %582 = llvm.mlir.constant(0 : i32) : i32 loc(#loc42)
    %583 = nvgpu.cluster_id loc(#loc42)
    %584 = llvm.mlir.constant(0 : i32) : i32 loc(#loc42)
    %585 = llvm.mlir.constant(0 : i32) : i32 loc(#loc42)
    %586 = llvm.mlir.constant(1 : i32) : i32 loc(#loc42)
    %587 = llvm.and %580, %586 : i32 loc(#loc42)
    %588 = llvm.icmp "eq" %587, %585 : i32 loc(#loc42)
    %589 = llvm.mlir.constant(2 : i32) : i32 loc(#loc42)
    %590 = llvm.and %580, %589 : i32 loc(#loc42)
    %591 = llvm.icmp "eq" %590, %585 : i32 loc(#loc42)
    %592 = llvm.mlir.constant(4 : i32) : i32 loc(#loc42)
    %593 = llvm.and %580, %592 : i32 loc(#loc42)
    %594 = llvm.icmp "eq" %593, %585 : i32 loc(#loc42)
    %595 = llvm.mlir.constant(8 : i32) : i32 loc(#loc42)
    %596 = llvm.and %580, %595 : i32 loc(#loc42)
    %597 = llvm.icmp "eq" %596, %585 : i32 loc(#loc42)
    %598 = llvm.mlir.constant(1 : i32) : i32 loc(#loc42)
    %599 = llvm.select %597, %585, %598 : i1, i32 loc(#loc42)
    %600 = llvm.xor %585, %599 : i32 loc(#loc42)
    %601 = llvm.mlir.constant(16 : i32) : i32 loc(#loc42)
    %602 = llvm.and %580, %601 : i32 loc(#loc42)
    %603 = llvm.icmp "eq" %602, %585 : i32 loc(#loc42)
    %604 = llvm.mlir.constant(2 : i32) : i32 loc(#loc42)
    %605 = llvm.select %603, %585, %604 : i1, i32 loc(#loc42)
    %606 = llvm.xor %600, %605 : i32 loc(#loc42)
    %607 = llvm.mlir.constant(1 : i32) : i32 loc(#loc42)
    %608 = llvm.and %581, %607 : i32 loc(#loc42)
    %609 = llvm.icmp "eq" %608, %585 : i32 loc(#loc42)
    %610 = llvm.mlir.constant(4 : i32) : i32 loc(#loc42)
    %611 = llvm.select %609, %585, %610 : i1, i32 loc(#loc42)
    %612 = llvm.xor %606, %611 : i32 loc(#loc42)
    %613 = llvm.mlir.constant(2 : i32) : i32 loc(#loc42)
    %614 = llvm.and %581, %613 : i32 loc(#loc42)
    %615 = llvm.icmp "eq" %614, %585 : i32 loc(#loc42)
    %616 = llvm.mlir.constant(8 : i32) : i32 loc(#loc42)
    %617 = llvm.select %615, %585, %616 : i1, i32 loc(#loc42)
    %618 = llvm.xor %612, %617 : i32 loc(#loc42)
    %619 = llvm.mlir.constant(0 : i32) : i32 loc(#loc42)
    %620 = llvm.xor %618, %619 : i32 loc(#loc42)
    %621 = llvm.add %620, %577 : i32 loc(#loc42)
    %622 = llvm.mlir.undef : !llvm.struct<(i32)> loc(#loc42)
    %623 = llvm.insertvalue %621, %622[0] : !llvm.struct<(i32)>  loc(#loc42)
    %624 = llvm.extractvalue %623[0] : !llvm.struct<(i32)>  loc(#loc42)
    %625 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc42)
    %626 = llvm.insertvalue %624, %625[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc42)
    %627 = llvm.insertvalue %624, %626[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc42)
    %628 = llvm.insertvalue %624, %627[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc42)
    %629 = llvm.insertvalue %624, %628[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc42)
    %630 = llvm.bitcast %arg7 : i32 to i32 loc(#loc43)
    %631 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc43)
    %632 = llvm.insertvalue %630, %631[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %633 = llvm.insertvalue %630, %632[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %634 = llvm.insertvalue %630, %633[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %635 = llvm.insertvalue %630, %634[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %636 = llvm.extractvalue %629[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %637 = llvm.extractvalue %629[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %638 = llvm.extractvalue %629[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %639 = llvm.extractvalue %629[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %640 = llvm.extractvalue %635[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %641 = llvm.extractvalue %635[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %642 = llvm.extractvalue %635[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %643 = llvm.extractvalue %635[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %644 = llvm.mul %636, %640 : i32 loc(#loc43)
    %645 = llvm.mul %637, %641 : i32 loc(#loc43)
    %646 = llvm.mul %638, %642 : i32 loc(#loc43)
    %647 = llvm.mul %639, %643 : i32 loc(#loc43)
    %648 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc43)
    %649 = llvm.insertvalue %644, %648[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %650 = llvm.insertvalue %645, %649[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %651 = llvm.insertvalue %646, %650[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %652 = llvm.insertvalue %647, %651[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc43)
    %653 = llvm.extractvalue %437[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc44)
    %654 = llvm.extractvalue %437[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc44)
    %655 = llvm.extractvalue %437[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc44)
    %656 = llvm.extractvalue %437[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc44)
    %657 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc44)
    %658 = llvm.insertvalue %653, %657[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc44)
    %659 = llvm.insertvalue %654, %658[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc44)
    %660 = llvm.insertvalue %655, %659[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc44)
    %661 = llvm.insertvalue %656, %660[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc44)
    %662 = llvm.extractvalue %652[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %663 = llvm.extractvalue %652[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %664 = llvm.extractvalue %652[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %665 = llvm.extractvalue %652[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %666 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc45)
    %667 = llvm.insertvalue %665, %666[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %668 = llvm.insertvalue %665, %667[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %669 = llvm.insertvalue %665, %668[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %670 = llvm.insertvalue %665, %669[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %671 = llvm.extractvalue %661[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %672 = llvm.extractvalue %661[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %673 = llvm.extractvalue %661[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %674 = llvm.extractvalue %661[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %675 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc45)
    %676 = llvm.insertvalue %671, %675[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %677 = llvm.insertvalue %672, %676[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %678 = llvm.insertvalue %673, %677[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %679 = llvm.insertvalue %674, %678[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %680 = llvm.extractvalue %670[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %681 = llvm.extractvalue %670[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %682 = llvm.extractvalue %670[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %683 = llvm.extractvalue %670[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %684 = llvm.extractvalue %679[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %685 = llvm.extractvalue %679[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %686 = llvm.extractvalue %679[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %687 = llvm.extractvalue %679[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %688 = llvm.add %680, %684 : i32 loc(#loc45)
    %689 = llvm.add %681, %685 : i32 loc(#loc45)
    %690 = llvm.add %682, %686 : i32 loc(#loc45)
    %691 = llvm.add %683, %687 : i32 loc(#loc45)
    %692 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc45)
    %693 = llvm.insertvalue %688, %692[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %694 = llvm.insertvalue %689, %693[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %695 = llvm.insertvalue %690, %694[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %696 = llvm.insertvalue %691, %695[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc45)
    %697 = llvm.bitcast %arg1 : !llvm.ptr<1> to !llvm.ptr<1> loc(#loc46)
    %698 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc46)
    %699 = llvm.insertvalue %697, %698[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %700 = llvm.insertvalue %697, %699[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %701 = llvm.insertvalue %697, %700[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %702 = llvm.insertvalue %697, %701[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %703 = llvm.extractvalue %702[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %704 = llvm.extractvalue %702[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %705 = llvm.extractvalue %702[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %706 = llvm.extractvalue %702[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %707 = llvm.extractvalue %696[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc46)
    %708 = llvm.extractvalue %696[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc46)
    %709 = llvm.extractvalue %696[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc46)
    %710 = llvm.extractvalue %696[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc46)
    %711 = llvm.getelementptr %703[%707] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc46)
    %712 = llvm.getelementptr %704[%708] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc46)
    %713 = llvm.getelementptr %705[%709] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc46)
    %714 = llvm.getelementptr %706[%710] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc46)
    %715 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc46)
    %716 = llvm.insertvalue %711, %715[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %717 = llvm.insertvalue %712, %716[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %718 = llvm.insertvalue %713, %717[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %719 = llvm.insertvalue %714, %718[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc46)
    %720 = builtin.unrealized_conversion_cast %719 : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> to tensor<16x32x!tt.ptr<f32>, #blocked1> loc(#loc46)
    %721 = builtin.unrealized_conversion_cast %720 : tensor<16x32x!tt.ptr<f32>, #blocked1> to !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc2)
    %722 = llvm.add %arg5, %29 : i32 loc(#loc73)
    %723 = llvm.sdiv %722, %12 : i32 loc(#loc74)
    %724 = llvm.mul %arg7, %12 : i32 loc(#loc48)
    %725 = llvm.bitcast %724 : i32 to i32 loc(#loc49)
    %726 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %727 = llvm.insertvalue %725, %726[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %728 = llvm.insertvalue %725, %727[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %729 = llvm.insertvalue %725, %728[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %730 = llvm.insertvalue %725, %729[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %731 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %732 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc)
    %733 = llvm.getelementptr %732[%731] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc50)
    %734 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %735 = llvm.mlir.undef : !llvm.struct<(ptr<3>, i32, i32, i32)> loc(#loc50)
    %736 = llvm.insertvalue %733, %735[0] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %737 = llvm.insertvalue %734, %736[1] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %738 = llvm.insertvalue %734, %737[2] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %739 = llvm.insertvalue %734, %738[3] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %740 = llvm.mlir.constant(2048 : i32) : i32 loc(#loc51)
    %741 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc)
    %742 = llvm.getelementptr %741[%740] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc51)
    %743 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %744 = llvm.mlir.undef : !llvm.struct<(ptr<3>, i32, i32, i32)> loc(#loc51)
    %745 = llvm.insertvalue %742, %744[0] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %746 = llvm.insertvalue %743, %745[1] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %747 = llvm.insertvalue %743, %746[2] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %748 = llvm.insertvalue %743, %747[3] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %749 = llvm.icmp "sgt" %723, %9 : i32 loc(#loc2)
    %750 = llvm.bitcast %arg5 : i32 to i32 loc(#loc52)
    %751 = llvm.mlir.undef : !llvm.struct<(i32)> loc(#loc52)
    %752 = llvm.insertvalue %750, %751[0] : !llvm.struct<(i32)>  loc(#loc52)
    %753 = llvm.extractvalue %519[0] : !llvm.struct<(i32)>  loc(#loc52)
    %754 = llvm.extractvalue %752[0] : !llvm.struct<(i32)>  loc(#loc52)
    %755 = llvm.icmp "slt" %753, %754 : i32 loc(#loc52)
    %756 = llvm.mlir.undef : !llvm.struct<(i1)> loc(#loc52)
    %757 = llvm.insertvalue %755, %756[0] : !llvm.struct<(i1)>  loc(#loc52)
    %758 = llvm.extractvalue %757[0] : !llvm.struct<(i1)>  loc(#loc50)
    %759 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc50)
    %760 = llvm.insertvalue %758, %759[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %761 = llvm.insertvalue %758, %760[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %762 = llvm.insertvalue %758, %761[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %763 = llvm.insertvalue %758, %762[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %764 = llvm.extractvalue %739[0] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %765 = llvm.extractvalue %739[1] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %766 = llvm.extractvalue %739[2] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %767 = llvm.extractvalue %739[3] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %768 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %769 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %770 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %771 = llvm.add %9, %766 : i32 loc(#loc50)
    %772 = llvm.add %9, %767 : i32 loc(#loc50)
    %773 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %774 = llvm.mul %9, %770 : i32 loc(#loc50)
    %775 = llvm.add %773, %774 : i32 loc(#loc50)
    %776 = llvm.mul %9, %769 : i32 loc(#loc50)
    %777 = llvm.add %775, %776 : i32 loc(#loc50)
    %778 = llvm.mul %9, %768 : i32 loc(#loc50)
    %779 = llvm.add %777, %778 : i32 loc(#loc50)
    %780 = llvm.getelementptr %764[%779] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %781 = llvm.mlir.undef : !llvm.struct<(ptr<3>, i32, i32)> loc(#loc50)
    %782 = llvm.insertvalue %780, %781[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %783 = llvm.insertvalue %771, %782[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %784 = llvm.insertvalue %772, %783[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %785 = llvm.bitcast %749 : i1 to i1 loc(#loc2)
    %786 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc2)
    %787 = llvm.insertvalue %785, %786[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %788 = llvm.insertvalue %785, %787[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %789 = llvm.insertvalue %785, %788[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %790 = llvm.insertvalue %785, %789[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %791 = llvm.extractvalue %790[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %792 = llvm.extractvalue %790[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %793 = llvm.extractvalue %790[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %794 = llvm.extractvalue %790[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %795 = llvm.extractvalue %763[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %796 = llvm.extractvalue %763[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %797 = llvm.extractvalue %763[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %798 = llvm.extractvalue %763[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %799 = llvm.and %791, %795 : i1 loc(#loc2)
    %800 = llvm.and %792, %796 : i1 loc(#loc2)
    %801 = llvm.and %793, %797 : i1 loc(#loc2)
    %802 = llvm.and %794, %798 : i1 loc(#loc2)
    %803 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc2)
    %804 = llvm.insertvalue %799, %803[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %805 = llvm.insertvalue %800, %804[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %806 = llvm.insertvalue %801, %805[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %807 = llvm.insertvalue %802, %806[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %808 = llvm.extractvalue %574[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc50)
    %809 = llvm.extractvalue %574[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc50)
    %810 = llvm.extractvalue %574[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc50)
    %811 = llvm.extractvalue %574[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc50)
    %812 = llvm.extractvalue %784[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %813 = llvm.extractvalue %784[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %814 = llvm.extractvalue %784[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %815 = llvm.extractvalue %807[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %816 = llvm.extractvalue %807[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %817 = llvm.extractvalue %807[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %818 = llvm.extractvalue %807[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %819 = llvm.extractvalue %19[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc50)
    %820 = llvm.extractvalue %19[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc50)
    %821 = llvm.extractvalue %19[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc50)
    %822 = llvm.extractvalue %19[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc50)
    %823 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc50)
    %824 = llvm.mlir.constant(32 : i32) : i32 loc(#loc50)
    %825 = llvm.urem %823, %824 : i32 loc(#loc50)
    %826 = llvm.udiv %823, %824 : i32 loc(#loc50)
    %827 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %828 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %829 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %830 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %831 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %832 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %833 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %834 = llvm.and %825, %833 : i32 loc(#loc50)
    %835 = llvm.icmp "eq" %834, %832 : i32 loc(#loc50)
    %836 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %837 = llvm.select %835, %832, %836 : i1, i32 loc(#loc50)
    %838 = llvm.xor %832, %837 : i32 loc(#loc50)
    %839 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %840 = llvm.and %825, %839 : i32 loc(#loc50)
    %841 = llvm.icmp "eq" %840, %832 : i32 loc(#loc50)
    %842 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %843 = llvm.select %841, %832, %842 : i1, i32 loc(#loc50)
    %844 = llvm.xor %838, %843 : i32 loc(#loc50)
    %845 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %846 = llvm.and %825, %845 : i32 loc(#loc50)
    %847 = llvm.icmp "eq" %846, %832 : i32 loc(#loc50)
    %848 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %849 = llvm.select %847, %832, %848 : i1, i32 loc(#loc50)
    %850 = llvm.xor %844, %849 : i32 loc(#loc50)
    %851 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %852 = llvm.and %825, %851 : i32 loc(#loc50)
    %853 = llvm.icmp "eq" %852, %832 : i32 loc(#loc50)
    %854 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %855 = llvm.select %853, %832, %854 : i1, i32 loc(#loc50)
    %856 = llvm.xor %850, %855 : i32 loc(#loc50)
    %857 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %858 = llvm.and %825, %857 : i32 loc(#loc50)
    %859 = llvm.icmp "eq" %858, %832 : i32 loc(#loc50)
    %860 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %861 = llvm.select %859, %832, %860 : i1, i32 loc(#loc50)
    %862 = llvm.xor %856, %861 : i32 loc(#loc50)
    %863 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %864 = llvm.and %826, %863 : i32 loc(#loc50)
    %865 = llvm.icmp "eq" %864, %832 : i32 loc(#loc50)
    %866 = llvm.mlir.constant(36 : i32) : i32 loc(#loc50)
    %867 = llvm.select %865, %832, %866 : i1, i32 loc(#loc50)
    %868 = llvm.xor %862, %867 : i32 loc(#loc50)
    %869 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %870 = llvm.and %826, %869 : i32 loc(#loc50)
    %871 = llvm.icmp "eq" %870, %832 : i32 loc(#loc50)
    %872 = llvm.mlir.constant(72 : i32) : i32 loc(#loc50)
    %873 = llvm.select %871, %832, %872 : i1, i32 loc(#loc50)
    %874 = llvm.xor %868, %873 : i32 loc(#loc50)
    %875 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %876 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %877 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %878 = llvm.and %825, %877 : i32 loc(#loc50)
    %879 = llvm.icmp "eq" %878, %876 : i32 loc(#loc50)
    %880 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %881 = llvm.select %879, %876, %880 : i1, i32 loc(#loc50)
    %882 = llvm.xor %876, %881 : i32 loc(#loc50)
    %883 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %884 = llvm.and %825, %883 : i32 loc(#loc50)
    %885 = llvm.icmp "eq" %884, %876 : i32 loc(#loc50)
    %886 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %887 = llvm.select %885, %876, %886 : i1, i32 loc(#loc50)
    %888 = llvm.xor %882, %887 : i32 loc(#loc50)
    %889 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %890 = llvm.and %825, %889 : i32 loc(#loc50)
    %891 = llvm.icmp "eq" %890, %876 : i32 loc(#loc50)
    %892 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %893 = llvm.select %891, %876, %892 : i1, i32 loc(#loc50)
    %894 = llvm.xor %888, %893 : i32 loc(#loc50)
    %895 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %896 = llvm.and %825, %895 : i32 loc(#loc50)
    %897 = llvm.icmp "eq" %896, %876 : i32 loc(#loc50)
    %898 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %899 = llvm.select %897, %876, %898 : i1, i32 loc(#loc50)
    %900 = llvm.xor %894, %899 : i32 loc(#loc50)
    %901 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %902 = llvm.and %825, %901 : i32 loc(#loc50)
    %903 = llvm.icmp "eq" %902, %876 : i32 loc(#loc50)
    %904 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %905 = llvm.select %903, %876, %904 : i1, i32 loc(#loc50)
    %906 = llvm.xor %876, %905 : i32 loc(#loc50)
    %907 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %908 = llvm.and %826, %907 : i32 loc(#loc50)
    %909 = llvm.icmp "eq" %908, %876 : i32 loc(#loc50)
    %910 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %911 = llvm.select %909, %876, %910 : i1, i32 loc(#loc50)
    %912 = llvm.xor %900, %911 : i32 loc(#loc50)
    %913 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %914 = llvm.select %909, %876, %913 : i1, i32 loc(#loc50)
    %915 = llvm.xor %906, %914 : i32 loc(#loc50)
    %916 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %917 = llvm.and %826, %916 : i32 loc(#loc50)
    %918 = llvm.icmp "eq" %917, %876 : i32 loc(#loc50)
    %919 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %920 = llvm.select %918, %876, %919 : i1, i32 loc(#loc50)
    %921 = llvm.xor %912, %920 : i32 loc(#loc50)
    %922 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %923 = llvm.select %918, %876, %922 : i1, i32 loc(#loc50)
    %924 = llvm.xor %915, %923 : i32 loc(#loc50)
    %925 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %926 = llvm.mul %921, %829 : i32 loc(#loc50)
    %927 = llvm.add %925, %926 : i32 loc(#loc50)
    %928 = llvm.mul %924, %830 : i32 loc(#loc50)
    %929 = llvm.add %927, %928 : i32 loc(#loc50)
    %930 = llvm.getelementptr inbounds %812[%929] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %931 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %932 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %933 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %934 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %935 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %936 = llvm.mlir.constant(128 : i32) : i32 loc(#loc50)
    %937 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %938 = llvm.and %825, %937 : i32 loc(#loc50)
    %939 = llvm.icmp "eq" %938, %935 : i32 loc(#loc50)
    %940 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %941 = llvm.select %939, %935, %940 : i1, i32 loc(#loc50)
    %942 = llvm.xor %936, %941 : i32 loc(#loc50)
    %943 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %944 = llvm.and %825, %943 : i32 loc(#loc50)
    %945 = llvm.icmp "eq" %944, %935 : i32 loc(#loc50)
    %946 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %947 = llvm.select %945, %935, %946 : i1, i32 loc(#loc50)
    %948 = llvm.xor %942, %947 : i32 loc(#loc50)
    %949 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %950 = llvm.and %825, %949 : i32 loc(#loc50)
    %951 = llvm.icmp "eq" %950, %935 : i32 loc(#loc50)
    %952 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %953 = llvm.select %951, %935, %952 : i1, i32 loc(#loc50)
    %954 = llvm.xor %948, %953 : i32 loc(#loc50)
    %955 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %956 = llvm.and %825, %955 : i32 loc(#loc50)
    %957 = llvm.icmp "eq" %956, %935 : i32 loc(#loc50)
    %958 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %959 = llvm.select %957, %935, %958 : i1, i32 loc(#loc50)
    %960 = llvm.xor %954, %959 : i32 loc(#loc50)
    %961 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %962 = llvm.and %825, %961 : i32 loc(#loc50)
    %963 = llvm.icmp "eq" %962, %935 : i32 loc(#loc50)
    %964 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %965 = llvm.select %963, %935, %964 : i1, i32 loc(#loc50)
    %966 = llvm.xor %960, %965 : i32 loc(#loc50)
    %967 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %968 = llvm.and %826, %967 : i32 loc(#loc50)
    %969 = llvm.icmp "eq" %968, %935 : i32 loc(#loc50)
    %970 = llvm.mlir.constant(36 : i32) : i32 loc(#loc50)
    %971 = llvm.select %969, %935, %970 : i1, i32 loc(#loc50)
    %972 = llvm.xor %966, %971 : i32 loc(#loc50)
    %973 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %974 = llvm.and %826, %973 : i32 loc(#loc50)
    %975 = llvm.icmp "eq" %974, %935 : i32 loc(#loc50)
    %976 = llvm.mlir.constant(72 : i32) : i32 loc(#loc50)
    %977 = llvm.select %975, %935, %976 : i1, i32 loc(#loc50)
    %978 = llvm.xor %972, %977 : i32 loc(#loc50)
    %979 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %980 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %981 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %982 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %983 = llvm.and %825, %982 : i32 loc(#loc50)
    %984 = llvm.icmp "eq" %983, %980 : i32 loc(#loc50)
    %985 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %986 = llvm.select %984, %980, %985 : i1, i32 loc(#loc50)
    %987 = llvm.xor %980, %986 : i32 loc(#loc50)
    %988 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %989 = llvm.and %825, %988 : i32 loc(#loc50)
    %990 = llvm.icmp "eq" %989, %980 : i32 loc(#loc50)
    %991 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %992 = llvm.select %990, %980, %991 : i1, i32 loc(#loc50)
    %993 = llvm.xor %987, %992 : i32 loc(#loc50)
    %994 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %995 = llvm.and %825, %994 : i32 loc(#loc50)
    %996 = llvm.icmp "eq" %995, %980 : i32 loc(#loc50)
    %997 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %998 = llvm.select %996, %980, %997 : i1, i32 loc(#loc50)
    %999 = llvm.xor %993, %998 : i32 loc(#loc50)
    %1000 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1001 = llvm.and %825, %1000 : i32 loc(#loc50)
    %1002 = llvm.icmp "eq" %1001, %980 : i32 loc(#loc50)
    %1003 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1004 = llvm.select %1002, %980, %1003 : i1, i32 loc(#loc50)
    %1005 = llvm.xor %999, %1004 : i32 loc(#loc50)
    %1006 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1007 = llvm.and %825, %1006 : i32 loc(#loc50)
    %1008 = llvm.icmp "eq" %1007, %980 : i32 loc(#loc50)
    %1009 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1010 = llvm.select %1008, %980, %1009 : i1, i32 loc(#loc50)
    %1011 = llvm.xor %981, %1010 : i32 loc(#loc50)
    %1012 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1013 = llvm.and %826, %1012 : i32 loc(#loc50)
    %1014 = llvm.icmp "eq" %1013, %980 : i32 loc(#loc50)
    %1015 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1016 = llvm.select %1014, %980, %1015 : i1, i32 loc(#loc50)
    %1017 = llvm.xor %1005, %1016 : i32 loc(#loc50)
    %1018 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1019 = llvm.select %1014, %980, %1018 : i1, i32 loc(#loc50)
    %1020 = llvm.xor %1011, %1019 : i32 loc(#loc50)
    %1021 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1022 = llvm.and %826, %1021 : i32 loc(#loc50)
    %1023 = llvm.icmp "eq" %1022, %980 : i32 loc(#loc50)
    %1024 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1025 = llvm.select %1023, %980, %1024 : i1, i32 loc(#loc50)
    %1026 = llvm.xor %1017, %1025 : i32 loc(#loc50)
    %1027 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1028 = llvm.select %1023, %980, %1027 : i1, i32 loc(#loc50)
    %1029 = llvm.xor %1020, %1028 : i32 loc(#loc50)
    %1030 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1031 = llvm.mul %1026, %932 : i32 loc(#loc50)
    %1032 = llvm.add %1030, %1031 : i32 loc(#loc50)
    %1033 = llvm.mul %1029, %933 : i32 loc(#loc50)
    %1034 = llvm.add %1032, %1033 : i32 loc(#loc50)
    %1035 = llvm.getelementptr inbounds %812[%1034] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %1036 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1037 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1038 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1039 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %1040 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1041 = llvm.mlir.constant(256 : i32) : i32 loc(#loc50)
    %1042 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1043 = llvm.and %825, %1042 : i32 loc(#loc50)
    %1044 = llvm.icmp "eq" %1043, %1040 : i32 loc(#loc50)
    %1045 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1046 = llvm.select %1044, %1040, %1045 : i1, i32 loc(#loc50)
    %1047 = llvm.xor %1041, %1046 : i32 loc(#loc50)
    %1048 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1049 = llvm.and %825, %1048 : i32 loc(#loc50)
    %1050 = llvm.icmp "eq" %1049, %1040 : i32 loc(#loc50)
    %1051 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1052 = llvm.select %1050, %1040, %1051 : i1, i32 loc(#loc50)
    %1053 = llvm.xor %1047, %1052 : i32 loc(#loc50)
    %1054 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1055 = llvm.and %825, %1054 : i32 loc(#loc50)
    %1056 = llvm.icmp "eq" %1055, %1040 : i32 loc(#loc50)
    %1057 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1058 = llvm.select %1056, %1040, %1057 : i1, i32 loc(#loc50)
    %1059 = llvm.xor %1053, %1058 : i32 loc(#loc50)
    %1060 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1061 = llvm.and %825, %1060 : i32 loc(#loc50)
    %1062 = llvm.icmp "eq" %1061, %1040 : i32 loc(#loc50)
    %1063 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1064 = llvm.select %1062, %1040, %1063 : i1, i32 loc(#loc50)
    %1065 = llvm.xor %1059, %1064 : i32 loc(#loc50)
    %1066 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1067 = llvm.and %825, %1066 : i32 loc(#loc50)
    %1068 = llvm.icmp "eq" %1067, %1040 : i32 loc(#loc50)
    %1069 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1070 = llvm.select %1068, %1040, %1069 : i1, i32 loc(#loc50)
    %1071 = llvm.xor %1065, %1070 : i32 loc(#loc50)
    %1072 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1073 = llvm.and %826, %1072 : i32 loc(#loc50)
    %1074 = llvm.icmp "eq" %1073, %1040 : i32 loc(#loc50)
    %1075 = llvm.mlir.constant(36 : i32) : i32 loc(#loc50)
    %1076 = llvm.select %1074, %1040, %1075 : i1, i32 loc(#loc50)
    %1077 = llvm.xor %1071, %1076 : i32 loc(#loc50)
    %1078 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1079 = llvm.and %826, %1078 : i32 loc(#loc50)
    %1080 = llvm.icmp "eq" %1079, %1040 : i32 loc(#loc50)
    %1081 = llvm.mlir.constant(72 : i32) : i32 loc(#loc50)
    %1082 = llvm.select %1080, %1040, %1081 : i1, i32 loc(#loc50)
    %1083 = llvm.xor %1077, %1082 : i32 loc(#loc50)
    %1084 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1085 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1086 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1087 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1088 = llvm.and %825, %1087 : i32 loc(#loc50)
    %1089 = llvm.icmp "eq" %1088, %1085 : i32 loc(#loc50)
    %1090 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1091 = llvm.select %1089, %1085, %1090 : i1, i32 loc(#loc50)
    %1092 = llvm.xor %1085, %1091 : i32 loc(#loc50)
    %1093 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1094 = llvm.and %825, %1093 : i32 loc(#loc50)
    %1095 = llvm.icmp "eq" %1094, %1085 : i32 loc(#loc50)
    %1096 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1097 = llvm.select %1095, %1085, %1096 : i1, i32 loc(#loc50)
    %1098 = llvm.xor %1092, %1097 : i32 loc(#loc50)
    %1099 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1100 = llvm.and %825, %1099 : i32 loc(#loc50)
    %1101 = llvm.icmp "eq" %1100, %1085 : i32 loc(#loc50)
    %1102 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1103 = llvm.select %1101, %1085, %1102 : i1, i32 loc(#loc50)
    %1104 = llvm.xor %1098, %1103 : i32 loc(#loc50)
    %1105 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1106 = llvm.and %825, %1105 : i32 loc(#loc50)
    %1107 = llvm.icmp "eq" %1106, %1085 : i32 loc(#loc50)
    %1108 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1109 = llvm.select %1107, %1085, %1108 : i1, i32 loc(#loc50)
    %1110 = llvm.xor %1104, %1109 : i32 loc(#loc50)
    %1111 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1112 = llvm.and %825, %1111 : i32 loc(#loc50)
    %1113 = llvm.icmp "eq" %1112, %1085 : i32 loc(#loc50)
    %1114 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1115 = llvm.select %1113, %1085, %1114 : i1, i32 loc(#loc50)
    %1116 = llvm.xor %1086, %1115 : i32 loc(#loc50)
    %1117 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1118 = llvm.and %826, %1117 : i32 loc(#loc50)
    %1119 = llvm.icmp "eq" %1118, %1085 : i32 loc(#loc50)
    %1120 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1121 = llvm.select %1119, %1085, %1120 : i1, i32 loc(#loc50)
    %1122 = llvm.xor %1110, %1121 : i32 loc(#loc50)
    %1123 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1124 = llvm.select %1119, %1085, %1123 : i1, i32 loc(#loc50)
    %1125 = llvm.xor %1116, %1124 : i32 loc(#loc50)
    %1126 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1127 = llvm.and %826, %1126 : i32 loc(#loc50)
    %1128 = llvm.icmp "eq" %1127, %1085 : i32 loc(#loc50)
    %1129 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1130 = llvm.select %1128, %1085, %1129 : i1, i32 loc(#loc50)
    %1131 = llvm.xor %1122, %1130 : i32 loc(#loc50)
    %1132 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1133 = llvm.select %1128, %1085, %1132 : i1, i32 loc(#loc50)
    %1134 = llvm.xor %1125, %1133 : i32 loc(#loc50)
    %1135 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1136 = llvm.mul %1131, %1037 : i32 loc(#loc50)
    %1137 = llvm.add %1135, %1136 : i32 loc(#loc50)
    %1138 = llvm.mul %1134, %1038 : i32 loc(#loc50)
    %1139 = llvm.add %1137, %1138 : i32 loc(#loc50)
    %1140 = llvm.getelementptr inbounds %812[%1139] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %1141 = llvm.mlir.constant(3 : i32) : i32 loc(#loc50)
    %1142 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1143 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1144 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %1145 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1146 = llvm.mlir.constant(384 : i32) : i32 loc(#loc50)
    %1147 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1148 = llvm.and %825, %1147 : i32 loc(#loc50)
    %1149 = llvm.icmp "eq" %1148, %1145 : i32 loc(#loc50)
    %1150 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1151 = llvm.select %1149, %1145, %1150 : i1, i32 loc(#loc50)
    %1152 = llvm.xor %1146, %1151 : i32 loc(#loc50)
    %1153 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1154 = llvm.and %825, %1153 : i32 loc(#loc50)
    %1155 = llvm.icmp "eq" %1154, %1145 : i32 loc(#loc50)
    %1156 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1157 = llvm.select %1155, %1145, %1156 : i1, i32 loc(#loc50)
    %1158 = llvm.xor %1152, %1157 : i32 loc(#loc50)
    %1159 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1160 = llvm.and %825, %1159 : i32 loc(#loc50)
    %1161 = llvm.icmp "eq" %1160, %1145 : i32 loc(#loc50)
    %1162 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1163 = llvm.select %1161, %1145, %1162 : i1, i32 loc(#loc50)
    %1164 = llvm.xor %1158, %1163 : i32 loc(#loc50)
    %1165 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1166 = llvm.and %825, %1165 : i32 loc(#loc50)
    %1167 = llvm.icmp "eq" %1166, %1145 : i32 loc(#loc50)
    %1168 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1169 = llvm.select %1167, %1145, %1168 : i1, i32 loc(#loc50)
    %1170 = llvm.xor %1164, %1169 : i32 loc(#loc50)
    %1171 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1172 = llvm.and %825, %1171 : i32 loc(#loc50)
    %1173 = llvm.icmp "eq" %1172, %1145 : i32 loc(#loc50)
    %1174 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1175 = llvm.select %1173, %1145, %1174 : i1, i32 loc(#loc50)
    %1176 = llvm.xor %1170, %1175 : i32 loc(#loc50)
    %1177 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1178 = llvm.and %826, %1177 : i32 loc(#loc50)
    %1179 = llvm.icmp "eq" %1178, %1145 : i32 loc(#loc50)
    %1180 = llvm.mlir.constant(36 : i32) : i32 loc(#loc50)
    %1181 = llvm.select %1179, %1145, %1180 : i1, i32 loc(#loc50)
    %1182 = llvm.xor %1176, %1181 : i32 loc(#loc50)
    %1183 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1184 = llvm.and %826, %1183 : i32 loc(#loc50)
    %1185 = llvm.icmp "eq" %1184, %1145 : i32 loc(#loc50)
    %1186 = llvm.mlir.constant(72 : i32) : i32 loc(#loc50)
    %1187 = llvm.select %1185, %1145, %1186 : i1, i32 loc(#loc50)
    %1188 = llvm.xor %1182, %1187 : i32 loc(#loc50)
    %1189 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1190 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1191 = llvm.mlir.constant(24 : i32) : i32 loc(#loc50)
    %1192 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1193 = llvm.and %825, %1192 : i32 loc(#loc50)
    %1194 = llvm.icmp "eq" %1193, %1190 : i32 loc(#loc50)
    %1195 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1196 = llvm.select %1194, %1190, %1195 : i1, i32 loc(#loc50)
    %1197 = llvm.xor %1190, %1196 : i32 loc(#loc50)
    %1198 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1199 = llvm.and %825, %1198 : i32 loc(#loc50)
    %1200 = llvm.icmp "eq" %1199, %1190 : i32 loc(#loc50)
    %1201 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1202 = llvm.select %1200, %1190, %1201 : i1, i32 loc(#loc50)
    %1203 = llvm.xor %1197, %1202 : i32 loc(#loc50)
    %1204 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1205 = llvm.and %825, %1204 : i32 loc(#loc50)
    %1206 = llvm.icmp "eq" %1205, %1190 : i32 loc(#loc50)
    %1207 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1208 = llvm.select %1206, %1190, %1207 : i1, i32 loc(#loc50)
    %1209 = llvm.xor %1203, %1208 : i32 loc(#loc50)
    %1210 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1211 = llvm.and %825, %1210 : i32 loc(#loc50)
    %1212 = llvm.icmp "eq" %1211, %1190 : i32 loc(#loc50)
    %1213 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1214 = llvm.select %1212, %1190, %1213 : i1, i32 loc(#loc50)
    %1215 = llvm.xor %1209, %1214 : i32 loc(#loc50)
    %1216 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1217 = llvm.and %825, %1216 : i32 loc(#loc50)
    %1218 = llvm.icmp "eq" %1217, %1190 : i32 loc(#loc50)
    %1219 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1220 = llvm.select %1218, %1190, %1219 : i1, i32 loc(#loc50)
    %1221 = llvm.xor %1191, %1220 : i32 loc(#loc50)
    %1222 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1223 = llvm.and %826, %1222 : i32 loc(#loc50)
    %1224 = llvm.icmp "eq" %1223, %1190 : i32 loc(#loc50)
    %1225 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1226 = llvm.select %1224, %1190, %1225 : i1, i32 loc(#loc50)
    %1227 = llvm.xor %1215, %1226 : i32 loc(#loc50)
    %1228 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1229 = llvm.select %1224, %1190, %1228 : i1, i32 loc(#loc50)
    %1230 = llvm.xor %1221, %1229 : i32 loc(#loc50)
    %1231 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1232 = llvm.and %826, %1231 : i32 loc(#loc50)
    %1233 = llvm.icmp "eq" %1232, %1190 : i32 loc(#loc50)
    %1234 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1235 = llvm.select %1233, %1190, %1234 : i1, i32 loc(#loc50)
    %1236 = llvm.xor %1227, %1235 : i32 loc(#loc50)
    %1237 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1238 = llvm.select %1233, %1190, %1237 : i1, i32 loc(#loc50)
    %1239 = llvm.xor %1230, %1238 : i32 loc(#loc50)
    %1240 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1241 = llvm.mul %1236, %1142 : i32 loc(#loc50)
    %1242 = llvm.add %1240, %1241 : i32 loc(#loc50)
    %1243 = llvm.mul %1239, %1143 : i32 loc(#loc50)
    %1244 = llvm.add %1242, %1243 : i32 loc(#loc50)
    %1245 = llvm.getelementptr inbounds %812[%1244] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %1246 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1247 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc50)
    %1248 = llvm.mlir.constant(32 : i32) : i32 loc(#loc50)
    %1249 = llvm.urem %1247, %1248 : i32 loc(#loc50)
    %1250 = llvm.udiv %1247, %1248 : i32 loc(#loc50)
    %1251 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1252 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1253 = llvm.select %815, %1251, %1252 : i1, i32 loc(#loc50)
    %1254 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %930, %808, %1253 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc50)
    %1255 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1256 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1257 = llvm.select %816, %1255, %1256 : i1, i32 loc(#loc50)
    %1258 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %1035, %809, %1257 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc50)
    %1259 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1260 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1261 = llvm.select %817, %1259, %1260 : i1, i32 loc(#loc50)
    %1262 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %1140, %810, %1261 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc50)
    %1263 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1264 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1265 = llvm.select %818, %1263, %1264 : i1, i32 loc(#loc50)
    %1266 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %1245, %811, %1265 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc50)
    %1267 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    nvvm.cp.async.commit.group loc(#loc50)
    %1268 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1269 = llvm.bitcast %arg5 : i32 to i32 loc(#loc53)
    %1270 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc53)
    %1271 = llvm.insertvalue %1269, %1270[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1272 = llvm.insertvalue %1269, %1271[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1273 = llvm.insertvalue %1269, %1272[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1274 = llvm.insertvalue %1269, %1273[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1275 = llvm.extractvalue %629[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1276 = llvm.extractvalue %629[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1277 = llvm.extractvalue %629[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1278 = llvm.extractvalue %629[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1279 = llvm.extractvalue %1274[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1280 = llvm.extractvalue %1274[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1281 = llvm.extractvalue %1274[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1282 = llvm.extractvalue %1274[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %1283 = llvm.icmp "slt" %1275, %1279 : i32 loc(#loc53)
    %1284 = llvm.icmp "slt" %1276, %1280 : i32 loc(#loc53)
    %1285 = llvm.icmp "slt" %1277, %1281 : i32 loc(#loc53)
    %1286 = llvm.icmp "slt" %1278, %1282 : i32 loc(#loc53)
    %1287 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc53)
    %1288 = llvm.insertvalue %1283, %1287[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc53)
    %1289 = llvm.insertvalue %1284, %1288[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc53)
    %1290 = llvm.insertvalue %1285, %1289[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc53)
    %1291 = llvm.insertvalue %1286, %1290[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc53)
    %1292 = llvm.extractvalue %1291[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1293 = llvm.extractvalue %1291[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1294 = llvm.extractvalue %1291[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1295 = llvm.extractvalue %1291[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1296 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc51)
    %1297 = llvm.insertvalue %1295, %1296[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1298 = llvm.insertvalue %1295, %1297[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1299 = llvm.insertvalue %1295, %1298[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1300 = llvm.insertvalue %1295, %1299[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1301 = llvm.extractvalue %748[0] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %1302 = llvm.extractvalue %748[1] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %1303 = llvm.extractvalue %748[2] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %1304 = llvm.extractvalue %748[3] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %1305 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1306 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %1307 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %1308 = llvm.add %9, %1303 : i32 loc(#loc51)
    %1309 = llvm.add %9, %1304 : i32 loc(#loc51)
    %1310 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1311 = llvm.mul %9, %1307 : i32 loc(#loc51)
    %1312 = llvm.add %1310, %1311 : i32 loc(#loc51)
    %1313 = llvm.mul %9, %1306 : i32 loc(#loc51)
    %1314 = llvm.add %1312, %1313 : i32 loc(#loc51)
    %1315 = llvm.mul %9, %1305 : i32 loc(#loc51)
    %1316 = llvm.add %1314, %1315 : i32 loc(#loc51)
    %1317 = llvm.getelementptr %1301[%1316] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %1318 = llvm.mlir.undef : !llvm.struct<(ptr<3>, i32, i32)> loc(#loc51)
    %1319 = llvm.insertvalue %1317, %1318[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1320 = llvm.insertvalue %1308, %1319[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1321 = llvm.insertvalue %1309, %1320[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1322 = llvm.bitcast %749 : i1 to i1 loc(#loc2)
    %1323 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc2)
    %1324 = llvm.insertvalue %1322, %1323[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1325 = llvm.insertvalue %1322, %1324[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1326 = llvm.insertvalue %1322, %1325[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1327 = llvm.insertvalue %1322, %1326[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1328 = llvm.extractvalue %1327[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1329 = llvm.extractvalue %1327[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1330 = llvm.extractvalue %1327[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1331 = llvm.extractvalue %1327[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1332 = llvm.extractvalue %1300[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1333 = llvm.extractvalue %1300[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1334 = llvm.extractvalue %1300[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1335 = llvm.extractvalue %1300[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1336 = llvm.and %1328, %1332 : i1 loc(#loc2)
    %1337 = llvm.and %1329, %1333 : i1 loc(#loc2)
    %1338 = llvm.and %1330, %1334 : i1 loc(#loc2)
    %1339 = llvm.and %1331, %1335 : i1 loc(#loc2)
    %1340 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc2)
    %1341 = llvm.insertvalue %1336, %1340[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1342 = llvm.insertvalue %1336, %1341[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1343 = llvm.insertvalue %1336, %1342[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1344 = llvm.insertvalue %1336, %1343[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %1345 = llvm.extractvalue %719[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc51)
    %1346 = llvm.extractvalue %719[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc51)
    %1347 = llvm.extractvalue %719[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc51)
    %1348 = llvm.extractvalue %719[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc51)
    %1349 = llvm.extractvalue %1321[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1350 = llvm.extractvalue %1321[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1351 = llvm.extractvalue %1321[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1352 = llvm.extractvalue %1344[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1353 = llvm.extractvalue %1344[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1354 = llvm.extractvalue %1344[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1355 = llvm.extractvalue %1344[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %1356 = llvm.extractvalue %7[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %1357 = llvm.extractvalue %7[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %1358 = llvm.extractvalue %7[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %1359 = llvm.extractvalue %7[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %1360 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc51)
    %1361 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %1362 = llvm.urem %1360, %1361 : i32 loc(#loc51)
    %1363 = llvm.udiv %1360, %1361 : i32 loc(#loc51)
    %1364 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1365 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1366 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1367 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %1368 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %1369 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1370 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1371 = llvm.and %1362, %1370 : i32 loc(#loc51)
    %1372 = llvm.icmp "eq" %1371, %1369 : i32 loc(#loc51)
    %1373 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1374 = llvm.select %1372, %1369, %1373 : i1, i32 loc(#loc51)
    %1375 = llvm.xor %1369, %1374 : i32 loc(#loc51)
    %1376 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1377 = llvm.and %1362, %1376 : i32 loc(#loc51)
    %1378 = llvm.icmp "eq" %1377, %1369 : i32 loc(#loc51)
    %1379 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1380 = llvm.select %1378, %1369, %1379 : i1, i32 loc(#loc51)
    %1381 = llvm.xor %1375, %1380 : i32 loc(#loc51)
    %1382 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1383 = llvm.and %1362, %1382 : i32 loc(#loc51)
    %1384 = llvm.icmp "eq" %1383, %1369 : i32 loc(#loc51)
    %1385 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1386 = llvm.select %1384, %1369, %1385 : i1, i32 loc(#loc51)
    %1387 = llvm.xor %1381, %1386 : i32 loc(#loc51)
    %1388 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1389 = llvm.and %1362, %1388 : i32 loc(#loc51)
    %1390 = llvm.icmp "eq" %1389, %1369 : i32 loc(#loc51)
    %1391 = llvm.mlir.constant(40 : i32) : i32 loc(#loc51)
    %1392 = llvm.select %1390, %1369, %1391 : i1, i32 loc(#loc51)
    %1393 = llvm.xor %1387, %1392 : i32 loc(#loc51)
    %1394 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1395 = llvm.and %1362, %1394 : i32 loc(#loc51)
    %1396 = llvm.icmp "eq" %1395, %1369 : i32 loc(#loc51)
    %1397 = llvm.mlir.constant(80 : i32) : i32 loc(#loc51)
    %1398 = llvm.select %1396, %1369, %1397 : i1, i32 loc(#loc51)
    %1399 = llvm.xor %1393, %1398 : i32 loc(#loc51)
    %1400 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1401 = llvm.and %1363, %1400 : i32 loc(#loc51)
    %1402 = llvm.icmp "eq" %1401, %1369 : i32 loc(#loc51)
    %1403 = llvm.mlir.constant(128 : i32) : i32 loc(#loc51)
    %1404 = llvm.select %1402, %1369, %1403 : i1, i32 loc(#loc51)
    %1405 = llvm.xor %1399, %1404 : i32 loc(#loc51)
    %1406 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1407 = llvm.and %1363, %1406 : i32 loc(#loc51)
    %1408 = llvm.icmp "eq" %1407, %1369 : i32 loc(#loc51)
    %1409 = llvm.mlir.constant(256 : i32) : i32 loc(#loc51)
    %1410 = llvm.select %1408, %1369, %1409 : i1, i32 loc(#loc51)
    %1411 = llvm.xor %1405, %1410 : i32 loc(#loc51)
    %1412 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1413 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1414 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1415 = llvm.and %1362, %1414 : i32 loc(#loc51)
    %1416 = llvm.icmp "eq" %1415, %1413 : i32 loc(#loc51)
    %1417 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1418 = llvm.select %1416, %1413, %1417 : i1, i32 loc(#loc51)
    %1419 = llvm.xor %1413, %1418 : i32 loc(#loc51)
    %1420 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1421 = llvm.and %1362, %1420 : i32 loc(#loc51)
    %1422 = llvm.icmp "eq" %1421, %1413 : i32 loc(#loc51)
    %1423 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1424 = llvm.select %1422, %1413, %1423 : i1, i32 loc(#loc51)
    %1425 = llvm.xor %1419, %1424 : i32 loc(#loc51)
    %1426 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1427 = llvm.and %1362, %1426 : i32 loc(#loc51)
    %1428 = llvm.icmp "eq" %1427, %1413 : i32 loc(#loc51)
    %1429 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1430 = llvm.select %1428, %1413, %1429 : i1, i32 loc(#loc51)
    %1431 = llvm.xor %1425, %1430 : i32 loc(#loc51)
    %1432 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1433 = llvm.and %1362, %1432 : i32 loc(#loc51)
    %1434 = llvm.icmp "eq" %1433, %1413 : i32 loc(#loc51)
    %1435 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1436 = llvm.select %1434, %1413, %1435 : i1, i32 loc(#loc51)
    %1437 = llvm.xor %1431, %1436 : i32 loc(#loc51)
    %1438 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1439 = llvm.select %1434, %1413, %1438 : i1, i32 loc(#loc51)
    %1440 = llvm.xor %1413, %1439 : i32 loc(#loc51)
    %1441 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1442 = llvm.and %1362, %1441 : i32 loc(#loc51)
    %1443 = llvm.icmp "eq" %1442, %1413 : i32 loc(#loc51)
    %1444 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1445 = llvm.select %1443, %1413, %1444 : i1, i32 loc(#loc51)
    %1446 = llvm.xor %1437, %1445 : i32 loc(#loc51)
    %1447 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1448 = llvm.select %1443, %1413, %1447 : i1, i32 loc(#loc51)
    %1449 = llvm.xor %1440, %1448 : i32 loc(#loc51)
    %1450 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1451 = llvm.and %1363, %1450 : i32 loc(#loc51)
    %1452 = llvm.icmp "eq" %1451, %1413 : i32 loc(#loc51)
    %1453 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1454 = llvm.select %1452, %1413, %1453 : i1, i32 loc(#loc51)
    %1455 = llvm.xor %1449, %1454 : i32 loc(#loc51)
    %1456 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1457 = llvm.and %1363, %1456 : i32 loc(#loc51)
    %1458 = llvm.icmp "eq" %1457, %1413 : i32 loc(#loc51)
    %1459 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1460 = llvm.select %1458, %1413, %1459 : i1, i32 loc(#loc51)
    %1461 = llvm.xor %1455, %1460 : i32 loc(#loc51)
    %1462 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1463 = llvm.mul %1446, %1366 : i32 loc(#loc51)
    %1464 = llvm.add %1462, %1463 : i32 loc(#loc51)
    %1465 = llvm.mul %1461, %1367 : i32 loc(#loc51)
    %1466 = llvm.add %1464, %1465 : i32 loc(#loc51)
    %1467 = llvm.getelementptr inbounds %1349[%1466] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %1468 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1469 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc51)
    %1470 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %1471 = llvm.urem %1469, %1470 : i32 loc(#loc51)
    %1472 = llvm.udiv %1469, %1470 : i32 loc(#loc51)
    %1473 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1474 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1475 = llvm.select %1352, %1473, %1474 : i1, i32 loc(#loc51)
    %1476 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %1467, %1345, %1475 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc51)
    %1477 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    nvvm.cp.async.commit.group loc(#loc51)
    %1478 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1479 = builtin.unrealized_conversion_cast %1478 : i32 to !ttg.async.token loc(#loc51)
    %1480 = builtin.unrealized_conversion_cast %1479 : !ttg.async.token to i32 loc(#loc2)
    llvm.br ^bb1(%9, %42, %576, %721, %9, %0, %1480 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32, i32) loc(#loc2)
  ^bb1(%1481: i32 loc("examples/kernels/binary_ops.py":168:22), %1482: !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(unknown), %1483: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":159:22), %1484: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":160:22), %1485: i32 loc(unknown), %1486: i32 loc(unknown), %1487: i32 loc("examples/kernels/binary_ops.py":172:20)):  // 2 preds: ^bb0, ^bb2
    %1488 = llvm.icmp "slt" %1481, %723 : i32 loc(#loc2)
    llvm.cond_br %1488, ^bb2, ^bb3 loc(#loc2)
  ^bb2:  // pred: ^bb1
    %1489 = llvm.sub %723, %27 : i32 loc(#loc2)
    %1490 = llvm.icmp "slt" %1481, %1489 : i32 loc(#loc2)
    %1491 = llvm.add %1486, %27 : i32 loc(#loc2)
    %1492 = llvm.icmp "slt" %1491, %27 : i32 loc(#loc2)
    %1493 = llvm.select %1492, %1491, %9 : i1, i32 loc(#loc2)
    nvvm.cp.async.wait.group 0 loc(#loc50)
    %1494 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    nvvm.barrier0 loc(#loc50)
    %1495 = llvm.extractvalue %739[0] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %1496 = llvm.extractvalue %739[1] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %1497 = llvm.extractvalue %739[2] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %1498 = llvm.extractvalue %739[3] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %1499 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1500 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1501 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %1502 = llvm.add %9, %1497 : i32 loc(#loc50)
    %1503 = llvm.add %9, %1498 : i32 loc(#loc50)
    %1504 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1505 = llvm.mul %1493, %1501 : i32 loc(#loc50)
    %1506 = llvm.add %1504, %1505 : i32 loc(#loc50)
    %1507 = llvm.mul %9, %1500 : i32 loc(#loc50)
    %1508 = llvm.add %1506, %1507 : i32 loc(#loc50)
    %1509 = llvm.mul %9, %1499 : i32 loc(#loc50)
    %1510 = llvm.add %1508, %1509 : i32 loc(#loc50)
    %1511 = llvm.getelementptr %1495[%1510] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %1512 = llvm.mlir.undef : !llvm.struct<(ptr<3>, i32, i32)> loc(#loc50)
    %1513 = llvm.insertvalue %1511, %1512[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %1514 = llvm.insertvalue %1502, %1513[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %1515 = llvm.insertvalue %1503, %1514[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %1516 = llvm.extractvalue %1515[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %1517 = llvm.extractvalue %1515[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %1518 = llvm.extractvalue %1515[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %1519 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc50)
    %1520 = llvm.mlir.constant(32 : i32) : i32 loc(#loc50)
    %1521 = llvm.urem %1519, %1520 : i32 loc(#loc50)
    %1522 = llvm.udiv %1519, %1520 : i32 loc(#loc50)
    %1523 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1524 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1525 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1526 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1527 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %1528 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1529 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1530 = llvm.and %1521, %1529 : i32 loc(#loc50)
    %1531 = llvm.icmp "eq" %1530, %1528 : i32 loc(#loc50)
    %1532 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1533 = llvm.select %1531, %1528, %1532 : i1, i32 loc(#loc50)
    %1534 = llvm.xor %1528, %1533 : i32 loc(#loc50)
    %1535 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1536 = llvm.and %1521, %1535 : i32 loc(#loc50)
    %1537 = llvm.icmp "eq" %1536, %1528 : i32 loc(#loc50)
    %1538 = llvm.mlir.constant(36 : i32) : i32 loc(#loc50)
    %1539 = llvm.select %1537, %1528, %1538 : i1, i32 loc(#loc50)
    %1540 = llvm.xor %1534, %1539 : i32 loc(#loc50)
    %1541 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1542 = llvm.and %1521, %1541 : i32 loc(#loc50)
    %1543 = llvm.icmp "eq" %1542, %1528 : i32 loc(#loc50)
    %1544 = llvm.mlir.constant(72 : i32) : i32 loc(#loc50)
    %1545 = llvm.select %1543, %1528, %1544 : i1, i32 loc(#loc50)
    %1546 = llvm.xor %1540, %1545 : i32 loc(#loc50)
    %1547 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1548 = llvm.and %1521, %1547 : i32 loc(#loc50)
    %1549 = llvm.icmp "eq" %1548, %1528 : i32 loc(#loc50)
    %1550 = llvm.mlir.constant(128 : i32) : i32 loc(#loc50)
    %1551 = llvm.select %1549, %1528, %1550 : i1, i32 loc(#loc50)
    %1552 = llvm.xor %1546, %1551 : i32 loc(#loc50)
    %1553 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1554 = llvm.and %1521, %1553 : i32 loc(#loc50)
    %1555 = llvm.icmp "eq" %1554, %1528 : i32 loc(#loc50)
    %1556 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1557 = llvm.select %1555, %1528, %1556 : i1, i32 loc(#loc50)
    %1558 = llvm.xor %1552, %1557 : i32 loc(#loc50)
    %1559 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1560 = llvm.and %1522, %1559 : i32 loc(#loc50)
    %1561 = llvm.icmp "eq" %1560, %1528 : i32 loc(#loc50)
    %1562 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1563 = llvm.and %1522, %1562 : i32 loc(#loc50)
    %1564 = llvm.icmp "eq" %1563, %1528 : i32 loc(#loc50)
    %1565 = llvm.mlir.constant(256 : i32) : i32 loc(#loc50)
    %1566 = llvm.select %1564, %1528, %1565 : i1, i32 loc(#loc50)
    %1567 = llvm.xor %1558, %1566 : i32 loc(#loc50)
    %1568 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1569 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1570 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1571 = llvm.and %1521, %1570 : i32 loc(#loc50)
    %1572 = llvm.icmp "eq" %1571, %1569 : i32 loc(#loc50)
    %1573 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1574 = llvm.select %1572, %1569, %1573 : i1, i32 loc(#loc50)
    %1575 = llvm.xor %1569, %1574 : i32 loc(#loc50)
    %1576 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1577 = llvm.and %1521, %1576 : i32 loc(#loc50)
    %1578 = llvm.icmp "eq" %1577, %1569 : i32 loc(#loc50)
    %1579 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1580 = llvm.select %1578, %1569, %1579 : i1, i32 loc(#loc50)
    %1581 = llvm.xor %1569, %1580 : i32 loc(#loc50)
    %1582 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1583 = llvm.select %1578, %1569, %1582 : i1, i32 loc(#loc50)
    %1584 = llvm.xor %1575, %1583 : i32 loc(#loc50)
    %1585 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1586 = llvm.and %1521, %1585 : i32 loc(#loc50)
    %1587 = llvm.icmp "eq" %1586, %1569 : i32 loc(#loc50)
    %1588 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1589 = llvm.select %1587, %1569, %1588 : i1, i32 loc(#loc50)
    %1590 = llvm.xor %1581, %1589 : i32 loc(#loc50)
    %1591 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1592 = llvm.select %1587, %1569, %1591 : i1, i32 loc(#loc50)
    %1593 = llvm.xor %1584, %1592 : i32 loc(#loc50)
    %1594 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1595 = llvm.and %1521, %1594 : i32 loc(#loc50)
    %1596 = llvm.icmp "eq" %1595, %1569 : i32 loc(#loc50)
    %1597 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1598 = llvm.select %1596, %1569, %1597 : i1, i32 loc(#loc50)
    %1599 = llvm.xor %1593, %1598 : i32 loc(#loc50)
    %1600 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1601 = llvm.and %1521, %1600 : i32 loc(#loc50)
    %1602 = llvm.icmp "eq" %1601, %1569 : i32 loc(#loc50)
    %1603 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1604 = llvm.select %1602, %1569, %1603 : i1, i32 loc(#loc50)
    %1605 = llvm.xor %1590, %1604 : i32 loc(#loc50)
    %1606 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1607 = llvm.and %1522, %1606 : i32 loc(#loc50)
    %1608 = llvm.icmp "eq" %1607, %1569 : i32 loc(#loc50)
    %1609 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1610 = llvm.and %1522, %1609 : i32 loc(#loc50)
    %1611 = llvm.icmp "eq" %1610, %1569 : i32 loc(#loc50)
    %1612 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1613 = llvm.select %1611, %1569, %1612 : i1, i32 loc(#loc50)
    %1614 = llvm.xor %1599, %1613 : i32 loc(#loc50)
    %1615 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1616 = llvm.mul %1605, %1525 : i32 loc(#loc50)
    %1617 = llvm.add %1615, %1616 : i32 loc(#loc50)
    %1618 = llvm.mul %1614, %1526 : i32 loc(#loc50)
    %1619 = llvm.add %1617, %1618 : i32 loc(#loc50)
    %1620 = llvm.getelementptr inbounds %1516[%1619] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %1621 = nvgpu.ldmatrix %1620 : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc50)
    %1622 = llvm.extractvalue %1621[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc50)
    %1623 = llvm.extractvalue %1621[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc50)
    %1624 = llvm.extractvalue %1621[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc50)
    %1625 = llvm.extractvalue %1621[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc50)
    %1626 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1627 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1628 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1629 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %1630 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1631 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1632 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1633 = llvm.and %1521, %1632 : i32 loc(#loc50)
    %1634 = llvm.icmp "eq" %1633, %1630 : i32 loc(#loc50)
    %1635 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1636 = llvm.select %1634, %1630, %1635 : i1, i32 loc(#loc50)
    %1637 = llvm.xor %1631, %1636 : i32 loc(#loc50)
    %1638 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1639 = llvm.and %1521, %1638 : i32 loc(#loc50)
    %1640 = llvm.icmp "eq" %1639, %1630 : i32 loc(#loc50)
    %1641 = llvm.mlir.constant(36 : i32) : i32 loc(#loc50)
    %1642 = llvm.select %1640, %1630, %1641 : i1, i32 loc(#loc50)
    %1643 = llvm.xor %1637, %1642 : i32 loc(#loc50)
    %1644 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1645 = llvm.and %1521, %1644 : i32 loc(#loc50)
    %1646 = llvm.icmp "eq" %1645, %1630 : i32 loc(#loc50)
    %1647 = llvm.mlir.constant(72 : i32) : i32 loc(#loc50)
    %1648 = llvm.select %1646, %1630, %1647 : i1, i32 loc(#loc50)
    %1649 = llvm.xor %1643, %1648 : i32 loc(#loc50)
    %1650 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1651 = llvm.and %1521, %1650 : i32 loc(#loc50)
    %1652 = llvm.icmp "eq" %1651, %1630 : i32 loc(#loc50)
    %1653 = llvm.mlir.constant(128 : i32) : i32 loc(#loc50)
    %1654 = llvm.select %1652, %1630, %1653 : i1, i32 loc(#loc50)
    %1655 = llvm.xor %1649, %1654 : i32 loc(#loc50)
    %1656 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1657 = llvm.and %1521, %1656 : i32 loc(#loc50)
    %1658 = llvm.icmp "eq" %1657, %1630 : i32 loc(#loc50)
    %1659 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1660 = llvm.select %1658, %1630, %1659 : i1, i32 loc(#loc50)
    %1661 = llvm.xor %1655, %1660 : i32 loc(#loc50)
    %1662 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1663 = llvm.and %1522, %1662 : i32 loc(#loc50)
    %1664 = llvm.icmp "eq" %1663, %1630 : i32 loc(#loc50)
    %1665 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1666 = llvm.and %1522, %1665 : i32 loc(#loc50)
    %1667 = llvm.icmp "eq" %1666, %1630 : i32 loc(#loc50)
    %1668 = llvm.mlir.constant(256 : i32) : i32 loc(#loc50)
    %1669 = llvm.select %1667, %1630, %1668 : i1, i32 loc(#loc50)
    %1670 = llvm.xor %1661, %1669 : i32 loc(#loc50)
    %1671 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1672 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1673 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1674 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1675 = llvm.and %1521, %1674 : i32 loc(#loc50)
    %1676 = llvm.icmp "eq" %1675, %1672 : i32 loc(#loc50)
    %1677 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1678 = llvm.select %1676, %1672, %1677 : i1, i32 loc(#loc50)
    %1679 = llvm.xor %1672, %1678 : i32 loc(#loc50)
    %1680 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1681 = llvm.and %1521, %1680 : i32 loc(#loc50)
    %1682 = llvm.icmp "eq" %1681, %1672 : i32 loc(#loc50)
    %1683 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1684 = llvm.select %1682, %1672, %1683 : i1, i32 loc(#loc50)
    %1685 = llvm.xor %1673, %1684 : i32 loc(#loc50)
    %1686 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1687 = llvm.select %1682, %1672, %1686 : i1, i32 loc(#loc50)
    %1688 = llvm.xor %1679, %1687 : i32 loc(#loc50)
    %1689 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1690 = llvm.and %1521, %1689 : i32 loc(#loc50)
    %1691 = llvm.icmp "eq" %1690, %1672 : i32 loc(#loc50)
    %1692 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1693 = llvm.select %1691, %1672, %1692 : i1, i32 loc(#loc50)
    %1694 = llvm.xor %1685, %1693 : i32 loc(#loc50)
    %1695 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1696 = llvm.select %1691, %1672, %1695 : i1, i32 loc(#loc50)
    %1697 = llvm.xor %1688, %1696 : i32 loc(#loc50)
    %1698 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1699 = llvm.and %1521, %1698 : i32 loc(#loc50)
    %1700 = llvm.icmp "eq" %1699, %1672 : i32 loc(#loc50)
    %1701 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %1702 = llvm.select %1700, %1672, %1701 : i1, i32 loc(#loc50)
    %1703 = llvm.xor %1697, %1702 : i32 loc(#loc50)
    %1704 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1705 = llvm.and %1521, %1704 : i32 loc(#loc50)
    %1706 = llvm.icmp "eq" %1705, %1672 : i32 loc(#loc50)
    %1707 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %1708 = llvm.select %1706, %1672, %1707 : i1, i32 loc(#loc50)
    %1709 = llvm.xor %1694, %1708 : i32 loc(#loc50)
    %1710 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %1711 = llvm.and %1522, %1710 : i32 loc(#loc50)
    %1712 = llvm.icmp "eq" %1711, %1672 : i32 loc(#loc50)
    %1713 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %1714 = llvm.and %1522, %1713 : i32 loc(#loc50)
    %1715 = llvm.icmp "eq" %1714, %1672 : i32 loc(#loc50)
    %1716 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %1717 = llvm.select %1715, %1672, %1716 : i1, i32 loc(#loc50)
    %1718 = llvm.xor %1703, %1717 : i32 loc(#loc50)
    %1719 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1720 = llvm.mul %1709, %1627 : i32 loc(#loc50)
    %1721 = llvm.add %1719, %1720 : i32 loc(#loc50)
    %1722 = llvm.mul %1718, %1628 : i32 loc(#loc50)
    %1723 = llvm.add %1721, %1722 : i32 loc(#loc50)
    %1724 = llvm.getelementptr inbounds %1516[%1723] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %1725 = nvgpu.ldmatrix %1724 : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc50)
    %1726 = llvm.extractvalue %1725[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc50)
    %1727 = llvm.extractvalue %1725[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc50)
    %1728 = llvm.extractvalue %1725[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc50)
    %1729 = llvm.extractvalue %1725[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc50)
    %1730 = llvm.bitcast %1622 : i32 to vector<1xf32> loc(#loc50)
    %1731 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1732 = llvm.extractelement %1730[%1731 : i32] : vector<1xf32> loc(#loc50)
    %1733 = llvm.bitcast %1623 : i32 to vector<1xf32> loc(#loc50)
    %1734 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1735 = llvm.extractelement %1733[%1734 : i32] : vector<1xf32> loc(#loc50)
    %1736 = llvm.bitcast %1624 : i32 to vector<1xf32> loc(#loc50)
    %1737 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1738 = llvm.extractelement %1736[%1737 : i32] : vector<1xf32> loc(#loc50)
    %1739 = llvm.bitcast %1625 : i32 to vector<1xf32> loc(#loc50)
    %1740 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1741 = llvm.extractelement %1739[%1740 : i32] : vector<1xf32> loc(#loc50)
    %1742 = llvm.bitcast %1726 : i32 to vector<1xf32> loc(#loc50)
    %1743 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1744 = llvm.extractelement %1742[%1743 : i32] : vector<1xf32> loc(#loc50)
    %1745 = llvm.bitcast %1727 : i32 to vector<1xf32> loc(#loc50)
    %1746 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1747 = llvm.extractelement %1745[%1746 : i32] : vector<1xf32> loc(#loc50)
    %1748 = llvm.bitcast %1728 : i32 to vector<1xf32> loc(#loc50)
    %1749 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1750 = llvm.extractelement %1748[%1749 : i32] : vector<1xf32> loc(#loc50)
    %1751 = llvm.bitcast %1729 : i32 to vector<1xf32> loc(#loc50)
    %1752 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %1753 = llvm.extractelement %1751[%1752 : i32] : vector<1xf32> loc(#loc50)
    %1754 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc50)
    %1755 = llvm.insertvalue %1732, %1754[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc50)
    %1756 = llvm.insertvalue %1735, %1755[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc50)
    %1757 = llvm.insertvalue %1738, %1756[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc50)
    %1758 = llvm.insertvalue %1741, %1757[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc50)
    %1759 = llvm.insertvalue %1744, %1758[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc50)
    %1760 = llvm.insertvalue %1747, %1759[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc50)
    %1761 = llvm.insertvalue %1750, %1760[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc50)
    %1762 = llvm.insertvalue %1753, %1761[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc50)
    %1763 = llvm.extractvalue %748[0] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %1764 = llvm.extractvalue %748[1] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %1765 = llvm.extractvalue %748[2] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %1766 = llvm.extractvalue %748[3] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %1767 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1768 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %1769 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %1770 = llvm.add %9, %1765 : i32 loc(#loc51)
    %1771 = llvm.add %9, %1766 : i32 loc(#loc51)
    %1772 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1773 = llvm.mul %1493, %1769 : i32 loc(#loc51)
    %1774 = llvm.add %1772, %1773 : i32 loc(#loc51)
    %1775 = llvm.mul %9, %1768 : i32 loc(#loc51)
    %1776 = llvm.add %1774, %1775 : i32 loc(#loc51)
    %1777 = llvm.mul %9, %1767 : i32 loc(#loc51)
    %1778 = llvm.add %1776, %1777 : i32 loc(#loc51)
    %1779 = llvm.getelementptr %1763[%1778] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %1780 = llvm.mlir.undef : !llvm.struct<(ptr<3>, i32, i32)> loc(#loc51)
    %1781 = llvm.insertvalue %1779, %1780[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1782 = llvm.insertvalue %1770, %1781[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1783 = llvm.insertvalue %1771, %1782[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1784 = llvm.extractvalue %1783[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1785 = llvm.extractvalue %1783[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1786 = llvm.extractvalue %1783[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %1787 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc51)
    %1788 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %1789 = llvm.urem %1787, %1788 : i32 loc(#loc51)
    %1790 = llvm.udiv %1787, %1788 : i32 loc(#loc51)
    %1791 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1792 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1793 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1794 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %1795 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %1796 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1797 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1798 = llvm.and %1789, %1797 : i32 loc(#loc51)
    %1799 = llvm.icmp "eq" %1798, %1796 : i32 loc(#loc51)
    %1800 = llvm.mlir.constant(40 : i32) : i32 loc(#loc51)
    %1801 = llvm.select %1799, %1796, %1800 : i1, i32 loc(#loc51)
    %1802 = llvm.xor %1796, %1801 : i32 loc(#loc51)
    %1803 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1804 = llvm.and %1789, %1803 : i32 loc(#loc51)
    %1805 = llvm.icmp "eq" %1804, %1796 : i32 loc(#loc51)
    %1806 = llvm.mlir.constant(80 : i32) : i32 loc(#loc51)
    %1807 = llvm.select %1805, %1796, %1806 : i1, i32 loc(#loc51)
    %1808 = llvm.xor %1802, %1807 : i32 loc(#loc51)
    %1809 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1810 = llvm.and %1789, %1809 : i32 loc(#loc51)
    %1811 = llvm.icmp "eq" %1810, %1796 : i32 loc(#loc51)
    %1812 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1813 = llvm.select %1811, %1796, %1812 : i1, i32 loc(#loc51)
    %1814 = llvm.xor %1808, %1813 : i32 loc(#loc51)
    %1815 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1816 = llvm.and %1789, %1815 : i32 loc(#loc51)
    %1817 = llvm.icmp "eq" %1816, %1796 : i32 loc(#loc51)
    %1818 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1819 = llvm.select %1817, %1796, %1818 : i1, i32 loc(#loc51)
    %1820 = llvm.xor %1814, %1819 : i32 loc(#loc51)
    %1821 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1822 = llvm.and %1789, %1821 : i32 loc(#loc51)
    %1823 = llvm.icmp "eq" %1822, %1796 : i32 loc(#loc51)
    %1824 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1825 = llvm.select %1823, %1796, %1824 : i1, i32 loc(#loc51)
    %1826 = llvm.xor %1820, %1825 : i32 loc(#loc51)
    %1827 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1828 = llvm.and %1790, %1827 : i32 loc(#loc51)
    %1829 = llvm.icmp "eq" %1828, %1796 : i32 loc(#loc51)
    %1830 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1831 = llvm.select %1829, %1796, %1830 : i1, i32 loc(#loc51)
    %1832 = llvm.xor %1826, %1831 : i32 loc(#loc51)
    %1833 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1834 = llvm.and %1790, %1833 : i32 loc(#loc51)
    %1835 = llvm.icmp "eq" %1834, %1796 : i32 loc(#loc51)
    %1836 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1837 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1838 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1839 = llvm.and %1789, %1838 : i32 loc(#loc51)
    %1840 = llvm.icmp "eq" %1839, %1837 : i32 loc(#loc51)
    %1841 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1842 = llvm.select %1840, %1837, %1841 : i1, i32 loc(#loc51)
    %1843 = llvm.xor %1837, %1842 : i32 loc(#loc51)
    %1844 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1845 = llvm.select %1840, %1837, %1844 : i1, i32 loc(#loc51)
    %1846 = llvm.xor %1837, %1845 : i32 loc(#loc51)
    %1847 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1848 = llvm.and %1789, %1847 : i32 loc(#loc51)
    %1849 = llvm.icmp "eq" %1848, %1837 : i32 loc(#loc51)
    %1850 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1851 = llvm.select %1849, %1837, %1850 : i1, i32 loc(#loc51)
    %1852 = llvm.xor %1843, %1851 : i32 loc(#loc51)
    %1853 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1854 = llvm.select %1849, %1837, %1853 : i1, i32 loc(#loc51)
    %1855 = llvm.xor %1846, %1854 : i32 loc(#loc51)
    %1856 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1857 = llvm.and %1789, %1856 : i32 loc(#loc51)
    %1858 = llvm.icmp "eq" %1857, %1837 : i32 loc(#loc51)
    %1859 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1860 = llvm.select %1858, %1837, %1859 : i1, i32 loc(#loc51)
    %1861 = llvm.xor %1852, %1860 : i32 loc(#loc51)
    %1862 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1863 = llvm.and %1789, %1862 : i32 loc(#loc51)
    %1864 = llvm.icmp "eq" %1863, %1837 : i32 loc(#loc51)
    %1865 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1866 = llvm.select %1864, %1837, %1865 : i1, i32 loc(#loc51)
    %1867 = llvm.xor %1861, %1866 : i32 loc(#loc51)
    %1868 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1869 = llvm.and %1789, %1868 : i32 loc(#loc51)
    %1870 = llvm.icmp "eq" %1869, %1837 : i32 loc(#loc51)
    %1871 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1872 = llvm.select %1870, %1837, %1871 : i1, i32 loc(#loc51)
    %1873 = llvm.xor %1867, %1872 : i32 loc(#loc51)
    %1874 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1875 = llvm.and %1790, %1874 : i32 loc(#loc51)
    %1876 = llvm.icmp "eq" %1875, %1837 : i32 loc(#loc51)
    %1877 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1878 = llvm.select %1876, %1837, %1877 : i1, i32 loc(#loc51)
    %1879 = llvm.xor %1873, %1878 : i32 loc(#loc51)
    %1880 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1881 = llvm.and %1790, %1880 : i32 loc(#loc51)
    %1882 = llvm.icmp "eq" %1881, %1837 : i32 loc(#loc51)
    %1883 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1884 = llvm.mul %1879, %1793 : i32 loc(#loc51)
    %1885 = llvm.add %1883, %1884 : i32 loc(#loc51)
    %1886 = llvm.mul %1855, %1794 : i32 loc(#loc51)
    %1887 = llvm.add %1885, %1886 : i32 loc(#loc51)
    %1888 = llvm.getelementptr inbounds %1784[%1887] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %1889 = llvm.load %1888 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc51)
    %1890 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1891 = llvm.extractelement %1889[%1890 : i32] : vector<1xf32> loc(#loc51)
    %1892 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1893 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1894 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %1895 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %1896 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1897 = llvm.mlir.constant(128 : i32) : i32 loc(#loc51)
    %1898 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1899 = llvm.and %1789, %1898 : i32 loc(#loc51)
    %1900 = llvm.icmp "eq" %1899, %1896 : i32 loc(#loc51)
    %1901 = llvm.mlir.constant(40 : i32) : i32 loc(#loc51)
    %1902 = llvm.select %1900, %1896, %1901 : i1, i32 loc(#loc51)
    %1903 = llvm.xor %1897, %1902 : i32 loc(#loc51)
    %1904 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1905 = llvm.and %1789, %1904 : i32 loc(#loc51)
    %1906 = llvm.icmp "eq" %1905, %1896 : i32 loc(#loc51)
    %1907 = llvm.mlir.constant(80 : i32) : i32 loc(#loc51)
    %1908 = llvm.select %1906, %1896, %1907 : i1, i32 loc(#loc51)
    %1909 = llvm.xor %1903, %1908 : i32 loc(#loc51)
    %1910 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1911 = llvm.and %1789, %1910 : i32 loc(#loc51)
    %1912 = llvm.icmp "eq" %1911, %1896 : i32 loc(#loc51)
    %1913 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1914 = llvm.select %1912, %1896, %1913 : i1, i32 loc(#loc51)
    %1915 = llvm.xor %1909, %1914 : i32 loc(#loc51)
    %1916 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1917 = llvm.and %1789, %1916 : i32 loc(#loc51)
    %1918 = llvm.icmp "eq" %1917, %1896 : i32 loc(#loc51)
    %1919 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1920 = llvm.select %1918, %1896, %1919 : i1, i32 loc(#loc51)
    %1921 = llvm.xor %1915, %1920 : i32 loc(#loc51)
    %1922 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1923 = llvm.and %1789, %1922 : i32 loc(#loc51)
    %1924 = llvm.icmp "eq" %1923, %1896 : i32 loc(#loc51)
    %1925 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1926 = llvm.select %1924, %1896, %1925 : i1, i32 loc(#loc51)
    %1927 = llvm.xor %1921, %1926 : i32 loc(#loc51)
    %1928 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1929 = llvm.and %1790, %1928 : i32 loc(#loc51)
    %1930 = llvm.icmp "eq" %1929, %1896 : i32 loc(#loc51)
    %1931 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1932 = llvm.select %1930, %1896, %1931 : i1, i32 loc(#loc51)
    %1933 = llvm.xor %1927, %1932 : i32 loc(#loc51)
    %1934 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1935 = llvm.and %1790, %1934 : i32 loc(#loc51)
    %1936 = llvm.icmp "eq" %1935, %1896 : i32 loc(#loc51)
    %1937 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1938 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1939 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1940 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1941 = llvm.and %1789, %1940 : i32 loc(#loc51)
    %1942 = llvm.icmp "eq" %1941, %1938 : i32 loc(#loc51)
    %1943 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1944 = llvm.select %1942, %1938, %1943 : i1, i32 loc(#loc51)
    %1945 = llvm.xor %1938, %1944 : i32 loc(#loc51)
    %1946 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1947 = llvm.select %1942, %1938, %1946 : i1, i32 loc(#loc51)
    %1948 = llvm.xor %1939, %1947 : i32 loc(#loc51)
    %1949 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1950 = llvm.and %1789, %1949 : i32 loc(#loc51)
    %1951 = llvm.icmp "eq" %1950, %1938 : i32 loc(#loc51)
    %1952 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1953 = llvm.select %1951, %1938, %1952 : i1, i32 loc(#loc51)
    %1954 = llvm.xor %1945, %1953 : i32 loc(#loc51)
    %1955 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1956 = llvm.select %1951, %1938, %1955 : i1, i32 loc(#loc51)
    %1957 = llvm.xor %1948, %1956 : i32 loc(#loc51)
    %1958 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1959 = llvm.and %1789, %1958 : i32 loc(#loc51)
    %1960 = llvm.icmp "eq" %1959, %1938 : i32 loc(#loc51)
    %1961 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1962 = llvm.select %1960, %1938, %1961 : i1, i32 loc(#loc51)
    %1963 = llvm.xor %1954, %1962 : i32 loc(#loc51)
    %1964 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1965 = llvm.and %1789, %1964 : i32 loc(#loc51)
    %1966 = llvm.icmp "eq" %1965, %1938 : i32 loc(#loc51)
    %1967 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1968 = llvm.select %1966, %1938, %1967 : i1, i32 loc(#loc51)
    %1969 = llvm.xor %1963, %1968 : i32 loc(#loc51)
    %1970 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %1971 = llvm.and %1789, %1970 : i32 loc(#loc51)
    %1972 = llvm.icmp "eq" %1971, %1938 : i32 loc(#loc51)
    %1973 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %1974 = llvm.select %1972, %1938, %1973 : i1, i32 loc(#loc51)
    %1975 = llvm.xor %1969, %1974 : i32 loc(#loc51)
    %1976 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1977 = llvm.and %1790, %1976 : i32 loc(#loc51)
    %1978 = llvm.icmp "eq" %1977, %1938 : i32 loc(#loc51)
    %1979 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %1980 = llvm.select %1978, %1938, %1979 : i1, i32 loc(#loc51)
    %1981 = llvm.xor %1975, %1980 : i32 loc(#loc51)
    %1982 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1983 = llvm.and %1790, %1982 : i32 loc(#loc51)
    %1984 = llvm.icmp "eq" %1983, %1938 : i32 loc(#loc51)
    %1985 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1986 = llvm.mul %1981, %1893 : i32 loc(#loc51)
    %1987 = llvm.add %1985, %1986 : i32 loc(#loc51)
    %1988 = llvm.mul %1957, %1894 : i32 loc(#loc51)
    %1989 = llvm.add %1987, %1988 : i32 loc(#loc51)
    %1990 = llvm.getelementptr inbounds %1784[%1989] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %1991 = llvm.load %1990 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc51)
    %1992 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1993 = llvm.extractelement %1991[%1992 : i32] : vector<1xf32> loc(#loc51)
    %1994 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %1995 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %1996 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %1997 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %1998 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %1999 = llvm.mlir.constant(256 : i32) : i32 loc(#loc51)
    %2000 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2001 = llvm.and %1789, %2000 : i32 loc(#loc51)
    %2002 = llvm.icmp "eq" %2001, %1998 : i32 loc(#loc51)
    %2003 = llvm.mlir.constant(40 : i32) : i32 loc(#loc51)
    %2004 = llvm.select %2002, %1998, %2003 : i1, i32 loc(#loc51)
    %2005 = llvm.xor %1999, %2004 : i32 loc(#loc51)
    %2006 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2007 = llvm.and %1789, %2006 : i32 loc(#loc51)
    %2008 = llvm.icmp "eq" %2007, %1998 : i32 loc(#loc51)
    %2009 = llvm.mlir.constant(80 : i32) : i32 loc(#loc51)
    %2010 = llvm.select %2008, %1998, %2009 : i1, i32 loc(#loc51)
    %2011 = llvm.xor %2005, %2010 : i32 loc(#loc51)
    %2012 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2013 = llvm.and %1789, %2012 : i32 loc(#loc51)
    %2014 = llvm.icmp "eq" %2013, %1998 : i32 loc(#loc51)
    %2015 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2016 = llvm.select %2014, %1998, %2015 : i1, i32 loc(#loc51)
    %2017 = llvm.xor %2011, %2016 : i32 loc(#loc51)
    %2018 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2019 = llvm.and %1789, %2018 : i32 loc(#loc51)
    %2020 = llvm.icmp "eq" %2019, %1998 : i32 loc(#loc51)
    %2021 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2022 = llvm.select %2020, %1998, %2021 : i1, i32 loc(#loc51)
    %2023 = llvm.xor %2017, %2022 : i32 loc(#loc51)
    %2024 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2025 = llvm.and %1789, %2024 : i32 loc(#loc51)
    %2026 = llvm.icmp "eq" %2025, %1998 : i32 loc(#loc51)
    %2027 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2028 = llvm.select %2026, %1998, %2027 : i1, i32 loc(#loc51)
    %2029 = llvm.xor %2023, %2028 : i32 loc(#loc51)
    %2030 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2031 = llvm.and %1790, %2030 : i32 loc(#loc51)
    %2032 = llvm.icmp "eq" %2031, %1998 : i32 loc(#loc51)
    %2033 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2034 = llvm.select %2032, %1998, %2033 : i1, i32 loc(#loc51)
    %2035 = llvm.xor %2029, %2034 : i32 loc(#loc51)
    %2036 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2037 = llvm.and %1790, %2036 : i32 loc(#loc51)
    %2038 = llvm.icmp "eq" %2037, %1998 : i32 loc(#loc51)
    %2039 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2040 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2041 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2042 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2043 = llvm.and %1789, %2042 : i32 loc(#loc51)
    %2044 = llvm.icmp "eq" %2043, %2040 : i32 loc(#loc51)
    %2045 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2046 = llvm.select %2044, %2040, %2045 : i1, i32 loc(#loc51)
    %2047 = llvm.xor %2040, %2046 : i32 loc(#loc51)
    %2048 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2049 = llvm.select %2044, %2040, %2048 : i1, i32 loc(#loc51)
    %2050 = llvm.xor %2041, %2049 : i32 loc(#loc51)
    %2051 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2052 = llvm.and %1789, %2051 : i32 loc(#loc51)
    %2053 = llvm.icmp "eq" %2052, %2040 : i32 loc(#loc51)
    %2054 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2055 = llvm.select %2053, %2040, %2054 : i1, i32 loc(#loc51)
    %2056 = llvm.xor %2047, %2055 : i32 loc(#loc51)
    %2057 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2058 = llvm.select %2053, %2040, %2057 : i1, i32 loc(#loc51)
    %2059 = llvm.xor %2050, %2058 : i32 loc(#loc51)
    %2060 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2061 = llvm.and %1789, %2060 : i32 loc(#loc51)
    %2062 = llvm.icmp "eq" %2061, %2040 : i32 loc(#loc51)
    %2063 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2064 = llvm.select %2062, %2040, %2063 : i1, i32 loc(#loc51)
    %2065 = llvm.xor %2056, %2064 : i32 loc(#loc51)
    %2066 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2067 = llvm.and %1789, %2066 : i32 loc(#loc51)
    %2068 = llvm.icmp "eq" %2067, %2040 : i32 loc(#loc51)
    %2069 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2070 = llvm.select %2068, %2040, %2069 : i1, i32 loc(#loc51)
    %2071 = llvm.xor %2065, %2070 : i32 loc(#loc51)
    %2072 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2073 = llvm.and %1789, %2072 : i32 loc(#loc51)
    %2074 = llvm.icmp "eq" %2073, %2040 : i32 loc(#loc51)
    %2075 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2076 = llvm.select %2074, %2040, %2075 : i1, i32 loc(#loc51)
    %2077 = llvm.xor %2071, %2076 : i32 loc(#loc51)
    %2078 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2079 = llvm.and %1790, %2078 : i32 loc(#loc51)
    %2080 = llvm.icmp "eq" %2079, %2040 : i32 loc(#loc51)
    %2081 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2082 = llvm.select %2080, %2040, %2081 : i1, i32 loc(#loc51)
    %2083 = llvm.xor %2077, %2082 : i32 loc(#loc51)
    %2084 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2085 = llvm.and %1790, %2084 : i32 loc(#loc51)
    %2086 = llvm.icmp "eq" %2085, %2040 : i32 loc(#loc51)
    %2087 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2088 = llvm.mul %2083, %1995 : i32 loc(#loc51)
    %2089 = llvm.add %2087, %2088 : i32 loc(#loc51)
    %2090 = llvm.mul %2059, %1996 : i32 loc(#loc51)
    %2091 = llvm.add %2089, %2090 : i32 loc(#loc51)
    %2092 = llvm.getelementptr inbounds %1784[%2091] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %2093 = llvm.load %2092 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc51)
    %2094 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2095 = llvm.extractelement %2093[%2094 : i32] : vector<1xf32> loc(#loc51)
    %2096 = llvm.mlir.constant(3 : i32) : i32 loc(#loc51)
    %2097 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2098 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %2099 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %2100 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2101 = llvm.mlir.constant(384 : i32) : i32 loc(#loc51)
    %2102 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2103 = llvm.and %1789, %2102 : i32 loc(#loc51)
    %2104 = llvm.icmp "eq" %2103, %2100 : i32 loc(#loc51)
    %2105 = llvm.mlir.constant(40 : i32) : i32 loc(#loc51)
    %2106 = llvm.select %2104, %2100, %2105 : i1, i32 loc(#loc51)
    %2107 = llvm.xor %2101, %2106 : i32 loc(#loc51)
    %2108 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2109 = llvm.and %1789, %2108 : i32 loc(#loc51)
    %2110 = llvm.icmp "eq" %2109, %2100 : i32 loc(#loc51)
    %2111 = llvm.mlir.constant(80 : i32) : i32 loc(#loc51)
    %2112 = llvm.select %2110, %2100, %2111 : i1, i32 loc(#loc51)
    %2113 = llvm.xor %2107, %2112 : i32 loc(#loc51)
    %2114 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2115 = llvm.and %1789, %2114 : i32 loc(#loc51)
    %2116 = llvm.icmp "eq" %2115, %2100 : i32 loc(#loc51)
    %2117 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2118 = llvm.select %2116, %2100, %2117 : i1, i32 loc(#loc51)
    %2119 = llvm.xor %2113, %2118 : i32 loc(#loc51)
    %2120 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2121 = llvm.and %1789, %2120 : i32 loc(#loc51)
    %2122 = llvm.icmp "eq" %2121, %2100 : i32 loc(#loc51)
    %2123 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2124 = llvm.select %2122, %2100, %2123 : i1, i32 loc(#loc51)
    %2125 = llvm.xor %2119, %2124 : i32 loc(#loc51)
    %2126 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2127 = llvm.and %1789, %2126 : i32 loc(#loc51)
    %2128 = llvm.icmp "eq" %2127, %2100 : i32 loc(#loc51)
    %2129 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2130 = llvm.select %2128, %2100, %2129 : i1, i32 loc(#loc51)
    %2131 = llvm.xor %2125, %2130 : i32 loc(#loc51)
    %2132 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2133 = llvm.and %1790, %2132 : i32 loc(#loc51)
    %2134 = llvm.icmp "eq" %2133, %2100 : i32 loc(#loc51)
    %2135 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2136 = llvm.select %2134, %2100, %2135 : i1, i32 loc(#loc51)
    %2137 = llvm.xor %2131, %2136 : i32 loc(#loc51)
    %2138 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2139 = llvm.and %1790, %2138 : i32 loc(#loc51)
    %2140 = llvm.icmp "eq" %2139, %2100 : i32 loc(#loc51)
    %2141 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2142 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2143 = llvm.mlir.constant(12 : i32) : i32 loc(#loc51)
    %2144 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2145 = llvm.and %1789, %2144 : i32 loc(#loc51)
    %2146 = llvm.icmp "eq" %2145, %2142 : i32 loc(#loc51)
    %2147 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2148 = llvm.select %2146, %2142, %2147 : i1, i32 loc(#loc51)
    %2149 = llvm.xor %2142, %2148 : i32 loc(#loc51)
    %2150 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2151 = llvm.select %2146, %2142, %2150 : i1, i32 loc(#loc51)
    %2152 = llvm.xor %2143, %2151 : i32 loc(#loc51)
    %2153 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2154 = llvm.and %1789, %2153 : i32 loc(#loc51)
    %2155 = llvm.icmp "eq" %2154, %2142 : i32 loc(#loc51)
    %2156 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2157 = llvm.select %2155, %2142, %2156 : i1, i32 loc(#loc51)
    %2158 = llvm.xor %2149, %2157 : i32 loc(#loc51)
    %2159 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2160 = llvm.select %2155, %2142, %2159 : i1, i32 loc(#loc51)
    %2161 = llvm.xor %2152, %2160 : i32 loc(#loc51)
    %2162 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2163 = llvm.and %1789, %2162 : i32 loc(#loc51)
    %2164 = llvm.icmp "eq" %2163, %2142 : i32 loc(#loc51)
    %2165 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2166 = llvm.select %2164, %2142, %2165 : i1, i32 loc(#loc51)
    %2167 = llvm.xor %2158, %2166 : i32 loc(#loc51)
    %2168 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2169 = llvm.and %1789, %2168 : i32 loc(#loc51)
    %2170 = llvm.icmp "eq" %2169, %2142 : i32 loc(#loc51)
    %2171 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2172 = llvm.select %2170, %2142, %2171 : i1, i32 loc(#loc51)
    %2173 = llvm.xor %2167, %2172 : i32 loc(#loc51)
    %2174 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2175 = llvm.and %1789, %2174 : i32 loc(#loc51)
    %2176 = llvm.icmp "eq" %2175, %2142 : i32 loc(#loc51)
    %2177 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2178 = llvm.select %2176, %2142, %2177 : i1, i32 loc(#loc51)
    %2179 = llvm.xor %2173, %2178 : i32 loc(#loc51)
    %2180 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2181 = llvm.and %1790, %2180 : i32 loc(#loc51)
    %2182 = llvm.icmp "eq" %2181, %2142 : i32 loc(#loc51)
    %2183 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2184 = llvm.select %2182, %2142, %2183 : i1, i32 loc(#loc51)
    %2185 = llvm.xor %2179, %2184 : i32 loc(#loc51)
    %2186 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2187 = llvm.and %1790, %2186 : i32 loc(#loc51)
    %2188 = llvm.icmp "eq" %2187, %2142 : i32 loc(#loc51)
    %2189 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2190 = llvm.mul %2185, %2097 : i32 loc(#loc51)
    %2191 = llvm.add %2189, %2190 : i32 loc(#loc51)
    %2192 = llvm.mul %2161, %2098 : i32 loc(#loc51)
    %2193 = llvm.add %2191, %2192 : i32 loc(#loc51)
    %2194 = llvm.getelementptr inbounds %1784[%2193] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %2195 = llvm.load %2194 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc51)
    %2196 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2197 = llvm.extractelement %2195[%2196 : i32] : vector<1xf32> loc(#loc51)
    %2198 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2199 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2200 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %2201 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %2202 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2203 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2204 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2205 = llvm.and %1789, %2204 : i32 loc(#loc51)
    %2206 = llvm.icmp "eq" %2205, %2202 : i32 loc(#loc51)
    %2207 = llvm.mlir.constant(40 : i32) : i32 loc(#loc51)
    %2208 = llvm.select %2206, %2202, %2207 : i1, i32 loc(#loc51)
    %2209 = llvm.xor %2203, %2208 : i32 loc(#loc51)
    %2210 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2211 = llvm.and %1789, %2210 : i32 loc(#loc51)
    %2212 = llvm.icmp "eq" %2211, %2202 : i32 loc(#loc51)
    %2213 = llvm.mlir.constant(80 : i32) : i32 loc(#loc51)
    %2214 = llvm.select %2212, %2202, %2213 : i1, i32 loc(#loc51)
    %2215 = llvm.xor %2209, %2214 : i32 loc(#loc51)
    %2216 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2217 = llvm.and %1789, %2216 : i32 loc(#loc51)
    %2218 = llvm.icmp "eq" %2217, %2202 : i32 loc(#loc51)
    %2219 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2220 = llvm.select %2218, %2202, %2219 : i1, i32 loc(#loc51)
    %2221 = llvm.xor %2215, %2220 : i32 loc(#loc51)
    %2222 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2223 = llvm.and %1789, %2222 : i32 loc(#loc51)
    %2224 = llvm.icmp "eq" %2223, %2202 : i32 loc(#loc51)
    %2225 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2226 = llvm.select %2224, %2202, %2225 : i1, i32 loc(#loc51)
    %2227 = llvm.xor %2221, %2226 : i32 loc(#loc51)
    %2228 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2229 = llvm.and %1789, %2228 : i32 loc(#loc51)
    %2230 = llvm.icmp "eq" %2229, %2202 : i32 loc(#loc51)
    %2231 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2232 = llvm.select %2230, %2202, %2231 : i1, i32 loc(#loc51)
    %2233 = llvm.xor %2227, %2232 : i32 loc(#loc51)
    %2234 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2235 = llvm.and %1790, %2234 : i32 loc(#loc51)
    %2236 = llvm.icmp "eq" %2235, %2202 : i32 loc(#loc51)
    %2237 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2238 = llvm.select %2236, %2202, %2237 : i1, i32 loc(#loc51)
    %2239 = llvm.xor %2233, %2238 : i32 loc(#loc51)
    %2240 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2241 = llvm.and %1790, %2240 : i32 loc(#loc51)
    %2242 = llvm.icmp "eq" %2241, %2202 : i32 loc(#loc51)
    %2243 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2244 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2245 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2246 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2247 = llvm.and %1789, %2246 : i32 loc(#loc51)
    %2248 = llvm.icmp "eq" %2247, %2244 : i32 loc(#loc51)
    %2249 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2250 = llvm.select %2248, %2244, %2249 : i1, i32 loc(#loc51)
    %2251 = llvm.xor %2245, %2250 : i32 loc(#loc51)
    %2252 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2253 = llvm.select %2248, %2244, %2252 : i1, i32 loc(#loc51)
    %2254 = llvm.xor %2244, %2253 : i32 loc(#loc51)
    %2255 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2256 = llvm.and %1789, %2255 : i32 loc(#loc51)
    %2257 = llvm.icmp "eq" %2256, %2244 : i32 loc(#loc51)
    %2258 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2259 = llvm.select %2257, %2244, %2258 : i1, i32 loc(#loc51)
    %2260 = llvm.xor %2251, %2259 : i32 loc(#loc51)
    %2261 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2262 = llvm.select %2257, %2244, %2261 : i1, i32 loc(#loc51)
    %2263 = llvm.xor %2254, %2262 : i32 loc(#loc51)
    %2264 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2265 = llvm.and %1789, %2264 : i32 loc(#loc51)
    %2266 = llvm.icmp "eq" %2265, %2244 : i32 loc(#loc51)
    %2267 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2268 = llvm.select %2266, %2244, %2267 : i1, i32 loc(#loc51)
    %2269 = llvm.xor %2260, %2268 : i32 loc(#loc51)
    %2270 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2271 = llvm.and %1789, %2270 : i32 loc(#loc51)
    %2272 = llvm.icmp "eq" %2271, %2244 : i32 loc(#loc51)
    %2273 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2274 = llvm.select %2272, %2244, %2273 : i1, i32 loc(#loc51)
    %2275 = llvm.xor %2269, %2274 : i32 loc(#loc51)
    %2276 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2277 = llvm.and %1789, %2276 : i32 loc(#loc51)
    %2278 = llvm.icmp "eq" %2277, %2244 : i32 loc(#loc51)
    %2279 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2280 = llvm.select %2278, %2244, %2279 : i1, i32 loc(#loc51)
    %2281 = llvm.xor %2275, %2280 : i32 loc(#loc51)
    %2282 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2283 = llvm.and %1790, %2282 : i32 loc(#loc51)
    %2284 = llvm.icmp "eq" %2283, %2244 : i32 loc(#loc51)
    %2285 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2286 = llvm.select %2284, %2244, %2285 : i1, i32 loc(#loc51)
    %2287 = llvm.xor %2281, %2286 : i32 loc(#loc51)
    %2288 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2289 = llvm.and %1790, %2288 : i32 loc(#loc51)
    %2290 = llvm.icmp "eq" %2289, %2244 : i32 loc(#loc51)
    %2291 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2292 = llvm.mul %2287, %2199 : i32 loc(#loc51)
    %2293 = llvm.add %2291, %2292 : i32 loc(#loc51)
    %2294 = llvm.mul %2263, %2200 : i32 loc(#loc51)
    %2295 = llvm.add %2293, %2294 : i32 loc(#loc51)
    %2296 = llvm.getelementptr inbounds %1784[%2295] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %2297 = llvm.load %2296 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc51)
    %2298 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2299 = llvm.extractelement %2297[%2298 : i32] : vector<1xf32> loc(#loc51)
    %2300 = llvm.mlir.constant(5 : i32) : i32 loc(#loc51)
    %2301 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2302 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %2303 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %2304 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2305 = llvm.mlir.constant(144 : i32) : i32 loc(#loc51)
    %2306 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2307 = llvm.and %1789, %2306 : i32 loc(#loc51)
    %2308 = llvm.icmp "eq" %2307, %2304 : i32 loc(#loc51)
    %2309 = llvm.mlir.constant(40 : i32) : i32 loc(#loc51)
    %2310 = llvm.select %2308, %2304, %2309 : i1, i32 loc(#loc51)
    %2311 = llvm.xor %2305, %2310 : i32 loc(#loc51)
    %2312 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2313 = llvm.and %1789, %2312 : i32 loc(#loc51)
    %2314 = llvm.icmp "eq" %2313, %2304 : i32 loc(#loc51)
    %2315 = llvm.mlir.constant(80 : i32) : i32 loc(#loc51)
    %2316 = llvm.select %2314, %2304, %2315 : i1, i32 loc(#loc51)
    %2317 = llvm.xor %2311, %2316 : i32 loc(#loc51)
    %2318 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2319 = llvm.and %1789, %2318 : i32 loc(#loc51)
    %2320 = llvm.icmp "eq" %2319, %2304 : i32 loc(#loc51)
    %2321 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2322 = llvm.select %2320, %2304, %2321 : i1, i32 loc(#loc51)
    %2323 = llvm.xor %2317, %2322 : i32 loc(#loc51)
    %2324 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2325 = llvm.and %1789, %2324 : i32 loc(#loc51)
    %2326 = llvm.icmp "eq" %2325, %2304 : i32 loc(#loc51)
    %2327 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2328 = llvm.select %2326, %2304, %2327 : i1, i32 loc(#loc51)
    %2329 = llvm.xor %2323, %2328 : i32 loc(#loc51)
    %2330 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2331 = llvm.and %1789, %2330 : i32 loc(#loc51)
    %2332 = llvm.icmp "eq" %2331, %2304 : i32 loc(#loc51)
    %2333 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2334 = llvm.select %2332, %2304, %2333 : i1, i32 loc(#loc51)
    %2335 = llvm.xor %2329, %2334 : i32 loc(#loc51)
    %2336 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2337 = llvm.and %1790, %2336 : i32 loc(#loc51)
    %2338 = llvm.icmp "eq" %2337, %2304 : i32 loc(#loc51)
    %2339 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2340 = llvm.select %2338, %2304, %2339 : i1, i32 loc(#loc51)
    %2341 = llvm.xor %2335, %2340 : i32 loc(#loc51)
    %2342 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2343 = llvm.and %1790, %2342 : i32 loc(#loc51)
    %2344 = llvm.icmp "eq" %2343, %2304 : i32 loc(#loc51)
    %2345 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2346 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2347 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2348 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2349 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2350 = llvm.and %1789, %2349 : i32 loc(#loc51)
    %2351 = llvm.icmp "eq" %2350, %2346 : i32 loc(#loc51)
    %2352 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2353 = llvm.select %2351, %2346, %2352 : i1, i32 loc(#loc51)
    %2354 = llvm.xor %2347, %2353 : i32 loc(#loc51)
    %2355 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2356 = llvm.select %2351, %2346, %2355 : i1, i32 loc(#loc51)
    %2357 = llvm.xor %2348, %2356 : i32 loc(#loc51)
    %2358 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2359 = llvm.and %1789, %2358 : i32 loc(#loc51)
    %2360 = llvm.icmp "eq" %2359, %2346 : i32 loc(#loc51)
    %2361 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2362 = llvm.select %2360, %2346, %2361 : i1, i32 loc(#loc51)
    %2363 = llvm.xor %2354, %2362 : i32 loc(#loc51)
    %2364 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2365 = llvm.select %2360, %2346, %2364 : i1, i32 loc(#loc51)
    %2366 = llvm.xor %2357, %2365 : i32 loc(#loc51)
    %2367 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2368 = llvm.and %1789, %2367 : i32 loc(#loc51)
    %2369 = llvm.icmp "eq" %2368, %2346 : i32 loc(#loc51)
    %2370 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2371 = llvm.select %2369, %2346, %2370 : i1, i32 loc(#loc51)
    %2372 = llvm.xor %2363, %2371 : i32 loc(#loc51)
    %2373 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2374 = llvm.and %1789, %2373 : i32 loc(#loc51)
    %2375 = llvm.icmp "eq" %2374, %2346 : i32 loc(#loc51)
    %2376 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2377 = llvm.select %2375, %2346, %2376 : i1, i32 loc(#loc51)
    %2378 = llvm.xor %2372, %2377 : i32 loc(#loc51)
    %2379 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2380 = llvm.and %1789, %2379 : i32 loc(#loc51)
    %2381 = llvm.icmp "eq" %2380, %2346 : i32 loc(#loc51)
    %2382 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2383 = llvm.select %2381, %2346, %2382 : i1, i32 loc(#loc51)
    %2384 = llvm.xor %2378, %2383 : i32 loc(#loc51)
    %2385 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2386 = llvm.and %1790, %2385 : i32 loc(#loc51)
    %2387 = llvm.icmp "eq" %2386, %2346 : i32 loc(#loc51)
    %2388 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2389 = llvm.select %2387, %2346, %2388 : i1, i32 loc(#loc51)
    %2390 = llvm.xor %2384, %2389 : i32 loc(#loc51)
    %2391 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2392 = llvm.and %1790, %2391 : i32 loc(#loc51)
    %2393 = llvm.icmp "eq" %2392, %2346 : i32 loc(#loc51)
    %2394 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2395 = llvm.mul %2390, %2301 : i32 loc(#loc51)
    %2396 = llvm.add %2394, %2395 : i32 loc(#loc51)
    %2397 = llvm.mul %2366, %2302 : i32 loc(#loc51)
    %2398 = llvm.add %2396, %2397 : i32 loc(#loc51)
    %2399 = llvm.getelementptr inbounds %1784[%2398] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %2400 = llvm.load %2399 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc51)
    %2401 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2402 = llvm.extractelement %2400[%2401 : i32] : vector<1xf32> loc(#loc51)
    %2403 = llvm.mlir.constant(6 : i32) : i32 loc(#loc51)
    %2404 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2405 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %2406 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %2407 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2408 = llvm.mlir.constant(272 : i32) : i32 loc(#loc51)
    %2409 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2410 = llvm.and %1789, %2409 : i32 loc(#loc51)
    %2411 = llvm.icmp "eq" %2410, %2407 : i32 loc(#loc51)
    %2412 = llvm.mlir.constant(40 : i32) : i32 loc(#loc51)
    %2413 = llvm.select %2411, %2407, %2412 : i1, i32 loc(#loc51)
    %2414 = llvm.xor %2408, %2413 : i32 loc(#loc51)
    %2415 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2416 = llvm.and %1789, %2415 : i32 loc(#loc51)
    %2417 = llvm.icmp "eq" %2416, %2407 : i32 loc(#loc51)
    %2418 = llvm.mlir.constant(80 : i32) : i32 loc(#loc51)
    %2419 = llvm.select %2417, %2407, %2418 : i1, i32 loc(#loc51)
    %2420 = llvm.xor %2414, %2419 : i32 loc(#loc51)
    %2421 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2422 = llvm.and %1789, %2421 : i32 loc(#loc51)
    %2423 = llvm.icmp "eq" %2422, %2407 : i32 loc(#loc51)
    %2424 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2425 = llvm.select %2423, %2407, %2424 : i1, i32 loc(#loc51)
    %2426 = llvm.xor %2420, %2425 : i32 loc(#loc51)
    %2427 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2428 = llvm.and %1789, %2427 : i32 loc(#loc51)
    %2429 = llvm.icmp "eq" %2428, %2407 : i32 loc(#loc51)
    %2430 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2431 = llvm.select %2429, %2407, %2430 : i1, i32 loc(#loc51)
    %2432 = llvm.xor %2426, %2431 : i32 loc(#loc51)
    %2433 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2434 = llvm.and %1789, %2433 : i32 loc(#loc51)
    %2435 = llvm.icmp "eq" %2434, %2407 : i32 loc(#loc51)
    %2436 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2437 = llvm.select %2435, %2407, %2436 : i1, i32 loc(#loc51)
    %2438 = llvm.xor %2432, %2437 : i32 loc(#loc51)
    %2439 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2440 = llvm.and %1790, %2439 : i32 loc(#loc51)
    %2441 = llvm.icmp "eq" %2440, %2407 : i32 loc(#loc51)
    %2442 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2443 = llvm.select %2441, %2407, %2442 : i1, i32 loc(#loc51)
    %2444 = llvm.xor %2438, %2443 : i32 loc(#loc51)
    %2445 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2446 = llvm.and %1790, %2445 : i32 loc(#loc51)
    %2447 = llvm.icmp "eq" %2446, %2407 : i32 loc(#loc51)
    %2448 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2449 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2450 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2451 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2452 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2453 = llvm.and %1789, %2452 : i32 loc(#loc51)
    %2454 = llvm.icmp "eq" %2453, %2449 : i32 loc(#loc51)
    %2455 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2456 = llvm.select %2454, %2449, %2455 : i1, i32 loc(#loc51)
    %2457 = llvm.xor %2450, %2456 : i32 loc(#loc51)
    %2458 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2459 = llvm.select %2454, %2449, %2458 : i1, i32 loc(#loc51)
    %2460 = llvm.xor %2451, %2459 : i32 loc(#loc51)
    %2461 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2462 = llvm.and %1789, %2461 : i32 loc(#loc51)
    %2463 = llvm.icmp "eq" %2462, %2449 : i32 loc(#loc51)
    %2464 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2465 = llvm.select %2463, %2449, %2464 : i1, i32 loc(#loc51)
    %2466 = llvm.xor %2457, %2465 : i32 loc(#loc51)
    %2467 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2468 = llvm.select %2463, %2449, %2467 : i1, i32 loc(#loc51)
    %2469 = llvm.xor %2460, %2468 : i32 loc(#loc51)
    %2470 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2471 = llvm.and %1789, %2470 : i32 loc(#loc51)
    %2472 = llvm.icmp "eq" %2471, %2449 : i32 loc(#loc51)
    %2473 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2474 = llvm.select %2472, %2449, %2473 : i1, i32 loc(#loc51)
    %2475 = llvm.xor %2466, %2474 : i32 loc(#loc51)
    %2476 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2477 = llvm.and %1789, %2476 : i32 loc(#loc51)
    %2478 = llvm.icmp "eq" %2477, %2449 : i32 loc(#loc51)
    %2479 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2480 = llvm.select %2478, %2449, %2479 : i1, i32 loc(#loc51)
    %2481 = llvm.xor %2475, %2480 : i32 loc(#loc51)
    %2482 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2483 = llvm.and %1789, %2482 : i32 loc(#loc51)
    %2484 = llvm.icmp "eq" %2483, %2449 : i32 loc(#loc51)
    %2485 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2486 = llvm.select %2484, %2449, %2485 : i1, i32 loc(#loc51)
    %2487 = llvm.xor %2481, %2486 : i32 loc(#loc51)
    %2488 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2489 = llvm.and %1790, %2488 : i32 loc(#loc51)
    %2490 = llvm.icmp "eq" %2489, %2449 : i32 loc(#loc51)
    %2491 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2492 = llvm.select %2490, %2449, %2491 : i1, i32 loc(#loc51)
    %2493 = llvm.xor %2487, %2492 : i32 loc(#loc51)
    %2494 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2495 = llvm.and %1790, %2494 : i32 loc(#loc51)
    %2496 = llvm.icmp "eq" %2495, %2449 : i32 loc(#loc51)
    %2497 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2498 = llvm.mul %2493, %2404 : i32 loc(#loc51)
    %2499 = llvm.add %2497, %2498 : i32 loc(#loc51)
    %2500 = llvm.mul %2469, %2405 : i32 loc(#loc51)
    %2501 = llvm.add %2499, %2500 : i32 loc(#loc51)
    %2502 = llvm.getelementptr inbounds %1784[%2501] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %2503 = llvm.load %2502 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc51)
    %2504 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2505 = llvm.extractelement %2503[%2504 : i32] : vector<1xf32> loc(#loc51)
    %2506 = llvm.mlir.constant(7 : i32) : i32 loc(#loc51)
    %2507 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2508 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %2509 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %2510 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2511 = llvm.mlir.constant(400 : i32) : i32 loc(#loc51)
    %2512 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2513 = llvm.and %1789, %2512 : i32 loc(#loc51)
    %2514 = llvm.icmp "eq" %2513, %2510 : i32 loc(#loc51)
    %2515 = llvm.mlir.constant(40 : i32) : i32 loc(#loc51)
    %2516 = llvm.select %2514, %2510, %2515 : i1, i32 loc(#loc51)
    %2517 = llvm.xor %2511, %2516 : i32 loc(#loc51)
    %2518 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2519 = llvm.and %1789, %2518 : i32 loc(#loc51)
    %2520 = llvm.icmp "eq" %2519, %2510 : i32 loc(#loc51)
    %2521 = llvm.mlir.constant(80 : i32) : i32 loc(#loc51)
    %2522 = llvm.select %2520, %2510, %2521 : i1, i32 loc(#loc51)
    %2523 = llvm.xor %2517, %2522 : i32 loc(#loc51)
    %2524 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2525 = llvm.and %1789, %2524 : i32 loc(#loc51)
    %2526 = llvm.icmp "eq" %2525, %2510 : i32 loc(#loc51)
    %2527 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2528 = llvm.select %2526, %2510, %2527 : i1, i32 loc(#loc51)
    %2529 = llvm.xor %2523, %2528 : i32 loc(#loc51)
    %2530 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2531 = llvm.and %1789, %2530 : i32 loc(#loc51)
    %2532 = llvm.icmp "eq" %2531, %2510 : i32 loc(#loc51)
    %2533 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2534 = llvm.select %2532, %2510, %2533 : i1, i32 loc(#loc51)
    %2535 = llvm.xor %2529, %2534 : i32 loc(#loc51)
    %2536 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2537 = llvm.and %1789, %2536 : i32 loc(#loc51)
    %2538 = llvm.icmp "eq" %2537, %2510 : i32 loc(#loc51)
    %2539 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2540 = llvm.select %2538, %2510, %2539 : i1, i32 loc(#loc51)
    %2541 = llvm.xor %2535, %2540 : i32 loc(#loc51)
    %2542 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2543 = llvm.and %1790, %2542 : i32 loc(#loc51)
    %2544 = llvm.icmp "eq" %2543, %2510 : i32 loc(#loc51)
    %2545 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2546 = llvm.select %2544, %2510, %2545 : i1, i32 loc(#loc51)
    %2547 = llvm.xor %2541, %2546 : i32 loc(#loc51)
    %2548 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2549 = llvm.and %1790, %2548 : i32 loc(#loc51)
    %2550 = llvm.icmp "eq" %2549, %2510 : i32 loc(#loc51)
    %2551 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2552 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2553 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2554 = llvm.mlir.constant(12 : i32) : i32 loc(#loc51)
    %2555 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2556 = llvm.and %1789, %2555 : i32 loc(#loc51)
    %2557 = llvm.icmp "eq" %2556, %2552 : i32 loc(#loc51)
    %2558 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2559 = llvm.select %2557, %2552, %2558 : i1, i32 loc(#loc51)
    %2560 = llvm.xor %2553, %2559 : i32 loc(#loc51)
    %2561 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2562 = llvm.select %2557, %2552, %2561 : i1, i32 loc(#loc51)
    %2563 = llvm.xor %2554, %2562 : i32 loc(#loc51)
    %2564 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2565 = llvm.and %1789, %2564 : i32 loc(#loc51)
    %2566 = llvm.icmp "eq" %2565, %2552 : i32 loc(#loc51)
    %2567 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2568 = llvm.select %2566, %2552, %2567 : i1, i32 loc(#loc51)
    %2569 = llvm.xor %2560, %2568 : i32 loc(#loc51)
    %2570 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2571 = llvm.select %2566, %2552, %2570 : i1, i32 loc(#loc51)
    %2572 = llvm.xor %2563, %2571 : i32 loc(#loc51)
    %2573 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2574 = llvm.and %1789, %2573 : i32 loc(#loc51)
    %2575 = llvm.icmp "eq" %2574, %2552 : i32 loc(#loc51)
    %2576 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2577 = llvm.select %2575, %2552, %2576 : i1, i32 loc(#loc51)
    %2578 = llvm.xor %2569, %2577 : i32 loc(#loc51)
    %2579 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2580 = llvm.and %1789, %2579 : i32 loc(#loc51)
    %2581 = llvm.icmp "eq" %2580, %2552 : i32 loc(#loc51)
    %2582 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2583 = llvm.select %2581, %2552, %2582 : i1, i32 loc(#loc51)
    %2584 = llvm.xor %2578, %2583 : i32 loc(#loc51)
    %2585 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %2586 = llvm.and %1789, %2585 : i32 loc(#loc51)
    %2587 = llvm.icmp "eq" %2586, %2552 : i32 loc(#loc51)
    %2588 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %2589 = llvm.select %2587, %2552, %2588 : i1, i32 loc(#loc51)
    %2590 = llvm.xor %2584, %2589 : i32 loc(#loc51)
    %2591 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %2592 = llvm.and %1790, %2591 : i32 loc(#loc51)
    %2593 = llvm.icmp "eq" %2592, %2552 : i32 loc(#loc51)
    %2594 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %2595 = llvm.select %2593, %2552, %2594 : i1, i32 loc(#loc51)
    %2596 = llvm.xor %2590, %2595 : i32 loc(#loc51)
    %2597 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %2598 = llvm.and %1790, %2597 : i32 loc(#loc51)
    %2599 = llvm.icmp "eq" %2598, %2552 : i32 loc(#loc51)
    %2600 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2601 = llvm.mul %2596, %2507 : i32 loc(#loc51)
    %2602 = llvm.add %2600, %2601 : i32 loc(#loc51)
    %2603 = llvm.mul %2572, %2508 : i32 loc(#loc51)
    %2604 = llvm.add %2602, %2603 : i32 loc(#loc51)
    %2605 = llvm.getelementptr inbounds %1784[%2604] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %2606 = llvm.load %2605 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc51)
    %2607 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %2608 = llvm.extractelement %2606[%2607 : i32] : vector<1xf32> loc(#loc51)
    %2609 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc51)
    %2610 = llvm.insertvalue %1891, %2609[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %2611 = llvm.insertvalue %1993, %2610[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %2612 = llvm.insertvalue %2095, %2611[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %2613 = llvm.insertvalue %2197, %2612[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %2614 = llvm.insertvalue %2299, %2613[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %2615 = llvm.insertvalue %2402, %2614[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %2616 = llvm.insertvalue %2505, %2615[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %2617 = llvm.insertvalue %2608, %2616[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %2618 = llvm.extractvalue %1762[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2619 = llvm.extractvalue %1762[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2620 = llvm.extractvalue %1762[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2621 = llvm.extractvalue %1762[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2622 = llvm.extractvalue %1762[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2623 = llvm.extractvalue %1762[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2624 = llvm.extractvalue %1762[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2625 = llvm.extractvalue %1762[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2626 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2627 = llvm.bitcast %2618 : f32 to f32 loc(#loc54)
    %2628 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2629 = llvm.insertelement %2627, %2626[%2628 : i32] : vector<1xf32> loc(#loc54)
    %2630 = llvm.bitcast %2629 : vector<1xf32> to i32 loc(#loc54)
    %2631 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2632 = llvm.bitcast %2619 : f32 to f32 loc(#loc54)
    %2633 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2634 = llvm.insertelement %2632, %2631[%2633 : i32] : vector<1xf32> loc(#loc54)
    %2635 = llvm.bitcast %2634 : vector<1xf32> to i32 loc(#loc54)
    %2636 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2637 = llvm.bitcast %2620 : f32 to f32 loc(#loc54)
    %2638 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2639 = llvm.insertelement %2637, %2636[%2638 : i32] : vector<1xf32> loc(#loc54)
    %2640 = llvm.bitcast %2639 : vector<1xf32> to i32 loc(#loc54)
    %2641 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2642 = llvm.bitcast %2621 : f32 to f32 loc(#loc54)
    %2643 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2644 = llvm.insertelement %2642, %2641[%2643 : i32] : vector<1xf32> loc(#loc54)
    %2645 = llvm.bitcast %2644 : vector<1xf32> to i32 loc(#loc54)
    %2646 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2647 = llvm.bitcast %2622 : f32 to f32 loc(#loc54)
    %2648 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2649 = llvm.insertelement %2647, %2646[%2648 : i32] : vector<1xf32> loc(#loc54)
    %2650 = llvm.bitcast %2649 : vector<1xf32> to i32 loc(#loc54)
    %2651 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2652 = llvm.bitcast %2623 : f32 to f32 loc(#loc54)
    %2653 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2654 = llvm.insertelement %2652, %2651[%2653 : i32] : vector<1xf32> loc(#loc54)
    %2655 = llvm.bitcast %2654 : vector<1xf32> to i32 loc(#loc54)
    %2656 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2657 = llvm.bitcast %2624 : f32 to f32 loc(#loc54)
    %2658 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2659 = llvm.insertelement %2657, %2656[%2658 : i32] : vector<1xf32> loc(#loc54)
    %2660 = llvm.bitcast %2659 : vector<1xf32> to i32 loc(#loc54)
    %2661 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2662 = llvm.bitcast %2625 : f32 to f32 loc(#loc54)
    %2663 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2664 = llvm.insertelement %2662, %2661[%2663 : i32] : vector<1xf32> loc(#loc54)
    %2665 = llvm.bitcast %2664 : vector<1xf32> to i32 loc(#loc54)
    %2666 = llvm.extractvalue %2617[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2667 = llvm.extractvalue %2617[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2668 = llvm.extractvalue %2617[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2669 = llvm.extractvalue %2617[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2670 = llvm.extractvalue %2617[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2671 = llvm.extractvalue %2617[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2672 = llvm.extractvalue %2617[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2673 = llvm.extractvalue %2617[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2674 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2675 = llvm.bitcast %2666 : f32 to f32 loc(#loc54)
    %2676 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2677 = llvm.insertelement %2675, %2674[%2676 : i32] : vector<1xf32> loc(#loc54)
    %2678 = llvm.bitcast %2677 : vector<1xf32> to i32 loc(#loc54)
    %2679 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2680 = llvm.bitcast %2667 : f32 to f32 loc(#loc54)
    %2681 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2682 = llvm.insertelement %2680, %2679[%2681 : i32] : vector<1xf32> loc(#loc54)
    %2683 = llvm.bitcast %2682 : vector<1xf32> to i32 loc(#loc54)
    %2684 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2685 = llvm.bitcast %2668 : f32 to f32 loc(#loc54)
    %2686 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2687 = llvm.insertelement %2685, %2684[%2686 : i32] : vector<1xf32> loc(#loc54)
    %2688 = llvm.bitcast %2687 : vector<1xf32> to i32 loc(#loc54)
    %2689 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2690 = llvm.bitcast %2669 : f32 to f32 loc(#loc54)
    %2691 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2692 = llvm.insertelement %2690, %2689[%2691 : i32] : vector<1xf32> loc(#loc54)
    %2693 = llvm.bitcast %2692 : vector<1xf32> to i32 loc(#loc54)
    %2694 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2695 = llvm.bitcast %2670 : f32 to f32 loc(#loc54)
    %2696 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2697 = llvm.insertelement %2695, %2694[%2696 : i32] : vector<1xf32> loc(#loc54)
    %2698 = llvm.bitcast %2697 : vector<1xf32> to i32 loc(#loc54)
    %2699 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2700 = llvm.bitcast %2671 : f32 to f32 loc(#loc54)
    %2701 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2702 = llvm.insertelement %2700, %2699[%2701 : i32] : vector<1xf32> loc(#loc54)
    %2703 = llvm.bitcast %2702 : vector<1xf32> to i32 loc(#loc54)
    %2704 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2705 = llvm.bitcast %2672 : f32 to f32 loc(#loc54)
    %2706 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2707 = llvm.insertelement %2705, %2704[%2706 : i32] : vector<1xf32> loc(#loc54)
    %2708 = llvm.bitcast %2707 : vector<1xf32> to i32 loc(#loc54)
    %2709 = llvm.mlir.undef : vector<1xf32> loc(#loc54)
    %2710 = llvm.bitcast %2673 : f32 to f32 loc(#loc54)
    %2711 = llvm.mlir.constant(0 : i32) : i32 loc(#loc54)
    %2712 = llvm.insertelement %2710, %2709[%2711 : i32] : vector<1xf32> loc(#loc54)
    %2713 = llvm.bitcast %2712 : vector<1xf32> to i32 loc(#loc54)
    %2714 = llvm.extractvalue %1482[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2715 = llvm.extractvalue %1482[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2716 = llvm.extractvalue %1482[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2717 = llvm.extractvalue %1482[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2718 = llvm.extractvalue %1482[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2719 = llvm.extractvalue %1482[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2720 = llvm.extractvalue %1482[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2721 = llvm.extractvalue %1482[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2722 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %2714, %2715, %2716, %2717, %2630, %2635, %2640, %2645, %2678, %2683 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc54)
    %2723 = llvm.extractvalue %2722[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2724 = llvm.extractvalue %2722[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2725 = llvm.extractvalue %2722[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2726 = llvm.extractvalue %2722[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2727 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %2718, %2719, %2720, %2721, %2630, %2635, %2640, %2645, %2698, %2703 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc54)
    %2728 = llvm.extractvalue %2727[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2729 = llvm.extractvalue %2727[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2730 = llvm.extractvalue %2727[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2731 = llvm.extractvalue %2727[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2732 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %2723, %2724, %2725, %2726, %2650, %2655, %2660, %2665, %2688, %2693 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc54)
    %2733 = llvm.extractvalue %2732[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2734 = llvm.extractvalue %2732[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2735 = llvm.extractvalue %2732[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2736 = llvm.extractvalue %2732[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2737 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %2728, %2729, %2730, %2731, %2650, %2655, %2660, %2665, %2708, %2713 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc54)
    %2738 = llvm.extractvalue %2737[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2739 = llvm.extractvalue %2737[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2740 = llvm.extractvalue %2737[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2741 = llvm.extractvalue %2737[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc54)
    %2742 = llvm.bitcast %2733 : f32 to f32 loc(#loc54)
    %2743 = llvm.bitcast %2734 : f32 to f32 loc(#loc54)
    %2744 = llvm.bitcast %2735 : f32 to f32 loc(#loc54)
    %2745 = llvm.bitcast %2736 : f32 to f32 loc(#loc54)
    %2746 = llvm.bitcast %2738 : f32 to f32 loc(#loc54)
    %2747 = llvm.bitcast %2739 : f32 to f32 loc(#loc54)
    %2748 = llvm.bitcast %2740 : f32 to f32 loc(#loc54)
    %2749 = llvm.bitcast %2741 : f32 to f32 loc(#loc54)
    %2750 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc54)
    %2751 = llvm.insertvalue %2742, %2750[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2752 = llvm.insertvalue %2743, %2751[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2753 = llvm.insertvalue %2744, %2752[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2754 = llvm.insertvalue %2745, %2753[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2755 = llvm.insertvalue %2746, %2754[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2756 = llvm.insertvalue %2747, %2755[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2757 = llvm.insertvalue %2748, %2756[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2758 = llvm.insertvalue %2749, %2757[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc54)
    %2759 = builtin.unrealized_conversion_cast %2758 : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> to tensor<32x32xf32, #mma> loc(#loc54)
    %2760 = builtin.unrealized_conversion_cast %2759 : tensor<32x32xf32, #mma> to !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc2)
    %2761 = llvm.extractvalue %1483[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc55)
    %2762 = llvm.extractvalue %1483[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc55)
    %2763 = llvm.extractvalue %1483[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc55)
    %2764 = llvm.extractvalue %1483[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc55)
    %2765 = llvm.extractvalue %26[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc55)
    %2766 = llvm.extractvalue %26[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc55)
    %2767 = llvm.extractvalue %26[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc55)
    %2768 = llvm.extractvalue %26[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc55)
    %2769 = llvm.getelementptr %2761[%2765] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc55)
    %2770 = llvm.getelementptr %2762[%2766] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc55)
    %2771 = llvm.getelementptr %2763[%2767] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc55)
    %2772 = llvm.getelementptr %2764[%2768] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc55)
    %2773 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc55)
    %2774 = llvm.insertvalue %2769, %2773[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc55)
    %2775 = llvm.insertvalue %2770, %2774[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc55)
    %2776 = llvm.insertvalue %2771, %2775[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc55)
    %2777 = llvm.insertvalue %2772, %2776[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc55)
    %2778 = builtin.unrealized_conversion_cast %2777 : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> to tensor<32x16x!tt.ptr<f32>, #blocked> loc(#loc55)
    %2779 = builtin.unrealized_conversion_cast %2778 : tensor<32x16x!tt.ptr<f32>, #blocked> to !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc2)
    %2780 = llvm.extractvalue %1484[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc49)
    %2781 = llvm.extractvalue %1484[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc49)
    %2782 = llvm.extractvalue %1484[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc49)
    %2783 = llvm.extractvalue %1484[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc49)
    %2784 = llvm.extractvalue %730[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %2785 = llvm.extractvalue %730[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %2786 = llvm.extractvalue %730[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %2787 = llvm.extractvalue %730[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %2788 = llvm.getelementptr %2780[%2784] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc49)
    %2789 = llvm.getelementptr %2781[%2785] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc49)
    %2790 = llvm.getelementptr %2782[%2786] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc49)
    %2791 = llvm.getelementptr %2783[%2787] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc49)
    %2792 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc49)
    %2793 = llvm.insertvalue %2788, %2792[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc49)
    %2794 = llvm.insertvalue %2789, %2793[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc49)
    %2795 = llvm.insertvalue %2790, %2794[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc49)
    %2796 = llvm.insertvalue %2791, %2795[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc49)
    %2797 = builtin.unrealized_conversion_cast %2796 : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> to tensor<16x32x!tt.ptr<f32>, #blocked1> loc(#loc49)
    %2798 = builtin.unrealized_conversion_cast %2797 : tensor<16x32x!tt.ptr<f32>, #blocked1> to !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc2)
    %2799 = llvm.add %1485, %27 : i32 loc(#loc2)
    %2800 = llvm.icmp "slt" %2799, %27 : i32 loc(#loc2)
    %2801 = llvm.select %2800, %2799, %9 : i1, i32 loc(#loc2)
    %2802 = llvm.add %1481, %27 : i32 loc(#loc2)
    %2803 = llvm.mul %2802, %12 : i32 loc(#loc56)
    %2804 = llvm.sub %arg5, %2803 : i32 loc(#loc57)
    %2805 = llvm.bitcast %2804 : i32 to i32 loc(#loc52)
    %2806 = llvm.mlir.undef : !llvm.struct<(i32)> loc(#loc52)
    %2807 = llvm.insertvalue %2805, %2806[0] : !llvm.struct<(i32)>  loc(#loc52)
    %2808 = llvm.extractvalue %519[0] : !llvm.struct<(i32)>  loc(#loc52)
    %2809 = llvm.extractvalue %2807[0] : !llvm.struct<(i32)>  loc(#loc52)
    %2810 = llvm.icmp "slt" %2808, %2809 : i32 loc(#loc52)
    %2811 = llvm.mlir.undef : !llvm.struct<(i1)> loc(#loc52)
    %2812 = llvm.insertvalue %2810, %2811[0] : !llvm.struct<(i1)>  loc(#loc52)
    %2813 = llvm.extractvalue %2812[0] : !llvm.struct<(i1)>  loc(#loc50)
    %2814 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc50)
    %2815 = llvm.insertvalue %2813, %2814[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %2816 = llvm.insertvalue %2813, %2815[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %2817 = llvm.insertvalue %2813, %2816[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %2818 = llvm.insertvalue %2813, %2817[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %2819 = llvm.extractvalue %739[0] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %2820 = llvm.extractvalue %739[1] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %2821 = llvm.extractvalue %739[2] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %2822 = llvm.extractvalue %739[3] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc50)
    %2823 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2824 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %2825 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %2826 = llvm.add %9, %2821 : i32 loc(#loc50)
    %2827 = llvm.add %9, %2822 : i32 loc(#loc50)
    %2828 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %2829 = llvm.mul %2801, %2825 : i32 loc(#loc50)
    %2830 = llvm.add %2828, %2829 : i32 loc(#loc50)
    %2831 = llvm.mul %9, %2824 : i32 loc(#loc50)
    %2832 = llvm.add %2830, %2831 : i32 loc(#loc50)
    %2833 = llvm.mul %9, %2823 : i32 loc(#loc50)
    %2834 = llvm.add %2832, %2833 : i32 loc(#loc50)
    %2835 = llvm.getelementptr %2819[%2834] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %2836 = llvm.mlir.undef : !llvm.struct<(ptr<3>, i32, i32)> loc(#loc50)
    %2837 = llvm.insertvalue %2835, %2836[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %2838 = llvm.insertvalue %2826, %2837[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %2839 = llvm.insertvalue %2827, %2838[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %2840 = llvm.bitcast %1490 : i1 to i1 loc(#loc2)
    %2841 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc2)
    %2842 = llvm.insertvalue %2840, %2841[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2843 = llvm.insertvalue %2840, %2842[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2844 = llvm.insertvalue %2840, %2843[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2845 = llvm.insertvalue %2840, %2844[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2846 = llvm.extractvalue %2845[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2847 = llvm.extractvalue %2845[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2848 = llvm.extractvalue %2845[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2849 = llvm.extractvalue %2845[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2850 = llvm.extractvalue %2818[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2851 = llvm.extractvalue %2818[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2852 = llvm.extractvalue %2818[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2853 = llvm.extractvalue %2818[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2854 = llvm.and %2846, %2850 : i1 loc(#loc2)
    %2855 = llvm.and %2847, %2851 : i1 loc(#loc2)
    %2856 = llvm.and %2848, %2852 : i1 loc(#loc2)
    %2857 = llvm.and %2849, %2853 : i1 loc(#loc2)
    %2858 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc2)
    %2859 = llvm.insertvalue %2854, %2858[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2860 = llvm.insertvalue %2855, %2859[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2861 = llvm.insertvalue %2856, %2860[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %2862 = llvm.insertvalue %2857, %2861[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    nvvm.barrier0 loc(#loc50)
    %2863 = llvm.extractvalue %2777[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc50)
    %2864 = llvm.extractvalue %2777[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc50)
    %2865 = llvm.extractvalue %2777[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc50)
    %2866 = llvm.extractvalue %2777[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc50)
    %2867 = llvm.extractvalue %2839[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %2868 = llvm.extractvalue %2839[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %2869 = llvm.extractvalue %2839[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc50)
    %2870 = llvm.extractvalue %2862[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %2871 = llvm.extractvalue %2862[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %2872 = llvm.extractvalue %2862[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %2873 = llvm.extractvalue %2862[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc50)
    %2874 = llvm.extractvalue %19[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc50)
    %2875 = llvm.extractvalue %19[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc50)
    %2876 = llvm.extractvalue %19[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc50)
    %2877 = llvm.extractvalue %19[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc50)
    %2878 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc50)
    %2879 = llvm.mlir.constant(32 : i32) : i32 loc(#loc50)
    %2880 = llvm.urem %2878, %2879 : i32 loc(#loc50)
    %2881 = llvm.udiv %2878, %2879 : i32 loc(#loc50)
    %2882 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %2883 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %2884 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2885 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %2886 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %2887 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %2888 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2889 = llvm.and %2880, %2888 : i32 loc(#loc50)
    %2890 = llvm.icmp "eq" %2889, %2887 : i32 loc(#loc50)
    %2891 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2892 = llvm.select %2890, %2887, %2891 : i1, i32 loc(#loc50)
    %2893 = llvm.xor %2887, %2892 : i32 loc(#loc50)
    %2894 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %2895 = llvm.and %2880, %2894 : i32 loc(#loc50)
    %2896 = llvm.icmp "eq" %2895, %2887 : i32 loc(#loc50)
    %2897 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %2898 = llvm.select %2896, %2887, %2897 : i1, i32 loc(#loc50)
    %2899 = llvm.xor %2893, %2898 : i32 loc(#loc50)
    %2900 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %2901 = llvm.and %2880, %2900 : i32 loc(#loc50)
    %2902 = llvm.icmp "eq" %2901, %2887 : i32 loc(#loc50)
    %2903 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %2904 = llvm.select %2902, %2887, %2903 : i1, i32 loc(#loc50)
    %2905 = llvm.xor %2899, %2904 : i32 loc(#loc50)
    %2906 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %2907 = llvm.and %2880, %2906 : i32 loc(#loc50)
    %2908 = llvm.icmp "eq" %2907, %2887 : i32 loc(#loc50)
    %2909 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %2910 = llvm.select %2908, %2887, %2909 : i1, i32 loc(#loc50)
    %2911 = llvm.xor %2905, %2910 : i32 loc(#loc50)
    %2912 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %2913 = llvm.and %2880, %2912 : i32 loc(#loc50)
    %2914 = llvm.icmp "eq" %2913, %2887 : i32 loc(#loc50)
    %2915 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %2916 = llvm.select %2914, %2887, %2915 : i1, i32 loc(#loc50)
    %2917 = llvm.xor %2911, %2916 : i32 loc(#loc50)
    %2918 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2919 = llvm.and %2881, %2918 : i32 loc(#loc50)
    %2920 = llvm.icmp "eq" %2919, %2887 : i32 loc(#loc50)
    %2921 = llvm.mlir.constant(36 : i32) : i32 loc(#loc50)
    %2922 = llvm.select %2920, %2887, %2921 : i1, i32 loc(#loc50)
    %2923 = llvm.xor %2917, %2922 : i32 loc(#loc50)
    %2924 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %2925 = llvm.and %2881, %2924 : i32 loc(#loc50)
    %2926 = llvm.icmp "eq" %2925, %2887 : i32 loc(#loc50)
    %2927 = llvm.mlir.constant(72 : i32) : i32 loc(#loc50)
    %2928 = llvm.select %2926, %2887, %2927 : i1, i32 loc(#loc50)
    %2929 = llvm.xor %2923, %2928 : i32 loc(#loc50)
    %2930 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %2931 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %2932 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2933 = llvm.and %2880, %2932 : i32 loc(#loc50)
    %2934 = llvm.icmp "eq" %2933, %2931 : i32 loc(#loc50)
    %2935 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2936 = llvm.select %2934, %2931, %2935 : i1, i32 loc(#loc50)
    %2937 = llvm.xor %2931, %2936 : i32 loc(#loc50)
    %2938 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %2939 = llvm.and %2880, %2938 : i32 loc(#loc50)
    %2940 = llvm.icmp "eq" %2939, %2931 : i32 loc(#loc50)
    %2941 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %2942 = llvm.select %2940, %2931, %2941 : i1, i32 loc(#loc50)
    %2943 = llvm.xor %2937, %2942 : i32 loc(#loc50)
    %2944 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %2945 = llvm.and %2880, %2944 : i32 loc(#loc50)
    %2946 = llvm.icmp "eq" %2945, %2931 : i32 loc(#loc50)
    %2947 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %2948 = llvm.select %2946, %2931, %2947 : i1, i32 loc(#loc50)
    %2949 = llvm.xor %2943, %2948 : i32 loc(#loc50)
    %2950 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %2951 = llvm.and %2880, %2950 : i32 loc(#loc50)
    %2952 = llvm.icmp "eq" %2951, %2931 : i32 loc(#loc50)
    %2953 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %2954 = llvm.select %2952, %2931, %2953 : i1, i32 loc(#loc50)
    %2955 = llvm.xor %2949, %2954 : i32 loc(#loc50)
    %2956 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %2957 = llvm.and %2880, %2956 : i32 loc(#loc50)
    %2958 = llvm.icmp "eq" %2957, %2931 : i32 loc(#loc50)
    %2959 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2960 = llvm.select %2958, %2931, %2959 : i1, i32 loc(#loc50)
    %2961 = llvm.xor %2931, %2960 : i32 loc(#loc50)
    %2962 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2963 = llvm.and %2881, %2962 : i32 loc(#loc50)
    %2964 = llvm.icmp "eq" %2963, %2931 : i32 loc(#loc50)
    %2965 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %2966 = llvm.select %2964, %2931, %2965 : i1, i32 loc(#loc50)
    %2967 = llvm.xor %2955, %2966 : i32 loc(#loc50)
    %2968 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %2969 = llvm.select %2964, %2931, %2968 : i1, i32 loc(#loc50)
    %2970 = llvm.xor %2961, %2969 : i32 loc(#loc50)
    %2971 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %2972 = llvm.and %2881, %2971 : i32 loc(#loc50)
    %2973 = llvm.icmp "eq" %2972, %2931 : i32 loc(#loc50)
    %2974 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %2975 = llvm.select %2973, %2931, %2974 : i1, i32 loc(#loc50)
    %2976 = llvm.xor %2967, %2975 : i32 loc(#loc50)
    %2977 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %2978 = llvm.select %2973, %2931, %2977 : i1, i32 loc(#loc50)
    %2979 = llvm.xor %2970, %2978 : i32 loc(#loc50)
    %2980 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %2981 = llvm.mul %2976, %2884 : i32 loc(#loc50)
    %2982 = llvm.add %2980, %2981 : i32 loc(#loc50)
    %2983 = llvm.mul %2979, %2885 : i32 loc(#loc50)
    %2984 = llvm.add %2982, %2983 : i32 loc(#loc50)
    %2985 = llvm.getelementptr inbounds %2867[%2984] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %2986 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2987 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2988 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %2989 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %2990 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %2991 = llvm.mlir.constant(128 : i32) : i32 loc(#loc50)
    %2992 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2993 = llvm.and %2880, %2992 : i32 loc(#loc50)
    %2994 = llvm.icmp "eq" %2993, %2990 : i32 loc(#loc50)
    %2995 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %2996 = llvm.select %2994, %2990, %2995 : i1, i32 loc(#loc50)
    %2997 = llvm.xor %2991, %2996 : i32 loc(#loc50)
    %2998 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %2999 = llvm.and %2880, %2998 : i32 loc(#loc50)
    %3000 = llvm.icmp "eq" %2999, %2990 : i32 loc(#loc50)
    %3001 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3002 = llvm.select %3000, %2990, %3001 : i1, i32 loc(#loc50)
    %3003 = llvm.xor %2997, %3002 : i32 loc(#loc50)
    %3004 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3005 = llvm.and %2880, %3004 : i32 loc(#loc50)
    %3006 = llvm.icmp "eq" %3005, %2990 : i32 loc(#loc50)
    %3007 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3008 = llvm.select %3006, %2990, %3007 : i1, i32 loc(#loc50)
    %3009 = llvm.xor %3003, %3008 : i32 loc(#loc50)
    %3010 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3011 = llvm.and %2880, %3010 : i32 loc(#loc50)
    %3012 = llvm.icmp "eq" %3011, %2990 : i32 loc(#loc50)
    %3013 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3014 = llvm.select %3012, %2990, %3013 : i1, i32 loc(#loc50)
    %3015 = llvm.xor %3009, %3014 : i32 loc(#loc50)
    %3016 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3017 = llvm.and %2880, %3016 : i32 loc(#loc50)
    %3018 = llvm.icmp "eq" %3017, %2990 : i32 loc(#loc50)
    %3019 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3020 = llvm.select %3018, %2990, %3019 : i1, i32 loc(#loc50)
    %3021 = llvm.xor %3015, %3020 : i32 loc(#loc50)
    %3022 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3023 = llvm.and %2881, %3022 : i32 loc(#loc50)
    %3024 = llvm.icmp "eq" %3023, %2990 : i32 loc(#loc50)
    %3025 = llvm.mlir.constant(36 : i32) : i32 loc(#loc50)
    %3026 = llvm.select %3024, %2990, %3025 : i1, i32 loc(#loc50)
    %3027 = llvm.xor %3021, %3026 : i32 loc(#loc50)
    %3028 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3029 = llvm.and %2881, %3028 : i32 loc(#loc50)
    %3030 = llvm.icmp "eq" %3029, %2990 : i32 loc(#loc50)
    %3031 = llvm.mlir.constant(72 : i32) : i32 loc(#loc50)
    %3032 = llvm.select %3030, %2990, %3031 : i1, i32 loc(#loc50)
    %3033 = llvm.xor %3027, %3032 : i32 loc(#loc50)
    %3034 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3035 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3036 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3037 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3038 = llvm.and %2880, %3037 : i32 loc(#loc50)
    %3039 = llvm.icmp "eq" %3038, %3035 : i32 loc(#loc50)
    %3040 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3041 = llvm.select %3039, %3035, %3040 : i1, i32 loc(#loc50)
    %3042 = llvm.xor %3035, %3041 : i32 loc(#loc50)
    %3043 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3044 = llvm.and %2880, %3043 : i32 loc(#loc50)
    %3045 = llvm.icmp "eq" %3044, %3035 : i32 loc(#loc50)
    %3046 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3047 = llvm.select %3045, %3035, %3046 : i1, i32 loc(#loc50)
    %3048 = llvm.xor %3042, %3047 : i32 loc(#loc50)
    %3049 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3050 = llvm.and %2880, %3049 : i32 loc(#loc50)
    %3051 = llvm.icmp "eq" %3050, %3035 : i32 loc(#loc50)
    %3052 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3053 = llvm.select %3051, %3035, %3052 : i1, i32 loc(#loc50)
    %3054 = llvm.xor %3048, %3053 : i32 loc(#loc50)
    %3055 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3056 = llvm.and %2880, %3055 : i32 loc(#loc50)
    %3057 = llvm.icmp "eq" %3056, %3035 : i32 loc(#loc50)
    %3058 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3059 = llvm.select %3057, %3035, %3058 : i1, i32 loc(#loc50)
    %3060 = llvm.xor %3054, %3059 : i32 loc(#loc50)
    %3061 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3062 = llvm.and %2880, %3061 : i32 loc(#loc50)
    %3063 = llvm.icmp "eq" %3062, %3035 : i32 loc(#loc50)
    %3064 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3065 = llvm.select %3063, %3035, %3064 : i1, i32 loc(#loc50)
    %3066 = llvm.xor %3036, %3065 : i32 loc(#loc50)
    %3067 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3068 = llvm.and %2881, %3067 : i32 loc(#loc50)
    %3069 = llvm.icmp "eq" %3068, %3035 : i32 loc(#loc50)
    %3070 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3071 = llvm.select %3069, %3035, %3070 : i1, i32 loc(#loc50)
    %3072 = llvm.xor %3060, %3071 : i32 loc(#loc50)
    %3073 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3074 = llvm.select %3069, %3035, %3073 : i1, i32 loc(#loc50)
    %3075 = llvm.xor %3066, %3074 : i32 loc(#loc50)
    %3076 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3077 = llvm.and %2881, %3076 : i32 loc(#loc50)
    %3078 = llvm.icmp "eq" %3077, %3035 : i32 loc(#loc50)
    %3079 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3080 = llvm.select %3078, %3035, %3079 : i1, i32 loc(#loc50)
    %3081 = llvm.xor %3072, %3080 : i32 loc(#loc50)
    %3082 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3083 = llvm.select %3078, %3035, %3082 : i1, i32 loc(#loc50)
    %3084 = llvm.xor %3075, %3083 : i32 loc(#loc50)
    %3085 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3086 = llvm.mul %3081, %2987 : i32 loc(#loc50)
    %3087 = llvm.add %3085, %3086 : i32 loc(#loc50)
    %3088 = llvm.mul %3084, %2988 : i32 loc(#loc50)
    %3089 = llvm.add %3087, %3088 : i32 loc(#loc50)
    %3090 = llvm.getelementptr inbounds %2867[%3089] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %3091 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3092 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3093 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3094 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %3095 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3096 = llvm.mlir.constant(256 : i32) : i32 loc(#loc50)
    %3097 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3098 = llvm.and %2880, %3097 : i32 loc(#loc50)
    %3099 = llvm.icmp "eq" %3098, %3095 : i32 loc(#loc50)
    %3100 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3101 = llvm.select %3099, %3095, %3100 : i1, i32 loc(#loc50)
    %3102 = llvm.xor %3096, %3101 : i32 loc(#loc50)
    %3103 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3104 = llvm.and %2880, %3103 : i32 loc(#loc50)
    %3105 = llvm.icmp "eq" %3104, %3095 : i32 loc(#loc50)
    %3106 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3107 = llvm.select %3105, %3095, %3106 : i1, i32 loc(#loc50)
    %3108 = llvm.xor %3102, %3107 : i32 loc(#loc50)
    %3109 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3110 = llvm.and %2880, %3109 : i32 loc(#loc50)
    %3111 = llvm.icmp "eq" %3110, %3095 : i32 loc(#loc50)
    %3112 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3113 = llvm.select %3111, %3095, %3112 : i1, i32 loc(#loc50)
    %3114 = llvm.xor %3108, %3113 : i32 loc(#loc50)
    %3115 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3116 = llvm.and %2880, %3115 : i32 loc(#loc50)
    %3117 = llvm.icmp "eq" %3116, %3095 : i32 loc(#loc50)
    %3118 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3119 = llvm.select %3117, %3095, %3118 : i1, i32 loc(#loc50)
    %3120 = llvm.xor %3114, %3119 : i32 loc(#loc50)
    %3121 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3122 = llvm.and %2880, %3121 : i32 loc(#loc50)
    %3123 = llvm.icmp "eq" %3122, %3095 : i32 loc(#loc50)
    %3124 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3125 = llvm.select %3123, %3095, %3124 : i1, i32 loc(#loc50)
    %3126 = llvm.xor %3120, %3125 : i32 loc(#loc50)
    %3127 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3128 = llvm.and %2881, %3127 : i32 loc(#loc50)
    %3129 = llvm.icmp "eq" %3128, %3095 : i32 loc(#loc50)
    %3130 = llvm.mlir.constant(36 : i32) : i32 loc(#loc50)
    %3131 = llvm.select %3129, %3095, %3130 : i1, i32 loc(#loc50)
    %3132 = llvm.xor %3126, %3131 : i32 loc(#loc50)
    %3133 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3134 = llvm.and %2881, %3133 : i32 loc(#loc50)
    %3135 = llvm.icmp "eq" %3134, %3095 : i32 loc(#loc50)
    %3136 = llvm.mlir.constant(72 : i32) : i32 loc(#loc50)
    %3137 = llvm.select %3135, %3095, %3136 : i1, i32 loc(#loc50)
    %3138 = llvm.xor %3132, %3137 : i32 loc(#loc50)
    %3139 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3140 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3141 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3142 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3143 = llvm.and %2880, %3142 : i32 loc(#loc50)
    %3144 = llvm.icmp "eq" %3143, %3140 : i32 loc(#loc50)
    %3145 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3146 = llvm.select %3144, %3140, %3145 : i1, i32 loc(#loc50)
    %3147 = llvm.xor %3140, %3146 : i32 loc(#loc50)
    %3148 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3149 = llvm.and %2880, %3148 : i32 loc(#loc50)
    %3150 = llvm.icmp "eq" %3149, %3140 : i32 loc(#loc50)
    %3151 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3152 = llvm.select %3150, %3140, %3151 : i1, i32 loc(#loc50)
    %3153 = llvm.xor %3147, %3152 : i32 loc(#loc50)
    %3154 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3155 = llvm.and %2880, %3154 : i32 loc(#loc50)
    %3156 = llvm.icmp "eq" %3155, %3140 : i32 loc(#loc50)
    %3157 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3158 = llvm.select %3156, %3140, %3157 : i1, i32 loc(#loc50)
    %3159 = llvm.xor %3153, %3158 : i32 loc(#loc50)
    %3160 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3161 = llvm.and %2880, %3160 : i32 loc(#loc50)
    %3162 = llvm.icmp "eq" %3161, %3140 : i32 loc(#loc50)
    %3163 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3164 = llvm.select %3162, %3140, %3163 : i1, i32 loc(#loc50)
    %3165 = llvm.xor %3159, %3164 : i32 loc(#loc50)
    %3166 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3167 = llvm.and %2880, %3166 : i32 loc(#loc50)
    %3168 = llvm.icmp "eq" %3167, %3140 : i32 loc(#loc50)
    %3169 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3170 = llvm.select %3168, %3140, %3169 : i1, i32 loc(#loc50)
    %3171 = llvm.xor %3141, %3170 : i32 loc(#loc50)
    %3172 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3173 = llvm.and %2881, %3172 : i32 loc(#loc50)
    %3174 = llvm.icmp "eq" %3173, %3140 : i32 loc(#loc50)
    %3175 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3176 = llvm.select %3174, %3140, %3175 : i1, i32 loc(#loc50)
    %3177 = llvm.xor %3165, %3176 : i32 loc(#loc50)
    %3178 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3179 = llvm.select %3174, %3140, %3178 : i1, i32 loc(#loc50)
    %3180 = llvm.xor %3171, %3179 : i32 loc(#loc50)
    %3181 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3182 = llvm.and %2881, %3181 : i32 loc(#loc50)
    %3183 = llvm.icmp "eq" %3182, %3140 : i32 loc(#loc50)
    %3184 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3185 = llvm.select %3183, %3140, %3184 : i1, i32 loc(#loc50)
    %3186 = llvm.xor %3177, %3185 : i32 loc(#loc50)
    %3187 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3188 = llvm.select %3183, %3140, %3187 : i1, i32 loc(#loc50)
    %3189 = llvm.xor %3180, %3188 : i32 loc(#loc50)
    %3190 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3191 = llvm.mul %3186, %3092 : i32 loc(#loc50)
    %3192 = llvm.add %3190, %3191 : i32 loc(#loc50)
    %3193 = llvm.mul %3189, %3093 : i32 loc(#loc50)
    %3194 = llvm.add %3192, %3193 : i32 loc(#loc50)
    %3195 = llvm.getelementptr inbounds %2867[%3194] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %3196 = llvm.mlir.constant(3 : i32) : i32 loc(#loc50)
    %3197 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3198 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3199 = llvm.mlir.constant(512 : i32) : i32 loc(#loc50)
    %3200 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3201 = llvm.mlir.constant(384 : i32) : i32 loc(#loc50)
    %3202 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3203 = llvm.and %2880, %3202 : i32 loc(#loc50)
    %3204 = llvm.icmp "eq" %3203, %3200 : i32 loc(#loc50)
    %3205 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3206 = llvm.select %3204, %3200, %3205 : i1, i32 loc(#loc50)
    %3207 = llvm.xor %3201, %3206 : i32 loc(#loc50)
    %3208 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3209 = llvm.and %2880, %3208 : i32 loc(#loc50)
    %3210 = llvm.icmp "eq" %3209, %3200 : i32 loc(#loc50)
    %3211 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3212 = llvm.select %3210, %3200, %3211 : i1, i32 loc(#loc50)
    %3213 = llvm.xor %3207, %3212 : i32 loc(#loc50)
    %3214 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3215 = llvm.and %2880, %3214 : i32 loc(#loc50)
    %3216 = llvm.icmp "eq" %3215, %3200 : i32 loc(#loc50)
    %3217 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3218 = llvm.select %3216, %3200, %3217 : i1, i32 loc(#loc50)
    %3219 = llvm.xor %3213, %3218 : i32 loc(#loc50)
    %3220 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3221 = llvm.and %2880, %3220 : i32 loc(#loc50)
    %3222 = llvm.icmp "eq" %3221, %3200 : i32 loc(#loc50)
    %3223 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3224 = llvm.select %3222, %3200, %3223 : i1, i32 loc(#loc50)
    %3225 = llvm.xor %3219, %3224 : i32 loc(#loc50)
    %3226 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3227 = llvm.and %2880, %3226 : i32 loc(#loc50)
    %3228 = llvm.icmp "eq" %3227, %3200 : i32 loc(#loc50)
    %3229 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3230 = llvm.select %3228, %3200, %3229 : i1, i32 loc(#loc50)
    %3231 = llvm.xor %3225, %3230 : i32 loc(#loc50)
    %3232 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3233 = llvm.and %2881, %3232 : i32 loc(#loc50)
    %3234 = llvm.icmp "eq" %3233, %3200 : i32 loc(#loc50)
    %3235 = llvm.mlir.constant(36 : i32) : i32 loc(#loc50)
    %3236 = llvm.select %3234, %3200, %3235 : i1, i32 loc(#loc50)
    %3237 = llvm.xor %3231, %3236 : i32 loc(#loc50)
    %3238 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3239 = llvm.and %2881, %3238 : i32 loc(#loc50)
    %3240 = llvm.icmp "eq" %3239, %3200 : i32 loc(#loc50)
    %3241 = llvm.mlir.constant(72 : i32) : i32 loc(#loc50)
    %3242 = llvm.select %3240, %3200, %3241 : i1, i32 loc(#loc50)
    %3243 = llvm.xor %3237, %3242 : i32 loc(#loc50)
    %3244 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3245 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3246 = llvm.mlir.constant(24 : i32) : i32 loc(#loc50)
    %3247 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3248 = llvm.and %2880, %3247 : i32 loc(#loc50)
    %3249 = llvm.icmp "eq" %3248, %3245 : i32 loc(#loc50)
    %3250 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3251 = llvm.select %3249, %3245, %3250 : i1, i32 loc(#loc50)
    %3252 = llvm.xor %3245, %3251 : i32 loc(#loc50)
    %3253 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3254 = llvm.and %2880, %3253 : i32 loc(#loc50)
    %3255 = llvm.icmp "eq" %3254, %3245 : i32 loc(#loc50)
    %3256 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3257 = llvm.select %3255, %3245, %3256 : i1, i32 loc(#loc50)
    %3258 = llvm.xor %3252, %3257 : i32 loc(#loc50)
    %3259 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3260 = llvm.and %2880, %3259 : i32 loc(#loc50)
    %3261 = llvm.icmp "eq" %3260, %3245 : i32 loc(#loc50)
    %3262 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3263 = llvm.select %3261, %3245, %3262 : i1, i32 loc(#loc50)
    %3264 = llvm.xor %3258, %3263 : i32 loc(#loc50)
    %3265 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3266 = llvm.and %2880, %3265 : i32 loc(#loc50)
    %3267 = llvm.icmp "eq" %3266, %3245 : i32 loc(#loc50)
    %3268 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3269 = llvm.select %3267, %3245, %3268 : i1, i32 loc(#loc50)
    %3270 = llvm.xor %3264, %3269 : i32 loc(#loc50)
    %3271 = llvm.mlir.constant(16 : i32) : i32 loc(#loc50)
    %3272 = llvm.and %2880, %3271 : i32 loc(#loc50)
    %3273 = llvm.icmp "eq" %3272, %3245 : i32 loc(#loc50)
    %3274 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3275 = llvm.select %3273, %3245, %3274 : i1, i32 loc(#loc50)
    %3276 = llvm.xor %3246, %3275 : i32 loc(#loc50)
    %3277 = llvm.mlir.constant(1 : i32) : i32 loc(#loc50)
    %3278 = llvm.and %2881, %3277 : i32 loc(#loc50)
    %3279 = llvm.icmp "eq" %3278, %3245 : i32 loc(#loc50)
    %3280 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3281 = llvm.select %3279, %3245, %3280 : i1, i32 loc(#loc50)
    %3282 = llvm.xor %3270, %3281 : i32 loc(#loc50)
    %3283 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3284 = llvm.select %3279, %3245, %3283 : i1, i32 loc(#loc50)
    %3285 = llvm.xor %3276, %3284 : i32 loc(#loc50)
    %3286 = llvm.mlir.constant(2 : i32) : i32 loc(#loc50)
    %3287 = llvm.and %2881, %3286 : i32 loc(#loc50)
    %3288 = llvm.icmp "eq" %3287, %3245 : i32 loc(#loc50)
    %3289 = llvm.mlir.constant(8 : i32) : i32 loc(#loc50)
    %3290 = llvm.select %3288, %3245, %3289 : i1, i32 loc(#loc50)
    %3291 = llvm.xor %3282, %3290 : i32 loc(#loc50)
    %3292 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3293 = llvm.select %3288, %3245, %3292 : i1, i32 loc(#loc50)
    %3294 = llvm.xor %3285, %3293 : i32 loc(#loc50)
    %3295 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3296 = llvm.mul %3291, %3197 : i32 loc(#loc50)
    %3297 = llvm.add %3295, %3296 : i32 loc(#loc50)
    %3298 = llvm.mul %3294, %3198 : i32 loc(#loc50)
    %3299 = llvm.add %3297, %3298 : i32 loc(#loc50)
    %3300 = llvm.getelementptr inbounds %2867[%3299] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc50)
    %3301 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3302 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc50)
    %3303 = llvm.mlir.constant(32 : i32) : i32 loc(#loc50)
    %3304 = llvm.urem %3302, %3303 : i32 loc(#loc50)
    %3305 = llvm.udiv %3302, %3303 : i32 loc(#loc50)
    %3306 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3307 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3308 = llvm.select %2870, %3306, %3307 : i1, i32 loc(#loc50)
    %3309 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %2985, %2863, %3308 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc50)
    %3310 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3311 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3312 = llvm.select %2871, %3310, %3311 : i1, i32 loc(#loc50)
    %3313 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %3090, %2864, %3312 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc50)
    %3314 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3315 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3316 = llvm.select %2872, %3314, %3315 : i1, i32 loc(#loc50)
    %3317 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %3195, %2865, %3316 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc50)
    %3318 = llvm.mlir.constant(4 : i32) : i32 loc(#loc50)
    %3319 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3320 = llvm.select %2873, %3318, %3319 : i1, i32 loc(#loc50)
    %3321 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %3300, %2866, %3320 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc50)
    %3322 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    nvvm.cp.async.commit.group loc(#loc50)
    %3323 = llvm.mlir.constant(0 : i32) : i32 loc(#loc50)
    %3324 = llvm.bitcast %2804 : i32 to i32 loc(#loc53)
    %3325 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc53)
    %3326 = llvm.insertvalue %3324, %3325[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3327 = llvm.insertvalue %3324, %3326[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3328 = llvm.insertvalue %3324, %3327[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3329 = llvm.insertvalue %3324, %3328[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3330 = llvm.extractvalue %629[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3331 = llvm.extractvalue %629[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3332 = llvm.extractvalue %629[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3333 = llvm.extractvalue %629[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3334 = llvm.extractvalue %3329[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3335 = llvm.extractvalue %3329[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3336 = llvm.extractvalue %3329[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3337 = llvm.extractvalue %3329[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc53)
    %3338 = llvm.icmp "slt" %3330, %3334 : i32 loc(#loc53)
    %3339 = llvm.icmp "slt" %3331, %3335 : i32 loc(#loc53)
    %3340 = llvm.icmp "slt" %3332, %3336 : i32 loc(#loc53)
    %3341 = llvm.icmp "slt" %3333, %3337 : i32 loc(#loc53)
    %3342 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc53)
    %3343 = llvm.insertvalue %3338, %3342[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc53)
    %3344 = llvm.insertvalue %3339, %3343[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc53)
    %3345 = llvm.insertvalue %3340, %3344[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc53)
    %3346 = llvm.insertvalue %3341, %3345[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc53)
    %3347 = llvm.extractvalue %3346[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3348 = llvm.extractvalue %3346[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3349 = llvm.extractvalue %3346[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3350 = llvm.extractvalue %3346[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3351 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc51)
    %3352 = llvm.insertvalue %3350, %3351[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3353 = llvm.insertvalue %3350, %3352[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3354 = llvm.insertvalue %3350, %3353[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3355 = llvm.insertvalue %3350, %3354[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3356 = llvm.extractvalue %748[0] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %3357 = llvm.extractvalue %748[1] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %3358 = llvm.extractvalue %748[2] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %3359 = llvm.extractvalue %748[3] : !llvm.struct<(ptr<3>, i32, i32, i32)>  loc(#loc51)
    %3360 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %3361 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %3362 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %3363 = llvm.add %9, %3358 : i32 loc(#loc51)
    %3364 = llvm.add %9, %3359 : i32 loc(#loc51)
    %3365 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %3366 = llvm.mul %2801, %3362 : i32 loc(#loc51)
    %3367 = llvm.add %3365, %3366 : i32 loc(#loc51)
    %3368 = llvm.mul %9, %3361 : i32 loc(#loc51)
    %3369 = llvm.add %3367, %3368 : i32 loc(#loc51)
    %3370 = llvm.mul %9, %3360 : i32 loc(#loc51)
    %3371 = llvm.add %3369, %3370 : i32 loc(#loc51)
    %3372 = llvm.getelementptr %3356[%3371] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %3373 = llvm.mlir.undef : !llvm.struct<(ptr<3>, i32, i32)> loc(#loc51)
    %3374 = llvm.insertvalue %3372, %3373[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %3375 = llvm.insertvalue %3363, %3374[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %3376 = llvm.insertvalue %3364, %3375[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %3377 = llvm.bitcast %1490 : i1 to i1 loc(#loc2)
    %3378 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc2)
    %3379 = llvm.insertvalue %3377, %3378[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3380 = llvm.insertvalue %3377, %3379[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3381 = llvm.insertvalue %3377, %3380[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3382 = llvm.insertvalue %3377, %3381[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3383 = llvm.extractvalue %3382[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3384 = llvm.extractvalue %3382[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3385 = llvm.extractvalue %3382[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3386 = llvm.extractvalue %3382[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3387 = llvm.extractvalue %3355[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3388 = llvm.extractvalue %3355[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3389 = llvm.extractvalue %3355[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3390 = llvm.extractvalue %3355[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3391 = llvm.and %3383, %3387 : i1 loc(#loc2)
    %3392 = llvm.and %3384, %3388 : i1 loc(#loc2)
    %3393 = llvm.and %3385, %3389 : i1 loc(#loc2)
    %3394 = llvm.and %3386, %3390 : i1 loc(#loc2)
    %3395 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1)> loc(#loc2)
    %3396 = llvm.insertvalue %3391, %3395[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3397 = llvm.insertvalue %3391, %3396[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3398 = llvm.insertvalue %3391, %3397[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3399 = llvm.insertvalue %3391, %3398[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc2)
    %3400 = llvm.extractvalue %2796[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc51)
    %3401 = llvm.extractvalue %2796[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc51)
    %3402 = llvm.extractvalue %2796[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc51)
    %3403 = llvm.extractvalue %2796[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc51)
    %3404 = llvm.extractvalue %3376[0] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %3405 = llvm.extractvalue %3376[1] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %3406 = llvm.extractvalue %3376[2] : !llvm.struct<(ptr<3>, i32, i32)>  loc(#loc51)
    %3407 = llvm.extractvalue %3399[0] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3408 = llvm.extractvalue %3399[1] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3409 = llvm.extractvalue %3399[2] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3410 = llvm.extractvalue %3399[3] : !llvm.struct<(i1, i1, i1, i1)>  loc(#loc51)
    %3411 = llvm.extractvalue %7[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %3412 = llvm.extractvalue %7[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %3413 = llvm.extractvalue %7[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %3414 = llvm.extractvalue %7[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %3415 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc51)
    %3416 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %3417 = llvm.urem %3415, %3416 : i32 loc(#loc51)
    %3418 = llvm.udiv %3415, %3416 : i32 loc(#loc51)
    %3419 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %3420 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %3421 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %3422 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %3423 = llvm.mlir.constant(512 : i32) : i32 loc(#loc51)
    %3424 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %3425 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %3426 = llvm.and %3417, %3425 : i32 loc(#loc51)
    %3427 = llvm.icmp "eq" %3426, %3424 : i32 loc(#loc51)
    %3428 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %3429 = llvm.select %3427, %3424, %3428 : i1, i32 loc(#loc51)
    %3430 = llvm.xor %3424, %3429 : i32 loc(#loc51)
    %3431 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %3432 = llvm.and %3417, %3431 : i32 loc(#loc51)
    %3433 = llvm.icmp "eq" %3432, %3424 : i32 loc(#loc51)
    %3434 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %3435 = llvm.select %3433, %3424, %3434 : i1, i32 loc(#loc51)
    %3436 = llvm.xor %3430, %3435 : i32 loc(#loc51)
    %3437 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %3438 = llvm.and %3417, %3437 : i32 loc(#loc51)
    %3439 = llvm.icmp "eq" %3438, %3424 : i32 loc(#loc51)
    %3440 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %3441 = llvm.select %3439, %3424, %3440 : i1, i32 loc(#loc51)
    %3442 = llvm.xor %3436, %3441 : i32 loc(#loc51)
    %3443 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %3444 = llvm.and %3417, %3443 : i32 loc(#loc51)
    %3445 = llvm.icmp "eq" %3444, %3424 : i32 loc(#loc51)
    %3446 = llvm.mlir.constant(40 : i32) : i32 loc(#loc51)
    %3447 = llvm.select %3445, %3424, %3446 : i1, i32 loc(#loc51)
    %3448 = llvm.xor %3442, %3447 : i32 loc(#loc51)
    %3449 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %3450 = llvm.and %3417, %3449 : i32 loc(#loc51)
    %3451 = llvm.icmp "eq" %3450, %3424 : i32 loc(#loc51)
    %3452 = llvm.mlir.constant(80 : i32) : i32 loc(#loc51)
    %3453 = llvm.select %3451, %3424, %3452 : i1, i32 loc(#loc51)
    %3454 = llvm.xor %3448, %3453 : i32 loc(#loc51)
    %3455 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %3456 = llvm.and %3418, %3455 : i32 loc(#loc51)
    %3457 = llvm.icmp "eq" %3456, %3424 : i32 loc(#loc51)
    %3458 = llvm.mlir.constant(128 : i32) : i32 loc(#loc51)
    %3459 = llvm.select %3457, %3424, %3458 : i1, i32 loc(#loc51)
    %3460 = llvm.xor %3454, %3459 : i32 loc(#loc51)
    %3461 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %3462 = llvm.and %3418, %3461 : i32 loc(#loc51)
    %3463 = llvm.icmp "eq" %3462, %3424 : i32 loc(#loc51)
    %3464 = llvm.mlir.constant(256 : i32) : i32 loc(#loc51)
    %3465 = llvm.select %3463, %3424, %3464 : i1, i32 loc(#loc51)
    %3466 = llvm.xor %3460, %3465 : i32 loc(#loc51)
    %3467 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %3468 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %3469 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %3470 = llvm.and %3417, %3469 : i32 loc(#loc51)
    %3471 = llvm.icmp "eq" %3470, %3468 : i32 loc(#loc51)
    %3472 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %3473 = llvm.select %3471, %3468, %3472 : i1, i32 loc(#loc51)
    %3474 = llvm.xor %3468, %3473 : i32 loc(#loc51)
    %3475 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %3476 = llvm.and %3417, %3475 : i32 loc(#loc51)
    %3477 = llvm.icmp "eq" %3476, %3468 : i32 loc(#loc51)
    %3478 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %3479 = llvm.select %3477, %3468, %3478 : i1, i32 loc(#loc51)
    %3480 = llvm.xor %3474, %3479 : i32 loc(#loc51)
    %3481 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %3482 = llvm.and %3417, %3481 : i32 loc(#loc51)
    %3483 = llvm.icmp "eq" %3482, %3468 : i32 loc(#loc51)
    %3484 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %3485 = llvm.select %3483, %3468, %3484 : i1, i32 loc(#loc51)
    %3486 = llvm.xor %3480, %3485 : i32 loc(#loc51)
    %3487 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %3488 = llvm.and %3417, %3487 : i32 loc(#loc51)
    %3489 = llvm.icmp "eq" %3488, %3468 : i32 loc(#loc51)
    %3490 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %3491 = llvm.select %3489, %3468, %3490 : i1, i32 loc(#loc51)
    %3492 = llvm.xor %3486, %3491 : i32 loc(#loc51)
    %3493 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %3494 = llvm.select %3489, %3468, %3493 : i1, i32 loc(#loc51)
    %3495 = llvm.xor %3468, %3494 : i32 loc(#loc51)
    %3496 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %3497 = llvm.and %3417, %3496 : i32 loc(#loc51)
    %3498 = llvm.icmp "eq" %3497, %3468 : i32 loc(#loc51)
    %3499 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %3500 = llvm.select %3498, %3468, %3499 : i1, i32 loc(#loc51)
    %3501 = llvm.xor %3492, %3500 : i32 loc(#loc51)
    %3502 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %3503 = llvm.select %3498, %3468, %3502 : i1, i32 loc(#loc51)
    %3504 = llvm.xor %3495, %3503 : i32 loc(#loc51)
    %3505 = llvm.mlir.constant(1 : i32) : i32 loc(#loc51)
    %3506 = llvm.and %3418, %3505 : i32 loc(#loc51)
    %3507 = llvm.icmp "eq" %3506, %3468 : i32 loc(#loc51)
    %3508 = llvm.mlir.constant(4 : i32) : i32 loc(#loc51)
    %3509 = llvm.select %3507, %3468, %3508 : i1, i32 loc(#loc51)
    %3510 = llvm.xor %3504, %3509 : i32 loc(#loc51)
    %3511 = llvm.mlir.constant(2 : i32) : i32 loc(#loc51)
    %3512 = llvm.and %3418, %3511 : i32 loc(#loc51)
    %3513 = llvm.icmp "eq" %3512, %3468 : i32 loc(#loc51)
    %3514 = llvm.mlir.constant(8 : i32) : i32 loc(#loc51)
    %3515 = llvm.select %3513, %3468, %3514 : i1, i32 loc(#loc51)
    %3516 = llvm.xor %3510, %3515 : i32 loc(#loc51)
    %3517 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %3518 = llvm.mul %3501, %3421 : i32 loc(#loc51)
    %3519 = llvm.add %3517, %3518 : i32 loc(#loc51)
    %3520 = llvm.mul %3516, %3422 : i32 loc(#loc51)
    %3521 = llvm.add %3519, %3520 : i32 loc(#loc51)
    %3522 = llvm.getelementptr inbounds %3404[%3521] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc51)
    %3523 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %3524 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc51)
    %3525 = llvm.mlir.constant(32 : i32) : i32 loc(#loc51)
    %3526 = llvm.urem %3524, %3525 : i32 loc(#loc51)
    %3527 = llvm.udiv %3524, %3525 : i32 loc(#loc51)
    %3528 = llvm.mlir.constant(16 : i32) : i32 loc(#loc51)
    %3529 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %3530 = llvm.select %3407, %3528, %3529 : i1, i32 loc(#loc51)
    %3531 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %3522, %3400, %3530 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc51)
    %3532 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    nvvm.cp.async.commit.group loc(#loc51)
    %3533 = llvm.mlir.constant(0 : i32) : i32 loc(#loc51)
    %3534 = builtin.unrealized_conversion_cast %3533 : i32 to !ttg.async.token loc(#loc51)
    %3535 = builtin.unrealized_conversion_cast %3534 : !ttg.async.token to i32 loc(#loc2)
    %3536 = llvm.add %1481, %27 : i32 loc(#loc2)
    llvm.br ^bb1(%3536, %2760, %2779, %2798, %2801, %1493, %3535 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32, i32) loc(#loc2)
  ^bb3:  // pred: ^bb1
    nvvm.cp.async.wait.group 0 loc(#loc2)
    %3537 = llvm.mlir.constant(0 : i32) : i32 loc(#loc2)
    nvvm.barrier0 loc(#loc2)
    %3538 = llvm.extractvalue %1482[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc58)
    %3539 = llvm.extractvalue %1482[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc58)
    %3540 = llvm.extractvalue %1482[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc58)
    %3541 = llvm.extractvalue %1482[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc58)
    %3542 = llvm.extractvalue %1482[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc58)
    %3543 = llvm.extractvalue %1482[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc58)
    %3544 = llvm.extractvalue %1482[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc58)
    %3545 = llvm.extractvalue %1482[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc58)
    %3546 = llvm.fptrunc %3538 : f32 to f16 loc(#loc58)
    %3547 = llvm.fptrunc %3539 : f32 to f16 loc(#loc58)
    %3548 = llvm.fptrunc %3540 : f32 to f16 loc(#loc58)
    %3549 = llvm.fptrunc %3541 : f32 to f16 loc(#loc58)
    %3550 = llvm.fptrunc %3542 : f32 to f16 loc(#loc58)
    %3551 = llvm.fptrunc %3543 : f32 to f16 loc(#loc58)
    %3552 = llvm.fptrunc %3544 : f32 to f16 loc(#loc58)
    %3553 = llvm.fptrunc %3545 : f32 to f16 loc(#loc58)
    %3554 = llvm.mlir.undef : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)> loc(#loc58)
    %3555 = llvm.insertvalue %3546, %3554[0] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc58)
    %3556 = llvm.insertvalue %3547, %3555[1] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc58)
    %3557 = llvm.insertvalue %3548, %3556[2] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc58)
    %3558 = llvm.insertvalue %3549, %3557[3] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc58)
    %3559 = llvm.insertvalue %3550, %3558[4] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc58)
    %3560 = llvm.insertvalue %3551, %3559[5] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc58)
    %3561 = llvm.insertvalue %3552, %3560[6] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc58)
    %3562 = llvm.insertvalue %3553, %3561[7] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc58)
    %3563 = llvm.extractvalue %324[0] : !llvm.struct<(i32)>  loc(#loc59)
    %3564 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)> loc(#loc59)
    %3565 = llvm.insertvalue %3563, %3564[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc59)
    %3566 = llvm.insertvalue %3563, %3565[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc59)
    %3567 = llvm.insertvalue %3563, %3566[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc59)
    %3568 = llvm.insertvalue %3563, %3567[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc59)
    %3569 = llvm.insertvalue %3563, %3568[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc59)
    %3570 = llvm.insertvalue %3563, %3569[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc59)
    %3571 = llvm.insertvalue %3563, %3570[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc59)
    %3572 = llvm.insertvalue %3563, %3571[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc59)
    %3573 = llvm.bitcast %arg8 : i32 to i32 loc(#loc60)
    %3574 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)> loc(#loc60)
    %3575 = llvm.insertvalue %3573, %3574[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3576 = llvm.insertvalue %3573, %3575[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3577 = llvm.insertvalue %3573, %3576[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3578 = llvm.insertvalue %3573, %3577[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3579 = llvm.insertvalue %3573, %3578[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3580 = llvm.insertvalue %3573, %3579[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3581 = llvm.insertvalue %3573, %3580[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3582 = llvm.insertvalue %3573, %3581[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3583 = llvm.extractvalue %3582[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3584 = llvm.extractvalue %3582[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3585 = llvm.extractvalue %3582[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3586 = llvm.extractvalue %3582[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3587 = llvm.extractvalue %3582[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3588 = llvm.extractvalue %3582[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3589 = llvm.extractvalue %3582[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3590 = llvm.extractvalue %3582[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3591 = llvm.extractvalue %3572[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3592 = llvm.extractvalue %3572[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3593 = llvm.extractvalue %3572[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3594 = llvm.extractvalue %3572[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3595 = llvm.extractvalue %3572[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3596 = llvm.extractvalue %3572[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3597 = llvm.extractvalue %3572[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3598 = llvm.extractvalue %3572[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3599 = llvm.mul %3583, %3591 : i32 loc(#loc60)
    %3600 = llvm.mul %3584, %3592 : i32 loc(#loc60)
    %3601 = llvm.mul %3585, %3593 : i32 loc(#loc60)
    %3602 = llvm.mul %3586, %3594 : i32 loc(#loc60)
    %3603 = llvm.mul %3587, %3595 : i32 loc(#loc60)
    %3604 = llvm.mul %3588, %3596 : i32 loc(#loc60)
    %3605 = llvm.mul %3589, %3597 : i32 loc(#loc60)
    %3606 = llvm.mul %3590, %3598 : i32 loc(#loc60)
    %3607 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)> loc(#loc60)
    %3608 = llvm.insertvalue %3599, %3607[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3609 = llvm.insertvalue %3600, %3608[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3610 = llvm.insertvalue %3601, %3609[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3611 = llvm.insertvalue %3602, %3610[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3612 = llvm.insertvalue %3603, %3611[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3613 = llvm.insertvalue %3604, %3612[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3614 = llvm.insertvalue %3605, %3613[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3615 = llvm.insertvalue %3606, %3614[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc60)
    %3616 = llvm.bitcast %arg2 : !llvm.ptr<1> to !llvm.ptr<1> loc(#loc61)
    %3617 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc61)
    %3618 = llvm.insertvalue %3616, %3617[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3619 = llvm.insertvalue %3616, %3618[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3620 = llvm.insertvalue %3616, %3619[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3621 = llvm.insertvalue %3616, %3620[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3622 = llvm.insertvalue %3616, %3621[4] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3623 = llvm.insertvalue %3616, %3622[5] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3624 = llvm.insertvalue %3616, %3623[6] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3625 = llvm.insertvalue %3616, %3624[7] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3626 = llvm.extractvalue %3625[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3627 = llvm.extractvalue %3625[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3628 = llvm.extractvalue %3625[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3629 = llvm.extractvalue %3625[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3630 = llvm.extractvalue %3625[4] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3631 = llvm.extractvalue %3625[5] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3632 = llvm.extractvalue %3625[6] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3633 = llvm.extractvalue %3625[7] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3634 = llvm.extractvalue %3615[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc61)
    %3635 = llvm.extractvalue %3615[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc61)
    %3636 = llvm.extractvalue %3615[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc61)
    %3637 = llvm.extractvalue %3615[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc61)
    %3638 = llvm.extractvalue %3615[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc61)
    %3639 = llvm.extractvalue %3615[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc61)
    %3640 = llvm.extractvalue %3615[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc61)
    %3641 = llvm.extractvalue %3615[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc61)
    %3642 = llvm.getelementptr %3626[%3634] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc61)
    %3643 = llvm.getelementptr %3627[%3635] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc61)
    %3644 = llvm.getelementptr %3628[%3636] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc61)
    %3645 = llvm.getelementptr %3629[%3637] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc61)
    %3646 = llvm.getelementptr %3630[%3638] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc61)
    %3647 = llvm.getelementptr %3631[%3639] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc61)
    %3648 = llvm.getelementptr %3632[%3640] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc61)
    %3649 = llvm.getelementptr %3633[%3641] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc61)
    %3650 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc61)
    %3651 = llvm.insertvalue %3642, %3650[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3652 = llvm.insertvalue %3643, %3651[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3653 = llvm.insertvalue %3644, %3652[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3654 = llvm.insertvalue %3645, %3653[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3655 = llvm.insertvalue %3646, %3654[4] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3656 = llvm.insertvalue %3647, %3655[5] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3657 = llvm.insertvalue %3648, %3656[6] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3658 = llvm.insertvalue %3649, %3657[7] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc61)
    %3659 = llvm.extractvalue %414[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3660 = llvm.extractvalue %414[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3661 = llvm.extractvalue %414[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3662 = llvm.extractvalue %414[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3663 = llvm.extractvalue %414[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3664 = llvm.extractvalue %414[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3665 = llvm.extractvalue %414[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3666 = llvm.extractvalue %414[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3667 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)> loc(#loc62)
    %3668 = llvm.insertvalue %3659, %3667[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3669 = llvm.insertvalue %3660, %3668[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3670 = llvm.insertvalue %3661, %3669[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3671 = llvm.insertvalue %3662, %3670[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3672 = llvm.insertvalue %3663, %3671[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3673 = llvm.insertvalue %3664, %3672[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3674 = llvm.insertvalue %3665, %3673[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3675 = llvm.insertvalue %3666, %3674[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc62)
    %3676 = llvm.extractvalue %3658[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3677 = llvm.extractvalue %3658[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3678 = llvm.extractvalue %3658[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3679 = llvm.extractvalue %3658[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3680 = llvm.extractvalue %3658[4] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3681 = llvm.extractvalue %3658[5] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3682 = llvm.extractvalue %3658[6] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3683 = llvm.extractvalue %3658[7] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3684 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc63)
    %3685 = llvm.insertvalue %3683, %3684[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3686 = llvm.insertvalue %3683, %3685[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3687 = llvm.insertvalue %3683, %3686[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3688 = llvm.insertvalue %3683, %3687[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3689 = llvm.insertvalue %3683, %3688[4] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3690 = llvm.insertvalue %3683, %3689[5] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3691 = llvm.insertvalue %3683, %3690[6] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3692 = llvm.insertvalue %3683, %3691[7] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3693 = llvm.extractvalue %3675[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3694 = llvm.extractvalue %3675[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3695 = llvm.extractvalue %3675[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3696 = llvm.extractvalue %3675[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3697 = llvm.extractvalue %3675[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3698 = llvm.extractvalue %3675[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3699 = llvm.extractvalue %3675[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3700 = llvm.extractvalue %3675[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3701 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)> loc(#loc63)
    %3702 = llvm.insertvalue %3693, %3701[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3703 = llvm.insertvalue %3694, %3702[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3704 = llvm.insertvalue %3695, %3703[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3705 = llvm.insertvalue %3696, %3704[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3706 = llvm.insertvalue %3697, %3705[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3707 = llvm.insertvalue %3698, %3706[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3708 = llvm.insertvalue %3699, %3707[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3709 = llvm.insertvalue %3700, %3708[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3710 = llvm.extractvalue %3692[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3711 = llvm.extractvalue %3692[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3712 = llvm.extractvalue %3692[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3713 = llvm.extractvalue %3692[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3714 = llvm.extractvalue %3692[4] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3715 = llvm.extractvalue %3692[5] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3716 = llvm.extractvalue %3692[6] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3717 = llvm.extractvalue %3692[7] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3718 = llvm.extractvalue %3709[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3719 = llvm.extractvalue %3709[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3720 = llvm.extractvalue %3709[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3721 = llvm.extractvalue %3709[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3722 = llvm.extractvalue %3709[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3723 = llvm.extractvalue %3709[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3724 = llvm.extractvalue %3709[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3725 = llvm.extractvalue %3709[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc63)
    %3726 = llvm.getelementptr %3710[%3718] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc63)
    %3727 = llvm.getelementptr %3711[%3719] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc63)
    %3728 = llvm.getelementptr %3712[%3720] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc63)
    %3729 = llvm.getelementptr %3713[%3721] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc63)
    %3730 = llvm.getelementptr %3714[%3722] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc63)
    %3731 = llvm.getelementptr %3715[%3723] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc63)
    %3732 = llvm.getelementptr %3716[%3724] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc63)
    %3733 = llvm.getelementptr %3717[%3725] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc63)
    %3734 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc63)
    %3735 = llvm.insertvalue %3726, %3734[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3736 = llvm.insertvalue %3727, %3735[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3737 = llvm.insertvalue %3728, %3736[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3738 = llvm.insertvalue %3729, %3737[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3739 = llvm.insertvalue %3730, %3738[4] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3740 = llvm.insertvalue %3731, %3739[5] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3741 = llvm.insertvalue %3732, %3740[6] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3742 = llvm.insertvalue %3733, %3741[7] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc63)
    %3743 = llvm.bitcast %arg3 : i32 to i32 loc(#loc64)
    %3744 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)> loc(#loc64)
    %3745 = llvm.insertvalue %3743, %3744[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3746 = llvm.insertvalue %3743, %3745[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3747 = llvm.insertvalue %3743, %3746[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3748 = llvm.insertvalue %3743, %3747[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3749 = llvm.insertvalue %3743, %3748[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3750 = llvm.insertvalue %3743, %3749[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3751 = llvm.insertvalue %3743, %3750[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3752 = llvm.insertvalue %3743, %3751[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3753 = llvm.extractvalue %3572[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3754 = llvm.extractvalue %3572[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3755 = llvm.extractvalue %3572[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3756 = llvm.extractvalue %3572[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3757 = llvm.extractvalue %3572[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3758 = llvm.extractvalue %3572[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3759 = llvm.extractvalue %3572[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3760 = llvm.extractvalue %3572[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3761 = llvm.extractvalue %3752[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3762 = llvm.extractvalue %3752[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3763 = llvm.extractvalue %3752[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3764 = llvm.extractvalue %3752[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3765 = llvm.extractvalue %3752[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3766 = llvm.extractvalue %3752[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3767 = llvm.extractvalue %3752[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3768 = llvm.extractvalue %3752[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc64)
    %3769 = llvm.icmp "slt" %3753, %3761 : i32 loc(#loc64)
    %3770 = llvm.icmp "slt" %3754, %3762 : i32 loc(#loc64)
    %3771 = llvm.icmp "slt" %3755, %3763 : i32 loc(#loc64)
    %3772 = llvm.icmp "slt" %3756, %3764 : i32 loc(#loc64)
    %3773 = llvm.icmp "slt" %3757, %3765 : i32 loc(#loc64)
    %3774 = llvm.icmp "slt" %3758, %3766 : i32 loc(#loc64)
    %3775 = llvm.icmp "slt" %3759, %3767 : i32 loc(#loc64)
    %3776 = llvm.icmp "slt" %3760, %3768 : i32 loc(#loc64)
    %3777 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)> loc(#loc64)
    %3778 = llvm.insertvalue %3769, %3777[0] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc64)
    %3779 = llvm.insertvalue %3770, %3778[1] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc64)
    %3780 = llvm.insertvalue %3771, %3779[2] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc64)
    %3781 = llvm.insertvalue %3772, %3780[3] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc64)
    %3782 = llvm.insertvalue %3773, %3781[4] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc64)
    %3783 = llvm.insertvalue %3774, %3782[5] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc64)
    %3784 = llvm.insertvalue %3775, %3783[6] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc64)
    %3785 = llvm.insertvalue %3776, %3784[7] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc64)
    %3786 = llvm.bitcast %arg4 : i32 to i32 loc(#loc65)
    %3787 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)> loc(#loc65)
    %3788 = llvm.insertvalue %3786, %3787[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3789 = llvm.insertvalue %3786, %3788[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3790 = llvm.insertvalue %3786, %3789[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3791 = llvm.insertvalue %3786, %3790[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3792 = llvm.insertvalue %3786, %3791[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3793 = llvm.insertvalue %3786, %3792[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3794 = llvm.insertvalue %3786, %3793[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3795 = llvm.insertvalue %3786, %3794[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3796 = llvm.extractvalue %3675[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3797 = llvm.extractvalue %3675[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3798 = llvm.extractvalue %3675[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3799 = llvm.extractvalue %3675[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3800 = llvm.extractvalue %3675[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3801 = llvm.extractvalue %3675[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3802 = llvm.extractvalue %3675[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3803 = llvm.extractvalue %3675[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3804 = llvm.extractvalue %3795[0] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3805 = llvm.extractvalue %3795[1] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3806 = llvm.extractvalue %3795[2] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3807 = llvm.extractvalue %3795[3] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3808 = llvm.extractvalue %3795[4] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3809 = llvm.extractvalue %3795[5] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3810 = llvm.extractvalue %3795[6] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3811 = llvm.extractvalue %3795[7] : !llvm.struct<(i32, i32, i32, i32, i32, i32, i32, i32)>  loc(#loc65)
    %3812 = llvm.icmp "slt" %3796, %3804 : i32 loc(#loc65)
    %3813 = llvm.icmp "slt" %3797, %3805 : i32 loc(#loc65)
    %3814 = llvm.icmp "slt" %3798, %3806 : i32 loc(#loc65)
    %3815 = llvm.icmp "slt" %3799, %3807 : i32 loc(#loc65)
    %3816 = llvm.icmp "slt" %3800, %3808 : i32 loc(#loc65)
    %3817 = llvm.icmp "slt" %3801, %3809 : i32 loc(#loc65)
    %3818 = llvm.icmp "slt" %3802, %3810 : i32 loc(#loc65)
    %3819 = llvm.icmp "slt" %3803, %3811 : i32 loc(#loc65)
    %3820 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)> loc(#loc65)
    %3821 = llvm.insertvalue %3812, %3820[0] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc65)
    %3822 = llvm.insertvalue %3812, %3821[1] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc65)
    %3823 = llvm.insertvalue %3812, %3822[2] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc65)
    %3824 = llvm.insertvalue %3812, %3823[3] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc65)
    %3825 = llvm.insertvalue %3812, %3824[4] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc65)
    %3826 = llvm.insertvalue %3812, %3825[5] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc65)
    %3827 = llvm.insertvalue %3812, %3826[6] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc65)
    %3828 = llvm.insertvalue %3812, %3827[7] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc65)
    %3829 = llvm.extractvalue %3785[0] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3830 = llvm.extractvalue %3785[1] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3831 = llvm.extractvalue %3785[2] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3832 = llvm.extractvalue %3785[3] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3833 = llvm.extractvalue %3785[4] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3834 = llvm.extractvalue %3785[5] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3835 = llvm.extractvalue %3785[6] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3836 = llvm.extractvalue %3785[7] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3837 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)> loc(#loc66)
    %3838 = llvm.insertvalue %3836, %3837[0] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3839 = llvm.insertvalue %3836, %3838[1] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3840 = llvm.insertvalue %3836, %3839[2] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3841 = llvm.insertvalue %3836, %3840[3] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3842 = llvm.insertvalue %3836, %3841[4] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3843 = llvm.insertvalue %3836, %3842[5] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3844 = llvm.insertvalue %3836, %3843[6] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3845 = llvm.insertvalue %3836, %3844[7] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3846 = llvm.extractvalue %3828[0] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3847 = llvm.extractvalue %3828[1] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3848 = llvm.extractvalue %3828[2] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3849 = llvm.extractvalue %3828[3] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3850 = llvm.extractvalue %3828[4] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3851 = llvm.extractvalue %3828[5] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3852 = llvm.extractvalue %3828[6] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3853 = llvm.extractvalue %3828[7] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3854 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)> loc(#loc66)
    %3855 = llvm.insertvalue %3846, %3854[0] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3856 = llvm.insertvalue %3847, %3855[1] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3857 = llvm.insertvalue %3848, %3856[2] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3858 = llvm.insertvalue %3849, %3857[3] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3859 = llvm.insertvalue %3850, %3858[4] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3860 = llvm.insertvalue %3851, %3859[5] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3861 = llvm.insertvalue %3852, %3860[6] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3862 = llvm.insertvalue %3853, %3861[7] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3863 = llvm.extractvalue %3845[0] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3864 = llvm.extractvalue %3845[1] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3865 = llvm.extractvalue %3845[2] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3866 = llvm.extractvalue %3845[3] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3867 = llvm.extractvalue %3845[4] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3868 = llvm.extractvalue %3845[5] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3869 = llvm.extractvalue %3845[6] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3870 = llvm.extractvalue %3845[7] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3871 = llvm.extractvalue %3862[0] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3872 = llvm.extractvalue %3862[1] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3873 = llvm.extractvalue %3862[2] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3874 = llvm.extractvalue %3862[3] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3875 = llvm.extractvalue %3862[4] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3876 = llvm.extractvalue %3862[5] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3877 = llvm.extractvalue %3862[6] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3878 = llvm.extractvalue %3862[7] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3879 = llvm.and %3863, %3871 : i1 loc(#loc66)
    %3880 = llvm.and %3864, %3872 : i1 loc(#loc66)
    %3881 = llvm.and %3865, %3873 : i1 loc(#loc66)
    %3882 = llvm.and %3866, %3874 : i1 loc(#loc66)
    %3883 = llvm.and %3867, %3875 : i1 loc(#loc66)
    %3884 = llvm.and %3868, %3876 : i1 loc(#loc66)
    %3885 = llvm.and %3869, %3877 : i1 loc(#loc66)
    %3886 = llvm.and %3870, %3878 : i1 loc(#loc66)
    %3887 = llvm.mlir.undef : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)> loc(#loc66)
    %3888 = llvm.insertvalue %3879, %3887[0] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3889 = llvm.insertvalue %3879, %3888[1] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3890 = llvm.insertvalue %3879, %3889[2] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3891 = llvm.insertvalue %3879, %3890[3] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3892 = llvm.insertvalue %3879, %3891[4] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3893 = llvm.insertvalue %3879, %3892[5] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3894 = llvm.insertvalue %3879, %3893[6] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3895 = llvm.insertvalue %3879, %3894[7] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc66)
    %3896 = llvm.extractvalue %3562[0] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %3897 = llvm.extractvalue %3562[1] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %3898 = llvm.extractvalue %3562[2] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %3899 = llvm.extractvalue %3562[3] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %3900 = llvm.extractvalue %3562[4] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %3901 = llvm.extractvalue %3562[5] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %3902 = llvm.extractvalue %3562[6] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %3903 = llvm.extractvalue %3562[7] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %3904 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc67)
    %3905 = llvm.mlir.constant(32 : i32) : i32 loc(#loc67)
    %3906 = llvm.urem %3904, %3905 : i32 loc(#loc67)
    %3907 = llvm.udiv %3904, %3905 : i32 loc(#loc67)
    %3908 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %3909 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc)
    %3910 = llvm.getelementptr %3909[%3908] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, i8 loc(#loc67)
    %3911 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %3912 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %3913 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %3914 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %3915 = llvm.and %3906, %3914 : i32 loc(#loc67)
    %3916 = llvm.icmp "eq" %3915, %3913 : i32 loc(#loc67)
    %3917 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %3918 = llvm.select %3916, %3913, %3917 : i1, i32 loc(#loc67)
    %3919 = llvm.xor %3913, %3918 : i32 loc(#loc67)
    %3920 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %3921 = llvm.and %3906, %3920 : i32 loc(#loc67)
    %3922 = llvm.icmp "eq" %3921, %3913 : i32 loc(#loc67)
    %3923 = llvm.mlir.constant(4 : i32) : i32 loc(#loc67)
    %3924 = llvm.select %3922, %3913, %3923 : i1, i32 loc(#loc67)
    %3925 = llvm.xor %3919, %3924 : i32 loc(#loc67)
    %3926 = llvm.mlir.constant(4 : i32) : i32 loc(#loc67)
    %3927 = llvm.and %3906, %3926 : i32 loc(#loc67)
    %3928 = llvm.icmp "eq" %3927, %3913 : i32 loc(#loc67)
    %3929 = llvm.mlir.constant(32 : i32) : i32 loc(#loc67)
    %3930 = llvm.select %3928, %3913, %3929 : i1, i32 loc(#loc67)
    %3931 = llvm.xor %3925, %3930 : i32 loc(#loc67)
    %3932 = llvm.mlir.constant(8 : i32) : i32 loc(#loc67)
    %3933 = llvm.and %3906, %3932 : i32 loc(#loc67)
    %3934 = llvm.icmp "eq" %3933, %3913 : i32 loc(#loc67)
    %3935 = llvm.mlir.constant(64 : i32) : i32 loc(#loc67)
    %3936 = llvm.select %3934, %3913, %3935 : i1, i32 loc(#loc67)
    %3937 = llvm.xor %3931, %3936 : i32 loc(#loc67)
    %3938 = llvm.mlir.constant(16 : i32) : i32 loc(#loc67)
    %3939 = llvm.and %3906, %3938 : i32 loc(#loc67)
    %3940 = llvm.icmp "eq" %3939, %3913 : i32 loc(#loc67)
    %3941 = llvm.mlir.constant(128 : i32) : i32 loc(#loc67)
    %3942 = llvm.select %3940, %3913, %3941 : i1, i32 loc(#loc67)
    %3943 = llvm.xor %3937, %3942 : i32 loc(#loc67)
    %3944 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %3945 = llvm.and %3907, %3944 : i32 loc(#loc67)
    %3946 = llvm.icmp "eq" %3945, %3913 : i32 loc(#loc67)
    %3947 = llvm.mlir.constant(8 : i32) : i32 loc(#loc67)
    %3948 = llvm.select %3946, %3913, %3947 : i1, i32 loc(#loc67)
    %3949 = llvm.xor %3943, %3948 : i32 loc(#loc67)
    %3950 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %3951 = llvm.and %3907, %3950 : i32 loc(#loc67)
    %3952 = llvm.icmp "eq" %3951, %3913 : i32 loc(#loc67)
    %3953 = llvm.mlir.constant(512 : i32) : i32 loc(#loc67)
    %3954 = llvm.select %3952, %3913, %3953 : i1, i32 loc(#loc67)
    %3955 = llvm.xor %3949, %3954 : i32 loc(#loc67)
    %3956 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %3957 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %3958 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %3959 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %3960 = llvm.and %3906, %3959 : i32 loc(#loc67)
    %3961 = llvm.icmp "eq" %3960, %3958 : i32 loc(#loc67)
    %3962 = llvm.mlir.constant(8 : i32) : i32 loc(#loc67)
    %3963 = llvm.select %3961, %3958, %3962 : i1, i32 loc(#loc67)
    %3964 = llvm.xor %3958, %3963 : i32 loc(#loc67)
    %3965 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %3966 = llvm.and %3906, %3965 : i32 loc(#loc67)
    %3967 = llvm.icmp "eq" %3966, %3958 : i32 loc(#loc67)
    %3968 = llvm.mlir.constant(16 : i32) : i32 loc(#loc67)
    %3969 = llvm.select %3967, %3958, %3968 : i1, i32 loc(#loc67)
    %3970 = llvm.xor %3964, %3969 : i32 loc(#loc67)
    %3971 = llvm.mlir.constant(4 : i32) : i32 loc(#loc67)
    %3972 = llvm.and %3906, %3971 : i32 loc(#loc67)
    %3973 = llvm.icmp "eq" %3972, %3958 : i32 loc(#loc67)
    %3974 = llvm.mlir.constant(32 : i32) : i32 loc(#loc67)
    %3975 = llvm.select %3973, %3958, %3974 : i1, i32 loc(#loc67)
    %3976 = llvm.xor %3970, %3975 : i32 loc(#loc67)
    %3977 = llvm.mlir.constant(8 : i32) : i32 loc(#loc67)
    %3978 = llvm.and %3906, %3977 : i32 loc(#loc67)
    %3979 = llvm.icmp "eq" %3978, %3958 : i32 loc(#loc67)
    %3980 = llvm.mlir.constant(64 : i32) : i32 loc(#loc67)
    %3981 = llvm.select %3979, %3958, %3980 : i1, i32 loc(#loc67)
    %3982 = llvm.xor %3976, %3981 : i32 loc(#loc67)
    %3983 = llvm.mlir.constant(16 : i32) : i32 loc(#loc67)
    %3984 = llvm.and %3906, %3983 : i32 loc(#loc67)
    %3985 = llvm.icmp "eq" %3984, %3958 : i32 loc(#loc67)
    %3986 = llvm.mlir.constant(128 : i32) : i32 loc(#loc67)
    %3987 = llvm.select %3985, %3958, %3986 : i1, i32 loc(#loc67)
    %3988 = llvm.xor %3982, %3987 : i32 loc(#loc67)
    %3989 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %3990 = llvm.and %3907, %3989 : i32 loc(#loc67)
    %3991 = llvm.icmp "eq" %3990, %3958 : i32 loc(#loc67)
    %3992 = llvm.mlir.constant(256 : i32) : i32 loc(#loc67)
    %3993 = llvm.select %3991, %3958, %3992 : i1, i32 loc(#loc67)
    %3994 = llvm.xor %3988, %3993 : i32 loc(#loc67)
    %3995 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %3996 = llvm.and %3907, %3995 : i32 loc(#loc67)
    %3997 = llvm.icmp "eq" %3996, %3958 : i32 loc(#loc67)
    %3998 = llvm.mlir.constant(512 : i32) : i32 loc(#loc67)
    %3999 = llvm.select %3997, %3958, %3998 : i1, i32 loc(#loc67)
    %4000 = llvm.xor %3994, %3999 : i32 loc(#loc67)
    %4001 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4002 = llvm.xor %3955, %4001 : i32 loc(#loc67)
    %4003 = llvm.mlir.constant(5 : i32) : i32 loc(#loc67)
    %4004 = llvm.lshr %4002, %4003 : i32 loc(#loc67)
    %4005 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4006 = llvm.shl %4004, %4005 : i32 loc(#loc67)
    %4007 = llvm.add %4006, %4002 : i32 loc(#loc67)
    %4008 = llvm.getelementptr inbounds %3910[%4007] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc67)
    %4009 = llvm.mlir.undef : vector<2xf16> loc(#loc67)
    %4010 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4011 = llvm.insertelement %3896, %4009[%4010 : i32] : vector<2xf16> loc(#loc67)
    %4012 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4013 = llvm.insertelement %3897, %4011[%4012 : i32] : vector<2xf16> loc(#loc67)
    %4014 = llvm.mlir.constant(true) : i1 loc(#loc67)
    %4015 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4016 = llvm.extractelement %4013[%4015 : i32] : vector<2xf16> loc(#loc67)
    %4017 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4018 = llvm.extractelement %4013[%4017 : i32] : vector<2xf16> loc(#loc67)
    %4019 = llvm.bitcast %4016 : f16 to i16 loc(#loc67)
    %4020 = llvm.bitcast %4018 : f16 to i16 loc(#loc67)
    %4021 = llvm.mlir.undef : vector<2xi16> loc(#loc67)
    %4022 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4023 = llvm.insertelement %4019, %4021[%4022 : i32] : vector<2xi16> loc(#loc67)
    %4024 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4025 = llvm.insertelement %4020, %4023[%4024 : i32] : vector<2xi16> loc(#loc67)
    %4026 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4027 = llvm.extractelement %4025[%4026 : i32] : vector<2xi16> loc(#loc67)
    %4028 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4029 = llvm.extractelement %4025[%4028 : i32] : vector<2xi16> loc(#loc67)
    %4030 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %4008, %4027, %4029, %4014 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc67)
    %4031 = llvm.mlir.constant(256 : i32) : i32 loc(#loc67)
    %4032 = llvm.xor %3955, %4031 : i32 loc(#loc67)
    %4033 = llvm.mlir.constant(5 : i32) : i32 loc(#loc67)
    %4034 = llvm.lshr %4032, %4033 : i32 loc(#loc67)
    %4035 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4036 = llvm.shl %4034, %4035 : i32 loc(#loc67)
    %4037 = llvm.add %4036, %4032 : i32 loc(#loc67)
    %4038 = llvm.getelementptr inbounds %3910[%4037] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc67)
    %4039 = llvm.mlir.undef : vector<2xf16> loc(#loc67)
    %4040 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4041 = llvm.insertelement %3898, %4039[%4040 : i32] : vector<2xf16> loc(#loc67)
    %4042 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4043 = llvm.insertelement %3899, %4041[%4042 : i32] : vector<2xf16> loc(#loc67)
    %4044 = llvm.mlir.constant(true) : i1 loc(#loc67)
    %4045 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4046 = llvm.extractelement %4043[%4045 : i32] : vector<2xf16> loc(#loc67)
    %4047 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4048 = llvm.extractelement %4043[%4047 : i32] : vector<2xf16> loc(#loc67)
    %4049 = llvm.bitcast %4046 : f16 to i16 loc(#loc67)
    %4050 = llvm.bitcast %4048 : f16 to i16 loc(#loc67)
    %4051 = llvm.mlir.undef : vector<2xi16> loc(#loc67)
    %4052 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4053 = llvm.insertelement %4049, %4051[%4052 : i32] : vector<2xi16> loc(#loc67)
    %4054 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4055 = llvm.insertelement %4050, %4053[%4054 : i32] : vector<2xi16> loc(#loc67)
    %4056 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4057 = llvm.extractelement %4055[%4056 : i32] : vector<2xi16> loc(#loc67)
    %4058 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4059 = llvm.extractelement %4055[%4058 : i32] : vector<2xi16> loc(#loc67)
    %4060 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %4038, %4057, %4059, %4044 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc67)
    %4061 = llvm.mlir.constant(16 : i32) : i32 loc(#loc67)
    %4062 = llvm.xor %3955, %4061 : i32 loc(#loc67)
    %4063 = llvm.mlir.constant(5 : i32) : i32 loc(#loc67)
    %4064 = llvm.lshr %4062, %4063 : i32 loc(#loc67)
    %4065 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4066 = llvm.shl %4064, %4065 : i32 loc(#loc67)
    %4067 = llvm.add %4066, %4062 : i32 loc(#loc67)
    %4068 = llvm.getelementptr inbounds %3910[%4067] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc67)
    %4069 = llvm.mlir.undef : vector<2xf16> loc(#loc67)
    %4070 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4071 = llvm.insertelement %3900, %4069[%4070 : i32] : vector<2xf16> loc(#loc67)
    %4072 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4073 = llvm.insertelement %3901, %4071[%4072 : i32] : vector<2xf16> loc(#loc67)
    %4074 = llvm.mlir.constant(true) : i1 loc(#loc67)
    %4075 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4076 = llvm.extractelement %4073[%4075 : i32] : vector<2xf16> loc(#loc67)
    %4077 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4078 = llvm.extractelement %4073[%4077 : i32] : vector<2xf16> loc(#loc67)
    %4079 = llvm.bitcast %4076 : f16 to i16 loc(#loc67)
    %4080 = llvm.bitcast %4078 : f16 to i16 loc(#loc67)
    %4081 = llvm.mlir.undef : vector<2xi16> loc(#loc67)
    %4082 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4083 = llvm.insertelement %4079, %4081[%4082 : i32] : vector<2xi16> loc(#loc67)
    %4084 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4085 = llvm.insertelement %4080, %4083[%4084 : i32] : vector<2xi16> loc(#loc67)
    %4086 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4087 = llvm.extractelement %4085[%4086 : i32] : vector<2xi16> loc(#loc67)
    %4088 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4089 = llvm.extractelement %4085[%4088 : i32] : vector<2xi16> loc(#loc67)
    %4090 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %4068, %4087, %4089, %4074 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc67)
    %4091 = llvm.mlir.constant(272 : i32) : i32 loc(#loc67)
    %4092 = llvm.xor %3955, %4091 : i32 loc(#loc67)
    %4093 = llvm.mlir.constant(5 : i32) : i32 loc(#loc67)
    %4094 = llvm.lshr %4092, %4093 : i32 loc(#loc67)
    %4095 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4096 = llvm.shl %4094, %4095 : i32 loc(#loc67)
    %4097 = llvm.add %4096, %4092 : i32 loc(#loc67)
    %4098 = llvm.getelementptr inbounds %3910[%4097] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc67)
    %4099 = llvm.mlir.undef : vector<2xf16> loc(#loc67)
    %4100 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4101 = llvm.insertelement %3902, %4099[%4100 : i32] : vector<2xf16> loc(#loc67)
    %4102 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4103 = llvm.insertelement %3903, %4101[%4102 : i32] : vector<2xf16> loc(#loc67)
    %4104 = llvm.mlir.constant(true) : i1 loc(#loc67)
    %4105 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4106 = llvm.extractelement %4103[%4105 : i32] : vector<2xf16> loc(#loc67)
    %4107 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4108 = llvm.extractelement %4103[%4107 : i32] : vector<2xf16> loc(#loc67)
    %4109 = llvm.bitcast %4106 : f16 to i16 loc(#loc67)
    %4110 = llvm.bitcast %4108 : f16 to i16 loc(#loc67)
    %4111 = llvm.mlir.undef : vector<2xi16> loc(#loc67)
    %4112 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4113 = llvm.insertelement %4109, %4111[%4112 : i32] : vector<2xi16> loc(#loc67)
    %4114 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4115 = llvm.insertelement %4110, %4113[%4114 : i32] : vector<2xi16> loc(#loc67)
    %4116 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4117 = llvm.extractelement %4115[%4116 : i32] : vector<2xi16> loc(#loc67)
    %4118 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4119 = llvm.extractelement %4115[%4118 : i32] : vector<2xi16> loc(#loc67)
    %4120 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %4098, %4117, %4119, %4104 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc67)
    nvvm.barrier0 loc(#loc67)
    %4121 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4122 = llvm.xor %4000, %4121 : i32 loc(#loc67)
    %4123 = llvm.mlir.constant(5 : i32) : i32 loc(#loc67)
    %4124 = llvm.lshr %4122, %4123 : i32 loc(#loc67)
    %4125 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4126 = llvm.shl %4124, %4125 : i32 loc(#loc67)
    %4127 = llvm.add %4126, %4122 : i32 loc(#loc67)
    %4128 = llvm.getelementptr inbounds %3910[%4127] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc67)
    %4129 = llvm.mlir.constant(true) : i1 loc(#loc67)
    %4130 = llvm.load %4128 : !llvm.ptr<3> -> vector<4xi32> loc(#loc67)
    %4131 = llvm.mlir.undef : !llvm.struct<(i32, i32, i32, i32)> loc(#loc67)
    %4132 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4133 = llvm.extractelement %4130[%4132 : i32] : vector<4xi32> loc(#loc67)
    %4134 = llvm.insertvalue %4133, %4131[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc67)
    %4135 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4136 = llvm.extractelement %4130[%4135 : i32] : vector<4xi32> loc(#loc67)
    %4137 = llvm.insertvalue %4136, %4134[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc67)
    %4138 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %4139 = llvm.extractelement %4130[%4138 : i32] : vector<4xi32> loc(#loc67)
    %4140 = llvm.insertvalue %4139, %4137[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc67)
    %4141 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4142 = llvm.extractelement %4130[%4141 : i32] : vector<4xi32> loc(#loc67)
    %4143 = llvm.insertvalue %4142, %4140[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc67)
    %4144 = llvm.extractvalue %4143[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc67)
    %4145 = llvm.extractvalue %4143[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc67)
    %4146 = llvm.extractvalue %4143[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc67)
    %4147 = llvm.extractvalue %4143[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc67)
    %4148 = llvm.mlir.undef : vector<4xi32> loc(#loc67)
    %4149 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4150 = llvm.insertelement %4144, %4148[%4149 : i32] : vector<4xi32> loc(#loc67)
    %4151 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4152 = llvm.insertelement %4145, %4150[%4151 : i32] : vector<4xi32> loc(#loc67)
    %4153 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %4154 = llvm.insertelement %4146, %4152[%4153 : i32] : vector<4xi32> loc(#loc67)
    %4155 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4156 = llvm.insertelement %4147, %4154[%4155 : i32] : vector<4xi32> loc(#loc67)
    %4157 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4158 = llvm.extractelement %4156[%4157 : i32] : vector<4xi32> loc(#loc67)
    %4159 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4160 = llvm.extractelement %4156[%4159 : i32] : vector<4xi32> loc(#loc67)
    %4161 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %4162 = llvm.extractelement %4156[%4161 : i32] : vector<4xi32> loc(#loc67)
    %4163 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4164 = llvm.extractelement %4156[%4163 : i32] : vector<4xi32> loc(#loc67)
    %4165 = llvm.bitcast %4158 : i32 to vector<2xi16> loc(#loc67)
    %4166 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4167 = llvm.extractelement %4165[%4166 : i32] : vector<2xi16> loc(#loc67)
    %4168 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4169 = llvm.extractelement %4165[%4168 : i32] : vector<2xi16> loc(#loc67)
    %4170 = llvm.bitcast %4160 : i32 to vector<2xi16> loc(#loc67)
    %4171 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4172 = llvm.extractelement %4170[%4171 : i32] : vector<2xi16> loc(#loc67)
    %4173 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4174 = llvm.extractelement %4170[%4173 : i32] : vector<2xi16> loc(#loc67)
    %4175 = llvm.bitcast %4162 : i32 to vector<2xi16> loc(#loc67)
    %4176 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4177 = llvm.extractelement %4175[%4176 : i32] : vector<2xi16> loc(#loc67)
    %4178 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4179 = llvm.extractelement %4175[%4178 : i32] : vector<2xi16> loc(#loc67)
    %4180 = llvm.bitcast %4164 : i32 to vector<2xi16> loc(#loc67)
    %4181 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4182 = llvm.extractelement %4180[%4181 : i32] : vector<2xi16> loc(#loc67)
    %4183 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4184 = llvm.extractelement %4180[%4183 : i32] : vector<2xi16> loc(#loc67)
    %4185 = llvm.mlir.undef : vector<8xi16> loc(#loc67)
    %4186 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4187 = llvm.insertelement %4167, %4185[%4186 : i32] : vector<8xi16> loc(#loc67)
    %4188 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4189 = llvm.insertelement %4169, %4187[%4188 : i32] : vector<8xi16> loc(#loc67)
    %4190 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %4191 = llvm.insertelement %4172, %4189[%4190 : i32] : vector<8xi16> loc(#loc67)
    %4192 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4193 = llvm.insertelement %4174, %4191[%4192 : i32] : vector<8xi16> loc(#loc67)
    %4194 = llvm.mlir.constant(4 : i32) : i32 loc(#loc67)
    %4195 = llvm.insertelement %4177, %4193[%4194 : i32] : vector<8xi16> loc(#loc67)
    %4196 = llvm.mlir.constant(5 : i32) : i32 loc(#loc67)
    %4197 = llvm.insertelement %4179, %4195[%4196 : i32] : vector<8xi16> loc(#loc67)
    %4198 = llvm.mlir.constant(6 : i32) : i32 loc(#loc67)
    %4199 = llvm.insertelement %4182, %4197[%4198 : i32] : vector<8xi16> loc(#loc67)
    %4200 = llvm.mlir.constant(7 : i32) : i32 loc(#loc67)
    %4201 = llvm.insertelement %4184, %4199[%4200 : i32] : vector<8xi16> loc(#loc67)
    %4202 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4203 = llvm.extractelement %4201[%4202 : i32] : vector<8xi16> loc(#loc67)
    %4204 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4205 = llvm.extractelement %4201[%4204 : i32] : vector<8xi16> loc(#loc67)
    %4206 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %4207 = llvm.extractelement %4201[%4206 : i32] : vector<8xi16> loc(#loc67)
    %4208 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4209 = llvm.extractelement %4201[%4208 : i32] : vector<8xi16> loc(#loc67)
    %4210 = llvm.mlir.constant(4 : i32) : i32 loc(#loc67)
    %4211 = llvm.extractelement %4201[%4210 : i32] : vector<8xi16> loc(#loc67)
    %4212 = llvm.mlir.constant(5 : i32) : i32 loc(#loc67)
    %4213 = llvm.extractelement %4201[%4212 : i32] : vector<8xi16> loc(#loc67)
    %4214 = llvm.mlir.constant(6 : i32) : i32 loc(#loc67)
    %4215 = llvm.extractelement %4201[%4214 : i32] : vector<8xi16> loc(#loc67)
    %4216 = llvm.mlir.constant(7 : i32) : i32 loc(#loc67)
    %4217 = llvm.extractelement %4201[%4216 : i32] : vector<8xi16> loc(#loc67)
    %4218 = llvm.bitcast %4203 : i16 to f16 loc(#loc67)
    %4219 = llvm.bitcast %4205 : i16 to f16 loc(#loc67)
    %4220 = llvm.bitcast %4207 : i16 to f16 loc(#loc67)
    %4221 = llvm.bitcast %4209 : i16 to f16 loc(#loc67)
    %4222 = llvm.bitcast %4211 : i16 to f16 loc(#loc67)
    %4223 = llvm.bitcast %4213 : i16 to f16 loc(#loc67)
    %4224 = llvm.bitcast %4215 : i16 to f16 loc(#loc67)
    %4225 = llvm.bitcast %4217 : i16 to f16 loc(#loc67)
    %4226 = llvm.mlir.undef : vector<8xf16> loc(#loc67)
    %4227 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4228 = llvm.insertelement %4218, %4226[%4227 : i32] : vector<8xf16> loc(#loc67)
    %4229 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4230 = llvm.insertelement %4219, %4228[%4229 : i32] : vector<8xf16> loc(#loc67)
    %4231 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %4232 = llvm.insertelement %4220, %4230[%4231 : i32] : vector<8xf16> loc(#loc67)
    %4233 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4234 = llvm.insertelement %4221, %4232[%4233 : i32] : vector<8xf16> loc(#loc67)
    %4235 = llvm.mlir.constant(4 : i32) : i32 loc(#loc67)
    %4236 = llvm.insertelement %4222, %4234[%4235 : i32] : vector<8xf16> loc(#loc67)
    %4237 = llvm.mlir.constant(5 : i32) : i32 loc(#loc67)
    %4238 = llvm.insertelement %4223, %4236[%4237 : i32] : vector<8xf16> loc(#loc67)
    %4239 = llvm.mlir.constant(6 : i32) : i32 loc(#loc67)
    %4240 = llvm.insertelement %4224, %4238[%4239 : i32] : vector<8xf16> loc(#loc67)
    %4241 = llvm.mlir.constant(7 : i32) : i32 loc(#loc67)
    %4242 = llvm.insertelement %4225, %4240[%4241 : i32] : vector<8xf16> loc(#loc67)
    %4243 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4244 = llvm.extractelement %4242[%4243 : i32] : vector<8xf16> loc(#loc67)
    %4245 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4246 = llvm.extractelement %4242[%4245 : i32] : vector<8xf16> loc(#loc67)
    %4247 = llvm.mlir.constant(2 : i32) : i32 loc(#loc67)
    %4248 = llvm.extractelement %4242[%4247 : i32] : vector<8xf16> loc(#loc67)
    %4249 = llvm.mlir.constant(3 : i32) : i32 loc(#loc67)
    %4250 = llvm.extractelement %4242[%4249 : i32] : vector<8xf16> loc(#loc67)
    %4251 = llvm.mlir.constant(4 : i32) : i32 loc(#loc67)
    %4252 = llvm.extractelement %4242[%4251 : i32] : vector<8xf16> loc(#loc67)
    %4253 = llvm.mlir.constant(5 : i32) : i32 loc(#loc67)
    %4254 = llvm.extractelement %4242[%4253 : i32] : vector<8xf16> loc(#loc67)
    %4255 = llvm.mlir.constant(6 : i32) : i32 loc(#loc67)
    %4256 = llvm.extractelement %4242[%4255 : i32] : vector<8xf16> loc(#loc67)
    %4257 = llvm.mlir.constant(7 : i32) : i32 loc(#loc67)
    %4258 = llvm.extractelement %4242[%4257 : i32] : vector<8xf16> loc(#loc67)
    %4259 = llvm.mlir.undef : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)> loc(#loc67)
    %4260 = llvm.insertvalue %4244, %4259[0] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4261 = llvm.insertvalue %4246, %4260[1] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4262 = llvm.insertvalue %4248, %4261[2] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4263 = llvm.insertvalue %4250, %4262[3] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4264 = llvm.insertvalue %4252, %4263[4] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4265 = llvm.insertvalue %4254, %4264[5] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4266 = llvm.insertvalue %4256, %4265[6] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4267 = llvm.insertvalue %4258, %4266[7] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4268 = llvm.extractvalue %3742[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc67)
    %4269 = llvm.extractvalue %3742[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc67)
    %4270 = llvm.extractvalue %3742[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc67)
    %4271 = llvm.extractvalue %3742[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc67)
    %4272 = llvm.extractvalue %3742[4] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc67)
    %4273 = llvm.extractvalue %3742[5] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc67)
    %4274 = llvm.extractvalue %3742[6] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc67)
    %4275 = llvm.extractvalue %3742[7] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc67)
    %4276 = llvm.extractvalue %4267[0] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4277 = llvm.extractvalue %4267[1] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4278 = llvm.extractvalue %4267[2] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4279 = llvm.extractvalue %4267[3] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4280 = llvm.extractvalue %4267[4] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4281 = llvm.extractvalue %4267[5] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4282 = llvm.extractvalue %4267[6] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4283 = llvm.extractvalue %4267[7] : !llvm.struct<(f16, f16, f16, f16, f16, f16, f16, f16)>  loc(#loc67)
    %4284 = llvm.extractvalue %3895[0] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc67)
    %4285 = llvm.extractvalue %3895[1] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc67)
    %4286 = llvm.extractvalue %3895[2] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc67)
    %4287 = llvm.extractvalue %3895[3] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc67)
    %4288 = llvm.extractvalue %3895[4] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc67)
    %4289 = llvm.extractvalue %3895[5] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc67)
    %4290 = llvm.extractvalue %3895[6] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc67)
    %4291 = llvm.extractvalue %3895[7] : !llvm.struct<(i1, i1, i1, i1, i1, i1, i1, i1)>  loc(#loc67)
    %4292 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4293 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc67)
    %4294 = llvm.mlir.constant(32 : i32) : i32 loc(#loc67)
    %4295 = llvm.urem %4293, %4294 : i32 loc(#loc67)
    %4296 = llvm.udiv %4293, %4294 : i32 loc(#loc67)
    %4297 = llvm.mlir.undef : vector<2xf16> loc(#loc67)
    %4298 = llvm.bitcast %4276 : f16 to f16 loc(#loc67)
    %4299 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4300 = llvm.insertelement %4298, %4297[%4299 : i32] : vector<2xf16> loc(#loc67)
    %4301 = llvm.bitcast %4277 : f16 to f16 loc(#loc67)
    %4302 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4303 = llvm.insertelement %4301, %4300[%4302 : i32] : vector<2xf16> loc(#loc67)
    %4304 = llvm.bitcast %4303 : vector<2xf16> to i32 loc(#loc67)
    %4305 = llvm.mlir.undef : vector<2xf16> loc(#loc67)
    %4306 = llvm.bitcast %4278 : f16 to f16 loc(#loc67)
    %4307 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4308 = llvm.insertelement %4306, %4305[%4307 : i32] : vector<2xf16> loc(#loc67)
    %4309 = llvm.bitcast %4279 : f16 to f16 loc(#loc67)
    %4310 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4311 = llvm.insertelement %4309, %4308[%4310 : i32] : vector<2xf16> loc(#loc67)
    %4312 = llvm.bitcast %4311 : vector<2xf16> to i32 loc(#loc67)
    %4313 = llvm.mlir.undef : vector<2xf16> loc(#loc67)
    %4314 = llvm.bitcast %4280 : f16 to f16 loc(#loc67)
    %4315 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4316 = llvm.insertelement %4314, %4313[%4315 : i32] : vector<2xf16> loc(#loc67)
    %4317 = llvm.bitcast %4281 : f16 to f16 loc(#loc67)
    %4318 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4319 = llvm.insertelement %4317, %4316[%4318 : i32] : vector<2xf16> loc(#loc67)
    %4320 = llvm.bitcast %4319 : vector<2xf16> to i32 loc(#loc67)
    %4321 = llvm.mlir.undef : vector<2xf16> loc(#loc67)
    %4322 = llvm.bitcast %4282 : f16 to f16 loc(#loc67)
    %4323 = llvm.mlir.constant(0 : i32) : i32 loc(#loc67)
    %4324 = llvm.insertelement %4322, %4321[%4323 : i32] : vector<2xf16> loc(#loc67)
    %4325 = llvm.bitcast %4283 : f16 to f16 loc(#loc67)
    %4326 = llvm.mlir.constant(1 : i32) : i32 loc(#loc67)
    %4327 = llvm.insertelement %4325, %4324[%4326 : i32] : vector<2xf16> loc(#loc67)
    %4328 = llvm.bitcast %4327 : vector<2xf16> to i32 loc(#loc67)
    %4329 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$5 st.global.v4.b32 [ $4 + 0 ], { $0, $1, $2, $3 };", "r,r,r,r,l,b" %4304, %4312, %4320, %4328, %4268, %4284 : (i32, i32, i32, i32, !llvm.ptr<1>, i1) -> !llvm.void loc(#loc67)
    llvm.return loc(#loc68)
  } loc(#loc)
} loc(#loc)
#loc3 = loc("examples/kernels/binary_ops.py":126:24)
#loc4 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc5 = loc("examples/kernels/binary_ops.py":127:27)
#loc6 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc7 = loc("examples/kernels/binary_ops.py":128:27)
#loc8 = loc("examples/kernels/binary_ops.py":129:38)
#loc9 = loc("examples/kernels/binary_ops.py":130:22)
#loc10 = loc("examples/kernels/binary_ops.py":131:29)
#loc11 = loc("examples/kernels/binary_ops.py":132:35)
#loc12 = loc("examples/kernels/binary_ops.py":132:48)
#loc13 = loc("examples/kernels/binary_ops.py":133:34)
#loc14 = loc("examples/kernels/binary_ops.py":133:54)
#loc15 = loc("examples/kernels/binary_ops.py":133:27)
#loc16 = loc("examples/kernels/binary_ops.py":134:40)
#loc17 = loc("examples/kernels/binary_ops.py":140:23)
#loc18 = loc("examples/kernels/binary_ops.py":140:14)
#loc19 = loc("examples/kernels/binary_ops.py":141:23)
#loc20 = loc("examples/kernels/binary_ops.py":141:14)
#loc21 = loc("examples/kernels/binary_ops.py":142:26)
#loc22 = loc("examples/kernels/binary_ops.py":142:14)
#loc23 = loc("examples/kernels/binary_ops.py":143:14)
#loc24 = loc("examples/kernels/binary_ops.py":144:14)
#loc25 = loc("examples/kernels/binary_ops.py":145:26)
#loc26 = loc("examples/kernels/binary_ops.py":145:14)
#loc27 = loc("examples/kernels/binary_ops.py":146:26)
#loc28 = loc("examples/kernels/binary_ops.py":146:14)
#loc29 = loc("examples/kernels/binary_ops.py":147:14)
#loc30 = loc("examples/kernels/binary_ops.py":156:23)
#loc31 = loc("examples/kernels/binary_ops.py":156:51)
#loc32 = loc("examples/kernels/binary_ops.py":156:38)
#loc33 = loc("examples/kernels/binary_ops.py":156:68)
#loc34 = loc("examples/kernels/binary_ops.py":157:23)
#loc35 = loc("examples/kernels/binary_ops.py":157:38)
#loc36 = loc("examples/kernels/binary_ops.py":157:68)
#loc37 = loc("examples/kernels/binary_ops.py":159:30)
#loc38 = loc("examples/kernels/binary_ops.py":159:41)
#loc39 = loc("examples/kernels/binary_ops.py":159:60)
#loc40 = loc("examples/kernels/binary_ops.py":159:53)
#loc42 = loc("examples/kernels/binary_ops.py":160:29)
#loc43 = loc("examples/kernels/binary_ops.py":160:40)
#loc44 = loc("examples/kernels/binary_ops.py":160:60)
#loc45 = loc("examples/kernels/binary_ops.py":160:52)
#loc47 = loc("examples/kernels/binary_ops.py":168:33)
#loc48 = loc("examples/kernels/binary_ops.py":177:33)
#loc49 = loc("examples/kernels/binary_ops.py":177:18)
#loc50 = loc("examples/kernels/binary_ops.py":171:20)
#loc52 = loc("examples/kernels/binary_ops.py":171:51)
#loc53 = loc("examples/kernels/binary_ops.py":172:51)
#loc54 = loc("examples/kernels/binary_ops.py":174:35)
#loc55 = loc("examples/kernels/binary_ops.py":176:18)
#loc56 = loc("examples/kernels/binary_ops.py":171:59)
#loc57 = loc("examples/kernels/binary_ops.py":171:55)
#loc58 = loc("examples/kernels/binary_ops.py":182:23)
#loc59 = loc("examples/kernels/binary_ops.py":188:41)
#loc60 = loc("examples/kernels/binary_ops.py":188:33)
#loc61 = loc("examples/kernels/binary_ops.py":188:21)
#loc62 = loc("examples/kernels/binary_ops.py":188:72)
#loc63 = loc("examples/kernels/binary_ops.py":188:52)
#loc64 = loc("examples/kernels/binary_ops.py":189:33)
#loc65 = loc("examples/kernels/binary_ops.py":189:58)
#loc66 = loc("examples/kernels/binary_ops.py":189:39)
#loc67 = loc("examples/kernels/binary_ops.py":190:21)
#loc68 = loc("examples/kernels/binary_ops.py":190:4)
#loc69 = loc(callsite(#loc4 at #loc5))
#loc70 = loc(callsite(#loc6 at #loc5))
#loc71 = loc(callsite(#loc4 at #loc7))
#loc72 = loc(callsite(#loc6 at #loc7))
#loc73 = loc(callsite(#loc4 at #loc47))
#loc74 = loc(callsite(#loc6 at #loc47))


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc39 = loc("examples/kernels/binary_ops.py":159:22)
#loc43 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
module attributes {ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @matmul_kernel(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg9: !llvm.ptr<1> loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.undef : vector<8xf16> loc(#loc1)
    %1 = llvm.mlir.undef : vector<8xi16> loc(#loc1)
    %2 = llvm.mlir.undef : vector<4xi32> loc(#loc1)
    %3 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %4 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %5 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.undef : vector<1xf32> loc(#loc1)
    %7 = llvm.mlir.constant(272 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.constant(256 : i32) : i32 loc(#loc1)
    %10 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(512 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %13 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc1)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(6 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %22 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc1)
    %23 = llvm.mlir.constant(15 : i32) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(31 : i32) : i32 loc(#loc1)
    %25 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %26 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %27 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %28 = llvm.mlir.constant(true) : i1 loc(#loc1)
    %29 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %30 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %31 = llvm.mlir.constant(-1 : i32) : i32 loc(#loc1)
    %32 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %33 = llvm.insertvalue %32, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %34 = llvm.insertvalue %32, %33[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %35 = llvm.insertvalue %32, %34[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %36 = llvm.insertvalue %32, %35[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %37 = llvm.insertvalue %32, %36[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %38 = llvm.insertvalue %32, %37[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %39 = llvm.insertvalue %32, %38[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %40 = llvm.insertvalue %32, %39[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %41 = llvm.call_intrinsic "llvm.nvvm.read.ptx.sreg.ctaid.x"() : () -> i32 loc(#loc2)
    %42 = llvm.add %arg3, %24 : i32 loc(#loc65)
    %43 = llvm.sdiv %42, %27 : i32 loc(#loc66)
    %44 = llvm.add %arg4, %24 : i32 loc(#loc67)
    %45 = llvm.sdiv %44, %27 : i32 loc(#loc68)
    %46 = llvm.mul %45, %30 : i32 loc(#loc7)
    %47 = llvm.sdiv %41, %46 : i32 loc(#loc8)
    %48 = llvm.mul %47, %30 : i32 loc(#loc9)
    %49 = llvm.sub %43, %48 : i32 loc(#loc10)
    %50 = llvm.intr.smin(%49, %30) : (i32, i32) -> i32 loc(#loc11)
    %51 = llvm.srem %41, %46 : i32 loc(#loc12)
    %52 = llvm.srem %51, %50 : i32 loc(#loc13)
    %53 = llvm.add %48, %52 : i32 loc(#loc14)
    %54 = llvm.sdiv %51, %50 : i32 loc(#loc15)
    %55 = llvm.icmp "sge" %53, %29 : i32 loc(#loc16)
    llvm.intr.assume %55 : i1 loc(#loc17)
    %56 = llvm.icmp "sge" %54, %29 : i32 loc(#loc18)
    llvm.intr.assume %56 : i1 loc(#loc19)
    %57 = llvm.icmp "sgt" %arg6, %29 : i32 loc(#loc20)
    llvm.intr.assume %57 : i1 loc(#loc21)
    llvm.intr.assume %28 : i1 loc(#loc22)
    llvm.intr.assume %28 : i1 loc(#loc23)
    %58 = llvm.icmp "sgt" %arg7, %29 : i32 loc(#loc24)
    llvm.intr.assume %58 : i1 loc(#loc25)
    %59 = llvm.icmp "sgt" %arg8, %29 : i32 loc(#loc26)
    llvm.intr.assume %59 : i1 loc(#loc27)
    llvm.intr.assume %28 : i1 loc(#loc28)
    %60 = llvm.mul %53, %27 : i32 loc(#loc29)
    %61 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc30)
    %62 = llvm.urem %61, %27 : i32 loc(#loc30)
    %63 = llvm.udiv %61, %27 : i32 loc(#loc30)
    %64 = llvm.and %62, %26 : i32 loc(#loc30)
    %65 = llvm.icmp "eq" %64, %29 : i32 loc(#loc30)
    %66 = llvm.select %65, %29, %25 : i1, i32 loc(#loc30)
    %67 = llvm.xor %29, %66 : i32 loc(#loc30)
    %68 = llvm.and %63, %25 : i32 loc(#loc30)
    %69 = llvm.icmp "eq" %68, %29 : i32 loc(#loc30)
    %70 = llvm.select %69, %29, %20 : i1, i32 loc(#loc30)
    %71 = llvm.xor %67, %70 : i32 loc(#loc30)
    %72 = llvm.and %63, %20 : i32 loc(#loc30)
    %73 = llvm.icmp "eq" %72, %29 : i32 loc(#loc30)
    %74 = llvm.select %73, %29, %30 : i1, i32 loc(#loc30)
    %75 = llvm.xor %71, %74 : i32 loc(#loc30)
    %76 = llvm.xor %75, %29 : i32 loc(#loc30)
    %77 = llvm.xor %75, %19 : i32 loc(#loc30)
    %78 = llvm.xor %75, %26 : i32 loc(#loc30)
    %79 = llvm.xor %75, %18 : i32 loc(#loc30)
    %80 = llvm.add %76, %21 : i32 loc(#loc30)
    %81 = llvm.add %77, %21 : i32 loc(#loc30)
    %82 = llvm.add %78, %21 : i32 loc(#loc30)
    %83 = llvm.add %79, %21 : i32 loc(#loc30)
    %84 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc30)
    %85 = llvm.urem %84, %27 : i32 loc(#loc30)
    %86 = llvm.udiv %84, %27 : i32 loc(#loc30)
    %87 = llvm.and %85, %30 : i32 loc(#loc30)
    %88 = llvm.icmp "eq" %87, %29 : i32 loc(#loc30)
    %89 = llvm.select %88, %29, %25 : i1, i32 loc(#loc30)
    %90 = llvm.xor %29, %89 : i32 loc(#loc30)
    %91 = llvm.and %85, %19 : i32 loc(#loc30)
    %92 = llvm.icmp "eq" %91, %29 : i32 loc(#loc30)
    %93 = llvm.select %92, %29, %20 : i1, i32 loc(#loc30)
    %94 = llvm.xor %90, %93 : i32 loc(#loc30)
    %95 = llvm.and %85, %26 : i32 loc(#loc30)
    %96 = llvm.icmp "eq" %95, %29 : i32 loc(#loc30)
    %97 = llvm.select %96, %29, %30 : i1, i32 loc(#loc30)
    %98 = llvm.xor %94, %97 : i32 loc(#loc30)
    %99 = llvm.and %86, %25 : i32 loc(#loc30)
    %100 = llvm.icmp "eq" %99, %29 : i32 loc(#loc30)
    %101 = llvm.select %100, %29, %19 : i1, i32 loc(#loc30)
    %102 = llvm.xor %98, %101 : i32 loc(#loc30)
    %103 = llvm.and %86, %20 : i32 loc(#loc30)
    %104 = llvm.icmp "eq" %103, %29 : i32 loc(#loc30)
    %105 = llvm.select %104, %29, %26 : i1, i32 loc(#loc30)
    %106 = llvm.xor %102, %105 : i32 loc(#loc30)
    %107 = llvm.xor %106, %29 : i32 loc(#loc30)
    %108 = llvm.add %107, %21 : i32 loc(#loc30)
    %109 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc30)
    %110 = llvm.urem %109, %27 : i32 loc(#loc30)
    %111 = llvm.and %110, %25 : i32 loc(#loc30)
    %112 = llvm.icmp "eq" %111, %29 : i32 loc(#loc30)
    %113 = llvm.select %112, %29, %30 : i1, i32 loc(#loc30)
    %114 = llvm.xor %29, %113 : i32 loc(#loc30)
    %115 = llvm.and %110, %20 : i32 loc(#loc30)
    %116 = llvm.icmp "eq" %115, %29 : i32 loc(#loc30)
    %117 = llvm.select %116, %29, %19 : i1, i32 loc(#loc30)
    %118 = llvm.xor %114, %117 : i32 loc(#loc30)
    %119 = llvm.and %110, %30 : i32 loc(#loc30)
    %120 = llvm.icmp "eq" %119, %29 : i32 loc(#loc30)
    %121 = llvm.select %120, %29, %26 : i1, i32 loc(#loc30)
    %122 = llvm.xor %118, %121 : i32 loc(#loc30)
    %123 = llvm.xor %122, %29 : i32 loc(#loc30)
    %124 = llvm.xor %122, %25 : i32 loc(#loc30)
    %125 = llvm.xor %122, %20 : i32 loc(#loc30)
    %126 = llvm.xor %122, %17 : i32 loc(#loc30)
    %127 = llvm.add %123, %21 : i32 loc(#loc30)
    %128 = llvm.add %124, %21 : i32 loc(#loc30)
    %129 = llvm.add %125, %21 : i32 loc(#loc30)
    %130 = llvm.add %126, %21 : i32 loc(#loc30)
    %131 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc30)
    %132 = llvm.urem %131, %27 : i32 loc(#loc30)
    %133 = llvm.and %132, %25 : i32 loc(#loc30)
    %134 = llvm.icmp "eq" %133, %29 : i32 loc(#loc30)
    %135 = llvm.select %134, %29, %19 : i1, i32 loc(#loc30)
    %136 = llvm.xor %29, %135 : i32 loc(#loc30)
    %137 = llvm.and %132, %20 : i32 loc(#loc30)
    %138 = llvm.icmp "eq" %137, %29 : i32 loc(#loc30)
    %139 = llvm.select %138, %29, %26 : i1, i32 loc(#loc30)
    %140 = llvm.xor %136, %139 : i32 loc(#loc30)
    %141 = llvm.xor %140, %29 : i32 loc(#loc30)
    %142 = llvm.add %141, %21 : i32 loc(#loc30)
    %143 = llvm.add %60, %80 : i32 loc(#loc31)
    %144 = llvm.add %60, %81 : i32 loc(#loc31)
    %145 = llvm.add %60, %82 : i32 loc(#loc31)
    %146 = llvm.add %60, %83 : i32 loc(#loc31)
    %147 = llvm.add %60, %108 : i32 loc(#loc31)
    %148 = llvm.srem %143, %arg3 : i32 loc(#loc32)
    %149 = llvm.srem %144, %arg3 : i32 loc(#loc32)
    %150 = llvm.srem %145, %arg3 : i32 loc(#loc32)
    %151 = llvm.srem %146, %arg3 : i32 loc(#loc32)
    %152 = llvm.mul %54, %27 : i32 loc(#loc33)
    %153 = llvm.add %152, %127 : i32 loc(#loc34)
    %154 = llvm.add %152, %128 : i32 loc(#loc34)
    %155 = llvm.add %152, %129 : i32 loc(#loc34)
    %156 = llvm.add %152, %130 : i32 loc(#loc34)
    %157 = llvm.add %152, %142 : i32 loc(#loc34)
    %158 = llvm.srem %153, %arg4 : i32 loc(#loc35)
    %159 = llvm.srem %154, %arg4 : i32 loc(#loc35)
    %160 = llvm.srem %155, %arg4 : i32 loc(#loc35)
    %161 = llvm.srem %156, %arg4 : i32 loc(#loc35)
    %162 = llvm.mul %148, %arg6 : i32 loc(#loc36)
    %163 = llvm.mul %149, %arg6 : i32 loc(#loc36)
    %164 = llvm.mul %150, %arg6 : i32 loc(#loc36)
    %165 = llvm.mul %151, %arg6 : i32 loc(#loc36)
    %166 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc37)
    %167 = llvm.urem %166, %27 : i32 loc(#loc37)
    %168 = llvm.and %167, %25 : i32 loc(#loc37)
    %169 = llvm.icmp "eq" %168, %29 : i32 loc(#loc37)
    %170 = llvm.select %169, %29, %25 : i1, i32 loc(#loc37)
    %171 = llvm.xor %29, %170 : i32 loc(#loc37)
    %172 = llvm.and %167, %20 : i32 loc(#loc37)
    %173 = llvm.icmp "eq" %172, %29 : i32 loc(#loc37)
    %174 = llvm.select %173, %29, %20 : i1, i32 loc(#loc37)
    %175 = llvm.xor %171, %174 : i32 loc(#loc37)
    %176 = llvm.and %167, %30 : i32 loc(#loc37)
    %177 = llvm.icmp "eq" %176, %29 : i32 loc(#loc37)
    %178 = llvm.select %177, %29, %30 : i1, i32 loc(#loc37)
    %179 = llvm.xor %175, %178 : i32 loc(#loc37)
    %180 = llvm.and %167, %19 : i32 loc(#loc37)
    %181 = llvm.icmp "eq" %180, %29 : i32 loc(#loc37)
    %182 = llvm.select %181, %29, %19 : i1, i32 loc(#loc37)
    %183 = llvm.xor %179, %182 : i32 loc(#loc37)
    %184 = llvm.xor %183, %29 : i32 loc(#loc37)
    %185 = llvm.add %184, %21 : i32 loc(#loc37)
    %186 = llvm.add %162, %185 : i32 loc(#loc38)
    %187 = llvm.add %163, %185 : i32 loc(#loc38)
    %188 = llvm.add %164, %185 : i32 loc(#loc38)
    %189 = llvm.add %165, %185 : i32 loc(#loc38)
    %190 = llvm.getelementptr %arg0[%186] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %191 = llvm.getelementptr %arg0[%187] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %192 = llvm.getelementptr %arg0[%188] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %193 = llvm.getelementptr %arg0[%189] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %194 = llvm.insertvalue %190, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %195 = llvm.insertvalue %191, %194[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %196 = llvm.insertvalue %192, %195[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %197 = llvm.insertvalue %193, %196[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %198 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc40)
    %199 = llvm.urem %198, %27 : i32 loc(#loc40)
    %200 = llvm.udiv %198, %27 : i32 loc(#loc40)
    %201 = llvm.and %199, %19 : i32 loc(#loc40)
    %202 = llvm.icmp "eq" %201, %29 : i32 loc(#loc40)
    %203 = llvm.select %202, %29, %25 : i1, i32 loc(#loc40)
    %204 = llvm.xor %29, %203 : i32 loc(#loc40)
    %205 = llvm.and %199, %26 : i32 loc(#loc40)
    %206 = llvm.icmp "eq" %205, %29 : i32 loc(#loc40)
    %207 = llvm.select %206, %29, %20 : i1, i32 loc(#loc40)
    %208 = llvm.xor %204, %207 : i32 loc(#loc40)
    %209 = llvm.and %200, %25 : i32 loc(#loc40)
    %210 = llvm.icmp "eq" %209, %29 : i32 loc(#loc40)
    %211 = llvm.select %210, %29, %30 : i1, i32 loc(#loc40)
    %212 = llvm.xor %208, %211 : i32 loc(#loc40)
    %213 = llvm.and %200, %20 : i32 loc(#loc40)
    %214 = llvm.icmp "eq" %213, %29 : i32 loc(#loc40)
    %215 = llvm.select %214, %29, %19 : i1, i32 loc(#loc40)
    %216 = llvm.xor %212, %215 : i32 loc(#loc40)
    %217 = llvm.xor %216, %29 : i32 loc(#loc40)
    %218 = llvm.add %217, %21 : i32 loc(#loc40)
    %219 = llvm.mul %218, %arg7 : i32 loc(#loc41)
    %220 = llvm.add %219, %158 : i32 loc(#loc42)
    %221 = llvm.add %219, %159 : i32 loc(#loc42)
    %222 = llvm.add %219, %160 : i32 loc(#loc42)
    %223 = llvm.add %219, %161 : i32 loc(#loc42)
    %224 = llvm.getelementptr %arg1[%220] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %225 = llvm.getelementptr %arg1[%221] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %226 = llvm.getelementptr %arg1[%222] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %227 = llvm.getelementptr %arg1[%223] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %228 = llvm.insertvalue %224, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %229 = llvm.insertvalue %225, %228[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %230 = llvm.insertvalue %226, %229[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %231 = llvm.insertvalue %227, %230[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %232 = llvm.add %arg5, %23 : i32 loc(#loc69)
    %233 = llvm.sdiv %232, %26 : i32 loc(#loc70)
    %234 = llvm.mul %arg7, %26 : i32 loc(#loc45)
    %235 = llvm.getelementptr %12[2048] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc46)
    %236 = llvm.icmp "sgt" %233, %29 : i32 loc(#loc47)
    %237 = llvm.icmp "slt" %185, %arg5 : i32 loc(#loc48)
    %238 = llvm.mul %29, %11 : i32 loc(#loc49)
    %239 = llvm.add %238, %29 : i32 loc(#loc49)
    %240 = llvm.mul %29, %26 : i32 loc(#loc49)
    %241 = llvm.add %239, %240 : i32 loc(#loc49)
    %242 = llvm.mul %29, %25 : i32 loc(#loc49)
    %243 = llvm.add %241, %242 : i32 loc(#loc49)
    %244 = llvm.getelementptr %12[%243] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %245 = llvm.and %236, %237 : i1 loc(#loc47)
    %246 = llvm.and %236, %237 : i1 loc(#loc47)
    %247 = llvm.and %236, %237 : i1 loc(#loc47)
    %248 = llvm.and %236, %237 : i1 loc(#loc47)
    %249 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc49)
    %250 = llvm.urem %249, %27 : i32 loc(#loc49)
    %251 = llvm.udiv %249, %27 : i32 loc(#loc49)
    %252 = llvm.and %250, %25 : i32 loc(#loc49)
    %253 = llvm.icmp "eq" %252, %29 : i32 loc(#loc49)
    %254 = llvm.select %253, %29, %25 : i1, i32 loc(#loc49)
    %255 = llvm.xor %29, %254 : i32 loc(#loc49)
    %256 = llvm.and %250, %20 : i32 loc(#loc49)
    %257 = llvm.icmp "eq" %256, %29 : i32 loc(#loc49)
    %258 = llvm.select %257, %29, %20 : i1, i32 loc(#loc49)
    %259 = llvm.xor %255, %258 : i32 loc(#loc49)
    %260 = llvm.and %250, %30 : i32 loc(#loc49)
    %261 = llvm.icmp "eq" %260, %29 : i32 loc(#loc49)
    %262 = llvm.select %261, %29, %30 : i1, i32 loc(#loc49)
    %263 = llvm.xor %259, %262 : i32 loc(#loc49)
    %264 = llvm.and %250, %19 : i32 loc(#loc49)
    %265 = llvm.icmp "eq" %264, %29 : i32 loc(#loc49)
    %266 = llvm.select %265, %29, %19 : i1, i32 loc(#loc49)
    %267 = llvm.xor %263, %266 : i32 loc(#loc49)
    %268 = llvm.and %250, %26 : i32 loc(#loc49)
    %269 = llvm.icmp "eq" %268, %29 : i32 loc(#loc49)
    %270 = llvm.select %269, %29, %25 : i1, i32 loc(#loc49)
    %271 = llvm.xor %29, %270 : i32 loc(#loc49)
    %272 = llvm.and %251, %25 : i32 loc(#loc49)
    %273 = llvm.icmp "eq" %272, %29 : i32 loc(#loc49)
    %274 = llvm.select %273, %29, %30 : i1, i32 loc(#loc49)
    %275 = llvm.xor %267, %274 : i32 loc(#loc49)
    %276 = llvm.select %273, %29, %20 : i1, i32 loc(#loc49)
    %277 = llvm.xor %271, %276 : i32 loc(#loc49)
    %278 = llvm.and %251, %20 : i32 loc(#loc49)
    %279 = llvm.icmp "eq" %278, %29 : i32 loc(#loc49)
    %280 = llvm.select %279, %29, %19 : i1, i32 loc(#loc49)
    %281 = llvm.xor %275, %280 : i32 loc(#loc49)
    %282 = llvm.select %279, %29, %30 : i1, i32 loc(#loc49)
    %283 = llvm.xor %277, %282 : i32 loc(#loc49)
    %284 = llvm.mul %281, %25 : i32 loc(#loc49)
    %285 = llvm.add %284, %29 : i32 loc(#loc49)
    %286 = llvm.mul %283, %26 : i32 loc(#loc49)
    %287 = llvm.add %285, %286 : i32 loc(#loc49)
    %288 = llvm.getelementptr inbounds %244[%287] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %289 = llvm.and %250, %25 : i32 loc(#loc49)
    %290 = llvm.icmp "eq" %289, %29 : i32 loc(#loc49)
    %291 = llvm.select %290, %29, %25 : i1, i32 loc(#loc49)
    %292 = llvm.xor %29, %291 : i32 loc(#loc49)
    %293 = llvm.and %250, %20 : i32 loc(#loc49)
    %294 = llvm.icmp "eq" %293, %29 : i32 loc(#loc49)
    %295 = llvm.select %294, %29, %20 : i1, i32 loc(#loc49)
    %296 = llvm.xor %292, %295 : i32 loc(#loc49)
    %297 = llvm.and %250, %30 : i32 loc(#loc49)
    %298 = llvm.icmp "eq" %297, %29 : i32 loc(#loc49)
    %299 = llvm.select %298, %29, %30 : i1, i32 loc(#loc49)
    %300 = llvm.xor %296, %299 : i32 loc(#loc49)
    %301 = llvm.and %250, %19 : i32 loc(#loc49)
    %302 = llvm.icmp "eq" %301, %29 : i32 loc(#loc49)
    %303 = llvm.select %302, %29, %19 : i1, i32 loc(#loc49)
    %304 = llvm.xor %300, %303 : i32 loc(#loc49)
    %305 = llvm.and %250, %26 : i32 loc(#loc49)
    %306 = llvm.icmp "eq" %305, %29 : i32 loc(#loc49)
    %307 = llvm.select %306, %29, %25 : i1, i32 loc(#loc49)
    %308 = llvm.xor %19, %307 : i32 loc(#loc49)
    %309 = llvm.and %251, %25 : i32 loc(#loc49)
    %310 = llvm.icmp "eq" %309, %29 : i32 loc(#loc49)
    %311 = llvm.select %310, %29, %30 : i1, i32 loc(#loc49)
    %312 = llvm.xor %304, %311 : i32 loc(#loc49)
    %313 = llvm.select %310, %29, %20 : i1, i32 loc(#loc49)
    %314 = llvm.xor %308, %313 : i32 loc(#loc49)
    %315 = llvm.and %251, %20 : i32 loc(#loc49)
    %316 = llvm.icmp "eq" %315, %29 : i32 loc(#loc49)
    %317 = llvm.select %316, %29, %19 : i1, i32 loc(#loc49)
    %318 = llvm.xor %312, %317 : i32 loc(#loc49)
    %319 = llvm.select %316, %29, %30 : i1, i32 loc(#loc49)
    %320 = llvm.xor %314, %319 : i32 loc(#loc49)
    %321 = llvm.mul %318, %25 : i32 loc(#loc49)
    %322 = llvm.add %321, %29 : i32 loc(#loc49)
    %323 = llvm.mul %320, %26 : i32 loc(#loc49)
    %324 = llvm.add %322, %323 : i32 loc(#loc49)
    %325 = llvm.getelementptr inbounds %244[%324] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %326 = llvm.and %250, %25 : i32 loc(#loc49)
    %327 = llvm.icmp "eq" %326, %29 : i32 loc(#loc49)
    %328 = llvm.select %327, %29, %25 : i1, i32 loc(#loc49)
    %329 = llvm.xor %29, %328 : i32 loc(#loc49)
    %330 = llvm.and %250, %20 : i32 loc(#loc49)
    %331 = llvm.icmp "eq" %330, %29 : i32 loc(#loc49)
    %332 = llvm.select %331, %29, %20 : i1, i32 loc(#loc49)
    %333 = llvm.xor %329, %332 : i32 loc(#loc49)
    %334 = llvm.and %250, %30 : i32 loc(#loc49)
    %335 = llvm.icmp "eq" %334, %29 : i32 loc(#loc49)
    %336 = llvm.select %335, %29, %30 : i1, i32 loc(#loc49)
    %337 = llvm.xor %333, %336 : i32 loc(#loc49)
    %338 = llvm.and %250, %19 : i32 loc(#loc49)
    %339 = llvm.icmp "eq" %338, %29 : i32 loc(#loc49)
    %340 = llvm.select %339, %29, %19 : i1, i32 loc(#loc49)
    %341 = llvm.xor %337, %340 : i32 loc(#loc49)
    %342 = llvm.and %250, %26 : i32 loc(#loc49)
    %343 = llvm.icmp "eq" %342, %29 : i32 loc(#loc49)
    %344 = llvm.select %343, %29, %25 : i1, i32 loc(#loc49)
    %345 = llvm.xor %26, %344 : i32 loc(#loc49)
    %346 = llvm.and %251, %25 : i32 loc(#loc49)
    %347 = llvm.icmp "eq" %346, %29 : i32 loc(#loc49)
    %348 = llvm.select %347, %29, %30 : i1, i32 loc(#loc49)
    %349 = llvm.xor %341, %348 : i32 loc(#loc49)
    %350 = llvm.select %347, %29, %20 : i1, i32 loc(#loc49)
    %351 = llvm.xor %345, %350 : i32 loc(#loc49)
    %352 = llvm.and %251, %20 : i32 loc(#loc49)
    %353 = llvm.icmp "eq" %352, %29 : i32 loc(#loc49)
    %354 = llvm.select %353, %29, %19 : i1, i32 loc(#loc49)
    %355 = llvm.xor %349, %354 : i32 loc(#loc49)
    %356 = llvm.select %353, %29, %30 : i1, i32 loc(#loc49)
    %357 = llvm.xor %351, %356 : i32 loc(#loc49)
    %358 = llvm.mul %355, %25 : i32 loc(#loc49)
    %359 = llvm.add %358, %29 : i32 loc(#loc49)
    %360 = llvm.mul %357, %26 : i32 loc(#loc49)
    %361 = llvm.add %359, %360 : i32 loc(#loc49)
    %362 = llvm.getelementptr inbounds %244[%361] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %363 = llvm.and %250, %25 : i32 loc(#loc49)
    %364 = llvm.icmp "eq" %363, %29 : i32 loc(#loc49)
    %365 = llvm.select %364, %29, %25 : i1, i32 loc(#loc49)
    %366 = llvm.xor %29, %365 : i32 loc(#loc49)
    %367 = llvm.and %250, %20 : i32 loc(#loc49)
    %368 = llvm.icmp "eq" %367, %29 : i32 loc(#loc49)
    %369 = llvm.select %368, %29, %20 : i1, i32 loc(#loc49)
    %370 = llvm.xor %366, %369 : i32 loc(#loc49)
    %371 = llvm.and %250, %30 : i32 loc(#loc49)
    %372 = llvm.icmp "eq" %371, %29 : i32 loc(#loc49)
    %373 = llvm.select %372, %29, %30 : i1, i32 loc(#loc49)
    %374 = llvm.xor %370, %373 : i32 loc(#loc49)
    %375 = llvm.and %250, %19 : i32 loc(#loc49)
    %376 = llvm.icmp "eq" %375, %29 : i32 loc(#loc49)
    %377 = llvm.select %376, %29, %19 : i1, i32 loc(#loc49)
    %378 = llvm.xor %374, %377 : i32 loc(#loc49)
    %379 = llvm.and %250, %26 : i32 loc(#loc49)
    %380 = llvm.icmp "eq" %379, %29 : i32 loc(#loc49)
    %381 = llvm.select %380, %29, %25 : i1, i32 loc(#loc49)
    %382 = llvm.xor %18, %381 : i32 loc(#loc49)
    %383 = llvm.and %251, %25 : i32 loc(#loc49)
    %384 = llvm.icmp "eq" %383, %29 : i32 loc(#loc49)
    %385 = llvm.select %384, %29, %30 : i1, i32 loc(#loc49)
    %386 = llvm.xor %378, %385 : i32 loc(#loc49)
    %387 = llvm.select %384, %29, %20 : i1, i32 loc(#loc49)
    %388 = llvm.xor %382, %387 : i32 loc(#loc49)
    %389 = llvm.and %251, %20 : i32 loc(#loc49)
    %390 = llvm.icmp "eq" %389, %29 : i32 loc(#loc49)
    %391 = llvm.select %390, %29, %19 : i1, i32 loc(#loc49)
    %392 = llvm.xor %386, %391 : i32 loc(#loc49)
    %393 = llvm.select %390, %29, %30 : i1, i32 loc(#loc49)
    %394 = llvm.xor %388, %393 : i32 loc(#loc49)
    %395 = llvm.mul %392, %25 : i32 loc(#loc49)
    %396 = llvm.add %395, %29 : i32 loc(#loc49)
    %397 = llvm.mul %394, %26 : i32 loc(#loc49)
    %398 = llvm.add %396, %397 : i32 loc(#loc49)
    %399 = llvm.getelementptr inbounds %244[%398] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %400 = llvm.select %245, %30, %29 : i1, i32 loc(#loc49)
    %401 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %288, %190, %400 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %402 = llvm.select %246, %30, %29 : i1, i32 loc(#loc49)
    %403 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %325, %191, %402 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %404 = llvm.select %247, %30, %29 : i1, i32 loc(#loc49)
    %405 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %362, %192, %404 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %406 = llvm.select %248, %30, %29 : i1, i32 loc(#loc49)
    %407 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %399, %193, %406 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %408 = llvm.icmp "slt" %218, %arg5 : i32 loc(#loc50)
    %409 = llvm.mul %29, %11 : i32 loc(#loc46)
    %410 = llvm.add %409, %29 : i32 loc(#loc46)
    %411 = llvm.mul %29, %27 : i32 loc(#loc46)
    %412 = llvm.add %410, %411 : i32 loc(#loc46)
    %413 = llvm.mul %29, %25 : i32 loc(#loc46)
    %414 = llvm.add %412, %413 : i32 loc(#loc46)
    %415 = llvm.getelementptr %235[%414] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %416 = llvm.and %236, %408 : i1 loc(#loc47)
    %417 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc46)
    %418 = llvm.urem %417, %27 : i32 loc(#loc46)
    %419 = llvm.udiv %417, %27 : i32 loc(#loc46)
    %420 = llvm.and %418, %25 : i32 loc(#loc46)
    %421 = llvm.icmp "eq" %420, %29 : i32 loc(#loc46)
    %422 = llvm.select %421, %29, %30 : i1, i32 loc(#loc46)
    %423 = llvm.xor %29, %422 : i32 loc(#loc46)
    %424 = llvm.and %418, %20 : i32 loc(#loc46)
    %425 = llvm.icmp "eq" %424, %29 : i32 loc(#loc46)
    %426 = llvm.select %425, %29, %19 : i1, i32 loc(#loc46)
    %427 = llvm.xor %423, %426 : i32 loc(#loc46)
    %428 = llvm.and %418, %30 : i32 loc(#loc46)
    %429 = llvm.icmp "eq" %428, %29 : i32 loc(#loc46)
    %430 = llvm.select %429, %29, %26 : i1, i32 loc(#loc46)
    %431 = llvm.xor %427, %430 : i32 loc(#loc46)
    %432 = llvm.and %418, %19 : i32 loc(#loc46)
    %433 = llvm.icmp "eq" %432, %29 : i32 loc(#loc46)
    %434 = llvm.select %433, %29, %19 : i1, i32 loc(#loc46)
    %435 = llvm.xor %431, %434 : i32 loc(#loc46)
    %436 = llvm.select %433, %29, %25 : i1, i32 loc(#loc46)
    %437 = llvm.xor %29, %436 : i32 loc(#loc46)
    %438 = llvm.and %418, %26 : i32 loc(#loc46)
    %439 = llvm.icmp "eq" %438, %29 : i32 loc(#loc46)
    %440 = llvm.select %439, %29, %26 : i1, i32 loc(#loc46)
    %441 = llvm.xor %435, %440 : i32 loc(#loc46)
    %442 = llvm.select %439, %29, %20 : i1, i32 loc(#loc46)
    %443 = llvm.xor %437, %442 : i32 loc(#loc46)
    %444 = llvm.and %419, %25 : i32 loc(#loc46)
    %445 = llvm.icmp "eq" %444, %29 : i32 loc(#loc46)
    %446 = llvm.select %445, %29, %30 : i1, i32 loc(#loc46)
    %447 = llvm.xor %443, %446 : i32 loc(#loc46)
    %448 = llvm.and %419, %20 : i32 loc(#loc46)
    %449 = llvm.icmp "eq" %448, %29 : i32 loc(#loc46)
    %450 = llvm.select %449, %29, %19 : i1, i32 loc(#loc46)
    %451 = llvm.xor %447, %450 : i32 loc(#loc46)
    %452 = llvm.mul %441, %25 : i32 loc(#loc46)
    %453 = llvm.add %452, %29 : i32 loc(#loc46)
    %454 = llvm.mul %451, %27 : i32 loc(#loc46)
    %455 = llvm.add %453, %454 : i32 loc(#loc46)
    %456 = llvm.getelementptr inbounds %415[%455] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %457 = llvm.select %416, %26, %29 : i1, i32 loc(#loc46)
    %458 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %456, %224, %457 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%29, %40, %197, %231, %29, %31 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb1(%459: i32 loc("examples/kernels/binary_ops.py":168:22), %460: !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(unknown), %461: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":159:22), %462: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":160:22), %463: i32 loc(unknown), %464: i32 loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %465 = llvm.icmp "slt" %459, %233 : i32 loc(#loc47)
    llvm.cond_br %465, ^bb2, ^bb3 loc(#loc47)
  ^bb2:  // pred: ^bb1
    %466 = llvm.sub %233, %25 : i32 loc(#loc47)
    %467 = llvm.icmp "slt" %459, %466 : i32 loc(#loc47)
    %468 = llvm.add %464, %25 : i32 loc(#loc47)
    %469 = llvm.icmp "slt" %468, %25 : i32 loc(#loc47)
    %470 = llvm.select %469, %468, %29 : i1, i32 loc(#loc47)
    nvvm.cp.async.wait.group 0 loc(#loc49)
    nvvm.barrier0 loc(#loc49)
    %471 = llvm.mul %470, %11 : i32 loc(#loc49)
    %472 = llvm.add %471, %29 : i32 loc(#loc49)
    %473 = llvm.mul %29, %26 : i32 loc(#loc49)
    %474 = llvm.add %472, %473 : i32 loc(#loc49)
    %475 = llvm.mul %29, %25 : i32 loc(#loc49)
    %476 = llvm.add %474, %475 : i32 loc(#loc49)
    %477 = llvm.getelementptr %12[%476] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %478 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc49)
    %479 = llvm.urem %478, %27 : i32 loc(#loc49)
    %480 = llvm.udiv %478, %27 : i32 loc(#loc49)
    %481 = llvm.and %479, %25 : i32 loc(#loc49)
    %482 = llvm.icmp "eq" %481, %29 : i32 loc(#loc49)
    %483 = llvm.select %482, %29, %25 : i1, i32 loc(#loc49)
    %484 = llvm.xor %29, %483 : i32 loc(#loc49)
    %485 = llvm.and %479, %20 : i32 loc(#loc49)
    %486 = llvm.icmp "eq" %485, %29 : i32 loc(#loc49)
    %487 = llvm.select %486, %29, %30 : i1, i32 loc(#loc49)
    %488 = llvm.xor %29, %487 : i32 loc(#loc49)
    %489 = llvm.select %486, %29, %20 : i1, i32 loc(#loc49)
    %490 = llvm.xor %484, %489 : i32 loc(#loc49)
    %491 = llvm.and %479, %30 : i32 loc(#loc49)
    %492 = llvm.icmp "eq" %491, %29 : i32 loc(#loc49)
    %493 = llvm.select %492, %29, %19 : i1, i32 loc(#loc49)
    %494 = llvm.xor %488, %493 : i32 loc(#loc49)
    %495 = llvm.select %492, %29, %30 : i1, i32 loc(#loc49)
    %496 = llvm.xor %490, %495 : i32 loc(#loc49)
    %497 = llvm.and %479, %19 : i32 loc(#loc49)
    %498 = llvm.icmp "eq" %497, %29 : i32 loc(#loc49)
    %499 = llvm.select %498, %29, %19 : i1, i32 loc(#loc49)
    %500 = llvm.xor %496, %499 : i32 loc(#loc49)
    %501 = llvm.and %479, %26 : i32 loc(#loc49)
    %502 = llvm.icmp "eq" %501, %29 : i32 loc(#loc49)
    %503 = llvm.select %502, %29, %30 : i1, i32 loc(#loc49)
    %504 = llvm.xor %494, %503 : i32 loc(#loc49)
    %505 = llvm.and %480, %20 : i32 loc(#loc49)
    %506 = llvm.icmp "eq" %505, %29 : i32 loc(#loc49)
    %507 = llvm.select %506, %29, %26 : i1, i32 loc(#loc49)
    %508 = llvm.xor %500, %507 : i32 loc(#loc49)
    %509 = llvm.mul %504, %25 : i32 loc(#loc49)
    %510 = llvm.add %509, %29 : i32 loc(#loc49)
    %511 = llvm.mul %508, %26 : i32 loc(#loc49)
    %512 = llvm.add %510, %511 : i32 loc(#loc49)
    %513 = llvm.getelementptr inbounds %477[%512] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %514 = nvgpu.ldmatrix %513 : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %515 = llvm.extractvalue %514[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %516 = llvm.extractvalue %514[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %517 = llvm.extractvalue %514[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %518 = llvm.extractvalue %514[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %519 = llvm.and %479, %25 : i32 loc(#loc49)
    %520 = llvm.icmp "eq" %519, %29 : i32 loc(#loc49)
    %521 = llvm.select %520, %29, %25 : i1, i32 loc(#loc49)
    %522 = llvm.xor %29, %521 : i32 loc(#loc49)
    %523 = llvm.and %479, %20 : i32 loc(#loc49)
    %524 = llvm.icmp "eq" %523, %29 : i32 loc(#loc49)
    %525 = llvm.select %524, %29, %30 : i1, i32 loc(#loc49)
    %526 = llvm.xor %19, %525 : i32 loc(#loc49)
    %527 = llvm.select %524, %29, %20 : i1, i32 loc(#loc49)
    %528 = llvm.xor %522, %527 : i32 loc(#loc49)
    %529 = llvm.and %479, %30 : i32 loc(#loc49)
    %530 = llvm.icmp "eq" %529, %29 : i32 loc(#loc49)
    %531 = llvm.select %530, %29, %19 : i1, i32 loc(#loc49)
    %532 = llvm.xor %526, %531 : i32 loc(#loc49)
    %533 = llvm.select %530, %29, %30 : i1, i32 loc(#loc49)
    %534 = llvm.xor %528, %533 : i32 loc(#loc49)
    %535 = llvm.and %479, %19 : i32 loc(#loc49)
    %536 = llvm.icmp "eq" %535, %29 : i32 loc(#loc49)
    %537 = llvm.select %536, %29, %19 : i1, i32 loc(#loc49)
    %538 = llvm.xor %534, %537 : i32 loc(#loc49)
    %539 = llvm.and %479, %26 : i32 loc(#loc49)
    %540 = llvm.icmp "eq" %539, %29 : i32 loc(#loc49)
    %541 = llvm.select %540, %29, %30 : i1, i32 loc(#loc49)
    %542 = llvm.xor %532, %541 : i32 loc(#loc49)
    %543 = llvm.and %480, %20 : i32 loc(#loc49)
    %544 = llvm.icmp "eq" %543, %29 : i32 loc(#loc49)
    %545 = llvm.select %544, %29, %26 : i1, i32 loc(#loc49)
    %546 = llvm.xor %538, %545 : i32 loc(#loc49)
    %547 = llvm.mul %542, %25 : i32 loc(#loc49)
    %548 = llvm.add %547, %29 : i32 loc(#loc49)
    %549 = llvm.mul %546, %26 : i32 loc(#loc49)
    %550 = llvm.add %548, %549 : i32 loc(#loc49)
    %551 = llvm.getelementptr inbounds %477[%550] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %552 = nvgpu.ldmatrix %551 : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %553 = llvm.extractvalue %552[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %554 = llvm.extractvalue %552[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %555 = llvm.extractvalue %552[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %556 = llvm.extractvalue %552[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %557 = llvm.bitcast %515 : i32 to vector<1xf32> loc(#loc49)
    %558 = llvm.extractelement %557[%29 : i32] : vector<1xf32> loc(#loc49)
    %559 = llvm.bitcast %516 : i32 to vector<1xf32> loc(#loc49)
    %560 = llvm.extractelement %559[%29 : i32] : vector<1xf32> loc(#loc49)
    %561 = llvm.bitcast %517 : i32 to vector<1xf32> loc(#loc49)
    %562 = llvm.extractelement %561[%29 : i32] : vector<1xf32> loc(#loc49)
    %563 = llvm.bitcast %518 : i32 to vector<1xf32> loc(#loc49)
    %564 = llvm.extractelement %563[%29 : i32] : vector<1xf32> loc(#loc49)
    %565 = llvm.bitcast %553 : i32 to vector<1xf32> loc(#loc49)
    %566 = llvm.extractelement %565[%29 : i32] : vector<1xf32> loc(#loc49)
    %567 = llvm.bitcast %554 : i32 to vector<1xf32> loc(#loc49)
    %568 = llvm.extractelement %567[%29 : i32] : vector<1xf32> loc(#loc49)
    %569 = llvm.bitcast %555 : i32 to vector<1xf32> loc(#loc49)
    %570 = llvm.extractelement %569[%29 : i32] : vector<1xf32> loc(#loc49)
    %571 = llvm.bitcast %556 : i32 to vector<1xf32> loc(#loc49)
    %572 = llvm.extractelement %571[%29 : i32] : vector<1xf32> loc(#loc49)
    %573 = llvm.mul %470, %11 : i32 loc(#loc46)
    %574 = llvm.add %573, %29 : i32 loc(#loc46)
    %575 = llvm.mul %29, %27 : i32 loc(#loc46)
    %576 = llvm.add %574, %575 : i32 loc(#loc46)
    %577 = llvm.mul %29, %25 : i32 loc(#loc46)
    %578 = llvm.add %576, %577 : i32 loc(#loc46)
    %579 = llvm.getelementptr %235[%578] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %580 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc46)
    %581 = llvm.urem %580, %27 : i32 loc(#loc46)
    %582 = llvm.udiv %580, %27 : i32 loc(#loc46)
    %583 = llvm.and %581, %25 : i32 loc(#loc46)
    %584 = llvm.icmp "eq" %583, %29 : i32 loc(#loc46)
    %585 = llvm.select %584, %29, %19 : i1, i32 loc(#loc46)
    %586 = llvm.xor %29, %585 : i32 loc(#loc46)
    %587 = llvm.select %584, %29, %25 : i1, i32 loc(#loc46)
    %588 = llvm.xor %29, %587 : i32 loc(#loc46)
    %589 = llvm.and %581, %20 : i32 loc(#loc46)
    %590 = llvm.icmp "eq" %589, %29 : i32 loc(#loc46)
    %591 = llvm.select %590, %29, %26 : i1, i32 loc(#loc46)
    %592 = llvm.xor %586, %591 : i32 loc(#loc46)
    %593 = llvm.select %590, %29, %20 : i1, i32 loc(#loc46)
    %594 = llvm.xor %588, %593 : i32 loc(#loc46)
    %595 = llvm.and %581, %30 : i32 loc(#loc46)
    %596 = llvm.icmp "eq" %595, %29 : i32 loc(#loc46)
    %597 = llvm.select %596, %29, %25 : i1, i32 loc(#loc46)
    %598 = llvm.xor %592, %597 : i32 loc(#loc46)
    %599 = llvm.and %581, %19 : i32 loc(#loc46)
    %600 = llvm.icmp "eq" %599, %29 : i32 loc(#loc46)
    %601 = llvm.select %600, %29, %20 : i1, i32 loc(#loc46)
    %602 = llvm.xor %598, %601 : i32 loc(#loc46)
    %603 = llvm.and %581, %26 : i32 loc(#loc46)
    %604 = llvm.icmp "eq" %603, %29 : i32 loc(#loc46)
    %605 = llvm.select %604, %29, %30 : i1, i32 loc(#loc46)
    %606 = llvm.xor %602, %605 : i32 loc(#loc46)
    %607 = llvm.and %582, %25 : i32 loc(#loc46)
    %608 = llvm.icmp "eq" %607, %29 : i32 loc(#loc46)
    %609 = llvm.select %608, %29, %19 : i1, i32 loc(#loc46)
    %610 = llvm.xor %606, %609 : i32 loc(#loc46)
    %611 = llvm.mul %610, %25 : i32 loc(#loc46)
    %612 = llvm.add %611, %29 : i32 loc(#loc46)
    %613 = llvm.mul %594, %27 : i32 loc(#loc46)
    %614 = llvm.add %612, %613 : i32 loc(#loc46)
    %615 = llvm.getelementptr inbounds %579[%614] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %616 = llvm.load %615 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %617 = llvm.extractelement %616[%29 : i32] : vector<1xf32> loc(#loc46)
    %618 = llvm.and %581, %25 : i32 loc(#loc46)
    %619 = llvm.icmp "eq" %618, %29 : i32 loc(#loc46)
    %620 = llvm.select %619, %29, %19 : i1, i32 loc(#loc46)
    %621 = llvm.xor %29, %620 : i32 loc(#loc46)
    %622 = llvm.select %619, %29, %25 : i1, i32 loc(#loc46)
    %623 = llvm.xor %30, %622 : i32 loc(#loc46)
    %624 = llvm.and %581, %20 : i32 loc(#loc46)
    %625 = llvm.icmp "eq" %624, %29 : i32 loc(#loc46)
    %626 = llvm.select %625, %29, %26 : i1, i32 loc(#loc46)
    %627 = llvm.xor %621, %626 : i32 loc(#loc46)
    %628 = llvm.select %625, %29, %20 : i1, i32 loc(#loc46)
    %629 = llvm.xor %623, %628 : i32 loc(#loc46)
    %630 = llvm.and %581, %30 : i32 loc(#loc46)
    %631 = llvm.icmp "eq" %630, %29 : i32 loc(#loc46)
    %632 = llvm.select %631, %29, %25 : i1, i32 loc(#loc46)
    %633 = llvm.xor %627, %632 : i32 loc(#loc46)
    %634 = llvm.and %581, %19 : i32 loc(#loc46)
    %635 = llvm.icmp "eq" %634, %29 : i32 loc(#loc46)
    %636 = llvm.select %635, %29, %20 : i1, i32 loc(#loc46)
    %637 = llvm.xor %633, %636 : i32 loc(#loc46)
    %638 = llvm.and %581, %26 : i32 loc(#loc46)
    %639 = llvm.icmp "eq" %638, %29 : i32 loc(#loc46)
    %640 = llvm.select %639, %29, %30 : i1, i32 loc(#loc46)
    %641 = llvm.xor %637, %640 : i32 loc(#loc46)
    %642 = llvm.and %582, %25 : i32 loc(#loc46)
    %643 = llvm.icmp "eq" %642, %29 : i32 loc(#loc46)
    %644 = llvm.select %643, %29, %19 : i1, i32 loc(#loc46)
    %645 = llvm.xor %641, %644 : i32 loc(#loc46)
    %646 = llvm.mul %645, %25 : i32 loc(#loc46)
    %647 = llvm.add %646, %29 : i32 loc(#loc46)
    %648 = llvm.mul %629, %27 : i32 loc(#loc46)
    %649 = llvm.add %647, %648 : i32 loc(#loc46)
    %650 = llvm.getelementptr inbounds %579[%649] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %651 = llvm.load %650 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %652 = llvm.extractelement %651[%29 : i32] : vector<1xf32> loc(#loc46)
    %653 = llvm.and %581, %25 : i32 loc(#loc46)
    %654 = llvm.icmp "eq" %653, %29 : i32 loc(#loc46)
    %655 = llvm.select %654, %29, %19 : i1, i32 loc(#loc46)
    %656 = llvm.xor %29, %655 : i32 loc(#loc46)
    %657 = llvm.select %654, %29, %25 : i1, i32 loc(#loc46)
    %658 = llvm.xor %19, %657 : i32 loc(#loc46)
    %659 = llvm.and %581, %20 : i32 loc(#loc46)
    %660 = llvm.icmp "eq" %659, %29 : i32 loc(#loc46)
    %661 = llvm.select %660, %29, %26 : i1, i32 loc(#loc46)
    %662 = llvm.xor %656, %661 : i32 loc(#loc46)
    %663 = llvm.select %660, %29, %20 : i1, i32 loc(#loc46)
    %664 = llvm.xor %658, %663 : i32 loc(#loc46)
    %665 = llvm.and %581, %30 : i32 loc(#loc46)
    %666 = llvm.icmp "eq" %665, %29 : i32 loc(#loc46)
    %667 = llvm.select %666, %29, %25 : i1, i32 loc(#loc46)
    %668 = llvm.xor %662, %667 : i32 loc(#loc46)
    %669 = llvm.and %581, %19 : i32 loc(#loc46)
    %670 = llvm.icmp "eq" %669, %29 : i32 loc(#loc46)
    %671 = llvm.select %670, %29, %20 : i1, i32 loc(#loc46)
    %672 = llvm.xor %668, %671 : i32 loc(#loc46)
    %673 = llvm.and %581, %26 : i32 loc(#loc46)
    %674 = llvm.icmp "eq" %673, %29 : i32 loc(#loc46)
    %675 = llvm.select %674, %29, %30 : i1, i32 loc(#loc46)
    %676 = llvm.xor %672, %675 : i32 loc(#loc46)
    %677 = llvm.and %582, %25 : i32 loc(#loc46)
    %678 = llvm.icmp "eq" %677, %29 : i32 loc(#loc46)
    %679 = llvm.select %678, %29, %19 : i1, i32 loc(#loc46)
    %680 = llvm.xor %676, %679 : i32 loc(#loc46)
    %681 = llvm.mul %680, %25 : i32 loc(#loc46)
    %682 = llvm.add %681, %29 : i32 loc(#loc46)
    %683 = llvm.mul %664, %27 : i32 loc(#loc46)
    %684 = llvm.add %682, %683 : i32 loc(#loc46)
    %685 = llvm.getelementptr inbounds %579[%684] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %686 = llvm.load %685 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %687 = llvm.extractelement %686[%29 : i32] : vector<1xf32> loc(#loc46)
    %688 = llvm.and %581, %25 : i32 loc(#loc46)
    %689 = llvm.icmp "eq" %688, %29 : i32 loc(#loc46)
    %690 = llvm.select %689, %29, %19 : i1, i32 loc(#loc46)
    %691 = llvm.xor %29, %690 : i32 loc(#loc46)
    %692 = llvm.select %689, %29, %25 : i1, i32 loc(#loc46)
    %693 = llvm.xor %8, %692 : i32 loc(#loc46)
    %694 = llvm.and %581, %20 : i32 loc(#loc46)
    %695 = llvm.icmp "eq" %694, %29 : i32 loc(#loc46)
    %696 = llvm.select %695, %29, %26 : i1, i32 loc(#loc46)
    %697 = llvm.xor %691, %696 : i32 loc(#loc46)
    %698 = llvm.select %695, %29, %20 : i1, i32 loc(#loc46)
    %699 = llvm.xor %693, %698 : i32 loc(#loc46)
    %700 = llvm.and %581, %30 : i32 loc(#loc46)
    %701 = llvm.icmp "eq" %700, %29 : i32 loc(#loc46)
    %702 = llvm.select %701, %29, %25 : i1, i32 loc(#loc46)
    %703 = llvm.xor %697, %702 : i32 loc(#loc46)
    %704 = llvm.and %581, %19 : i32 loc(#loc46)
    %705 = llvm.icmp "eq" %704, %29 : i32 loc(#loc46)
    %706 = llvm.select %705, %29, %20 : i1, i32 loc(#loc46)
    %707 = llvm.xor %703, %706 : i32 loc(#loc46)
    %708 = llvm.and %581, %26 : i32 loc(#loc46)
    %709 = llvm.icmp "eq" %708, %29 : i32 loc(#loc46)
    %710 = llvm.select %709, %29, %30 : i1, i32 loc(#loc46)
    %711 = llvm.xor %707, %710 : i32 loc(#loc46)
    %712 = llvm.and %582, %25 : i32 loc(#loc46)
    %713 = llvm.icmp "eq" %712, %29 : i32 loc(#loc46)
    %714 = llvm.select %713, %29, %19 : i1, i32 loc(#loc46)
    %715 = llvm.xor %711, %714 : i32 loc(#loc46)
    %716 = llvm.mul %715, %25 : i32 loc(#loc46)
    %717 = llvm.add %716, %29 : i32 loc(#loc46)
    %718 = llvm.mul %699, %27 : i32 loc(#loc46)
    %719 = llvm.add %717, %718 : i32 loc(#loc46)
    %720 = llvm.getelementptr inbounds %579[%719] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %721 = llvm.load %720 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %722 = llvm.extractelement %721[%29 : i32] : vector<1xf32> loc(#loc46)
    %723 = llvm.and %581, %25 : i32 loc(#loc46)
    %724 = llvm.icmp "eq" %723, %29 : i32 loc(#loc46)
    %725 = llvm.select %724, %29, %19 : i1, i32 loc(#loc46)
    %726 = llvm.xor %26, %725 : i32 loc(#loc46)
    %727 = llvm.select %724, %29, %25 : i1, i32 loc(#loc46)
    %728 = llvm.xor %29, %727 : i32 loc(#loc46)
    %729 = llvm.and %581, %20 : i32 loc(#loc46)
    %730 = llvm.icmp "eq" %729, %29 : i32 loc(#loc46)
    %731 = llvm.select %730, %29, %26 : i1, i32 loc(#loc46)
    %732 = llvm.xor %726, %731 : i32 loc(#loc46)
    %733 = llvm.select %730, %29, %20 : i1, i32 loc(#loc46)
    %734 = llvm.xor %728, %733 : i32 loc(#loc46)
    %735 = llvm.and %581, %30 : i32 loc(#loc46)
    %736 = llvm.icmp "eq" %735, %29 : i32 loc(#loc46)
    %737 = llvm.select %736, %29, %25 : i1, i32 loc(#loc46)
    %738 = llvm.xor %732, %737 : i32 loc(#loc46)
    %739 = llvm.and %581, %19 : i32 loc(#loc46)
    %740 = llvm.icmp "eq" %739, %29 : i32 loc(#loc46)
    %741 = llvm.select %740, %29, %20 : i1, i32 loc(#loc46)
    %742 = llvm.xor %738, %741 : i32 loc(#loc46)
    %743 = llvm.and %581, %26 : i32 loc(#loc46)
    %744 = llvm.icmp "eq" %743, %29 : i32 loc(#loc46)
    %745 = llvm.select %744, %29, %30 : i1, i32 loc(#loc46)
    %746 = llvm.xor %742, %745 : i32 loc(#loc46)
    %747 = llvm.and %582, %25 : i32 loc(#loc46)
    %748 = llvm.icmp "eq" %747, %29 : i32 loc(#loc46)
    %749 = llvm.select %748, %29, %19 : i1, i32 loc(#loc46)
    %750 = llvm.xor %746, %749 : i32 loc(#loc46)
    %751 = llvm.mul %750, %25 : i32 loc(#loc46)
    %752 = llvm.add %751, %29 : i32 loc(#loc46)
    %753 = llvm.mul %734, %27 : i32 loc(#loc46)
    %754 = llvm.add %752, %753 : i32 loc(#loc46)
    %755 = llvm.getelementptr inbounds %579[%754] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %756 = llvm.load %755 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %757 = llvm.extractelement %756[%29 : i32] : vector<1xf32> loc(#loc46)
    %758 = llvm.and %581, %25 : i32 loc(#loc46)
    %759 = llvm.icmp "eq" %758, %29 : i32 loc(#loc46)
    %760 = llvm.select %759, %29, %19 : i1, i32 loc(#loc46)
    %761 = llvm.xor %26, %760 : i32 loc(#loc46)
    %762 = llvm.select %759, %29, %25 : i1, i32 loc(#loc46)
    %763 = llvm.xor %30, %762 : i32 loc(#loc46)
    %764 = llvm.and %581, %20 : i32 loc(#loc46)
    %765 = llvm.icmp "eq" %764, %29 : i32 loc(#loc46)
    %766 = llvm.select %765, %29, %26 : i1, i32 loc(#loc46)
    %767 = llvm.xor %761, %766 : i32 loc(#loc46)
    %768 = llvm.select %765, %29, %20 : i1, i32 loc(#loc46)
    %769 = llvm.xor %763, %768 : i32 loc(#loc46)
    %770 = llvm.and %581, %30 : i32 loc(#loc46)
    %771 = llvm.icmp "eq" %770, %29 : i32 loc(#loc46)
    %772 = llvm.select %771, %29, %25 : i1, i32 loc(#loc46)
    %773 = llvm.xor %767, %772 : i32 loc(#loc46)
    %774 = llvm.and %581, %19 : i32 loc(#loc46)
    %775 = llvm.icmp "eq" %774, %29 : i32 loc(#loc46)
    %776 = llvm.select %775, %29, %20 : i1, i32 loc(#loc46)
    %777 = llvm.xor %773, %776 : i32 loc(#loc46)
    %778 = llvm.and %581, %26 : i32 loc(#loc46)
    %779 = llvm.icmp "eq" %778, %29 : i32 loc(#loc46)
    %780 = llvm.select %779, %29, %30 : i1, i32 loc(#loc46)
    %781 = llvm.xor %777, %780 : i32 loc(#loc46)
    %782 = llvm.and %582, %25 : i32 loc(#loc46)
    %783 = llvm.icmp "eq" %782, %29 : i32 loc(#loc46)
    %784 = llvm.select %783, %29, %19 : i1, i32 loc(#loc46)
    %785 = llvm.xor %781, %784 : i32 loc(#loc46)
    %786 = llvm.mul %785, %25 : i32 loc(#loc46)
    %787 = llvm.add %786, %29 : i32 loc(#loc46)
    %788 = llvm.mul %769, %27 : i32 loc(#loc46)
    %789 = llvm.add %787, %788 : i32 loc(#loc46)
    %790 = llvm.getelementptr inbounds %579[%789] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %791 = llvm.load %790 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %792 = llvm.extractelement %791[%29 : i32] : vector<1xf32> loc(#loc46)
    %793 = llvm.and %581, %25 : i32 loc(#loc46)
    %794 = llvm.icmp "eq" %793, %29 : i32 loc(#loc46)
    %795 = llvm.select %794, %29, %19 : i1, i32 loc(#loc46)
    %796 = llvm.xor %26, %795 : i32 loc(#loc46)
    %797 = llvm.select %794, %29, %25 : i1, i32 loc(#loc46)
    %798 = llvm.xor %19, %797 : i32 loc(#loc46)
    %799 = llvm.and %581, %20 : i32 loc(#loc46)
    %800 = llvm.icmp "eq" %799, %29 : i32 loc(#loc46)
    %801 = llvm.select %800, %29, %26 : i1, i32 loc(#loc46)
    %802 = llvm.xor %796, %801 : i32 loc(#loc46)
    %803 = llvm.select %800, %29, %20 : i1, i32 loc(#loc46)
    %804 = llvm.xor %798, %803 : i32 loc(#loc46)
    %805 = llvm.and %581, %30 : i32 loc(#loc46)
    %806 = llvm.icmp "eq" %805, %29 : i32 loc(#loc46)
    %807 = llvm.select %806, %29, %25 : i1, i32 loc(#loc46)
    %808 = llvm.xor %802, %807 : i32 loc(#loc46)
    %809 = llvm.and %581, %19 : i32 loc(#loc46)
    %810 = llvm.icmp "eq" %809, %29 : i32 loc(#loc46)
    %811 = llvm.select %810, %29, %20 : i1, i32 loc(#loc46)
    %812 = llvm.xor %808, %811 : i32 loc(#loc46)
    %813 = llvm.and %581, %26 : i32 loc(#loc46)
    %814 = llvm.icmp "eq" %813, %29 : i32 loc(#loc46)
    %815 = llvm.select %814, %29, %30 : i1, i32 loc(#loc46)
    %816 = llvm.xor %812, %815 : i32 loc(#loc46)
    %817 = llvm.and %582, %25 : i32 loc(#loc46)
    %818 = llvm.icmp "eq" %817, %29 : i32 loc(#loc46)
    %819 = llvm.select %818, %29, %19 : i1, i32 loc(#loc46)
    %820 = llvm.xor %816, %819 : i32 loc(#loc46)
    %821 = llvm.mul %820, %25 : i32 loc(#loc46)
    %822 = llvm.add %821, %29 : i32 loc(#loc46)
    %823 = llvm.mul %804, %27 : i32 loc(#loc46)
    %824 = llvm.add %822, %823 : i32 loc(#loc46)
    %825 = llvm.getelementptr inbounds %579[%824] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %826 = llvm.load %825 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %827 = llvm.extractelement %826[%29 : i32] : vector<1xf32> loc(#loc46)
    %828 = llvm.and %581, %25 : i32 loc(#loc46)
    %829 = llvm.icmp "eq" %828, %29 : i32 loc(#loc46)
    %830 = llvm.select %829, %29, %19 : i1, i32 loc(#loc46)
    %831 = llvm.xor %26, %830 : i32 loc(#loc46)
    %832 = llvm.select %829, %29, %25 : i1, i32 loc(#loc46)
    %833 = llvm.xor %8, %832 : i32 loc(#loc46)
    %834 = llvm.and %581, %20 : i32 loc(#loc46)
    %835 = llvm.icmp "eq" %834, %29 : i32 loc(#loc46)
    %836 = llvm.select %835, %29, %26 : i1, i32 loc(#loc46)
    %837 = llvm.xor %831, %836 : i32 loc(#loc46)
    %838 = llvm.select %835, %29, %20 : i1, i32 loc(#loc46)
    %839 = llvm.xor %833, %838 : i32 loc(#loc46)
    %840 = llvm.and %581, %30 : i32 loc(#loc46)
    %841 = llvm.icmp "eq" %840, %29 : i32 loc(#loc46)
    %842 = llvm.select %841, %29, %25 : i1, i32 loc(#loc46)
    %843 = llvm.xor %837, %842 : i32 loc(#loc46)
    %844 = llvm.and %581, %19 : i32 loc(#loc46)
    %845 = llvm.icmp "eq" %844, %29 : i32 loc(#loc46)
    %846 = llvm.select %845, %29, %20 : i1, i32 loc(#loc46)
    %847 = llvm.xor %843, %846 : i32 loc(#loc46)
    %848 = llvm.and %581, %26 : i32 loc(#loc46)
    %849 = llvm.icmp "eq" %848, %29 : i32 loc(#loc46)
    %850 = llvm.select %849, %29, %30 : i1, i32 loc(#loc46)
    %851 = llvm.xor %847, %850 : i32 loc(#loc46)
    %852 = llvm.and %582, %25 : i32 loc(#loc46)
    %853 = llvm.icmp "eq" %852, %29 : i32 loc(#loc46)
    %854 = llvm.select %853, %29, %19 : i1, i32 loc(#loc46)
    %855 = llvm.xor %851, %854 : i32 loc(#loc46)
    %856 = llvm.mul %855, %25 : i32 loc(#loc46)
    %857 = llvm.add %856, %29 : i32 loc(#loc46)
    %858 = llvm.mul %839, %27 : i32 loc(#loc46)
    %859 = llvm.add %857, %858 : i32 loc(#loc46)
    %860 = llvm.getelementptr inbounds %579[%859] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %861 = llvm.load %860 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %862 = llvm.extractelement %861[%29 : i32] : vector<1xf32> loc(#loc46)
    %863 = llvm.insertelement %558, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %864 = llvm.bitcast %863 : vector<1xf32> to i32 loc(#loc51)
    %865 = llvm.insertelement %560, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %866 = llvm.bitcast %865 : vector<1xf32> to i32 loc(#loc51)
    %867 = llvm.insertelement %562, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %868 = llvm.bitcast %867 : vector<1xf32> to i32 loc(#loc51)
    %869 = llvm.insertelement %564, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %870 = llvm.bitcast %869 : vector<1xf32> to i32 loc(#loc51)
    %871 = llvm.insertelement %566, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %872 = llvm.bitcast %871 : vector<1xf32> to i32 loc(#loc51)
    %873 = llvm.insertelement %568, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %874 = llvm.bitcast %873 : vector<1xf32> to i32 loc(#loc51)
    %875 = llvm.insertelement %570, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %876 = llvm.bitcast %875 : vector<1xf32> to i32 loc(#loc51)
    %877 = llvm.insertelement %572, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %878 = llvm.bitcast %877 : vector<1xf32> to i32 loc(#loc51)
    %879 = llvm.insertelement %617, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %880 = llvm.bitcast %879 : vector<1xf32> to i32 loc(#loc51)
    %881 = llvm.insertelement %652, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %882 = llvm.bitcast %881 : vector<1xf32> to i32 loc(#loc51)
    %883 = llvm.insertelement %687, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %884 = llvm.bitcast %883 : vector<1xf32> to i32 loc(#loc51)
    %885 = llvm.insertelement %722, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %886 = llvm.bitcast %885 : vector<1xf32> to i32 loc(#loc51)
    %887 = llvm.insertelement %757, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %888 = llvm.bitcast %887 : vector<1xf32> to i32 loc(#loc51)
    %889 = llvm.insertelement %792, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %890 = llvm.bitcast %889 : vector<1xf32> to i32 loc(#loc51)
    %891 = llvm.insertelement %827, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %892 = llvm.bitcast %891 : vector<1xf32> to i32 loc(#loc51)
    %893 = llvm.insertelement %862, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %894 = llvm.bitcast %893 : vector<1xf32> to i32 loc(#loc51)
    %895 = llvm.extractvalue %460[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %896 = llvm.extractvalue %460[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %897 = llvm.extractvalue %460[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %898 = llvm.extractvalue %460[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %899 = llvm.extractvalue %460[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %900 = llvm.extractvalue %460[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %901 = llvm.extractvalue %460[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %902 = llvm.extractvalue %460[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %903 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %895, %896, %897, %898, %864, %866, %868, %870, %880, %882 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %904 = llvm.extractvalue %903[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %905 = llvm.extractvalue %903[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %906 = llvm.extractvalue %903[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %907 = llvm.extractvalue %903[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %908 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %899, %900, %901, %902, %864, %866, %868, %870, %888, %890 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %909 = llvm.extractvalue %908[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %910 = llvm.extractvalue %908[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %911 = llvm.extractvalue %908[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %912 = llvm.extractvalue %908[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %913 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %904, %905, %906, %907, %872, %874, %876, %878, %884, %886 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %914 = llvm.extractvalue %913[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %915 = llvm.extractvalue %913[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %916 = llvm.extractvalue %913[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %917 = llvm.extractvalue %913[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %918 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %909, %910, %911, %912, %872, %874, %876, %878, %892, %894 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %919 = llvm.extractvalue %918[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %920 = llvm.extractvalue %918[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %921 = llvm.extractvalue %918[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %922 = llvm.extractvalue %918[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %923 = llvm.insertvalue %914, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %924 = llvm.insertvalue %915, %923[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %925 = llvm.insertvalue %916, %924[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %926 = llvm.insertvalue %917, %925[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %927 = llvm.insertvalue %919, %926[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %928 = llvm.insertvalue %920, %927[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %929 = llvm.insertvalue %921, %928[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %930 = llvm.insertvalue %922, %929[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %931 = llvm.extractvalue %461[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %932 = llvm.extractvalue %461[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %933 = llvm.extractvalue %461[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %934 = llvm.extractvalue %461[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %935 = llvm.getelementptr %931[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %936 = llvm.getelementptr %932[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %937 = llvm.getelementptr %933[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %938 = llvm.getelementptr %934[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %939 = llvm.insertvalue %935, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %940 = llvm.insertvalue %936, %939[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %941 = llvm.insertvalue %937, %940[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %942 = llvm.insertvalue %938, %941[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %943 = llvm.extractvalue %462[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %944 = llvm.extractvalue %462[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %945 = llvm.extractvalue %462[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %946 = llvm.extractvalue %462[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %947 = llvm.getelementptr %943[%234] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %948 = llvm.getelementptr %944[%234] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %949 = llvm.getelementptr %945[%234] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %950 = llvm.getelementptr %946[%234] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %951 = llvm.insertvalue %947, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %952 = llvm.insertvalue %948, %951[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %953 = llvm.insertvalue %949, %952[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %954 = llvm.insertvalue %950, %953[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %955 = llvm.add %463, %25 : i32 loc(#loc47)
    %956 = llvm.icmp "slt" %955, %25 : i32 loc(#loc47)
    %957 = llvm.select %956, %955, %29 : i1, i32 loc(#loc47)
    %958 = llvm.add %459, %25 : i32 loc(#loc47)
    %959 = llvm.mul %958, %26 : i32 loc(#loc54)
    %960 = llvm.sub %arg5, %959 : i32 loc(#loc55)
    %961 = llvm.icmp "slt" %185, %960 : i32 loc(#loc48)
    %962 = llvm.mul %957, %11 : i32 loc(#loc49)
    %963 = llvm.add %962, %29 : i32 loc(#loc49)
    %964 = llvm.mul %29, %26 : i32 loc(#loc49)
    %965 = llvm.add %963, %964 : i32 loc(#loc49)
    %966 = llvm.mul %29, %25 : i32 loc(#loc49)
    %967 = llvm.add %965, %966 : i32 loc(#loc49)
    %968 = llvm.getelementptr %12[%967] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %969 = llvm.and %467, %961 : i1 loc(#loc47)
    %970 = llvm.and %467, %961 : i1 loc(#loc47)
    %971 = llvm.and %467, %961 : i1 loc(#loc47)
    %972 = llvm.and %467, %961 : i1 loc(#loc47)
    nvvm.barrier0 loc(#loc49)
    %973 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc49)
    %974 = llvm.urem %973, %27 : i32 loc(#loc49)
    %975 = llvm.udiv %973, %27 : i32 loc(#loc49)
    %976 = llvm.and %974, %25 : i32 loc(#loc49)
    %977 = llvm.icmp "eq" %976, %29 : i32 loc(#loc49)
    %978 = llvm.select %977, %29, %25 : i1, i32 loc(#loc49)
    %979 = llvm.xor %29, %978 : i32 loc(#loc49)
    %980 = llvm.and %974, %20 : i32 loc(#loc49)
    %981 = llvm.icmp "eq" %980, %29 : i32 loc(#loc49)
    %982 = llvm.select %981, %29, %20 : i1, i32 loc(#loc49)
    %983 = llvm.xor %979, %982 : i32 loc(#loc49)
    %984 = llvm.and %974, %30 : i32 loc(#loc49)
    %985 = llvm.icmp "eq" %984, %29 : i32 loc(#loc49)
    %986 = llvm.select %985, %29, %30 : i1, i32 loc(#loc49)
    %987 = llvm.xor %983, %986 : i32 loc(#loc49)
    %988 = llvm.and %974, %19 : i32 loc(#loc49)
    %989 = llvm.icmp "eq" %988, %29 : i32 loc(#loc49)
    %990 = llvm.select %989, %29, %19 : i1, i32 loc(#loc49)
    %991 = llvm.xor %987, %990 : i32 loc(#loc49)
    %992 = llvm.and %974, %26 : i32 loc(#loc49)
    %993 = llvm.icmp "eq" %992, %29 : i32 loc(#loc49)
    %994 = llvm.select %993, %29, %25 : i1, i32 loc(#loc49)
    %995 = llvm.xor %29, %994 : i32 loc(#loc49)
    %996 = llvm.and %975, %25 : i32 loc(#loc49)
    %997 = llvm.icmp "eq" %996, %29 : i32 loc(#loc49)
    %998 = llvm.select %997, %29, %30 : i1, i32 loc(#loc49)
    %999 = llvm.xor %991, %998 : i32 loc(#loc49)
    %1000 = llvm.select %997, %29, %20 : i1, i32 loc(#loc49)
    %1001 = llvm.xor %995, %1000 : i32 loc(#loc49)
    %1002 = llvm.and %975, %20 : i32 loc(#loc49)
    %1003 = llvm.icmp "eq" %1002, %29 : i32 loc(#loc49)
    %1004 = llvm.select %1003, %29, %19 : i1, i32 loc(#loc49)
    %1005 = llvm.xor %999, %1004 : i32 loc(#loc49)
    %1006 = llvm.select %1003, %29, %30 : i1, i32 loc(#loc49)
    %1007 = llvm.xor %1001, %1006 : i32 loc(#loc49)
    %1008 = llvm.mul %1005, %25 : i32 loc(#loc49)
    %1009 = llvm.add %1008, %29 : i32 loc(#loc49)
    %1010 = llvm.mul %1007, %26 : i32 loc(#loc49)
    %1011 = llvm.add %1009, %1010 : i32 loc(#loc49)
    %1012 = llvm.getelementptr inbounds %968[%1011] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %1013 = llvm.and %974, %25 : i32 loc(#loc49)
    %1014 = llvm.icmp "eq" %1013, %29 : i32 loc(#loc49)
    %1015 = llvm.select %1014, %29, %25 : i1, i32 loc(#loc49)
    %1016 = llvm.xor %29, %1015 : i32 loc(#loc49)
    %1017 = llvm.and %974, %20 : i32 loc(#loc49)
    %1018 = llvm.icmp "eq" %1017, %29 : i32 loc(#loc49)
    %1019 = llvm.select %1018, %29, %20 : i1, i32 loc(#loc49)
    %1020 = llvm.xor %1016, %1019 : i32 loc(#loc49)
    %1021 = llvm.and %974, %30 : i32 loc(#loc49)
    %1022 = llvm.icmp "eq" %1021, %29 : i32 loc(#loc49)
    %1023 = llvm.select %1022, %29, %30 : i1, i32 loc(#loc49)
    %1024 = llvm.xor %1020, %1023 : i32 loc(#loc49)
    %1025 = llvm.and %974, %19 : i32 loc(#loc49)
    %1026 = llvm.icmp "eq" %1025, %29 : i32 loc(#loc49)
    %1027 = llvm.select %1026, %29, %19 : i1, i32 loc(#loc49)
    %1028 = llvm.xor %1024, %1027 : i32 loc(#loc49)
    %1029 = llvm.and %974, %26 : i32 loc(#loc49)
    %1030 = llvm.icmp "eq" %1029, %29 : i32 loc(#loc49)
    %1031 = llvm.select %1030, %29, %25 : i1, i32 loc(#loc49)
    %1032 = llvm.xor %19, %1031 : i32 loc(#loc49)
    %1033 = llvm.and %975, %25 : i32 loc(#loc49)
    %1034 = llvm.icmp "eq" %1033, %29 : i32 loc(#loc49)
    %1035 = llvm.select %1034, %29, %30 : i1, i32 loc(#loc49)
    %1036 = llvm.xor %1028, %1035 : i32 loc(#loc49)
    %1037 = llvm.select %1034, %29, %20 : i1, i32 loc(#loc49)
    %1038 = llvm.xor %1032, %1037 : i32 loc(#loc49)
    %1039 = llvm.and %975, %20 : i32 loc(#loc49)
    %1040 = llvm.icmp "eq" %1039, %29 : i32 loc(#loc49)
    %1041 = llvm.select %1040, %29, %19 : i1, i32 loc(#loc49)
    %1042 = llvm.xor %1036, %1041 : i32 loc(#loc49)
    %1043 = llvm.select %1040, %29, %30 : i1, i32 loc(#loc49)
    %1044 = llvm.xor %1038, %1043 : i32 loc(#loc49)
    %1045 = llvm.mul %1042, %25 : i32 loc(#loc49)
    %1046 = llvm.add %1045, %29 : i32 loc(#loc49)
    %1047 = llvm.mul %1044, %26 : i32 loc(#loc49)
    %1048 = llvm.add %1046, %1047 : i32 loc(#loc49)
    %1049 = llvm.getelementptr inbounds %968[%1048] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %1050 = llvm.and %974, %25 : i32 loc(#loc49)
    %1051 = llvm.icmp "eq" %1050, %29 : i32 loc(#loc49)
    %1052 = llvm.select %1051, %29, %25 : i1, i32 loc(#loc49)
    %1053 = llvm.xor %29, %1052 : i32 loc(#loc49)
    %1054 = llvm.and %974, %20 : i32 loc(#loc49)
    %1055 = llvm.icmp "eq" %1054, %29 : i32 loc(#loc49)
    %1056 = llvm.select %1055, %29, %20 : i1, i32 loc(#loc49)
    %1057 = llvm.xor %1053, %1056 : i32 loc(#loc49)
    %1058 = llvm.and %974, %30 : i32 loc(#loc49)
    %1059 = llvm.icmp "eq" %1058, %29 : i32 loc(#loc49)
    %1060 = llvm.select %1059, %29, %30 : i1, i32 loc(#loc49)
    %1061 = llvm.xor %1057, %1060 : i32 loc(#loc49)
    %1062 = llvm.and %974, %19 : i32 loc(#loc49)
    %1063 = llvm.icmp "eq" %1062, %29 : i32 loc(#loc49)
    %1064 = llvm.select %1063, %29, %19 : i1, i32 loc(#loc49)
    %1065 = llvm.xor %1061, %1064 : i32 loc(#loc49)
    %1066 = llvm.and %974, %26 : i32 loc(#loc49)
    %1067 = llvm.icmp "eq" %1066, %29 : i32 loc(#loc49)
    %1068 = llvm.select %1067, %29, %25 : i1, i32 loc(#loc49)
    %1069 = llvm.xor %26, %1068 : i32 loc(#loc49)
    %1070 = llvm.and %975, %25 : i32 loc(#loc49)
    %1071 = llvm.icmp "eq" %1070, %29 : i32 loc(#loc49)
    %1072 = llvm.select %1071, %29, %30 : i1, i32 loc(#loc49)
    %1073 = llvm.xor %1065, %1072 : i32 loc(#loc49)
    %1074 = llvm.select %1071, %29, %20 : i1, i32 loc(#loc49)
    %1075 = llvm.xor %1069, %1074 : i32 loc(#loc49)
    %1076 = llvm.and %975, %20 : i32 loc(#loc49)
    %1077 = llvm.icmp "eq" %1076, %29 : i32 loc(#loc49)
    %1078 = llvm.select %1077, %29, %19 : i1, i32 loc(#loc49)
    %1079 = llvm.xor %1073, %1078 : i32 loc(#loc49)
    %1080 = llvm.select %1077, %29, %30 : i1, i32 loc(#loc49)
    %1081 = llvm.xor %1075, %1080 : i32 loc(#loc49)
    %1082 = llvm.mul %1079, %25 : i32 loc(#loc49)
    %1083 = llvm.add %1082, %29 : i32 loc(#loc49)
    %1084 = llvm.mul %1081, %26 : i32 loc(#loc49)
    %1085 = llvm.add %1083, %1084 : i32 loc(#loc49)
    %1086 = llvm.getelementptr inbounds %968[%1085] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %1087 = llvm.and %974, %25 : i32 loc(#loc49)
    %1088 = llvm.icmp "eq" %1087, %29 : i32 loc(#loc49)
    %1089 = llvm.select %1088, %29, %25 : i1, i32 loc(#loc49)
    %1090 = llvm.xor %29, %1089 : i32 loc(#loc49)
    %1091 = llvm.and %974, %20 : i32 loc(#loc49)
    %1092 = llvm.icmp "eq" %1091, %29 : i32 loc(#loc49)
    %1093 = llvm.select %1092, %29, %20 : i1, i32 loc(#loc49)
    %1094 = llvm.xor %1090, %1093 : i32 loc(#loc49)
    %1095 = llvm.and %974, %30 : i32 loc(#loc49)
    %1096 = llvm.icmp "eq" %1095, %29 : i32 loc(#loc49)
    %1097 = llvm.select %1096, %29, %30 : i1, i32 loc(#loc49)
    %1098 = llvm.xor %1094, %1097 : i32 loc(#loc49)
    %1099 = llvm.and %974, %19 : i32 loc(#loc49)
    %1100 = llvm.icmp "eq" %1099, %29 : i32 loc(#loc49)
    %1101 = llvm.select %1100, %29, %19 : i1, i32 loc(#loc49)
    %1102 = llvm.xor %1098, %1101 : i32 loc(#loc49)
    %1103 = llvm.and %974, %26 : i32 loc(#loc49)
    %1104 = llvm.icmp "eq" %1103, %29 : i32 loc(#loc49)
    %1105 = llvm.select %1104, %29, %25 : i1, i32 loc(#loc49)
    %1106 = llvm.xor %18, %1105 : i32 loc(#loc49)
    %1107 = llvm.and %975, %25 : i32 loc(#loc49)
    %1108 = llvm.icmp "eq" %1107, %29 : i32 loc(#loc49)
    %1109 = llvm.select %1108, %29, %30 : i1, i32 loc(#loc49)
    %1110 = llvm.xor %1102, %1109 : i32 loc(#loc49)
    %1111 = llvm.select %1108, %29, %20 : i1, i32 loc(#loc49)
    %1112 = llvm.xor %1106, %1111 : i32 loc(#loc49)
    %1113 = llvm.and %975, %20 : i32 loc(#loc49)
    %1114 = llvm.icmp "eq" %1113, %29 : i32 loc(#loc49)
    %1115 = llvm.select %1114, %29, %19 : i1, i32 loc(#loc49)
    %1116 = llvm.xor %1110, %1115 : i32 loc(#loc49)
    %1117 = llvm.select %1114, %29, %30 : i1, i32 loc(#loc49)
    %1118 = llvm.xor %1112, %1117 : i32 loc(#loc49)
    %1119 = llvm.mul %1116, %25 : i32 loc(#loc49)
    %1120 = llvm.add %1119, %29 : i32 loc(#loc49)
    %1121 = llvm.mul %1118, %26 : i32 loc(#loc49)
    %1122 = llvm.add %1120, %1121 : i32 loc(#loc49)
    %1123 = llvm.getelementptr inbounds %968[%1122] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %1124 = llvm.select %969, %30, %29 : i1, i32 loc(#loc49)
    %1125 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %1012, %935, %1124 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %1126 = llvm.select %970, %30, %29 : i1, i32 loc(#loc49)
    %1127 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %1049, %936, %1126 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %1128 = llvm.select %971, %30, %29 : i1, i32 loc(#loc49)
    %1129 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %1086, %937, %1128 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %1130 = llvm.select %972, %30, %29 : i1, i32 loc(#loc49)
    %1131 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %1123, %938, %1130 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %1132 = llvm.icmp "slt" %218, %960 : i32 loc(#loc50)
    %1133 = llvm.mul %957, %11 : i32 loc(#loc46)
    %1134 = llvm.add %1133, %29 : i32 loc(#loc46)
    %1135 = llvm.mul %29, %27 : i32 loc(#loc46)
    %1136 = llvm.add %1134, %1135 : i32 loc(#loc46)
    %1137 = llvm.mul %29, %25 : i32 loc(#loc46)
    %1138 = llvm.add %1136, %1137 : i32 loc(#loc46)
    %1139 = llvm.getelementptr %235[%1138] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %1140 = llvm.and %467, %1132 : i1 loc(#loc47)
    %1141 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc46)
    %1142 = llvm.urem %1141, %27 : i32 loc(#loc46)
    %1143 = llvm.udiv %1141, %27 : i32 loc(#loc46)
    %1144 = llvm.and %1142, %25 : i32 loc(#loc46)
    %1145 = llvm.icmp "eq" %1144, %29 : i32 loc(#loc46)
    %1146 = llvm.select %1145, %29, %30 : i1, i32 loc(#loc46)
    %1147 = llvm.xor %29, %1146 : i32 loc(#loc46)
    %1148 = llvm.and %1142, %20 : i32 loc(#loc46)
    %1149 = llvm.icmp "eq" %1148, %29 : i32 loc(#loc46)
    %1150 = llvm.select %1149, %29, %19 : i1, i32 loc(#loc46)
    %1151 = llvm.xor %1147, %1150 : i32 loc(#loc46)
    %1152 = llvm.and %1142, %30 : i32 loc(#loc46)
    %1153 = llvm.icmp "eq" %1152, %29 : i32 loc(#loc46)
    %1154 = llvm.select %1153, %29, %26 : i1, i32 loc(#loc46)
    %1155 = llvm.xor %1151, %1154 : i32 loc(#loc46)
    %1156 = llvm.and %1142, %19 : i32 loc(#loc46)
    %1157 = llvm.icmp "eq" %1156, %29 : i32 loc(#loc46)
    %1158 = llvm.select %1157, %29, %19 : i1, i32 loc(#loc46)
    %1159 = llvm.xor %1155, %1158 : i32 loc(#loc46)
    %1160 = llvm.select %1157, %29, %25 : i1, i32 loc(#loc46)
    %1161 = llvm.xor %29, %1160 : i32 loc(#loc46)
    %1162 = llvm.and %1142, %26 : i32 loc(#loc46)
    %1163 = llvm.icmp "eq" %1162, %29 : i32 loc(#loc46)
    %1164 = llvm.select %1163, %29, %26 : i1, i32 loc(#loc46)
    %1165 = llvm.xor %1159, %1164 : i32 loc(#loc46)
    %1166 = llvm.select %1163, %29, %20 : i1, i32 loc(#loc46)
    %1167 = llvm.xor %1161, %1166 : i32 loc(#loc46)
    %1168 = llvm.and %1143, %25 : i32 loc(#loc46)
    %1169 = llvm.icmp "eq" %1168, %29 : i32 loc(#loc46)
    %1170 = llvm.select %1169, %29, %30 : i1, i32 loc(#loc46)
    %1171 = llvm.xor %1167, %1170 : i32 loc(#loc46)
    %1172 = llvm.and %1143, %20 : i32 loc(#loc46)
    %1173 = llvm.icmp "eq" %1172, %29 : i32 loc(#loc46)
    %1174 = llvm.select %1173, %29, %19 : i1, i32 loc(#loc46)
    %1175 = llvm.xor %1171, %1174 : i32 loc(#loc46)
    %1176 = llvm.mul %1165, %25 : i32 loc(#loc46)
    %1177 = llvm.add %1176, %29 : i32 loc(#loc46)
    %1178 = llvm.mul %1175, %27 : i32 loc(#loc46)
    %1179 = llvm.add %1177, %1178 : i32 loc(#loc46)
    %1180 = llvm.getelementptr inbounds %1139[%1179] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %1181 = llvm.select %1140, %26, %29 : i1, i32 loc(#loc46)
    %1182 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %1180, %947, %1181 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    %1183 = llvm.add %459, %25 : i32 loc(#loc47)
    llvm.br ^bb1(%1183, %930, %942, %954, %957, %470 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb3:  // pred: ^bb1
    nvvm.cp.async.wait.group 0 loc(#loc47)
    nvvm.barrier0 loc(#loc47)
    %1184 = llvm.extractvalue %460[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %1185 = llvm.extractvalue %460[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %1186 = llvm.extractvalue %460[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %1187 = llvm.extractvalue %460[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %1188 = llvm.extractvalue %460[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %1189 = llvm.extractvalue %460[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %1190 = llvm.extractvalue %460[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %1191 = llvm.extractvalue %460[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %1192 = llvm.fptrunc %1184 : f32 to f16 loc(#loc56)
    %1193 = llvm.fptrunc %1185 : f32 to f16 loc(#loc56)
    %1194 = llvm.fptrunc %1186 : f32 to f16 loc(#loc56)
    %1195 = llvm.fptrunc %1187 : f32 to f16 loc(#loc56)
    %1196 = llvm.fptrunc %1188 : f32 to f16 loc(#loc56)
    %1197 = llvm.fptrunc %1189 : f32 to f16 loc(#loc56)
    %1198 = llvm.fptrunc %1190 : f32 to f16 loc(#loc56)
    %1199 = llvm.fptrunc %1191 : f32 to f16 loc(#loc56)
    %1200 = llvm.mul %arg8, %147 : i32 loc(#loc57)
    %1201 = llvm.getelementptr %arg2[%1200] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc58)
    %1202 = llvm.getelementptr %1201[%157] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc59)
    %1203 = llvm.icmp "slt" %147, %arg3 : i32 loc(#loc60)
    %1204 = llvm.icmp "slt" %157, %arg4 : i32 loc(#loc61)
    %1205 = llvm.and %1203, %1204 : i1 loc(#loc62)
    %1206 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc63)
    %1207 = llvm.urem %1206, %27 : i32 loc(#loc63)
    %1208 = llvm.udiv %1206, %27 : i32 loc(#loc63)
    %1209 = llvm.and %1207, %25 : i32 loc(#loc63)
    %1210 = llvm.icmp "eq" %1209, %29 : i32 loc(#loc63)
    %1211 = llvm.select %1210, %29, %20 : i1, i32 loc(#loc63)
    %1212 = llvm.xor %29, %1211 : i32 loc(#loc63)
    %1213 = llvm.and %1207, %20 : i32 loc(#loc63)
    %1214 = llvm.icmp "eq" %1213, %29 : i32 loc(#loc63)
    %1215 = llvm.select %1214, %29, %30 : i1, i32 loc(#loc63)
    %1216 = llvm.xor %1212, %1215 : i32 loc(#loc63)
    %1217 = llvm.and %1207, %30 : i32 loc(#loc63)
    %1218 = llvm.icmp "eq" %1217, %29 : i32 loc(#loc63)
    %1219 = llvm.select %1218, %29, %27 : i1, i32 loc(#loc63)
    %1220 = llvm.xor %1216, %1219 : i32 loc(#loc63)
    %1221 = llvm.and %1207, %19 : i32 loc(#loc63)
    %1222 = llvm.icmp "eq" %1221, %29 : i32 loc(#loc63)
    %1223 = llvm.select %1222, %29, %5 : i1, i32 loc(#loc63)
    %1224 = llvm.xor %1220, %1223 : i32 loc(#loc63)
    %1225 = llvm.and %1207, %26 : i32 loc(#loc63)
    %1226 = llvm.icmp "eq" %1225, %29 : i32 loc(#loc63)
    %1227 = llvm.select %1226, %29, %10 : i1, i32 loc(#loc63)
    %1228 = llvm.xor %1224, %1227 : i32 loc(#loc63)
    %1229 = llvm.and %1208, %25 : i32 loc(#loc63)
    %1230 = llvm.icmp "eq" %1229, %29 : i32 loc(#loc63)
    %1231 = llvm.select %1230, %29, %19 : i1, i32 loc(#loc63)
    %1232 = llvm.xor %1228, %1231 : i32 loc(#loc63)
    %1233 = llvm.and %1208, %20 : i32 loc(#loc63)
    %1234 = llvm.icmp "eq" %1233, %29 : i32 loc(#loc63)
    %1235 = llvm.select %1234, %29, %11 : i1, i32 loc(#loc63)
    %1236 = llvm.xor %1232, %1235 : i32 loc(#loc63)
    %1237 = llvm.and %1207, %25 : i32 loc(#loc63)
    %1238 = llvm.icmp "eq" %1237, %29 : i32 loc(#loc63)
    %1239 = llvm.select %1238, %29, %19 : i1, i32 loc(#loc63)
    %1240 = llvm.xor %29, %1239 : i32 loc(#loc63)
    %1241 = llvm.and %1207, %20 : i32 loc(#loc63)
    %1242 = llvm.icmp "eq" %1241, %29 : i32 loc(#loc63)
    %1243 = llvm.select %1242, %29, %26 : i1, i32 loc(#loc63)
    %1244 = llvm.xor %1240, %1243 : i32 loc(#loc63)
    %1245 = llvm.and %1207, %30 : i32 loc(#loc63)
    %1246 = llvm.icmp "eq" %1245, %29 : i32 loc(#loc63)
    %1247 = llvm.select %1246, %29, %27 : i1, i32 loc(#loc63)
    %1248 = llvm.xor %1244, %1247 : i32 loc(#loc63)
    %1249 = llvm.and %1207, %19 : i32 loc(#loc63)
    %1250 = llvm.icmp "eq" %1249, %29 : i32 loc(#loc63)
    %1251 = llvm.select %1250, %29, %5 : i1, i32 loc(#loc63)
    %1252 = llvm.xor %1248, %1251 : i32 loc(#loc63)
    %1253 = llvm.and %1207, %26 : i32 loc(#loc63)
    %1254 = llvm.icmp "eq" %1253, %29 : i32 loc(#loc63)
    %1255 = llvm.select %1254, %29, %10 : i1, i32 loc(#loc63)
    %1256 = llvm.xor %1252, %1255 : i32 loc(#loc63)
    %1257 = llvm.and %1208, %25 : i32 loc(#loc63)
    %1258 = llvm.icmp "eq" %1257, %29 : i32 loc(#loc63)
    %1259 = llvm.select %1258, %29, %9 : i1, i32 loc(#loc63)
    %1260 = llvm.xor %1256, %1259 : i32 loc(#loc63)
    %1261 = llvm.and %1208, %20 : i32 loc(#loc63)
    %1262 = llvm.icmp "eq" %1261, %29 : i32 loc(#loc63)
    %1263 = llvm.select %1262, %29, %11 : i1, i32 loc(#loc63)
    %1264 = llvm.xor %1260, %1263 : i32 loc(#loc63)
    %1265 = llvm.xor %1236, %29 : i32 loc(#loc63)
    %1266 = llvm.lshr %1265, %16 : i32 loc(#loc63)
    %1267 = llvm.shl %1266, %17 : i32 loc(#loc63)
    %1268 = llvm.add %1267, %1265 : i32 loc(#loc63)
    %1269 = llvm.getelementptr inbounds %12[%1268] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %1270 = llvm.insertelement %1192, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %1271 = llvm.insertelement %1193, %1270[%25 : i32] : vector<2xf16> loc(#loc63)
    %1272 = llvm.extractelement %1271[%29 : i32] : vector<2xf16> loc(#loc63)
    %1273 = llvm.extractelement %1271[%25 : i32] : vector<2xf16> loc(#loc63)
    %1274 = llvm.bitcast %1272 : f16 to i16 loc(#loc63)
    %1275 = llvm.bitcast %1273 : f16 to i16 loc(#loc63)
    %1276 = llvm.insertelement %1274, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %1277 = llvm.insertelement %1275, %1276[%25 : i32] : vector<2xi16> loc(#loc63)
    %1278 = llvm.extractelement %1277[%29 : i32] : vector<2xi16> loc(#loc63)
    %1279 = llvm.extractelement %1277[%25 : i32] : vector<2xi16> loc(#loc63)
    %1280 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %1269, %1278, %1279, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %1281 = llvm.xor %1236, %9 : i32 loc(#loc63)
    %1282 = llvm.lshr %1281, %16 : i32 loc(#loc63)
    %1283 = llvm.shl %1282, %17 : i32 loc(#loc63)
    %1284 = llvm.add %1283, %1281 : i32 loc(#loc63)
    %1285 = llvm.getelementptr inbounds %12[%1284] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %1286 = llvm.insertelement %1194, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %1287 = llvm.insertelement %1195, %1286[%25 : i32] : vector<2xf16> loc(#loc63)
    %1288 = llvm.extractelement %1287[%29 : i32] : vector<2xf16> loc(#loc63)
    %1289 = llvm.extractelement %1287[%25 : i32] : vector<2xf16> loc(#loc63)
    %1290 = llvm.bitcast %1288 : f16 to i16 loc(#loc63)
    %1291 = llvm.bitcast %1289 : f16 to i16 loc(#loc63)
    %1292 = llvm.insertelement %1290, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %1293 = llvm.insertelement %1291, %1292[%25 : i32] : vector<2xi16> loc(#loc63)
    %1294 = llvm.extractelement %1293[%29 : i32] : vector<2xi16> loc(#loc63)
    %1295 = llvm.extractelement %1293[%25 : i32] : vector<2xi16> loc(#loc63)
    %1296 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %1285, %1294, %1295, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %1297 = llvm.xor %1236, %26 : i32 loc(#loc63)
    %1298 = llvm.lshr %1297, %16 : i32 loc(#loc63)
    %1299 = llvm.shl %1298, %17 : i32 loc(#loc63)
    %1300 = llvm.add %1299, %1297 : i32 loc(#loc63)
    %1301 = llvm.getelementptr inbounds %12[%1300] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %1302 = llvm.insertelement %1196, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %1303 = llvm.insertelement %1197, %1302[%25 : i32] : vector<2xf16> loc(#loc63)
    %1304 = llvm.extractelement %1303[%29 : i32] : vector<2xf16> loc(#loc63)
    %1305 = llvm.extractelement %1303[%25 : i32] : vector<2xf16> loc(#loc63)
    %1306 = llvm.bitcast %1304 : f16 to i16 loc(#loc63)
    %1307 = llvm.bitcast %1305 : f16 to i16 loc(#loc63)
    %1308 = llvm.insertelement %1306, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %1309 = llvm.insertelement %1307, %1308[%25 : i32] : vector<2xi16> loc(#loc63)
    %1310 = llvm.extractelement %1309[%29 : i32] : vector<2xi16> loc(#loc63)
    %1311 = llvm.extractelement %1309[%25 : i32] : vector<2xi16> loc(#loc63)
    %1312 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %1301, %1310, %1311, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %1313 = llvm.xor %1236, %7 : i32 loc(#loc63)
    %1314 = llvm.lshr %1313, %16 : i32 loc(#loc63)
    %1315 = llvm.shl %1314, %17 : i32 loc(#loc63)
    %1316 = llvm.add %1315, %1313 : i32 loc(#loc63)
    %1317 = llvm.getelementptr inbounds %12[%1316] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %1318 = llvm.insertelement %1198, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %1319 = llvm.insertelement %1199, %1318[%25 : i32] : vector<2xf16> loc(#loc63)
    %1320 = llvm.extractelement %1319[%29 : i32] : vector<2xf16> loc(#loc63)
    %1321 = llvm.extractelement %1319[%25 : i32] : vector<2xf16> loc(#loc63)
    %1322 = llvm.bitcast %1320 : f16 to i16 loc(#loc63)
    %1323 = llvm.bitcast %1321 : f16 to i16 loc(#loc63)
    %1324 = llvm.insertelement %1322, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %1325 = llvm.insertelement %1323, %1324[%25 : i32] : vector<2xi16> loc(#loc63)
    %1326 = llvm.extractelement %1325[%29 : i32] : vector<2xi16> loc(#loc63)
    %1327 = llvm.extractelement %1325[%25 : i32] : vector<2xi16> loc(#loc63)
    %1328 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %1317, %1326, %1327, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    nvvm.barrier0 loc(#loc63)
    %1329 = llvm.xor %1264, %29 : i32 loc(#loc63)
    %1330 = llvm.lshr %1329, %16 : i32 loc(#loc63)
    %1331 = llvm.shl %1330, %17 : i32 loc(#loc63)
    %1332 = llvm.add %1331, %1329 : i32 loc(#loc63)
    %1333 = llvm.getelementptr inbounds %12[%1332] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %1334 = llvm.load %1333 : !llvm.ptr<3> -> vector<4xi32> loc(#loc63)
    %1335 = llvm.extractelement %1334[%29 : i32] : vector<4xi32> loc(#loc63)
    %1336 = llvm.extractelement %1334[%25 : i32] : vector<4xi32> loc(#loc63)
    %1337 = llvm.extractelement %1334[%20 : i32] : vector<4xi32> loc(#loc63)
    %1338 = llvm.extractelement %1334[%17 : i32] : vector<4xi32> loc(#loc63)
    %1339 = llvm.insertelement %1335, %2[%29 : i32] : vector<4xi32> loc(#loc63)
    %1340 = llvm.insertelement %1336, %1339[%25 : i32] : vector<4xi32> loc(#loc63)
    %1341 = llvm.insertelement %1337, %1340[%20 : i32] : vector<4xi32> loc(#loc63)
    %1342 = llvm.insertelement %1338, %1341[%17 : i32] : vector<4xi32> loc(#loc63)
    %1343 = llvm.extractelement %1342[%29 : i32] : vector<4xi32> loc(#loc63)
    %1344 = llvm.extractelement %1342[%25 : i32] : vector<4xi32> loc(#loc63)
    %1345 = llvm.extractelement %1342[%20 : i32] : vector<4xi32> loc(#loc63)
    %1346 = llvm.extractelement %1342[%17 : i32] : vector<4xi32> loc(#loc63)
    %1347 = llvm.bitcast %1343 : i32 to vector<2xi16> loc(#loc63)
    %1348 = llvm.extractelement %1347[%29 : i32] : vector<2xi16> loc(#loc63)
    %1349 = llvm.extractelement %1347[%25 : i32] : vector<2xi16> loc(#loc63)
    %1350 = llvm.bitcast %1344 : i32 to vector<2xi16> loc(#loc63)
    %1351 = llvm.extractelement %1350[%29 : i32] : vector<2xi16> loc(#loc63)
    %1352 = llvm.extractelement %1350[%25 : i32] : vector<2xi16> loc(#loc63)
    %1353 = llvm.bitcast %1345 : i32 to vector<2xi16> loc(#loc63)
    %1354 = llvm.extractelement %1353[%29 : i32] : vector<2xi16> loc(#loc63)
    %1355 = llvm.extractelement %1353[%25 : i32] : vector<2xi16> loc(#loc63)
    %1356 = llvm.bitcast %1346 : i32 to vector<2xi16> loc(#loc63)
    %1357 = llvm.extractelement %1356[%29 : i32] : vector<2xi16> loc(#loc63)
    %1358 = llvm.extractelement %1356[%25 : i32] : vector<2xi16> loc(#loc63)
    %1359 = llvm.insertelement %1348, %1[%29 : i32] : vector<8xi16> loc(#loc63)
    %1360 = llvm.insertelement %1349, %1359[%25 : i32] : vector<8xi16> loc(#loc63)
    %1361 = llvm.insertelement %1351, %1360[%20 : i32] : vector<8xi16> loc(#loc63)
    %1362 = llvm.insertelement %1352, %1361[%17 : i32] : vector<8xi16> loc(#loc63)
    %1363 = llvm.insertelement %1354, %1362[%30 : i32] : vector<8xi16> loc(#loc63)
    %1364 = llvm.insertelement %1355, %1363[%16 : i32] : vector<8xi16> loc(#loc63)
    %1365 = llvm.insertelement %1357, %1364[%15 : i32] : vector<8xi16> loc(#loc63)
    %1366 = llvm.insertelement %1358, %1365[%14 : i32] : vector<8xi16> loc(#loc63)
    %1367 = llvm.extractelement %1366[%29 : i32] : vector<8xi16> loc(#loc63)
    %1368 = llvm.extractelement %1366[%25 : i32] : vector<8xi16> loc(#loc63)
    %1369 = llvm.extractelement %1366[%20 : i32] : vector<8xi16> loc(#loc63)
    %1370 = llvm.extractelement %1366[%17 : i32] : vector<8xi16> loc(#loc63)
    %1371 = llvm.extractelement %1366[%30 : i32] : vector<8xi16> loc(#loc63)
    %1372 = llvm.extractelement %1366[%16 : i32] : vector<8xi16> loc(#loc63)
    %1373 = llvm.extractelement %1366[%15 : i32] : vector<8xi16> loc(#loc63)
    %1374 = llvm.extractelement %1366[%14 : i32] : vector<8xi16> loc(#loc63)
    %1375 = llvm.bitcast %1367 : i16 to f16 loc(#loc63)
    %1376 = llvm.bitcast %1368 : i16 to f16 loc(#loc63)
    %1377 = llvm.bitcast %1369 : i16 to f16 loc(#loc63)
    %1378 = llvm.bitcast %1370 : i16 to f16 loc(#loc63)
    %1379 = llvm.bitcast %1371 : i16 to f16 loc(#loc63)
    %1380 = llvm.bitcast %1372 : i16 to f16 loc(#loc63)
    %1381 = llvm.bitcast %1373 : i16 to f16 loc(#loc63)
    %1382 = llvm.bitcast %1374 : i16 to f16 loc(#loc63)
    %1383 = llvm.insertelement %1375, %0[%29 : i32] : vector<8xf16> loc(#loc63)
    %1384 = llvm.insertelement %1376, %1383[%25 : i32] : vector<8xf16> loc(#loc63)
    %1385 = llvm.insertelement %1377, %1384[%20 : i32] : vector<8xf16> loc(#loc63)
    %1386 = llvm.insertelement %1378, %1385[%17 : i32] : vector<8xf16> loc(#loc63)
    %1387 = llvm.insertelement %1379, %1386[%30 : i32] : vector<8xf16> loc(#loc63)
    %1388 = llvm.insertelement %1380, %1387[%16 : i32] : vector<8xf16> loc(#loc63)
    %1389 = llvm.insertelement %1381, %1388[%15 : i32] : vector<8xf16> loc(#loc63)
    %1390 = llvm.insertelement %1382, %1389[%14 : i32] : vector<8xf16> loc(#loc63)
    %1391 = llvm.extractelement %1390[%29 : i32] : vector<8xf16> loc(#loc63)
    %1392 = llvm.extractelement %1390[%25 : i32] : vector<8xf16> loc(#loc63)
    %1393 = llvm.extractelement %1390[%20 : i32] : vector<8xf16> loc(#loc63)
    %1394 = llvm.extractelement %1390[%17 : i32] : vector<8xf16> loc(#loc63)
    %1395 = llvm.extractelement %1390[%30 : i32] : vector<8xf16> loc(#loc63)
    %1396 = llvm.extractelement %1390[%16 : i32] : vector<8xf16> loc(#loc63)
    %1397 = llvm.extractelement %1390[%15 : i32] : vector<8xf16> loc(#loc63)
    %1398 = llvm.extractelement %1390[%14 : i32] : vector<8xf16> loc(#loc63)
    %1399 = llvm.insertelement %1391, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %1400 = llvm.insertelement %1392, %1399[%25 : i32] : vector<2xf16> loc(#loc63)
    %1401 = llvm.bitcast %1400 : vector<2xf16> to i32 loc(#loc63)
    %1402 = llvm.insertelement %1393, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %1403 = llvm.insertelement %1394, %1402[%25 : i32] : vector<2xf16> loc(#loc63)
    %1404 = llvm.bitcast %1403 : vector<2xf16> to i32 loc(#loc63)
    %1405 = llvm.insertelement %1395, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %1406 = llvm.insertelement %1396, %1405[%25 : i32] : vector<2xf16> loc(#loc63)
    %1407 = llvm.bitcast %1406 : vector<2xf16> to i32 loc(#loc63)
    %1408 = llvm.insertelement %1397, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %1409 = llvm.insertelement %1398, %1408[%25 : i32] : vector<2xf16> loc(#loc63)
    %1410 = llvm.bitcast %1409 : vector<2xf16> to i32 loc(#loc63)
    %1411 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$5 st.global.v4.b32 [ $4 + 0 ], { $0, $1, $2, $3 };", "r,r,r,r,l,b" %1401, %1404, %1407, %1410, %1202, %1205 : (i32, i32, i32, i32, !llvm.ptr<1>, i1) -> !llvm.void loc(#loc63)
    llvm.return loc(#loc64)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:41)
#loc37 = loc("examples/kernels/binary_ops.py":159:60)
#loc38 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":160:29)
#loc41 = loc("examples/kernels/binary_ops.py":160:40)
#loc42 = loc("examples/kernels/binary_ops.py":160:52)
#loc44 = loc("examples/kernels/binary_ops.py":168:33)
#loc45 = loc("examples/kernels/binary_ops.py":177:33)
#loc46 = loc("examples/kernels/binary_ops.py":172:20)
#loc48 = loc("examples/kernels/binary_ops.py":171:51)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:51)
#loc51 = loc("examples/kernels/binary_ops.py":174:35)
#loc52 = loc("examples/kernels/binary_ops.py":176:18)
#loc53 = loc("examples/kernels/binary_ops.py":177:18)
#loc54 = loc("examples/kernels/binary_ops.py":171:59)
#loc55 = loc("examples/kernels/binary_ops.py":171:55)
#loc56 = loc("examples/kernels/binary_ops.py":182:23)
#loc57 = loc("examples/kernels/binary_ops.py":188:33)
#loc58 = loc("examples/kernels/binary_ops.py":188:21)
#loc59 = loc("examples/kernels/binary_ops.py":188:52)
#loc60 = loc("examples/kernels/binary_ops.py":189:33)
#loc61 = loc("examples/kernels/binary_ops.py":189:58)
#loc62 = loc("examples/kernels/binary_ops.py":189:39)
#loc63 = loc("examples/kernels/binary_ops.py":190:21)
#loc64 = loc("examples/kernels/binary_ops.py":190:4)
#loc65 = loc(callsite(#loc3 at #loc4))
#loc66 = loc(callsite(#loc5 at #loc4))
#loc67 = loc(callsite(#loc3 at #loc6))
#loc68 = loc(callsite(#loc5 at #loc6))
#loc69 = loc(callsite(#loc3 at #loc44))
#loc70 = loc(callsite(#loc5 at #loc44))


// -----// IR Dump Before ConvertNVGPUToLLVM (convert-nv-gpu-to-llvm) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc39 = loc("examples/kernels/binary_ops.py":159:22)
#loc43 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
module attributes {ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @matmul_kernel(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg9: !llvm.ptr<1> loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.undef : vector<8xf16> loc(#loc1)
    %1 = llvm.mlir.undef : vector<8xi16> loc(#loc1)
    %2 = llvm.mlir.undef : vector<4xi32> loc(#loc1)
    %3 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %4 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %5 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.undef : vector<1xf32> loc(#loc1)
    %7 = llvm.mlir.constant(272 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.constant(256 : i32) : i32 loc(#loc1)
    %10 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(512 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %13 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc1)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(6 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %22 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc1)
    %23 = llvm.mlir.constant(15 : i32) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(31 : i32) : i32 loc(#loc1)
    %25 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %26 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %27 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %28 = llvm.mlir.constant(true) : i1 loc(#loc1)
    %29 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %30 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %31 = llvm.mlir.constant(-1 : i32) : i32 loc(#loc1)
    %32 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %33 = llvm.insertvalue %32, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %34 = llvm.insertvalue %32, %33[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %35 = llvm.insertvalue %32, %34[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %36 = llvm.insertvalue %32, %35[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %37 = llvm.insertvalue %32, %36[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %38 = llvm.insertvalue %32, %37[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %39 = llvm.insertvalue %32, %38[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %40 = llvm.insertvalue %32, %39[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %41 = llvm.call_intrinsic "llvm.nvvm.read.ptx.sreg.ctaid.x"() : () -> i32 loc(#loc2)
    %42 = llvm.add %arg3, %24 : i32 loc(#loc65)
    %43 = llvm.sdiv %42, %27 : i32 loc(#loc66)
    %44 = llvm.add %arg4, %24 : i32 loc(#loc67)
    %45 = llvm.sdiv %44, %27 : i32 loc(#loc68)
    %46 = llvm.mul %45, %30 : i32 loc(#loc7)
    %47 = llvm.sdiv %41, %46 : i32 loc(#loc8)
    %48 = llvm.mul %47, %30 : i32 loc(#loc9)
    %49 = llvm.sub %43, %48 : i32 loc(#loc10)
    %50 = llvm.intr.smin(%49, %30) : (i32, i32) -> i32 loc(#loc11)
    %51 = llvm.srem %41, %46 : i32 loc(#loc12)
    %52 = llvm.srem %51, %50 : i32 loc(#loc13)
    %53 = llvm.add %48, %52 : i32 loc(#loc14)
    %54 = llvm.sdiv %51, %50 : i32 loc(#loc15)
    %55 = llvm.icmp "sge" %53, %29 : i32 loc(#loc16)
    llvm.intr.assume %55 : i1 loc(#loc17)
    %56 = llvm.icmp "sge" %54, %29 : i32 loc(#loc18)
    llvm.intr.assume %56 : i1 loc(#loc19)
    %57 = llvm.icmp "sgt" %arg6, %29 : i32 loc(#loc20)
    llvm.intr.assume %57 : i1 loc(#loc21)
    llvm.intr.assume %28 : i1 loc(#loc22)
    llvm.intr.assume %28 : i1 loc(#loc23)
    %58 = llvm.icmp "sgt" %arg7, %29 : i32 loc(#loc24)
    llvm.intr.assume %58 : i1 loc(#loc25)
    %59 = llvm.icmp "sgt" %arg8, %29 : i32 loc(#loc26)
    llvm.intr.assume %59 : i1 loc(#loc27)
    llvm.intr.assume %28 : i1 loc(#loc28)
    %60 = llvm.mul %53, %27 : i32 loc(#loc29)
    %61 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc30)
    %62 = llvm.urem %61, %27 : i32 loc(#loc30)
    %63 = llvm.udiv %61, %27 : i32 loc(#loc30)
    %64 = llvm.and %62, %26 : i32 loc(#loc30)
    %65 = llvm.icmp "eq" %64, %29 : i32 loc(#loc30)
    %66 = llvm.select %65, %29, %25 : i1, i32 loc(#loc30)
    %67 = llvm.xor %29, %66 : i32 loc(#loc30)
    %68 = llvm.and %63, %25 : i32 loc(#loc30)
    %69 = llvm.icmp "eq" %68, %29 : i32 loc(#loc30)
    %70 = llvm.select %69, %29, %20 : i1, i32 loc(#loc30)
    %71 = llvm.xor %67, %70 : i32 loc(#loc30)
    %72 = llvm.and %63, %20 : i32 loc(#loc30)
    %73 = llvm.icmp "eq" %72, %29 : i32 loc(#loc30)
    %74 = llvm.select %73, %29, %30 : i1, i32 loc(#loc30)
    %75 = llvm.xor %71, %74 : i32 loc(#loc30)
    %76 = llvm.xor %75, %29 : i32 loc(#loc30)
    %77 = llvm.xor %75, %19 : i32 loc(#loc30)
    %78 = llvm.xor %75, %26 : i32 loc(#loc30)
    %79 = llvm.xor %75, %18 : i32 loc(#loc30)
    %80 = llvm.add %76, %21 : i32 loc(#loc30)
    %81 = llvm.add %77, %21 : i32 loc(#loc30)
    %82 = llvm.add %78, %21 : i32 loc(#loc30)
    %83 = llvm.add %79, %21 : i32 loc(#loc30)
    %84 = llvm.and %62, %30 : i32 loc(#loc30)
    %85 = llvm.icmp "eq" %84, %29 : i32 loc(#loc30)
    %86 = llvm.select %85, %29, %25 : i1, i32 loc(#loc30)
    %87 = llvm.xor %29, %86 : i32 loc(#loc30)
    %88 = llvm.and %62, %19 : i32 loc(#loc30)
    %89 = llvm.icmp "eq" %88, %29 : i32 loc(#loc30)
    %90 = llvm.select %89, %29, %20 : i1, i32 loc(#loc30)
    %91 = llvm.xor %87, %90 : i32 loc(#loc30)
    %92 = llvm.select %65, %29, %30 : i1, i32 loc(#loc30)
    %93 = llvm.xor %91, %92 : i32 loc(#loc30)
    %94 = llvm.select %69, %29, %19 : i1, i32 loc(#loc30)
    %95 = llvm.xor %93, %94 : i32 loc(#loc30)
    %96 = llvm.select %73, %29, %26 : i1, i32 loc(#loc30)
    %97 = llvm.xor %95, %96 : i32 loc(#loc30)
    %98 = llvm.xor %97, %29 : i32 loc(#loc30)
    %99 = llvm.add %98, %21 : i32 loc(#loc30)
    %100 = llvm.and %62, %25 : i32 loc(#loc30)
    %101 = llvm.icmp "eq" %100, %29 : i32 loc(#loc30)
    %102 = llvm.select %101, %29, %30 : i1, i32 loc(#loc30)
    %103 = llvm.xor %29, %102 : i32 loc(#loc30)
    %104 = llvm.and %62, %20 : i32 loc(#loc30)
    %105 = llvm.icmp "eq" %104, %29 : i32 loc(#loc30)
    %106 = llvm.select %105, %29, %19 : i1, i32 loc(#loc30)
    %107 = llvm.xor %103, %106 : i32 loc(#loc30)
    %108 = llvm.select %85, %29, %26 : i1, i32 loc(#loc30)
    %109 = llvm.xor %107, %108 : i32 loc(#loc30)
    %110 = llvm.xor %109, %29 : i32 loc(#loc30)
    %111 = llvm.xor %109, %25 : i32 loc(#loc30)
    %112 = llvm.xor %109, %20 : i32 loc(#loc30)
    %113 = llvm.xor %109, %17 : i32 loc(#loc30)
    %114 = llvm.add %110, %21 : i32 loc(#loc30)
    %115 = llvm.add %111, %21 : i32 loc(#loc30)
    %116 = llvm.add %112, %21 : i32 loc(#loc30)
    %117 = llvm.add %113, %21 : i32 loc(#loc30)
    %118 = llvm.select %101, %29, %19 : i1, i32 loc(#loc30)
    %119 = llvm.xor %29, %118 : i32 loc(#loc30)
    %120 = llvm.select %105, %29, %26 : i1, i32 loc(#loc30)
    %121 = llvm.xor %119, %120 : i32 loc(#loc30)
    %122 = llvm.xor %121, %29 : i32 loc(#loc30)
    %123 = llvm.add %122, %21 : i32 loc(#loc30)
    %124 = llvm.add %60, %80 : i32 loc(#loc31)
    %125 = llvm.add %60, %81 : i32 loc(#loc31)
    %126 = llvm.add %60, %82 : i32 loc(#loc31)
    %127 = llvm.add %60, %83 : i32 loc(#loc31)
    %128 = llvm.add %60, %99 : i32 loc(#loc31)
    %129 = llvm.srem %124, %arg3 : i32 loc(#loc32)
    %130 = llvm.srem %125, %arg3 : i32 loc(#loc32)
    %131 = llvm.srem %126, %arg3 : i32 loc(#loc32)
    %132 = llvm.srem %127, %arg3 : i32 loc(#loc32)
    %133 = llvm.mul %54, %27 : i32 loc(#loc33)
    %134 = llvm.add %133, %114 : i32 loc(#loc34)
    %135 = llvm.add %133, %115 : i32 loc(#loc34)
    %136 = llvm.add %133, %116 : i32 loc(#loc34)
    %137 = llvm.add %133, %117 : i32 loc(#loc34)
    %138 = llvm.add %133, %123 : i32 loc(#loc34)
    %139 = llvm.srem %134, %arg4 : i32 loc(#loc35)
    %140 = llvm.srem %135, %arg4 : i32 loc(#loc35)
    %141 = llvm.srem %136, %arg4 : i32 loc(#loc35)
    %142 = llvm.srem %137, %arg4 : i32 loc(#loc35)
    %143 = llvm.mul %129, %arg6 : i32 loc(#loc36)
    %144 = llvm.mul %130, %arg6 : i32 loc(#loc36)
    %145 = llvm.mul %131, %arg6 : i32 loc(#loc36)
    %146 = llvm.mul %132, %arg6 : i32 loc(#loc36)
    %147 = llvm.select %101, %29, %25 : i1, i32 loc(#loc37)
    %148 = llvm.xor %29, %147 : i32 loc(#loc37)
    %149 = llvm.select %105, %29, %20 : i1, i32 loc(#loc37)
    %150 = llvm.xor %148, %149 : i32 loc(#loc37)
    %151 = llvm.select %85, %29, %30 : i1, i32 loc(#loc37)
    %152 = llvm.xor %150, %151 : i32 loc(#loc37)
    %153 = llvm.select %89, %29, %19 : i1, i32 loc(#loc37)
    %154 = llvm.xor %152, %153 : i32 loc(#loc37)
    %155 = llvm.xor %154, %29 : i32 loc(#loc37)
    %156 = llvm.add %155, %21 : i32 loc(#loc37)
    %157 = llvm.add %143, %156 : i32 loc(#loc38)
    %158 = llvm.add %144, %156 : i32 loc(#loc38)
    %159 = llvm.add %145, %156 : i32 loc(#loc38)
    %160 = llvm.add %146, %156 : i32 loc(#loc38)
    %161 = llvm.getelementptr %arg0[%157] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %162 = llvm.getelementptr %arg0[%158] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %163 = llvm.getelementptr %arg0[%159] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %164 = llvm.getelementptr %arg0[%160] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %165 = llvm.insertvalue %161, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %166 = llvm.insertvalue %162, %165[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %167 = llvm.insertvalue %163, %166[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %168 = llvm.insertvalue %164, %167[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %169 = llvm.select %89, %29, %25 : i1, i32 loc(#loc40)
    %170 = llvm.xor %29, %169 : i32 loc(#loc40)
    %171 = llvm.select %65, %29, %20 : i1, i32 loc(#loc40)
    %172 = llvm.xor %170, %171 : i32 loc(#loc40)
    %173 = llvm.select %69, %29, %30 : i1, i32 loc(#loc40)
    %174 = llvm.xor %172, %173 : i32 loc(#loc40)
    %175 = llvm.select %73, %29, %19 : i1, i32 loc(#loc40)
    %176 = llvm.xor %174, %175 : i32 loc(#loc40)
    %177 = llvm.xor %176, %29 : i32 loc(#loc40)
    %178 = llvm.add %177, %21 : i32 loc(#loc40)
    %179 = llvm.mul %178, %arg7 : i32 loc(#loc41)
    %180 = llvm.add %179, %139 : i32 loc(#loc42)
    %181 = llvm.add %179, %140 : i32 loc(#loc42)
    %182 = llvm.add %179, %141 : i32 loc(#loc42)
    %183 = llvm.add %179, %142 : i32 loc(#loc42)
    %184 = llvm.getelementptr %arg1[%180] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %185 = llvm.getelementptr %arg1[%181] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %186 = llvm.getelementptr %arg1[%182] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %187 = llvm.getelementptr %arg1[%183] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %188 = llvm.insertvalue %184, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %189 = llvm.insertvalue %185, %188[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %190 = llvm.insertvalue %186, %189[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %191 = llvm.insertvalue %187, %190[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %192 = llvm.add %arg5, %23 : i32 loc(#loc69)
    %193 = llvm.sdiv %192, %26 : i32 loc(#loc70)
    %194 = llvm.mul %arg7, %26 : i32 loc(#loc45)
    %195 = llvm.getelementptr %12[2048] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc46)
    %196 = llvm.icmp "sgt" %193, %29 : i32 loc(#loc47)
    %197 = llvm.icmp "slt" %156, %arg5 : i32 loc(#loc48)
    %198 = llvm.mul %29, %11 : i32 loc(#loc49)
    %199 = llvm.add %198, %29 : i32 loc(#loc49)
    %200 = llvm.mul %29, %26 : i32 loc(#loc49)
    %201 = llvm.add %199, %200 : i32 loc(#loc49)
    %202 = llvm.mul %29, %25 : i32 loc(#loc49)
    %203 = llvm.add %201, %202 : i32 loc(#loc49)
    %204 = llvm.getelementptr %12[%203] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %205 = llvm.and %196, %197 : i1 loc(#loc47)
    %206 = llvm.xor %154, %173 : i32 loc(#loc49)
    %207 = llvm.xor %206, %175 : i32 loc(#loc49)
    %208 = llvm.mul %207, %25 : i32 loc(#loc49)
    %209 = llvm.add %208, %29 : i32 loc(#loc49)
    %210 = llvm.mul %75, %26 : i32 loc(#loc49)
    %211 = llvm.add %209, %210 : i32 loc(#loc49)
    %212 = llvm.getelementptr inbounds %204[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %213 = llvm.xor %19, %66 : i32 loc(#loc49)
    %214 = llvm.xor %213, %70 : i32 loc(#loc49)
    %215 = llvm.xor %214, %74 : i32 loc(#loc49)
    %216 = llvm.mul %215, %26 : i32 loc(#loc49)
    %217 = llvm.add %209, %216 : i32 loc(#loc49)
    %218 = llvm.getelementptr inbounds %204[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %219 = llvm.xor %26, %66 : i32 loc(#loc49)
    %220 = llvm.xor %219, %70 : i32 loc(#loc49)
    %221 = llvm.xor %220, %74 : i32 loc(#loc49)
    %222 = llvm.mul %221, %26 : i32 loc(#loc49)
    %223 = llvm.add %209, %222 : i32 loc(#loc49)
    %224 = llvm.getelementptr inbounds %204[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %225 = llvm.xor %18, %66 : i32 loc(#loc49)
    %226 = llvm.xor %225, %70 : i32 loc(#loc49)
    %227 = llvm.xor %226, %74 : i32 loc(#loc49)
    %228 = llvm.mul %227, %26 : i32 loc(#loc49)
    %229 = llvm.add %209, %228 : i32 loc(#loc49)
    %230 = llvm.getelementptr inbounds %204[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %231 = llvm.select %205, %30, %29 : i1, i32 loc(#loc49)
    %232 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %212, %161, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %233 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %218, %162, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %234 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %224, %163, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %235 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %230, %164, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %236 = llvm.icmp "slt" %178, %arg5 : i32 loc(#loc50)
    %237 = llvm.mul %29, %27 : i32 loc(#loc46)
    %238 = llvm.add %199, %237 : i32 loc(#loc46)
    %239 = llvm.add %238, %202 : i32 loc(#loc46)
    %240 = llvm.getelementptr %195[%239] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %241 = llvm.and %196, %236 : i1 loc(#loc47)
    %242 = llvm.xor %109, %153 : i32 loc(#loc46)
    %243 = llvm.select %65, %29, %26 : i1, i32 loc(#loc46)
    %244 = llvm.xor %242, %243 : i32 loc(#loc46)
    %245 = llvm.mul %244, %25 : i32 loc(#loc46)
    %246 = llvm.add %245, %29 : i32 loc(#loc46)
    %247 = llvm.mul %176, %27 : i32 loc(#loc46)
    %248 = llvm.add %246, %247 : i32 loc(#loc46)
    %249 = llvm.getelementptr inbounds %240[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %250 = llvm.select %241, %26, %29 : i1, i32 loc(#loc46)
    %251 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %249, %184, %250 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%29, %40, %168, %191, %29, %31 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb1(%252: i32 loc("examples/kernels/binary_ops.py":168:22), %253: !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(unknown), %254: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":159:22), %255: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":160:22), %256: i32 loc(unknown), %257: i32 loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %258 = llvm.icmp "slt" %252, %193 : i32 loc(#loc47)
    llvm.cond_br %258, ^bb2, ^bb3 loc(#loc47)
  ^bb2:  // pred: ^bb1
    %259 = llvm.sub %193, %25 : i32 loc(#loc47)
    %260 = llvm.icmp "slt" %252, %259 : i32 loc(#loc47)
    %261 = llvm.add %257, %25 : i32 loc(#loc47)
    %262 = llvm.icmp "slt" %261, %25 : i32 loc(#loc47)
    %263 = llvm.select %262, %261, %29 : i1, i32 loc(#loc47)
    nvvm.cp.async.wait.group 0 loc(#loc49)
    nvvm.barrier0 loc(#loc49)
    %264 = llvm.mul %263, %11 : i32 loc(#loc49)
    %265 = llvm.add %264, %29 : i32 loc(#loc49)
    %266 = llvm.add %265, %200 : i32 loc(#loc49)
    %267 = llvm.add %266, %202 : i32 loc(#loc49)
    %268 = llvm.getelementptr %12[%267] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %269 = llvm.select %105, %29, %30 : i1, i32 loc(#loc49)
    %270 = llvm.xor %29, %269 : i32 loc(#loc49)
    %271 = llvm.select %85, %29, %19 : i1, i32 loc(#loc49)
    %272 = llvm.xor %270, %271 : i32 loc(#loc49)
    %273 = llvm.xor %272, %92 : i32 loc(#loc49)
    %274 = llvm.xor %154, %96 : i32 loc(#loc49)
    %275 = llvm.mul %273, %25 : i32 loc(#loc49)
    %276 = llvm.add %275, %29 : i32 loc(#loc49)
    %277 = llvm.mul %274, %26 : i32 loc(#loc49)
    %278 = llvm.add %276, %277 : i32 loc(#loc49)
    %279 = llvm.getelementptr inbounds %268[%278] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %280 = nvgpu.ldmatrix %279 : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %281 = llvm.extractvalue %280[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %282 = llvm.extractvalue %280[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %283 = llvm.extractvalue %280[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %284 = llvm.extractvalue %280[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %285 = llvm.xor %19, %269 : i32 loc(#loc49)
    %286 = llvm.xor %285, %271 : i32 loc(#loc49)
    %287 = llvm.xor %286, %92 : i32 loc(#loc49)
    %288 = llvm.mul %287, %25 : i32 loc(#loc49)
    %289 = llvm.add %288, %29 : i32 loc(#loc49)
    %290 = llvm.add %289, %277 : i32 loc(#loc49)
    %291 = llvm.getelementptr inbounds %268[%290] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %292 = nvgpu.ldmatrix %291 : (!llvm.ptr<3>) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %293 = llvm.extractvalue %292[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %294 = llvm.extractvalue %292[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %295 = llvm.extractvalue %292[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %296 = llvm.extractvalue %292[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %297 = llvm.bitcast %281 : i32 to vector<1xf32> loc(#loc49)
    %298 = llvm.extractelement %297[%29 : i32] : vector<1xf32> loc(#loc49)
    %299 = llvm.bitcast %282 : i32 to vector<1xf32> loc(#loc49)
    %300 = llvm.extractelement %299[%29 : i32] : vector<1xf32> loc(#loc49)
    %301 = llvm.bitcast %283 : i32 to vector<1xf32> loc(#loc49)
    %302 = llvm.extractelement %301[%29 : i32] : vector<1xf32> loc(#loc49)
    %303 = llvm.bitcast %284 : i32 to vector<1xf32> loc(#loc49)
    %304 = llvm.extractelement %303[%29 : i32] : vector<1xf32> loc(#loc49)
    %305 = llvm.bitcast %293 : i32 to vector<1xf32> loc(#loc49)
    %306 = llvm.extractelement %305[%29 : i32] : vector<1xf32> loc(#loc49)
    %307 = llvm.bitcast %294 : i32 to vector<1xf32> loc(#loc49)
    %308 = llvm.extractelement %307[%29 : i32] : vector<1xf32> loc(#loc49)
    %309 = llvm.bitcast %295 : i32 to vector<1xf32> loc(#loc49)
    %310 = llvm.extractelement %309[%29 : i32] : vector<1xf32> loc(#loc49)
    %311 = llvm.bitcast %296 : i32 to vector<1xf32> loc(#loc49)
    %312 = llvm.extractelement %311[%29 : i32] : vector<1xf32> loc(#loc49)
    %313 = llvm.add %265, %237 : i32 loc(#loc46)
    %314 = llvm.add %313, %202 : i32 loc(#loc46)
    %315 = llvm.getelementptr %195[%314] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %316 = llvm.xor %121, %86 : i32 loc(#loc46)
    %317 = llvm.xor %316, %90 : i32 loc(#loc46)
    %318 = llvm.xor %317, %92 : i32 loc(#loc46)
    %319 = llvm.xor %318, %94 : i32 loc(#loc46)
    %320 = llvm.mul %319, %25 : i32 loc(#loc46)
    %321 = llvm.add %320, %29 : i32 loc(#loc46)
    %322 = llvm.mul %150, %27 : i32 loc(#loc46)
    %323 = llvm.add %321, %322 : i32 loc(#loc46)
    %324 = llvm.getelementptr inbounds %315[%323] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %325 = llvm.load %324 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %326 = llvm.extractelement %325[%29 : i32] : vector<1xf32> loc(#loc46)
    %327 = llvm.xor %30, %147 : i32 loc(#loc46)
    %328 = llvm.xor %327, %149 : i32 loc(#loc46)
    %329 = llvm.mul %328, %27 : i32 loc(#loc46)
    %330 = llvm.add %321, %329 : i32 loc(#loc46)
    %331 = llvm.getelementptr inbounds %315[%330] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %332 = llvm.load %331 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %333 = llvm.extractelement %332[%29 : i32] : vector<1xf32> loc(#loc46)
    %334 = llvm.xor %19, %147 : i32 loc(#loc46)
    %335 = llvm.xor %334, %149 : i32 loc(#loc46)
    %336 = llvm.mul %335, %27 : i32 loc(#loc46)
    %337 = llvm.add %321, %336 : i32 loc(#loc46)
    %338 = llvm.getelementptr inbounds %315[%337] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %339 = llvm.load %338 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %340 = llvm.extractelement %339[%29 : i32] : vector<1xf32> loc(#loc46)
    %341 = llvm.xor %8, %147 : i32 loc(#loc46)
    %342 = llvm.xor %341, %149 : i32 loc(#loc46)
    %343 = llvm.mul %342, %27 : i32 loc(#loc46)
    %344 = llvm.add %321, %343 : i32 loc(#loc46)
    %345 = llvm.getelementptr inbounds %315[%344] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %346 = llvm.load %345 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %347 = llvm.extractelement %346[%29 : i32] : vector<1xf32> loc(#loc46)
    %348 = llvm.xor %26, %118 : i32 loc(#loc46)
    %349 = llvm.xor %348, %120 : i32 loc(#loc46)
    %350 = llvm.xor %349, %86 : i32 loc(#loc46)
    %351 = llvm.xor %350, %90 : i32 loc(#loc46)
    %352 = llvm.xor %351, %92 : i32 loc(#loc46)
    %353 = llvm.xor %352, %94 : i32 loc(#loc46)
    %354 = llvm.mul %353, %25 : i32 loc(#loc46)
    %355 = llvm.add %354, %29 : i32 loc(#loc46)
    %356 = llvm.add %355, %322 : i32 loc(#loc46)
    %357 = llvm.getelementptr inbounds %315[%356] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %358 = llvm.load %357 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %359 = llvm.extractelement %358[%29 : i32] : vector<1xf32> loc(#loc46)
    %360 = llvm.add %355, %329 : i32 loc(#loc46)
    %361 = llvm.getelementptr inbounds %315[%360] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %362 = llvm.load %361 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %363 = llvm.extractelement %362[%29 : i32] : vector<1xf32> loc(#loc46)
    %364 = llvm.add %355, %336 : i32 loc(#loc46)
    %365 = llvm.getelementptr inbounds %315[%364] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %366 = llvm.load %365 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %367 = llvm.extractelement %366[%29 : i32] : vector<1xf32> loc(#loc46)
    %368 = llvm.add %355, %343 : i32 loc(#loc46)
    %369 = llvm.getelementptr inbounds %315[%368] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %370 = llvm.load %369 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %371 = llvm.extractelement %370[%29 : i32] : vector<1xf32> loc(#loc46)
    %372 = llvm.insertelement %298, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %373 = llvm.bitcast %372 : vector<1xf32> to i32 loc(#loc51)
    %374 = llvm.insertelement %300, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %375 = llvm.bitcast %374 : vector<1xf32> to i32 loc(#loc51)
    %376 = llvm.insertelement %302, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %377 = llvm.bitcast %376 : vector<1xf32> to i32 loc(#loc51)
    %378 = llvm.insertelement %304, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %379 = llvm.bitcast %378 : vector<1xf32> to i32 loc(#loc51)
    %380 = llvm.insertelement %306, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %381 = llvm.bitcast %380 : vector<1xf32> to i32 loc(#loc51)
    %382 = llvm.insertelement %308, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %383 = llvm.bitcast %382 : vector<1xf32> to i32 loc(#loc51)
    %384 = llvm.insertelement %310, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %385 = llvm.bitcast %384 : vector<1xf32> to i32 loc(#loc51)
    %386 = llvm.insertelement %312, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %387 = llvm.bitcast %386 : vector<1xf32> to i32 loc(#loc51)
    %388 = llvm.insertelement %326, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %389 = llvm.bitcast %388 : vector<1xf32> to i32 loc(#loc51)
    %390 = llvm.insertelement %333, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %391 = llvm.bitcast %390 : vector<1xf32> to i32 loc(#loc51)
    %392 = llvm.insertelement %340, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %393 = llvm.bitcast %392 : vector<1xf32> to i32 loc(#loc51)
    %394 = llvm.insertelement %347, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %395 = llvm.bitcast %394 : vector<1xf32> to i32 loc(#loc51)
    %396 = llvm.insertelement %359, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %397 = llvm.bitcast %396 : vector<1xf32> to i32 loc(#loc51)
    %398 = llvm.insertelement %363, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %399 = llvm.bitcast %398 : vector<1xf32> to i32 loc(#loc51)
    %400 = llvm.insertelement %367, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %401 = llvm.bitcast %400 : vector<1xf32> to i32 loc(#loc51)
    %402 = llvm.insertelement %371, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %403 = llvm.bitcast %402 : vector<1xf32> to i32 loc(#loc51)
    %404 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %405 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %406 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %407 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %408 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %409 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %410 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %411 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %412 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %404, %405, %406, %407, %373, %375, %377, %379, %389, %391 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %413 = llvm.extractvalue %412[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %414 = llvm.extractvalue %412[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %415 = llvm.extractvalue %412[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %416 = llvm.extractvalue %412[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %417 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %408, %409, %410, %411, %373, %375, %377, %379, %397, %399 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %418 = llvm.extractvalue %417[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %419 = llvm.extractvalue %417[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %420 = llvm.extractvalue %417[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %421 = llvm.extractvalue %417[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %422 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %413, %414, %415, %416, %381, %383, %385, %387, %393, %395 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %423 = llvm.extractvalue %422[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %424 = llvm.extractvalue %422[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %425 = llvm.extractvalue %422[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %426 = llvm.extractvalue %422[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %427 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %418, %419, %420, %421, %381, %383, %385, %387, %401, %403 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %428 = llvm.extractvalue %427[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %429 = llvm.extractvalue %427[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %430 = llvm.extractvalue %427[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %431 = llvm.extractvalue %427[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %432 = llvm.insertvalue %423, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %433 = llvm.insertvalue %424, %432[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %434 = llvm.insertvalue %425, %433[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %435 = llvm.insertvalue %426, %434[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %436 = llvm.insertvalue %428, %435[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %437 = llvm.insertvalue %429, %436[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %438 = llvm.insertvalue %430, %437[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %439 = llvm.insertvalue %431, %438[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %440 = llvm.extractvalue %254[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %441 = llvm.extractvalue %254[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %442 = llvm.extractvalue %254[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %443 = llvm.extractvalue %254[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %444 = llvm.getelementptr %440[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %445 = llvm.getelementptr %441[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %446 = llvm.getelementptr %442[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %447 = llvm.getelementptr %443[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %448 = llvm.insertvalue %444, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %449 = llvm.insertvalue %445, %448[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %450 = llvm.insertvalue %446, %449[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %451 = llvm.insertvalue %447, %450[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %452 = llvm.extractvalue %255[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %453 = llvm.extractvalue %255[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %454 = llvm.extractvalue %255[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %455 = llvm.extractvalue %255[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %456 = llvm.getelementptr %452[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %457 = llvm.getelementptr %453[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %458 = llvm.getelementptr %454[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %459 = llvm.getelementptr %455[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %460 = llvm.insertvalue %456, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %461 = llvm.insertvalue %457, %460[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %462 = llvm.insertvalue %458, %461[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %463 = llvm.insertvalue %459, %462[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %464 = llvm.add %256, %25 : i32 loc(#loc47)
    %465 = llvm.icmp "slt" %464, %25 : i32 loc(#loc47)
    %466 = llvm.select %465, %464, %29 : i1, i32 loc(#loc47)
    %467 = llvm.add %252, %25 : i32 loc(#loc47)
    %468 = llvm.mul %467, %26 : i32 loc(#loc54)
    %469 = llvm.sub %arg5, %468 : i32 loc(#loc55)
    %470 = llvm.icmp "slt" %156, %469 : i32 loc(#loc48)
    %471 = llvm.mul %466, %11 : i32 loc(#loc49)
    %472 = llvm.add %471, %29 : i32 loc(#loc49)
    %473 = llvm.add %472, %200 : i32 loc(#loc49)
    %474 = llvm.add %473, %202 : i32 loc(#loc49)
    %475 = llvm.getelementptr %12[%474] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %476 = llvm.and %260, %470 : i1 loc(#loc47)
    nvvm.barrier0 loc(#loc49)
    %477 = llvm.getelementptr inbounds %475[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %478 = llvm.getelementptr inbounds %475[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %479 = llvm.getelementptr inbounds %475[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %480 = llvm.getelementptr inbounds %475[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %481 = llvm.select %476, %30, %29 : i1, i32 loc(#loc49)
    %482 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %477, %444, %481 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %483 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %478, %445, %481 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %484 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %479, %446, %481 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %485 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %480, %447, %481 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %486 = llvm.icmp "slt" %178, %469 : i32 loc(#loc50)
    %487 = llvm.add %472, %237 : i32 loc(#loc46)
    %488 = llvm.add %487, %202 : i32 loc(#loc46)
    %489 = llvm.getelementptr %195[%488] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %490 = llvm.and %260, %486 : i1 loc(#loc47)
    %491 = llvm.getelementptr inbounds %489[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %492 = llvm.select %490, %26, %29 : i1, i32 loc(#loc46)
    %493 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %491, %456, %492 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%467, %439, %451, %463, %466, %263 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb3:  // pred: ^bb1
    nvvm.cp.async.wait.group 0 loc(#loc47)
    nvvm.barrier0 loc(#loc47)
    %494 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %495 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %496 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %497 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %498 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %499 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %500 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %501 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %502 = llvm.fptrunc %494 : f32 to f16 loc(#loc56)
    %503 = llvm.fptrunc %495 : f32 to f16 loc(#loc56)
    %504 = llvm.fptrunc %496 : f32 to f16 loc(#loc56)
    %505 = llvm.fptrunc %497 : f32 to f16 loc(#loc56)
    %506 = llvm.fptrunc %498 : f32 to f16 loc(#loc56)
    %507 = llvm.fptrunc %499 : f32 to f16 loc(#loc56)
    %508 = llvm.fptrunc %500 : f32 to f16 loc(#loc56)
    %509 = llvm.fptrunc %501 : f32 to f16 loc(#loc56)
    %510 = llvm.mul %arg8, %128 : i32 loc(#loc57)
    %511 = llvm.getelementptr %arg2[%510] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc58)
    %512 = llvm.getelementptr %511[%138] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc59)
    %513 = llvm.icmp "slt" %128, %arg3 : i32 loc(#loc60)
    %514 = llvm.icmp "slt" %138, %arg4 : i32 loc(#loc61)
    %515 = llvm.and %513, %514 : i1 loc(#loc62)
    %516 = llvm.select %101, %29, %20 : i1, i32 loc(#loc63)
    %517 = llvm.xor %29, %516 : i32 loc(#loc63)
    %518 = llvm.select %105, %29, %30 : i1, i32 loc(#loc63)
    %519 = llvm.xor %517, %518 : i32 loc(#loc63)
    %520 = llvm.select %85, %29, %27 : i1, i32 loc(#loc63)
    %521 = llvm.xor %519, %520 : i32 loc(#loc63)
    %522 = llvm.select %89, %29, %5 : i1, i32 loc(#loc63)
    %523 = llvm.xor %521, %522 : i32 loc(#loc63)
    %524 = llvm.select %65, %29, %10 : i1, i32 loc(#loc63)
    %525 = llvm.xor %523, %524 : i32 loc(#loc63)
    %526 = llvm.xor %525, %94 : i32 loc(#loc63)
    %527 = llvm.select %73, %29, %11 : i1, i32 loc(#loc63)
    %528 = llvm.xor %526, %527 : i32 loc(#loc63)
    %529 = llvm.xor %121, %520 : i32 loc(#loc63)
    %530 = llvm.xor %529, %522 : i32 loc(#loc63)
    %531 = llvm.xor %530, %524 : i32 loc(#loc63)
    %532 = llvm.select %69, %29, %9 : i1, i32 loc(#loc63)
    %533 = llvm.xor %531, %532 : i32 loc(#loc63)
    %534 = llvm.xor %533, %527 : i32 loc(#loc63)
    %535 = llvm.xor %528, %29 : i32 loc(#loc63)
    %536 = llvm.lshr %535, %16 : i32 loc(#loc63)
    %537 = llvm.shl %536, %17 : i32 loc(#loc63)
    %538 = llvm.add %537, %535 : i32 loc(#loc63)
    %539 = llvm.getelementptr inbounds %12[%538] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %540 = llvm.insertelement %502, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %541 = llvm.insertelement %503, %540[%25 : i32] : vector<2xf16> loc(#loc63)
    %542 = llvm.extractelement %541[%29 : i32] : vector<2xf16> loc(#loc63)
    %543 = llvm.extractelement %541[%25 : i32] : vector<2xf16> loc(#loc63)
    %544 = llvm.bitcast %542 : f16 to i16 loc(#loc63)
    %545 = llvm.bitcast %543 : f16 to i16 loc(#loc63)
    %546 = llvm.insertelement %544, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %547 = llvm.insertelement %545, %546[%25 : i32] : vector<2xi16> loc(#loc63)
    %548 = llvm.extractelement %547[%29 : i32] : vector<2xi16> loc(#loc63)
    %549 = llvm.extractelement %547[%25 : i32] : vector<2xi16> loc(#loc63)
    %550 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %539, %548, %549, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %551 = llvm.xor %528, %9 : i32 loc(#loc63)
    %552 = llvm.lshr %551, %16 : i32 loc(#loc63)
    %553 = llvm.shl %552, %17 : i32 loc(#loc63)
    %554 = llvm.add %553, %551 : i32 loc(#loc63)
    %555 = llvm.getelementptr inbounds %12[%554] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %556 = llvm.insertelement %504, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %557 = llvm.insertelement %505, %556[%25 : i32] : vector<2xf16> loc(#loc63)
    %558 = llvm.extractelement %557[%29 : i32] : vector<2xf16> loc(#loc63)
    %559 = llvm.extractelement %557[%25 : i32] : vector<2xf16> loc(#loc63)
    %560 = llvm.bitcast %558 : f16 to i16 loc(#loc63)
    %561 = llvm.bitcast %559 : f16 to i16 loc(#loc63)
    %562 = llvm.insertelement %560, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %563 = llvm.insertelement %561, %562[%25 : i32] : vector<2xi16> loc(#loc63)
    %564 = llvm.extractelement %563[%29 : i32] : vector<2xi16> loc(#loc63)
    %565 = llvm.extractelement %563[%25 : i32] : vector<2xi16> loc(#loc63)
    %566 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %555, %564, %565, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %567 = llvm.xor %528, %26 : i32 loc(#loc63)
    %568 = llvm.lshr %567, %16 : i32 loc(#loc63)
    %569 = llvm.shl %568, %17 : i32 loc(#loc63)
    %570 = llvm.add %569, %567 : i32 loc(#loc63)
    %571 = llvm.getelementptr inbounds %12[%570] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %572 = llvm.insertelement %506, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %573 = llvm.insertelement %507, %572[%25 : i32] : vector<2xf16> loc(#loc63)
    %574 = llvm.extractelement %573[%29 : i32] : vector<2xf16> loc(#loc63)
    %575 = llvm.extractelement %573[%25 : i32] : vector<2xf16> loc(#loc63)
    %576 = llvm.bitcast %574 : f16 to i16 loc(#loc63)
    %577 = llvm.bitcast %575 : f16 to i16 loc(#loc63)
    %578 = llvm.insertelement %576, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %579 = llvm.insertelement %577, %578[%25 : i32] : vector<2xi16> loc(#loc63)
    %580 = llvm.extractelement %579[%29 : i32] : vector<2xi16> loc(#loc63)
    %581 = llvm.extractelement %579[%25 : i32] : vector<2xi16> loc(#loc63)
    %582 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %571, %580, %581, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %583 = llvm.xor %528, %7 : i32 loc(#loc63)
    %584 = llvm.lshr %583, %16 : i32 loc(#loc63)
    %585 = llvm.shl %584, %17 : i32 loc(#loc63)
    %586 = llvm.add %585, %583 : i32 loc(#loc63)
    %587 = llvm.getelementptr inbounds %12[%586] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %588 = llvm.insertelement %508, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %589 = llvm.insertelement %509, %588[%25 : i32] : vector<2xf16> loc(#loc63)
    %590 = llvm.extractelement %589[%29 : i32] : vector<2xf16> loc(#loc63)
    %591 = llvm.extractelement %589[%25 : i32] : vector<2xf16> loc(#loc63)
    %592 = llvm.bitcast %590 : f16 to i16 loc(#loc63)
    %593 = llvm.bitcast %591 : f16 to i16 loc(#loc63)
    %594 = llvm.insertelement %592, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %595 = llvm.insertelement %593, %594[%25 : i32] : vector<2xi16> loc(#loc63)
    %596 = llvm.extractelement %595[%29 : i32] : vector<2xi16> loc(#loc63)
    %597 = llvm.extractelement %595[%25 : i32] : vector<2xi16> loc(#loc63)
    %598 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %587, %596, %597, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    nvvm.barrier0 loc(#loc63)
    %599 = llvm.xor %534, %29 : i32 loc(#loc63)
    %600 = llvm.lshr %599, %16 : i32 loc(#loc63)
    %601 = llvm.shl %600, %17 : i32 loc(#loc63)
    %602 = llvm.add %601, %599 : i32 loc(#loc63)
    %603 = llvm.getelementptr inbounds %12[%602] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %604 = llvm.load %603 : !llvm.ptr<3> -> vector<4xi32> loc(#loc63)
    %605 = llvm.extractelement %604[%29 : i32] : vector<4xi32> loc(#loc63)
    %606 = llvm.extractelement %604[%25 : i32] : vector<4xi32> loc(#loc63)
    %607 = llvm.extractelement %604[%20 : i32] : vector<4xi32> loc(#loc63)
    %608 = llvm.extractelement %604[%17 : i32] : vector<4xi32> loc(#loc63)
    %609 = llvm.insertelement %605, %2[%29 : i32] : vector<4xi32> loc(#loc63)
    %610 = llvm.insertelement %606, %609[%25 : i32] : vector<4xi32> loc(#loc63)
    %611 = llvm.insertelement %607, %610[%20 : i32] : vector<4xi32> loc(#loc63)
    %612 = llvm.insertelement %608, %611[%17 : i32] : vector<4xi32> loc(#loc63)
    %613 = llvm.extractelement %612[%29 : i32] : vector<4xi32> loc(#loc63)
    %614 = llvm.extractelement %612[%25 : i32] : vector<4xi32> loc(#loc63)
    %615 = llvm.extractelement %612[%20 : i32] : vector<4xi32> loc(#loc63)
    %616 = llvm.extractelement %612[%17 : i32] : vector<4xi32> loc(#loc63)
    %617 = llvm.bitcast %613 : i32 to vector<2xi16> loc(#loc63)
    %618 = llvm.extractelement %617[%29 : i32] : vector<2xi16> loc(#loc63)
    %619 = llvm.extractelement %617[%25 : i32] : vector<2xi16> loc(#loc63)
    %620 = llvm.bitcast %614 : i32 to vector<2xi16> loc(#loc63)
    %621 = llvm.extractelement %620[%29 : i32] : vector<2xi16> loc(#loc63)
    %622 = llvm.extractelement %620[%25 : i32] : vector<2xi16> loc(#loc63)
    %623 = llvm.bitcast %615 : i32 to vector<2xi16> loc(#loc63)
    %624 = llvm.extractelement %623[%29 : i32] : vector<2xi16> loc(#loc63)
    %625 = llvm.extractelement %623[%25 : i32] : vector<2xi16> loc(#loc63)
    %626 = llvm.bitcast %616 : i32 to vector<2xi16> loc(#loc63)
    %627 = llvm.extractelement %626[%29 : i32] : vector<2xi16> loc(#loc63)
    %628 = llvm.extractelement %626[%25 : i32] : vector<2xi16> loc(#loc63)
    %629 = llvm.insertelement %618, %1[%29 : i32] : vector<8xi16> loc(#loc63)
    %630 = llvm.insertelement %619, %629[%25 : i32] : vector<8xi16> loc(#loc63)
    %631 = llvm.insertelement %621, %630[%20 : i32] : vector<8xi16> loc(#loc63)
    %632 = llvm.insertelement %622, %631[%17 : i32] : vector<8xi16> loc(#loc63)
    %633 = llvm.insertelement %624, %632[%30 : i32] : vector<8xi16> loc(#loc63)
    %634 = llvm.insertelement %625, %633[%16 : i32] : vector<8xi16> loc(#loc63)
    %635 = llvm.insertelement %627, %634[%15 : i32] : vector<8xi16> loc(#loc63)
    %636 = llvm.insertelement %628, %635[%14 : i32] : vector<8xi16> loc(#loc63)
    %637 = llvm.extractelement %636[%29 : i32] : vector<8xi16> loc(#loc63)
    %638 = llvm.extractelement %636[%25 : i32] : vector<8xi16> loc(#loc63)
    %639 = llvm.extractelement %636[%20 : i32] : vector<8xi16> loc(#loc63)
    %640 = llvm.extractelement %636[%17 : i32] : vector<8xi16> loc(#loc63)
    %641 = llvm.extractelement %636[%30 : i32] : vector<8xi16> loc(#loc63)
    %642 = llvm.extractelement %636[%16 : i32] : vector<8xi16> loc(#loc63)
    %643 = llvm.extractelement %636[%15 : i32] : vector<8xi16> loc(#loc63)
    %644 = llvm.extractelement %636[%14 : i32] : vector<8xi16> loc(#loc63)
    %645 = llvm.bitcast %637 : i16 to f16 loc(#loc63)
    %646 = llvm.bitcast %638 : i16 to f16 loc(#loc63)
    %647 = llvm.bitcast %639 : i16 to f16 loc(#loc63)
    %648 = llvm.bitcast %640 : i16 to f16 loc(#loc63)
    %649 = llvm.bitcast %641 : i16 to f16 loc(#loc63)
    %650 = llvm.bitcast %642 : i16 to f16 loc(#loc63)
    %651 = llvm.bitcast %643 : i16 to f16 loc(#loc63)
    %652 = llvm.bitcast %644 : i16 to f16 loc(#loc63)
    %653 = llvm.insertelement %645, %0[%29 : i32] : vector<8xf16> loc(#loc63)
    %654 = llvm.insertelement %646, %653[%25 : i32] : vector<8xf16> loc(#loc63)
    %655 = llvm.insertelement %647, %654[%20 : i32] : vector<8xf16> loc(#loc63)
    %656 = llvm.insertelement %648, %655[%17 : i32] : vector<8xf16> loc(#loc63)
    %657 = llvm.insertelement %649, %656[%30 : i32] : vector<8xf16> loc(#loc63)
    %658 = llvm.insertelement %650, %657[%16 : i32] : vector<8xf16> loc(#loc63)
    %659 = llvm.insertelement %651, %658[%15 : i32] : vector<8xf16> loc(#loc63)
    %660 = llvm.insertelement %652, %659[%14 : i32] : vector<8xf16> loc(#loc63)
    %661 = llvm.extractelement %660[%29 : i32] : vector<8xf16> loc(#loc63)
    %662 = llvm.extractelement %660[%25 : i32] : vector<8xf16> loc(#loc63)
    %663 = llvm.extractelement %660[%20 : i32] : vector<8xf16> loc(#loc63)
    %664 = llvm.extractelement %660[%17 : i32] : vector<8xf16> loc(#loc63)
    %665 = llvm.extractelement %660[%30 : i32] : vector<8xf16> loc(#loc63)
    %666 = llvm.extractelement %660[%16 : i32] : vector<8xf16> loc(#loc63)
    %667 = llvm.extractelement %660[%15 : i32] : vector<8xf16> loc(#loc63)
    %668 = llvm.extractelement %660[%14 : i32] : vector<8xf16> loc(#loc63)
    %669 = llvm.insertelement %661, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %670 = llvm.insertelement %662, %669[%25 : i32] : vector<2xf16> loc(#loc63)
    %671 = llvm.bitcast %670 : vector<2xf16> to i32 loc(#loc63)
    %672 = llvm.insertelement %663, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %673 = llvm.insertelement %664, %672[%25 : i32] : vector<2xf16> loc(#loc63)
    %674 = llvm.bitcast %673 : vector<2xf16> to i32 loc(#loc63)
    %675 = llvm.insertelement %665, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %676 = llvm.insertelement %666, %675[%25 : i32] : vector<2xf16> loc(#loc63)
    %677 = llvm.bitcast %676 : vector<2xf16> to i32 loc(#loc63)
    %678 = llvm.insertelement %667, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %679 = llvm.insertelement %668, %678[%25 : i32] : vector<2xf16> loc(#loc63)
    %680 = llvm.bitcast %679 : vector<2xf16> to i32 loc(#loc63)
    %681 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$5 st.global.v4.b32 [ $4 + 0 ], { $0, $1, $2, $3 };", "r,r,r,r,l,b" %671, %674, %677, %680, %512, %515 : (i32, i32, i32, i32, !llvm.ptr<1>, i1) -> !llvm.void loc(#loc63)
    llvm.return loc(#loc64)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:41)
#loc37 = loc("examples/kernels/binary_ops.py":159:60)
#loc38 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":160:29)
#loc41 = loc("examples/kernels/binary_ops.py":160:40)
#loc42 = loc("examples/kernels/binary_ops.py":160:52)
#loc44 = loc("examples/kernels/binary_ops.py":168:33)
#loc45 = loc("examples/kernels/binary_ops.py":177:33)
#loc46 = loc("examples/kernels/binary_ops.py":172:20)
#loc48 = loc("examples/kernels/binary_ops.py":171:51)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:51)
#loc51 = loc("examples/kernels/binary_ops.py":174:35)
#loc52 = loc("examples/kernels/binary_ops.py":176:18)
#loc53 = loc("examples/kernels/binary_ops.py":177:18)
#loc54 = loc("examples/kernels/binary_ops.py":171:59)
#loc55 = loc("examples/kernels/binary_ops.py":171:55)
#loc56 = loc("examples/kernels/binary_ops.py":182:23)
#loc57 = loc("examples/kernels/binary_ops.py":188:33)
#loc58 = loc("examples/kernels/binary_ops.py":188:21)
#loc59 = loc("examples/kernels/binary_ops.py":188:52)
#loc60 = loc("examples/kernels/binary_ops.py":189:33)
#loc61 = loc("examples/kernels/binary_ops.py":189:58)
#loc62 = loc("examples/kernels/binary_ops.py":189:39)
#loc63 = loc("examples/kernels/binary_ops.py":190:21)
#loc64 = loc("examples/kernels/binary_ops.py":190:4)
#loc65 = loc(callsite(#loc3 at #loc4))
#loc66 = loc(callsite(#loc5 at #loc4))
#loc67 = loc(callsite(#loc3 at #loc6))
#loc68 = loc(callsite(#loc5 at #loc6))
#loc69 = loc(callsite(#loc3 at #loc44))
#loc70 = loc(callsite(#loc5 at #loc44))


// -----// IR Dump Before ConvertWarpSpecializeToLLVM (convert-warp-specialize-to-llvm) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc39 = loc("examples/kernels/binary_ops.py":159:22)
#loc43 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
module attributes {ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @matmul_kernel(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg9: !llvm.ptr<1> loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.undef : vector<8xf16> loc(#loc1)
    %1 = llvm.mlir.undef : vector<8xi16> loc(#loc1)
    %2 = llvm.mlir.undef : vector<4xi32> loc(#loc1)
    %3 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %4 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %5 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.undef : vector<1xf32> loc(#loc1)
    %7 = llvm.mlir.constant(272 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.constant(256 : i32) : i32 loc(#loc1)
    %10 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(512 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %13 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc1)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(6 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %22 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc1)
    %23 = llvm.mlir.constant(15 : i32) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(31 : i32) : i32 loc(#loc1)
    %25 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %26 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %27 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %28 = llvm.mlir.constant(true) : i1 loc(#loc1)
    %29 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %30 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %31 = llvm.mlir.constant(-1 : i32) : i32 loc(#loc1)
    %32 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %33 = llvm.insertvalue %32, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %34 = llvm.insertvalue %32, %33[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %35 = llvm.insertvalue %32, %34[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %36 = llvm.insertvalue %32, %35[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %37 = llvm.insertvalue %32, %36[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %38 = llvm.insertvalue %32, %37[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %39 = llvm.insertvalue %32, %38[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %40 = llvm.insertvalue %32, %39[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %41 = llvm.call_intrinsic "llvm.nvvm.read.ptx.sreg.ctaid.x"() : () -> i32 loc(#loc2)
    %42 = llvm.add %arg3, %24 : i32 loc(#loc65)
    %43 = llvm.sdiv %42, %27 : i32 loc(#loc66)
    %44 = llvm.add %arg4, %24 : i32 loc(#loc67)
    %45 = llvm.sdiv %44, %27 : i32 loc(#loc68)
    %46 = llvm.mul %45, %30 : i32 loc(#loc7)
    %47 = llvm.sdiv %41, %46 : i32 loc(#loc8)
    %48 = llvm.mul %47, %30 : i32 loc(#loc9)
    %49 = llvm.sub %43, %48 : i32 loc(#loc10)
    %50 = llvm.intr.smin(%49, %30) : (i32, i32) -> i32 loc(#loc11)
    %51 = llvm.srem %41, %46 : i32 loc(#loc12)
    %52 = llvm.srem %51, %50 : i32 loc(#loc13)
    %53 = llvm.add %48, %52 : i32 loc(#loc14)
    %54 = llvm.sdiv %51, %50 : i32 loc(#loc15)
    %55 = llvm.icmp "sge" %53, %29 : i32 loc(#loc16)
    llvm.intr.assume %55 : i1 loc(#loc17)
    %56 = llvm.icmp "sge" %54, %29 : i32 loc(#loc18)
    llvm.intr.assume %56 : i1 loc(#loc19)
    %57 = llvm.icmp "sgt" %arg6, %29 : i32 loc(#loc20)
    llvm.intr.assume %57 : i1 loc(#loc21)
    llvm.intr.assume %28 : i1 loc(#loc22)
    llvm.intr.assume %28 : i1 loc(#loc23)
    %58 = llvm.icmp "sgt" %arg7, %29 : i32 loc(#loc24)
    llvm.intr.assume %58 : i1 loc(#loc25)
    %59 = llvm.icmp "sgt" %arg8, %29 : i32 loc(#loc26)
    llvm.intr.assume %59 : i1 loc(#loc27)
    llvm.intr.assume %28 : i1 loc(#loc28)
    %60 = llvm.mul %53, %27 : i32 loc(#loc29)
    %61 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc30)
    %62 = llvm.urem %61, %27 : i32 loc(#loc30)
    %63 = llvm.udiv %61, %27 : i32 loc(#loc30)
    %64 = llvm.and %62, %26 : i32 loc(#loc30)
    %65 = llvm.icmp "eq" %64, %29 : i32 loc(#loc30)
    %66 = llvm.select %65, %29, %25 : i1, i32 loc(#loc30)
    %67 = llvm.xor %29, %66 : i32 loc(#loc30)
    %68 = llvm.and %63, %25 : i32 loc(#loc30)
    %69 = llvm.icmp "eq" %68, %29 : i32 loc(#loc30)
    %70 = llvm.select %69, %29, %20 : i1, i32 loc(#loc30)
    %71 = llvm.xor %67, %70 : i32 loc(#loc30)
    %72 = llvm.and %63, %20 : i32 loc(#loc30)
    %73 = llvm.icmp "eq" %72, %29 : i32 loc(#loc30)
    %74 = llvm.select %73, %29, %30 : i1, i32 loc(#loc30)
    %75 = llvm.xor %71, %74 : i32 loc(#loc30)
    %76 = llvm.xor %75, %29 : i32 loc(#loc30)
    %77 = llvm.xor %75, %19 : i32 loc(#loc30)
    %78 = llvm.xor %75, %26 : i32 loc(#loc30)
    %79 = llvm.xor %75, %18 : i32 loc(#loc30)
    %80 = llvm.add %76, %21 : i32 loc(#loc30)
    %81 = llvm.add %77, %21 : i32 loc(#loc30)
    %82 = llvm.add %78, %21 : i32 loc(#loc30)
    %83 = llvm.add %79, %21 : i32 loc(#loc30)
    %84 = llvm.and %62, %30 : i32 loc(#loc30)
    %85 = llvm.icmp "eq" %84, %29 : i32 loc(#loc30)
    %86 = llvm.select %85, %29, %25 : i1, i32 loc(#loc30)
    %87 = llvm.xor %29, %86 : i32 loc(#loc30)
    %88 = llvm.and %62, %19 : i32 loc(#loc30)
    %89 = llvm.icmp "eq" %88, %29 : i32 loc(#loc30)
    %90 = llvm.select %89, %29, %20 : i1, i32 loc(#loc30)
    %91 = llvm.xor %87, %90 : i32 loc(#loc30)
    %92 = llvm.select %65, %29, %30 : i1, i32 loc(#loc30)
    %93 = llvm.xor %91, %92 : i32 loc(#loc30)
    %94 = llvm.select %69, %29, %19 : i1, i32 loc(#loc30)
    %95 = llvm.xor %93, %94 : i32 loc(#loc30)
    %96 = llvm.select %73, %29, %26 : i1, i32 loc(#loc30)
    %97 = llvm.xor %95, %96 : i32 loc(#loc30)
    %98 = llvm.xor %97, %29 : i32 loc(#loc30)
    %99 = llvm.add %98, %21 : i32 loc(#loc30)
    %100 = llvm.and %62, %25 : i32 loc(#loc30)
    %101 = llvm.icmp "eq" %100, %29 : i32 loc(#loc30)
    %102 = llvm.select %101, %29, %30 : i1, i32 loc(#loc30)
    %103 = llvm.xor %29, %102 : i32 loc(#loc30)
    %104 = llvm.and %62, %20 : i32 loc(#loc30)
    %105 = llvm.icmp "eq" %104, %29 : i32 loc(#loc30)
    %106 = llvm.select %105, %29, %19 : i1, i32 loc(#loc30)
    %107 = llvm.xor %103, %106 : i32 loc(#loc30)
    %108 = llvm.select %85, %29, %26 : i1, i32 loc(#loc30)
    %109 = llvm.xor %107, %108 : i32 loc(#loc30)
    %110 = llvm.xor %109, %29 : i32 loc(#loc30)
    %111 = llvm.xor %109, %25 : i32 loc(#loc30)
    %112 = llvm.xor %109, %20 : i32 loc(#loc30)
    %113 = llvm.xor %109, %17 : i32 loc(#loc30)
    %114 = llvm.add %110, %21 : i32 loc(#loc30)
    %115 = llvm.add %111, %21 : i32 loc(#loc30)
    %116 = llvm.add %112, %21 : i32 loc(#loc30)
    %117 = llvm.add %113, %21 : i32 loc(#loc30)
    %118 = llvm.select %101, %29, %19 : i1, i32 loc(#loc30)
    %119 = llvm.xor %29, %118 : i32 loc(#loc30)
    %120 = llvm.select %105, %29, %26 : i1, i32 loc(#loc30)
    %121 = llvm.xor %119, %120 : i32 loc(#loc30)
    %122 = llvm.xor %121, %29 : i32 loc(#loc30)
    %123 = llvm.add %122, %21 : i32 loc(#loc30)
    %124 = llvm.add %60, %80 : i32 loc(#loc31)
    %125 = llvm.add %60, %81 : i32 loc(#loc31)
    %126 = llvm.add %60, %82 : i32 loc(#loc31)
    %127 = llvm.add %60, %83 : i32 loc(#loc31)
    %128 = llvm.add %60, %99 : i32 loc(#loc31)
    %129 = llvm.srem %124, %arg3 : i32 loc(#loc32)
    %130 = llvm.srem %125, %arg3 : i32 loc(#loc32)
    %131 = llvm.srem %126, %arg3 : i32 loc(#loc32)
    %132 = llvm.srem %127, %arg3 : i32 loc(#loc32)
    %133 = llvm.mul %54, %27 : i32 loc(#loc33)
    %134 = llvm.add %133, %114 : i32 loc(#loc34)
    %135 = llvm.add %133, %115 : i32 loc(#loc34)
    %136 = llvm.add %133, %116 : i32 loc(#loc34)
    %137 = llvm.add %133, %117 : i32 loc(#loc34)
    %138 = llvm.add %133, %123 : i32 loc(#loc34)
    %139 = llvm.srem %134, %arg4 : i32 loc(#loc35)
    %140 = llvm.srem %135, %arg4 : i32 loc(#loc35)
    %141 = llvm.srem %136, %arg4 : i32 loc(#loc35)
    %142 = llvm.srem %137, %arg4 : i32 loc(#loc35)
    %143 = llvm.mul %129, %arg6 : i32 loc(#loc36)
    %144 = llvm.mul %130, %arg6 : i32 loc(#loc36)
    %145 = llvm.mul %131, %arg6 : i32 loc(#loc36)
    %146 = llvm.mul %132, %arg6 : i32 loc(#loc36)
    %147 = llvm.select %101, %29, %25 : i1, i32 loc(#loc37)
    %148 = llvm.xor %29, %147 : i32 loc(#loc37)
    %149 = llvm.select %105, %29, %20 : i1, i32 loc(#loc37)
    %150 = llvm.xor %148, %149 : i32 loc(#loc37)
    %151 = llvm.select %85, %29, %30 : i1, i32 loc(#loc37)
    %152 = llvm.xor %150, %151 : i32 loc(#loc37)
    %153 = llvm.select %89, %29, %19 : i1, i32 loc(#loc37)
    %154 = llvm.xor %152, %153 : i32 loc(#loc37)
    %155 = llvm.xor %154, %29 : i32 loc(#loc37)
    %156 = llvm.add %155, %21 : i32 loc(#loc37)
    %157 = llvm.add %143, %156 : i32 loc(#loc38)
    %158 = llvm.add %144, %156 : i32 loc(#loc38)
    %159 = llvm.add %145, %156 : i32 loc(#loc38)
    %160 = llvm.add %146, %156 : i32 loc(#loc38)
    %161 = llvm.getelementptr %arg0[%157] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %162 = llvm.getelementptr %arg0[%158] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %163 = llvm.getelementptr %arg0[%159] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %164 = llvm.getelementptr %arg0[%160] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %165 = llvm.insertvalue %161, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %166 = llvm.insertvalue %162, %165[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %167 = llvm.insertvalue %163, %166[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %168 = llvm.insertvalue %164, %167[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %169 = llvm.select %89, %29, %25 : i1, i32 loc(#loc40)
    %170 = llvm.xor %29, %169 : i32 loc(#loc40)
    %171 = llvm.select %65, %29, %20 : i1, i32 loc(#loc40)
    %172 = llvm.xor %170, %171 : i32 loc(#loc40)
    %173 = llvm.select %69, %29, %30 : i1, i32 loc(#loc40)
    %174 = llvm.xor %172, %173 : i32 loc(#loc40)
    %175 = llvm.select %73, %29, %19 : i1, i32 loc(#loc40)
    %176 = llvm.xor %174, %175 : i32 loc(#loc40)
    %177 = llvm.xor %176, %29 : i32 loc(#loc40)
    %178 = llvm.add %177, %21 : i32 loc(#loc40)
    %179 = llvm.mul %178, %arg7 : i32 loc(#loc41)
    %180 = llvm.add %179, %139 : i32 loc(#loc42)
    %181 = llvm.add %179, %140 : i32 loc(#loc42)
    %182 = llvm.add %179, %141 : i32 loc(#loc42)
    %183 = llvm.add %179, %142 : i32 loc(#loc42)
    %184 = llvm.getelementptr %arg1[%180] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %185 = llvm.getelementptr %arg1[%181] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %186 = llvm.getelementptr %arg1[%182] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %187 = llvm.getelementptr %arg1[%183] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %188 = llvm.insertvalue %184, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %189 = llvm.insertvalue %185, %188[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %190 = llvm.insertvalue %186, %189[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %191 = llvm.insertvalue %187, %190[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %192 = llvm.add %arg5, %23 : i32 loc(#loc69)
    %193 = llvm.sdiv %192, %26 : i32 loc(#loc70)
    %194 = llvm.mul %arg7, %26 : i32 loc(#loc45)
    %195 = llvm.getelementptr %12[2048] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc46)
    %196 = llvm.icmp "sgt" %193, %29 : i32 loc(#loc47)
    %197 = llvm.icmp "slt" %156, %arg5 : i32 loc(#loc48)
    %198 = llvm.mul %29, %11 : i32 loc(#loc49)
    %199 = llvm.add %198, %29 : i32 loc(#loc49)
    %200 = llvm.mul %29, %26 : i32 loc(#loc49)
    %201 = llvm.add %199, %200 : i32 loc(#loc49)
    %202 = llvm.mul %29, %25 : i32 loc(#loc49)
    %203 = llvm.add %201, %202 : i32 loc(#loc49)
    %204 = llvm.getelementptr %12[%203] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %205 = llvm.and %196, %197 : i1 loc(#loc47)
    %206 = llvm.xor %154, %173 : i32 loc(#loc49)
    %207 = llvm.xor %206, %175 : i32 loc(#loc49)
    %208 = llvm.mul %207, %25 : i32 loc(#loc49)
    %209 = llvm.add %208, %29 : i32 loc(#loc49)
    %210 = llvm.mul %75, %26 : i32 loc(#loc49)
    %211 = llvm.add %209, %210 : i32 loc(#loc49)
    %212 = llvm.getelementptr inbounds %204[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %213 = llvm.xor %19, %66 : i32 loc(#loc49)
    %214 = llvm.xor %213, %70 : i32 loc(#loc49)
    %215 = llvm.xor %214, %74 : i32 loc(#loc49)
    %216 = llvm.mul %215, %26 : i32 loc(#loc49)
    %217 = llvm.add %209, %216 : i32 loc(#loc49)
    %218 = llvm.getelementptr inbounds %204[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %219 = llvm.xor %26, %66 : i32 loc(#loc49)
    %220 = llvm.xor %219, %70 : i32 loc(#loc49)
    %221 = llvm.xor %220, %74 : i32 loc(#loc49)
    %222 = llvm.mul %221, %26 : i32 loc(#loc49)
    %223 = llvm.add %209, %222 : i32 loc(#loc49)
    %224 = llvm.getelementptr inbounds %204[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %225 = llvm.xor %18, %66 : i32 loc(#loc49)
    %226 = llvm.xor %225, %70 : i32 loc(#loc49)
    %227 = llvm.xor %226, %74 : i32 loc(#loc49)
    %228 = llvm.mul %227, %26 : i32 loc(#loc49)
    %229 = llvm.add %209, %228 : i32 loc(#loc49)
    %230 = llvm.getelementptr inbounds %204[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %231 = llvm.select %205, %30, %29 : i1, i32 loc(#loc49)
    %232 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %212, %161, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %233 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %218, %162, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %234 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %224, %163, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %235 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %230, %164, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %236 = llvm.icmp "slt" %178, %arg5 : i32 loc(#loc50)
    %237 = llvm.mul %29, %27 : i32 loc(#loc46)
    %238 = llvm.add %199, %237 : i32 loc(#loc46)
    %239 = llvm.add %238, %202 : i32 loc(#loc46)
    %240 = llvm.getelementptr %195[%239] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %241 = llvm.and %196, %236 : i1 loc(#loc47)
    %242 = llvm.xor %109, %153 : i32 loc(#loc46)
    %243 = llvm.select %65, %29, %26 : i1, i32 loc(#loc46)
    %244 = llvm.xor %242, %243 : i32 loc(#loc46)
    %245 = llvm.mul %244, %25 : i32 loc(#loc46)
    %246 = llvm.add %245, %29 : i32 loc(#loc46)
    %247 = llvm.mul %176, %27 : i32 loc(#loc46)
    %248 = llvm.add %246, %247 : i32 loc(#loc46)
    %249 = llvm.getelementptr inbounds %240[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %250 = llvm.select %241, %26, %29 : i1, i32 loc(#loc46)
    %251 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %249, %184, %250 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%29, %40, %168, %191, %29, %31 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb1(%252: i32 loc("examples/kernels/binary_ops.py":168:22), %253: !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(unknown), %254: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":159:22), %255: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":160:22), %256: i32 loc(unknown), %257: i32 loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %258 = llvm.icmp "slt" %252, %193 : i32 loc(#loc47)
    llvm.cond_br %258, ^bb2, ^bb3 loc(#loc47)
  ^bb2:  // pred: ^bb1
    %259 = llvm.sub %193, %25 : i32 loc(#loc47)
    %260 = llvm.icmp "slt" %252, %259 : i32 loc(#loc47)
    %261 = llvm.add %257, %25 : i32 loc(#loc47)
    %262 = llvm.icmp "slt" %261, %25 : i32 loc(#loc47)
    %263 = llvm.select %262, %261, %29 : i1, i32 loc(#loc47)
    nvvm.cp.async.wait.group 0 loc(#loc49)
    nvvm.barrier0 loc(#loc49)
    %264 = llvm.mul %263, %11 : i32 loc(#loc49)
    %265 = llvm.add %264, %29 : i32 loc(#loc49)
    %266 = llvm.add %265, %200 : i32 loc(#loc49)
    %267 = llvm.add %266, %202 : i32 loc(#loc49)
    %268 = llvm.getelementptr %12[%267] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %269 = llvm.select %105, %29, %30 : i1, i32 loc(#loc49)
    %270 = llvm.xor %29, %269 : i32 loc(#loc49)
    %271 = llvm.select %85, %29, %19 : i1, i32 loc(#loc49)
    %272 = llvm.xor %270, %271 : i32 loc(#loc49)
    %273 = llvm.xor %272, %92 : i32 loc(#loc49)
    %274 = llvm.xor %154, %96 : i32 loc(#loc49)
    %275 = llvm.mul %273, %25 : i32 loc(#loc49)
    %276 = llvm.add %275, %29 : i32 loc(#loc49)
    %277 = llvm.mul %274, %26 : i32 loc(#loc49)
    %278 = llvm.add %276, %277 : i32 loc(#loc49)
    %279 = llvm.getelementptr inbounds %268[%278] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %280 = llvm.ptrtoint %279 : !llvm.ptr<3> to i32 loc(#loc49)
    %281 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %280 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %282 = llvm.extractvalue %281[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %283 = llvm.extractvalue %281[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %284 = llvm.extractvalue %281[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %285 = llvm.extractvalue %281[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %286 = llvm.xor %19, %269 : i32 loc(#loc49)
    %287 = llvm.xor %286, %271 : i32 loc(#loc49)
    %288 = llvm.xor %287, %92 : i32 loc(#loc49)
    %289 = llvm.mul %288, %25 : i32 loc(#loc49)
    %290 = llvm.add %289, %29 : i32 loc(#loc49)
    %291 = llvm.add %290, %277 : i32 loc(#loc49)
    %292 = llvm.getelementptr inbounds %268[%291] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %293 = llvm.ptrtoint %292 : !llvm.ptr<3> to i32 loc(#loc49)
    %294 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %293 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %295 = llvm.extractvalue %294[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %296 = llvm.extractvalue %294[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %297 = llvm.extractvalue %294[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %298 = llvm.extractvalue %294[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %299 = llvm.bitcast %282 : i32 to vector<1xf32> loc(#loc49)
    %300 = llvm.extractelement %299[%29 : i32] : vector<1xf32> loc(#loc49)
    %301 = llvm.bitcast %283 : i32 to vector<1xf32> loc(#loc49)
    %302 = llvm.extractelement %301[%29 : i32] : vector<1xf32> loc(#loc49)
    %303 = llvm.bitcast %284 : i32 to vector<1xf32> loc(#loc49)
    %304 = llvm.extractelement %303[%29 : i32] : vector<1xf32> loc(#loc49)
    %305 = llvm.bitcast %285 : i32 to vector<1xf32> loc(#loc49)
    %306 = llvm.extractelement %305[%29 : i32] : vector<1xf32> loc(#loc49)
    %307 = llvm.bitcast %295 : i32 to vector<1xf32> loc(#loc49)
    %308 = llvm.extractelement %307[%29 : i32] : vector<1xf32> loc(#loc49)
    %309 = llvm.bitcast %296 : i32 to vector<1xf32> loc(#loc49)
    %310 = llvm.extractelement %309[%29 : i32] : vector<1xf32> loc(#loc49)
    %311 = llvm.bitcast %297 : i32 to vector<1xf32> loc(#loc49)
    %312 = llvm.extractelement %311[%29 : i32] : vector<1xf32> loc(#loc49)
    %313 = llvm.bitcast %298 : i32 to vector<1xf32> loc(#loc49)
    %314 = llvm.extractelement %313[%29 : i32] : vector<1xf32> loc(#loc49)
    %315 = llvm.add %265, %237 : i32 loc(#loc46)
    %316 = llvm.add %315, %202 : i32 loc(#loc46)
    %317 = llvm.getelementptr %195[%316] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %318 = llvm.xor %121, %86 : i32 loc(#loc46)
    %319 = llvm.xor %318, %90 : i32 loc(#loc46)
    %320 = llvm.xor %319, %92 : i32 loc(#loc46)
    %321 = llvm.xor %320, %94 : i32 loc(#loc46)
    %322 = llvm.mul %321, %25 : i32 loc(#loc46)
    %323 = llvm.add %322, %29 : i32 loc(#loc46)
    %324 = llvm.mul %150, %27 : i32 loc(#loc46)
    %325 = llvm.add %323, %324 : i32 loc(#loc46)
    %326 = llvm.getelementptr inbounds %317[%325] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %327 = llvm.load %326 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %328 = llvm.extractelement %327[%29 : i32] : vector<1xf32> loc(#loc46)
    %329 = llvm.xor %30, %147 : i32 loc(#loc46)
    %330 = llvm.xor %329, %149 : i32 loc(#loc46)
    %331 = llvm.mul %330, %27 : i32 loc(#loc46)
    %332 = llvm.add %323, %331 : i32 loc(#loc46)
    %333 = llvm.getelementptr inbounds %317[%332] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %334 = llvm.load %333 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %335 = llvm.extractelement %334[%29 : i32] : vector<1xf32> loc(#loc46)
    %336 = llvm.xor %19, %147 : i32 loc(#loc46)
    %337 = llvm.xor %336, %149 : i32 loc(#loc46)
    %338 = llvm.mul %337, %27 : i32 loc(#loc46)
    %339 = llvm.add %323, %338 : i32 loc(#loc46)
    %340 = llvm.getelementptr inbounds %317[%339] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %341 = llvm.load %340 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %342 = llvm.extractelement %341[%29 : i32] : vector<1xf32> loc(#loc46)
    %343 = llvm.xor %8, %147 : i32 loc(#loc46)
    %344 = llvm.xor %343, %149 : i32 loc(#loc46)
    %345 = llvm.mul %344, %27 : i32 loc(#loc46)
    %346 = llvm.add %323, %345 : i32 loc(#loc46)
    %347 = llvm.getelementptr inbounds %317[%346] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %348 = llvm.load %347 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %349 = llvm.extractelement %348[%29 : i32] : vector<1xf32> loc(#loc46)
    %350 = llvm.xor %26, %118 : i32 loc(#loc46)
    %351 = llvm.xor %350, %120 : i32 loc(#loc46)
    %352 = llvm.xor %351, %86 : i32 loc(#loc46)
    %353 = llvm.xor %352, %90 : i32 loc(#loc46)
    %354 = llvm.xor %353, %92 : i32 loc(#loc46)
    %355 = llvm.xor %354, %94 : i32 loc(#loc46)
    %356 = llvm.mul %355, %25 : i32 loc(#loc46)
    %357 = llvm.add %356, %29 : i32 loc(#loc46)
    %358 = llvm.add %357, %324 : i32 loc(#loc46)
    %359 = llvm.getelementptr inbounds %317[%358] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %360 = llvm.load %359 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %361 = llvm.extractelement %360[%29 : i32] : vector<1xf32> loc(#loc46)
    %362 = llvm.add %357, %331 : i32 loc(#loc46)
    %363 = llvm.getelementptr inbounds %317[%362] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %364 = llvm.load %363 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %365 = llvm.extractelement %364[%29 : i32] : vector<1xf32> loc(#loc46)
    %366 = llvm.add %357, %338 : i32 loc(#loc46)
    %367 = llvm.getelementptr inbounds %317[%366] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %368 = llvm.load %367 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %369 = llvm.extractelement %368[%29 : i32] : vector<1xf32> loc(#loc46)
    %370 = llvm.add %357, %345 : i32 loc(#loc46)
    %371 = llvm.getelementptr inbounds %317[%370] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %372 = llvm.load %371 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %373 = llvm.extractelement %372[%29 : i32] : vector<1xf32> loc(#loc46)
    %374 = llvm.insertelement %300, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %375 = llvm.bitcast %374 : vector<1xf32> to i32 loc(#loc51)
    %376 = llvm.insertelement %302, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %377 = llvm.bitcast %376 : vector<1xf32> to i32 loc(#loc51)
    %378 = llvm.insertelement %304, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %379 = llvm.bitcast %378 : vector<1xf32> to i32 loc(#loc51)
    %380 = llvm.insertelement %306, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %381 = llvm.bitcast %380 : vector<1xf32> to i32 loc(#loc51)
    %382 = llvm.insertelement %308, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %383 = llvm.bitcast %382 : vector<1xf32> to i32 loc(#loc51)
    %384 = llvm.insertelement %310, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %385 = llvm.bitcast %384 : vector<1xf32> to i32 loc(#loc51)
    %386 = llvm.insertelement %312, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %387 = llvm.bitcast %386 : vector<1xf32> to i32 loc(#loc51)
    %388 = llvm.insertelement %314, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %389 = llvm.bitcast %388 : vector<1xf32> to i32 loc(#loc51)
    %390 = llvm.insertelement %328, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %391 = llvm.bitcast %390 : vector<1xf32> to i32 loc(#loc51)
    %392 = llvm.insertelement %335, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %393 = llvm.bitcast %392 : vector<1xf32> to i32 loc(#loc51)
    %394 = llvm.insertelement %342, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %395 = llvm.bitcast %394 : vector<1xf32> to i32 loc(#loc51)
    %396 = llvm.insertelement %349, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %397 = llvm.bitcast %396 : vector<1xf32> to i32 loc(#loc51)
    %398 = llvm.insertelement %361, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %399 = llvm.bitcast %398 : vector<1xf32> to i32 loc(#loc51)
    %400 = llvm.insertelement %365, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %401 = llvm.bitcast %400 : vector<1xf32> to i32 loc(#loc51)
    %402 = llvm.insertelement %369, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %403 = llvm.bitcast %402 : vector<1xf32> to i32 loc(#loc51)
    %404 = llvm.insertelement %373, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %405 = llvm.bitcast %404 : vector<1xf32> to i32 loc(#loc51)
    %406 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %407 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %408 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %409 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %410 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %411 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %412 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %413 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %414 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %406, %407, %408, %409, %375, %377, %379, %381, %391, %393 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %415 = llvm.extractvalue %414[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %416 = llvm.extractvalue %414[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %417 = llvm.extractvalue %414[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %418 = llvm.extractvalue %414[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %419 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %410, %411, %412, %413, %375, %377, %379, %381, %399, %401 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %420 = llvm.extractvalue %419[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %421 = llvm.extractvalue %419[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %422 = llvm.extractvalue %419[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %423 = llvm.extractvalue %419[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %424 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %415, %416, %417, %418, %383, %385, %387, %389, %395, %397 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %425 = llvm.extractvalue %424[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %426 = llvm.extractvalue %424[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %427 = llvm.extractvalue %424[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %428 = llvm.extractvalue %424[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %429 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %420, %421, %422, %423, %383, %385, %387, %389, %403, %405 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %430 = llvm.extractvalue %429[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %431 = llvm.extractvalue %429[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %432 = llvm.extractvalue %429[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %433 = llvm.extractvalue %429[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %434 = llvm.insertvalue %425, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %435 = llvm.insertvalue %426, %434[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %436 = llvm.insertvalue %427, %435[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %437 = llvm.insertvalue %428, %436[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %438 = llvm.insertvalue %430, %437[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %439 = llvm.insertvalue %431, %438[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %440 = llvm.insertvalue %432, %439[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %441 = llvm.insertvalue %433, %440[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %442 = llvm.extractvalue %254[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %443 = llvm.extractvalue %254[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %444 = llvm.extractvalue %254[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %445 = llvm.extractvalue %254[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %446 = llvm.getelementptr %442[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %447 = llvm.getelementptr %443[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %448 = llvm.getelementptr %444[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %449 = llvm.getelementptr %445[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %450 = llvm.insertvalue %446, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %451 = llvm.insertvalue %447, %450[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %452 = llvm.insertvalue %448, %451[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %453 = llvm.insertvalue %449, %452[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %454 = llvm.extractvalue %255[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %455 = llvm.extractvalue %255[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %456 = llvm.extractvalue %255[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %457 = llvm.extractvalue %255[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %458 = llvm.getelementptr %454[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %459 = llvm.getelementptr %455[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %460 = llvm.getelementptr %456[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %461 = llvm.getelementptr %457[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %462 = llvm.insertvalue %458, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %463 = llvm.insertvalue %459, %462[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %464 = llvm.insertvalue %460, %463[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %465 = llvm.insertvalue %461, %464[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %466 = llvm.add %256, %25 : i32 loc(#loc47)
    %467 = llvm.icmp "slt" %466, %25 : i32 loc(#loc47)
    %468 = llvm.select %467, %466, %29 : i1, i32 loc(#loc47)
    %469 = llvm.add %252, %25 : i32 loc(#loc47)
    %470 = llvm.mul %469, %26 : i32 loc(#loc54)
    %471 = llvm.sub %arg5, %470 : i32 loc(#loc55)
    %472 = llvm.icmp "slt" %156, %471 : i32 loc(#loc48)
    %473 = llvm.mul %468, %11 : i32 loc(#loc49)
    %474 = llvm.add %473, %29 : i32 loc(#loc49)
    %475 = llvm.add %474, %200 : i32 loc(#loc49)
    %476 = llvm.add %475, %202 : i32 loc(#loc49)
    %477 = llvm.getelementptr %12[%476] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %478 = llvm.and %260, %472 : i1 loc(#loc47)
    nvvm.barrier0 loc(#loc49)
    %479 = llvm.getelementptr inbounds %477[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %480 = llvm.getelementptr inbounds %477[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %481 = llvm.getelementptr inbounds %477[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %482 = llvm.getelementptr inbounds %477[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %483 = llvm.select %478, %30, %29 : i1, i32 loc(#loc49)
    %484 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %479, %446, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %485 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %480, %447, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %486 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %481, %448, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %487 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %482, %449, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %488 = llvm.icmp "slt" %178, %471 : i32 loc(#loc50)
    %489 = llvm.add %474, %237 : i32 loc(#loc46)
    %490 = llvm.add %489, %202 : i32 loc(#loc46)
    %491 = llvm.getelementptr %195[%490] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %492 = llvm.and %260, %488 : i1 loc(#loc47)
    %493 = llvm.getelementptr inbounds %491[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %494 = llvm.select %492, %26, %29 : i1, i32 loc(#loc46)
    %495 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %493, %458, %494 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%469, %441, %453, %465, %468, %263 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb3:  // pred: ^bb1
    nvvm.cp.async.wait.group 0 loc(#loc47)
    nvvm.barrier0 loc(#loc47)
    %496 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %497 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %498 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %499 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %500 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %501 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %502 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %503 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %504 = llvm.fptrunc %496 : f32 to f16 loc(#loc56)
    %505 = llvm.fptrunc %497 : f32 to f16 loc(#loc56)
    %506 = llvm.fptrunc %498 : f32 to f16 loc(#loc56)
    %507 = llvm.fptrunc %499 : f32 to f16 loc(#loc56)
    %508 = llvm.fptrunc %500 : f32 to f16 loc(#loc56)
    %509 = llvm.fptrunc %501 : f32 to f16 loc(#loc56)
    %510 = llvm.fptrunc %502 : f32 to f16 loc(#loc56)
    %511 = llvm.fptrunc %503 : f32 to f16 loc(#loc56)
    %512 = llvm.mul %arg8, %128 : i32 loc(#loc57)
    %513 = llvm.getelementptr %arg2[%512] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc58)
    %514 = llvm.getelementptr %513[%138] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc59)
    %515 = llvm.icmp "slt" %128, %arg3 : i32 loc(#loc60)
    %516 = llvm.icmp "slt" %138, %arg4 : i32 loc(#loc61)
    %517 = llvm.and %515, %516 : i1 loc(#loc62)
    %518 = llvm.select %101, %29, %20 : i1, i32 loc(#loc63)
    %519 = llvm.xor %29, %518 : i32 loc(#loc63)
    %520 = llvm.select %105, %29, %30 : i1, i32 loc(#loc63)
    %521 = llvm.xor %519, %520 : i32 loc(#loc63)
    %522 = llvm.select %85, %29, %27 : i1, i32 loc(#loc63)
    %523 = llvm.xor %521, %522 : i32 loc(#loc63)
    %524 = llvm.select %89, %29, %5 : i1, i32 loc(#loc63)
    %525 = llvm.xor %523, %524 : i32 loc(#loc63)
    %526 = llvm.select %65, %29, %10 : i1, i32 loc(#loc63)
    %527 = llvm.xor %525, %526 : i32 loc(#loc63)
    %528 = llvm.xor %527, %94 : i32 loc(#loc63)
    %529 = llvm.select %73, %29, %11 : i1, i32 loc(#loc63)
    %530 = llvm.xor %528, %529 : i32 loc(#loc63)
    %531 = llvm.xor %121, %522 : i32 loc(#loc63)
    %532 = llvm.xor %531, %524 : i32 loc(#loc63)
    %533 = llvm.xor %532, %526 : i32 loc(#loc63)
    %534 = llvm.select %69, %29, %9 : i1, i32 loc(#loc63)
    %535 = llvm.xor %533, %534 : i32 loc(#loc63)
    %536 = llvm.xor %535, %529 : i32 loc(#loc63)
    %537 = llvm.xor %530, %29 : i32 loc(#loc63)
    %538 = llvm.lshr %537, %16 : i32 loc(#loc63)
    %539 = llvm.shl %538, %17 : i32 loc(#loc63)
    %540 = llvm.add %539, %537 : i32 loc(#loc63)
    %541 = llvm.getelementptr inbounds %12[%540] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %542 = llvm.insertelement %504, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %543 = llvm.insertelement %505, %542[%25 : i32] : vector<2xf16> loc(#loc63)
    %544 = llvm.extractelement %543[%29 : i32] : vector<2xf16> loc(#loc63)
    %545 = llvm.extractelement %543[%25 : i32] : vector<2xf16> loc(#loc63)
    %546 = llvm.bitcast %544 : f16 to i16 loc(#loc63)
    %547 = llvm.bitcast %545 : f16 to i16 loc(#loc63)
    %548 = llvm.insertelement %546, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %549 = llvm.insertelement %547, %548[%25 : i32] : vector<2xi16> loc(#loc63)
    %550 = llvm.extractelement %549[%29 : i32] : vector<2xi16> loc(#loc63)
    %551 = llvm.extractelement %549[%25 : i32] : vector<2xi16> loc(#loc63)
    %552 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %541, %550, %551, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %553 = llvm.xor %530, %9 : i32 loc(#loc63)
    %554 = llvm.lshr %553, %16 : i32 loc(#loc63)
    %555 = llvm.shl %554, %17 : i32 loc(#loc63)
    %556 = llvm.add %555, %553 : i32 loc(#loc63)
    %557 = llvm.getelementptr inbounds %12[%556] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %558 = llvm.insertelement %506, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %559 = llvm.insertelement %507, %558[%25 : i32] : vector<2xf16> loc(#loc63)
    %560 = llvm.extractelement %559[%29 : i32] : vector<2xf16> loc(#loc63)
    %561 = llvm.extractelement %559[%25 : i32] : vector<2xf16> loc(#loc63)
    %562 = llvm.bitcast %560 : f16 to i16 loc(#loc63)
    %563 = llvm.bitcast %561 : f16 to i16 loc(#loc63)
    %564 = llvm.insertelement %562, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %565 = llvm.insertelement %563, %564[%25 : i32] : vector<2xi16> loc(#loc63)
    %566 = llvm.extractelement %565[%29 : i32] : vector<2xi16> loc(#loc63)
    %567 = llvm.extractelement %565[%25 : i32] : vector<2xi16> loc(#loc63)
    %568 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %557, %566, %567, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %569 = llvm.xor %530, %26 : i32 loc(#loc63)
    %570 = llvm.lshr %569, %16 : i32 loc(#loc63)
    %571 = llvm.shl %570, %17 : i32 loc(#loc63)
    %572 = llvm.add %571, %569 : i32 loc(#loc63)
    %573 = llvm.getelementptr inbounds %12[%572] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %574 = llvm.insertelement %508, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %575 = llvm.insertelement %509, %574[%25 : i32] : vector<2xf16> loc(#loc63)
    %576 = llvm.extractelement %575[%29 : i32] : vector<2xf16> loc(#loc63)
    %577 = llvm.extractelement %575[%25 : i32] : vector<2xf16> loc(#loc63)
    %578 = llvm.bitcast %576 : f16 to i16 loc(#loc63)
    %579 = llvm.bitcast %577 : f16 to i16 loc(#loc63)
    %580 = llvm.insertelement %578, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %581 = llvm.insertelement %579, %580[%25 : i32] : vector<2xi16> loc(#loc63)
    %582 = llvm.extractelement %581[%29 : i32] : vector<2xi16> loc(#loc63)
    %583 = llvm.extractelement %581[%25 : i32] : vector<2xi16> loc(#loc63)
    %584 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %573, %582, %583, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %585 = llvm.xor %530, %7 : i32 loc(#loc63)
    %586 = llvm.lshr %585, %16 : i32 loc(#loc63)
    %587 = llvm.shl %586, %17 : i32 loc(#loc63)
    %588 = llvm.add %587, %585 : i32 loc(#loc63)
    %589 = llvm.getelementptr inbounds %12[%588] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %590 = llvm.insertelement %510, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %591 = llvm.insertelement %511, %590[%25 : i32] : vector<2xf16> loc(#loc63)
    %592 = llvm.extractelement %591[%29 : i32] : vector<2xf16> loc(#loc63)
    %593 = llvm.extractelement %591[%25 : i32] : vector<2xf16> loc(#loc63)
    %594 = llvm.bitcast %592 : f16 to i16 loc(#loc63)
    %595 = llvm.bitcast %593 : f16 to i16 loc(#loc63)
    %596 = llvm.insertelement %594, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %597 = llvm.insertelement %595, %596[%25 : i32] : vector<2xi16> loc(#loc63)
    %598 = llvm.extractelement %597[%29 : i32] : vector<2xi16> loc(#loc63)
    %599 = llvm.extractelement %597[%25 : i32] : vector<2xi16> loc(#loc63)
    %600 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %589, %598, %599, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    nvvm.barrier0 loc(#loc63)
    %601 = llvm.xor %536, %29 : i32 loc(#loc63)
    %602 = llvm.lshr %601, %16 : i32 loc(#loc63)
    %603 = llvm.shl %602, %17 : i32 loc(#loc63)
    %604 = llvm.add %603, %601 : i32 loc(#loc63)
    %605 = llvm.getelementptr inbounds %12[%604] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %606 = llvm.load %605 : !llvm.ptr<3> -> vector<4xi32> loc(#loc63)
    %607 = llvm.extractelement %606[%29 : i32] : vector<4xi32> loc(#loc63)
    %608 = llvm.extractelement %606[%25 : i32] : vector<4xi32> loc(#loc63)
    %609 = llvm.extractelement %606[%20 : i32] : vector<4xi32> loc(#loc63)
    %610 = llvm.extractelement %606[%17 : i32] : vector<4xi32> loc(#loc63)
    %611 = llvm.insertelement %607, %2[%29 : i32] : vector<4xi32> loc(#loc63)
    %612 = llvm.insertelement %608, %611[%25 : i32] : vector<4xi32> loc(#loc63)
    %613 = llvm.insertelement %609, %612[%20 : i32] : vector<4xi32> loc(#loc63)
    %614 = llvm.insertelement %610, %613[%17 : i32] : vector<4xi32> loc(#loc63)
    %615 = llvm.extractelement %614[%29 : i32] : vector<4xi32> loc(#loc63)
    %616 = llvm.extractelement %614[%25 : i32] : vector<4xi32> loc(#loc63)
    %617 = llvm.extractelement %614[%20 : i32] : vector<4xi32> loc(#loc63)
    %618 = llvm.extractelement %614[%17 : i32] : vector<4xi32> loc(#loc63)
    %619 = llvm.bitcast %615 : i32 to vector<2xi16> loc(#loc63)
    %620 = llvm.extractelement %619[%29 : i32] : vector<2xi16> loc(#loc63)
    %621 = llvm.extractelement %619[%25 : i32] : vector<2xi16> loc(#loc63)
    %622 = llvm.bitcast %616 : i32 to vector<2xi16> loc(#loc63)
    %623 = llvm.extractelement %622[%29 : i32] : vector<2xi16> loc(#loc63)
    %624 = llvm.extractelement %622[%25 : i32] : vector<2xi16> loc(#loc63)
    %625 = llvm.bitcast %617 : i32 to vector<2xi16> loc(#loc63)
    %626 = llvm.extractelement %625[%29 : i32] : vector<2xi16> loc(#loc63)
    %627 = llvm.extractelement %625[%25 : i32] : vector<2xi16> loc(#loc63)
    %628 = llvm.bitcast %618 : i32 to vector<2xi16> loc(#loc63)
    %629 = llvm.extractelement %628[%29 : i32] : vector<2xi16> loc(#loc63)
    %630 = llvm.extractelement %628[%25 : i32] : vector<2xi16> loc(#loc63)
    %631 = llvm.insertelement %620, %1[%29 : i32] : vector<8xi16> loc(#loc63)
    %632 = llvm.insertelement %621, %631[%25 : i32] : vector<8xi16> loc(#loc63)
    %633 = llvm.insertelement %623, %632[%20 : i32] : vector<8xi16> loc(#loc63)
    %634 = llvm.insertelement %624, %633[%17 : i32] : vector<8xi16> loc(#loc63)
    %635 = llvm.insertelement %626, %634[%30 : i32] : vector<8xi16> loc(#loc63)
    %636 = llvm.insertelement %627, %635[%16 : i32] : vector<8xi16> loc(#loc63)
    %637 = llvm.insertelement %629, %636[%15 : i32] : vector<8xi16> loc(#loc63)
    %638 = llvm.insertelement %630, %637[%14 : i32] : vector<8xi16> loc(#loc63)
    %639 = llvm.extractelement %638[%29 : i32] : vector<8xi16> loc(#loc63)
    %640 = llvm.extractelement %638[%25 : i32] : vector<8xi16> loc(#loc63)
    %641 = llvm.extractelement %638[%20 : i32] : vector<8xi16> loc(#loc63)
    %642 = llvm.extractelement %638[%17 : i32] : vector<8xi16> loc(#loc63)
    %643 = llvm.extractelement %638[%30 : i32] : vector<8xi16> loc(#loc63)
    %644 = llvm.extractelement %638[%16 : i32] : vector<8xi16> loc(#loc63)
    %645 = llvm.extractelement %638[%15 : i32] : vector<8xi16> loc(#loc63)
    %646 = llvm.extractelement %638[%14 : i32] : vector<8xi16> loc(#loc63)
    %647 = llvm.bitcast %639 : i16 to f16 loc(#loc63)
    %648 = llvm.bitcast %640 : i16 to f16 loc(#loc63)
    %649 = llvm.bitcast %641 : i16 to f16 loc(#loc63)
    %650 = llvm.bitcast %642 : i16 to f16 loc(#loc63)
    %651 = llvm.bitcast %643 : i16 to f16 loc(#loc63)
    %652 = llvm.bitcast %644 : i16 to f16 loc(#loc63)
    %653 = llvm.bitcast %645 : i16 to f16 loc(#loc63)
    %654 = llvm.bitcast %646 : i16 to f16 loc(#loc63)
    %655 = llvm.insertelement %647, %0[%29 : i32] : vector<8xf16> loc(#loc63)
    %656 = llvm.insertelement %648, %655[%25 : i32] : vector<8xf16> loc(#loc63)
    %657 = llvm.insertelement %649, %656[%20 : i32] : vector<8xf16> loc(#loc63)
    %658 = llvm.insertelement %650, %657[%17 : i32] : vector<8xf16> loc(#loc63)
    %659 = llvm.insertelement %651, %658[%30 : i32] : vector<8xf16> loc(#loc63)
    %660 = llvm.insertelement %652, %659[%16 : i32] : vector<8xf16> loc(#loc63)
    %661 = llvm.insertelement %653, %660[%15 : i32] : vector<8xf16> loc(#loc63)
    %662 = llvm.insertelement %654, %661[%14 : i32] : vector<8xf16> loc(#loc63)
    %663 = llvm.extractelement %662[%29 : i32] : vector<8xf16> loc(#loc63)
    %664 = llvm.extractelement %662[%25 : i32] : vector<8xf16> loc(#loc63)
    %665 = llvm.extractelement %662[%20 : i32] : vector<8xf16> loc(#loc63)
    %666 = llvm.extractelement %662[%17 : i32] : vector<8xf16> loc(#loc63)
    %667 = llvm.extractelement %662[%30 : i32] : vector<8xf16> loc(#loc63)
    %668 = llvm.extractelement %662[%16 : i32] : vector<8xf16> loc(#loc63)
    %669 = llvm.extractelement %662[%15 : i32] : vector<8xf16> loc(#loc63)
    %670 = llvm.extractelement %662[%14 : i32] : vector<8xf16> loc(#loc63)
    %671 = llvm.insertelement %663, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %672 = llvm.insertelement %664, %671[%25 : i32] : vector<2xf16> loc(#loc63)
    %673 = llvm.bitcast %672 : vector<2xf16> to i32 loc(#loc63)
    %674 = llvm.insertelement %665, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %675 = llvm.insertelement %666, %674[%25 : i32] : vector<2xf16> loc(#loc63)
    %676 = llvm.bitcast %675 : vector<2xf16> to i32 loc(#loc63)
    %677 = llvm.insertelement %667, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %678 = llvm.insertelement %668, %677[%25 : i32] : vector<2xf16> loc(#loc63)
    %679 = llvm.bitcast %678 : vector<2xf16> to i32 loc(#loc63)
    %680 = llvm.insertelement %669, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %681 = llvm.insertelement %670, %680[%25 : i32] : vector<2xf16> loc(#loc63)
    %682 = llvm.bitcast %681 : vector<2xf16> to i32 loc(#loc63)
    %683 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$5 st.global.v4.b32 [ $4 + 0 ], { $0, $1, $2, $3 };", "r,r,r,r,l,b" %673, %676, %679, %682, %514, %517 : (i32, i32, i32, i32, !llvm.ptr<1>, i1) -> !llvm.void loc(#loc63)
    llvm.return loc(#loc64)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:41)
#loc37 = loc("examples/kernels/binary_ops.py":159:60)
#loc38 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":160:29)
#loc41 = loc("examples/kernels/binary_ops.py":160:40)
#loc42 = loc("examples/kernels/binary_ops.py":160:52)
#loc44 = loc("examples/kernels/binary_ops.py":168:33)
#loc45 = loc("examples/kernels/binary_ops.py":177:33)
#loc46 = loc("examples/kernels/binary_ops.py":172:20)
#loc48 = loc("examples/kernels/binary_ops.py":171:51)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:51)
#loc51 = loc("examples/kernels/binary_ops.py":174:35)
#loc52 = loc("examples/kernels/binary_ops.py":176:18)
#loc53 = loc("examples/kernels/binary_ops.py":177:18)
#loc54 = loc("examples/kernels/binary_ops.py":171:59)
#loc55 = loc("examples/kernels/binary_ops.py":171:55)
#loc56 = loc("examples/kernels/binary_ops.py":182:23)
#loc57 = loc("examples/kernels/binary_ops.py":188:33)
#loc58 = loc("examples/kernels/binary_ops.py":188:21)
#loc59 = loc("examples/kernels/binary_ops.py":188:52)
#loc60 = loc("examples/kernels/binary_ops.py":189:33)
#loc61 = loc("examples/kernels/binary_ops.py":189:58)
#loc62 = loc("examples/kernels/binary_ops.py":189:39)
#loc63 = loc("examples/kernels/binary_ops.py":190:21)
#loc64 = loc("examples/kernels/binary_ops.py":190:4)
#loc65 = loc(callsite(#loc3 at #loc4))
#loc66 = loc(callsite(#loc5 at #loc4))
#loc67 = loc(callsite(#loc3 at #loc6))
#loc68 = loc(callsite(#loc5 at #loc6))
#loc69 = loc(callsite(#loc3 at #loc44))
#loc70 = loc(callsite(#loc5 at #loc44))


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc39 = loc("examples/kernels/binary_ops.py":159:22)
#loc43 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
module attributes {ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @matmul_kernel(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg9: !llvm.ptr<1> loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.undef : vector<8xf16> loc(#loc1)
    %1 = llvm.mlir.undef : vector<8xi16> loc(#loc1)
    %2 = llvm.mlir.undef : vector<4xi32> loc(#loc1)
    %3 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %4 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %5 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.undef : vector<1xf32> loc(#loc1)
    %7 = llvm.mlir.constant(272 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.constant(256 : i32) : i32 loc(#loc1)
    %10 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(512 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %13 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc1)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(6 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %22 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc1)
    %23 = llvm.mlir.constant(15 : i32) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(31 : i32) : i32 loc(#loc1)
    %25 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %26 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %27 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %28 = llvm.mlir.constant(true) : i1 loc(#loc1)
    %29 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %30 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %31 = llvm.mlir.constant(-1 : i32) : i32 loc(#loc1)
    %32 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %33 = llvm.insertvalue %32, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %34 = llvm.insertvalue %32, %33[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %35 = llvm.insertvalue %32, %34[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %36 = llvm.insertvalue %32, %35[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %37 = llvm.insertvalue %32, %36[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %38 = llvm.insertvalue %32, %37[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %39 = llvm.insertvalue %32, %38[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %40 = llvm.insertvalue %32, %39[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %41 = llvm.call_intrinsic "llvm.nvvm.read.ptx.sreg.ctaid.x"() : () -> i32 loc(#loc2)
    %42 = llvm.add %arg3, %24 : i32 loc(#loc65)
    %43 = llvm.sdiv %42, %27 : i32 loc(#loc66)
    %44 = llvm.add %arg4, %24 : i32 loc(#loc67)
    %45 = llvm.sdiv %44, %27 : i32 loc(#loc68)
    %46 = llvm.mul %45, %30 : i32 loc(#loc7)
    %47 = llvm.sdiv %41, %46 : i32 loc(#loc8)
    %48 = llvm.mul %47, %30 : i32 loc(#loc9)
    %49 = llvm.sub %43, %48 : i32 loc(#loc10)
    %50 = llvm.intr.smin(%49, %30) : (i32, i32) -> i32 loc(#loc11)
    %51 = llvm.srem %41, %46 : i32 loc(#loc12)
    %52 = llvm.srem %51, %50 : i32 loc(#loc13)
    %53 = llvm.add %48, %52 : i32 loc(#loc14)
    %54 = llvm.sdiv %51, %50 : i32 loc(#loc15)
    %55 = llvm.icmp "sge" %53, %29 : i32 loc(#loc16)
    llvm.intr.assume %55 : i1 loc(#loc17)
    %56 = llvm.icmp "sge" %54, %29 : i32 loc(#loc18)
    llvm.intr.assume %56 : i1 loc(#loc19)
    %57 = llvm.icmp "sgt" %arg6, %29 : i32 loc(#loc20)
    llvm.intr.assume %57 : i1 loc(#loc21)
    llvm.intr.assume %28 : i1 loc(#loc22)
    llvm.intr.assume %28 : i1 loc(#loc23)
    %58 = llvm.icmp "sgt" %arg7, %29 : i32 loc(#loc24)
    llvm.intr.assume %58 : i1 loc(#loc25)
    %59 = llvm.icmp "sgt" %arg8, %29 : i32 loc(#loc26)
    llvm.intr.assume %59 : i1 loc(#loc27)
    llvm.intr.assume %28 : i1 loc(#loc28)
    %60 = llvm.mul %53, %27 : i32 loc(#loc29)
    %61 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc30)
    %62 = llvm.urem %61, %27 : i32 loc(#loc30)
    %63 = llvm.udiv %61, %27 : i32 loc(#loc30)
    %64 = llvm.and %62, %26 : i32 loc(#loc30)
    %65 = llvm.icmp "eq" %64, %29 : i32 loc(#loc30)
    %66 = llvm.select %65, %29, %25 : i1, i32 loc(#loc30)
    %67 = llvm.xor %29, %66 : i32 loc(#loc30)
    %68 = llvm.and %63, %25 : i32 loc(#loc30)
    %69 = llvm.icmp "eq" %68, %29 : i32 loc(#loc30)
    %70 = llvm.select %69, %29, %20 : i1, i32 loc(#loc30)
    %71 = llvm.xor %67, %70 : i32 loc(#loc30)
    %72 = llvm.and %63, %20 : i32 loc(#loc30)
    %73 = llvm.icmp "eq" %72, %29 : i32 loc(#loc30)
    %74 = llvm.select %73, %29, %30 : i1, i32 loc(#loc30)
    %75 = llvm.xor %71, %74 : i32 loc(#loc30)
    %76 = llvm.xor %75, %29 : i32 loc(#loc30)
    %77 = llvm.xor %75, %19 : i32 loc(#loc30)
    %78 = llvm.xor %75, %26 : i32 loc(#loc30)
    %79 = llvm.xor %75, %18 : i32 loc(#loc30)
    %80 = llvm.add %76, %21 : i32 loc(#loc30)
    %81 = llvm.add %77, %21 : i32 loc(#loc30)
    %82 = llvm.add %78, %21 : i32 loc(#loc30)
    %83 = llvm.add %79, %21 : i32 loc(#loc30)
    %84 = llvm.and %62, %30 : i32 loc(#loc30)
    %85 = llvm.icmp "eq" %84, %29 : i32 loc(#loc30)
    %86 = llvm.select %85, %29, %25 : i1, i32 loc(#loc30)
    %87 = llvm.xor %29, %86 : i32 loc(#loc30)
    %88 = llvm.and %62, %19 : i32 loc(#loc30)
    %89 = llvm.icmp "eq" %88, %29 : i32 loc(#loc30)
    %90 = llvm.select %89, %29, %20 : i1, i32 loc(#loc30)
    %91 = llvm.xor %87, %90 : i32 loc(#loc30)
    %92 = llvm.select %65, %29, %30 : i1, i32 loc(#loc30)
    %93 = llvm.xor %91, %92 : i32 loc(#loc30)
    %94 = llvm.select %69, %29, %19 : i1, i32 loc(#loc30)
    %95 = llvm.xor %93, %94 : i32 loc(#loc30)
    %96 = llvm.select %73, %29, %26 : i1, i32 loc(#loc30)
    %97 = llvm.xor %95, %96 : i32 loc(#loc30)
    %98 = llvm.xor %97, %29 : i32 loc(#loc30)
    %99 = llvm.add %98, %21 : i32 loc(#loc30)
    %100 = llvm.and %62, %25 : i32 loc(#loc30)
    %101 = llvm.icmp "eq" %100, %29 : i32 loc(#loc30)
    %102 = llvm.select %101, %29, %30 : i1, i32 loc(#loc30)
    %103 = llvm.xor %29, %102 : i32 loc(#loc30)
    %104 = llvm.and %62, %20 : i32 loc(#loc30)
    %105 = llvm.icmp "eq" %104, %29 : i32 loc(#loc30)
    %106 = llvm.select %105, %29, %19 : i1, i32 loc(#loc30)
    %107 = llvm.xor %103, %106 : i32 loc(#loc30)
    %108 = llvm.select %85, %29, %26 : i1, i32 loc(#loc30)
    %109 = llvm.xor %107, %108 : i32 loc(#loc30)
    %110 = llvm.xor %109, %29 : i32 loc(#loc30)
    %111 = llvm.xor %109, %25 : i32 loc(#loc30)
    %112 = llvm.xor %109, %20 : i32 loc(#loc30)
    %113 = llvm.xor %109, %17 : i32 loc(#loc30)
    %114 = llvm.add %110, %21 : i32 loc(#loc30)
    %115 = llvm.add %111, %21 : i32 loc(#loc30)
    %116 = llvm.add %112, %21 : i32 loc(#loc30)
    %117 = llvm.add %113, %21 : i32 loc(#loc30)
    %118 = llvm.select %101, %29, %19 : i1, i32 loc(#loc30)
    %119 = llvm.xor %29, %118 : i32 loc(#loc30)
    %120 = llvm.select %105, %29, %26 : i1, i32 loc(#loc30)
    %121 = llvm.xor %119, %120 : i32 loc(#loc30)
    %122 = llvm.xor %121, %29 : i32 loc(#loc30)
    %123 = llvm.add %122, %21 : i32 loc(#loc30)
    %124 = llvm.add %60, %80 : i32 loc(#loc31)
    %125 = llvm.add %60, %81 : i32 loc(#loc31)
    %126 = llvm.add %60, %82 : i32 loc(#loc31)
    %127 = llvm.add %60, %83 : i32 loc(#loc31)
    %128 = llvm.add %60, %99 : i32 loc(#loc31)
    %129 = llvm.srem %124, %arg3 : i32 loc(#loc32)
    %130 = llvm.srem %125, %arg3 : i32 loc(#loc32)
    %131 = llvm.srem %126, %arg3 : i32 loc(#loc32)
    %132 = llvm.srem %127, %arg3 : i32 loc(#loc32)
    %133 = llvm.mul %54, %27 : i32 loc(#loc33)
    %134 = llvm.add %133, %114 : i32 loc(#loc34)
    %135 = llvm.add %133, %115 : i32 loc(#loc34)
    %136 = llvm.add %133, %116 : i32 loc(#loc34)
    %137 = llvm.add %133, %117 : i32 loc(#loc34)
    %138 = llvm.add %133, %123 : i32 loc(#loc34)
    %139 = llvm.srem %134, %arg4 : i32 loc(#loc35)
    %140 = llvm.srem %135, %arg4 : i32 loc(#loc35)
    %141 = llvm.srem %136, %arg4 : i32 loc(#loc35)
    %142 = llvm.srem %137, %arg4 : i32 loc(#loc35)
    %143 = llvm.mul %129, %arg6 : i32 loc(#loc36)
    %144 = llvm.mul %130, %arg6 : i32 loc(#loc36)
    %145 = llvm.mul %131, %arg6 : i32 loc(#loc36)
    %146 = llvm.mul %132, %arg6 : i32 loc(#loc36)
    %147 = llvm.select %101, %29, %25 : i1, i32 loc(#loc37)
    %148 = llvm.xor %29, %147 : i32 loc(#loc37)
    %149 = llvm.select %105, %29, %20 : i1, i32 loc(#loc37)
    %150 = llvm.xor %148, %149 : i32 loc(#loc37)
    %151 = llvm.select %85, %29, %30 : i1, i32 loc(#loc37)
    %152 = llvm.xor %150, %151 : i32 loc(#loc37)
    %153 = llvm.select %89, %29, %19 : i1, i32 loc(#loc37)
    %154 = llvm.xor %152, %153 : i32 loc(#loc37)
    %155 = llvm.xor %154, %29 : i32 loc(#loc37)
    %156 = llvm.add %155, %21 : i32 loc(#loc37)
    %157 = llvm.add %143, %156 : i32 loc(#loc38)
    %158 = llvm.add %144, %156 : i32 loc(#loc38)
    %159 = llvm.add %145, %156 : i32 loc(#loc38)
    %160 = llvm.add %146, %156 : i32 loc(#loc38)
    %161 = llvm.getelementptr %arg0[%157] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %162 = llvm.getelementptr %arg0[%158] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %163 = llvm.getelementptr %arg0[%159] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %164 = llvm.getelementptr %arg0[%160] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %165 = llvm.insertvalue %161, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %166 = llvm.insertvalue %162, %165[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %167 = llvm.insertvalue %163, %166[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %168 = llvm.insertvalue %164, %167[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %169 = llvm.select %89, %29, %25 : i1, i32 loc(#loc40)
    %170 = llvm.xor %29, %169 : i32 loc(#loc40)
    %171 = llvm.select %65, %29, %20 : i1, i32 loc(#loc40)
    %172 = llvm.xor %170, %171 : i32 loc(#loc40)
    %173 = llvm.select %69, %29, %30 : i1, i32 loc(#loc40)
    %174 = llvm.xor %172, %173 : i32 loc(#loc40)
    %175 = llvm.select %73, %29, %19 : i1, i32 loc(#loc40)
    %176 = llvm.xor %174, %175 : i32 loc(#loc40)
    %177 = llvm.xor %176, %29 : i32 loc(#loc40)
    %178 = llvm.add %177, %21 : i32 loc(#loc40)
    %179 = llvm.mul %178, %arg7 : i32 loc(#loc41)
    %180 = llvm.add %179, %139 : i32 loc(#loc42)
    %181 = llvm.add %179, %140 : i32 loc(#loc42)
    %182 = llvm.add %179, %141 : i32 loc(#loc42)
    %183 = llvm.add %179, %142 : i32 loc(#loc42)
    %184 = llvm.getelementptr %arg1[%180] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %185 = llvm.getelementptr %arg1[%181] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %186 = llvm.getelementptr %arg1[%182] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %187 = llvm.getelementptr %arg1[%183] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %188 = llvm.insertvalue %184, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %189 = llvm.insertvalue %185, %188[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %190 = llvm.insertvalue %186, %189[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %191 = llvm.insertvalue %187, %190[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %192 = llvm.add %arg5, %23 : i32 loc(#loc69)
    %193 = llvm.sdiv %192, %26 : i32 loc(#loc70)
    %194 = llvm.mul %arg7, %26 : i32 loc(#loc45)
    %195 = llvm.getelementptr %12[2048] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc46)
    %196 = llvm.icmp "sgt" %193, %29 : i32 loc(#loc47)
    %197 = llvm.icmp "slt" %156, %arg5 : i32 loc(#loc48)
    %198 = llvm.mul %29, %11 : i32 loc(#loc49)
    %199 = llvm.add %198, %29 : i32 loc(#loc49)
    %200 = llvm.mul %29, %26 : i32 loc(#loc49)
    %201 = llvm.add %199, %200 : i32 loc(#loc49)
    %202 = llvm.mul %29, %25 : i32 loc(#loc49)
    %203 = llvm.add %201, %202 : i32 loc(#loc49)
    %204 = llvm.getelementptr %12[%203] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %205 = llvm.and %196, %197 : i1 loc(#loc47)
    %206 = llvm.xor %154, %173 : i32 loc(#loc49)
    %207 = llvm.xor %206, %175 : i32 loc(#loc49)
    %208 = llvm.mul %207, %25 : i32 loc(#loc49)
    %209 = llvm.add %208, %29 : i32 loc(#loc49)
    %210 = llvm.mul %75, %26 : i32 loc(#loc49)
    %211 = llvm.add %209, %210 : i32 loc(#loc49)
    %212 = llvm.getelementptr inbounds %204[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %213 = llvm.xor %19, %66 : i32 loc(#loc49)
    %214 = llvm.xor %213, %70 : i32 loc(#loc49)
    %215 = llvm.xor %214, %74 : i32 loc(#loc49)
    %216 = llvm.mul %215, %26 : i32 loc(#loc49)
    %217 = llvm.add %209, %216 : i32 loc(#loc49)
    %218 = llvm.getelementptr inbounds %204[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %219 = llvm.xor %26, %66 : i32 loc(#loc49)
    %220 = llvm.xor %219, %70 : i32 loc(#loc49)
    %221 = llvm.xor %220, %74 : i32 loc(#loc49)
    %222 = llvm.mul %221, %26 : i32 loc(#loc49)
    %223 = llvm.add %209, %222 : i32 loc(#loc49)
    %224 = llvm.getelementptr inbounds %204[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %225 = llvm.xor %18, %66 : i32 loc(#loc49)
    %226 = llvm.xor %225, %70 : i32 loc(#loc49)
    %227 = llvm.xor %226, %74 : i32 loc(#loc49)
    %228 = llvm.mul %227, %26 : i32 loc(#loc49)
    %229 = llvm.add %209, %228 : i32 loc(#loc49)
    %230 = llvm.getelementptr inbounds %204[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %231 = llvm.select %205, %30, %29 : i1, i32 loc(#loc49)
    %232 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %212, %161, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %233 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %218, %162, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %234 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %224, %163, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %235 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %230, %164, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %236 = llvm.icmp "slt" %178, %arg5 : i32 loc(#loc50)
    %237 = llvm.mul %29, %27 : i32 loc(#loc46)
    %238 = llvm.add %199, %237 : i32 loc(#loc46)
    %239 = llvm.add %238, %202 : i32 loc(#loc46)
    %240 = llvm.getelementptr %195[%239] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %241 = llvm.and %196, %236 : i1 loc(#loc47)
    %242 = llvm.xor %109, %153 : i32 loc(#loc46)
    %243 = llvm.select %65, %29, %26 : i1, i32 loc(#loc46)
    %244 = llvm.xor %242, %243 : i32 loc(#loc46)
    %245 = llvm.mul %244, %25 : i32 loc(#loc46)
    %246 = llvm.add %245, %29 : i32 loc(#loc46)
    %247 = llvm.mul %176, %27 : i32 loc(#loc46)
    %248 = llvm.add %246, %247 : i32 loc(#loc46)
    %249 = llvm.getelementptr inbounds %240[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %250 = llvm.select %241, %26, %29 : i1, i32 loc(#loc46)
    %251 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %249, %184, %250 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%29, %40, %168, %191, %29, %31 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb1(%252: i32 loc("examples/kernels/binary_ops.py":168:22), %253: !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(unknown), %254: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":159:22), %255: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":160:22), %256: i32 loc(unknown), %257: i32 loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %258 = llvm.icmp "slt" %252, %193 : i32 loc(#loc47)
    llvm.cond_br %258, ^bb2, ^bb3 loc(#loc47)
  ^bb2:  // pred: ^bb1
    %259 = llvm.sub %193, %25 : i32 loc(#loc47)
    %260 = llvm.icmp "slt" %252, %259 : i32 loc(#loc47)
    %261 = llvm.add %257, %25 : i32 loc(#loc47)
    %262 = llvm.icmp "slt" %261, %25 : i32 loc(#loc47)
    %263 = llvm.select %262, %261, %29 : i1, i32 loc(#loc47)
    nvvm.cp.async.wait.group 0 loc(#loc49)
    nvvm.barrier0 loc(#loc49)
    %264 = llvm.mul %263, %11 : i32 loc(#loc49)
    %265 = llvm.add %264, %29 : i32 loc(#loc49)
    %266 = llvm.add %265, %200 : i32 loc(#loc49)
    %267 = llvm.add %266, %202 : i32 loc(#loc49)
    %268 = llvm.getelementptr %12[%267] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %269 = llvm.select %105, %29, %30 : i1, i32 loc(#loc49)
    %270 = llvm.xor %29, %269 : i32 loc(#loc49)
    %271 = llvm.select %85, %29, %19 : i1, i32 loc(#loc49)
    %272 = llvm.xor %270, %271 : i32 loc(#loc49)
    %273 = llvm.xor %272, %92 : i32 loc(#loc49)
    %274 = llvm.xor %154, %96 : i32 loc(#loc49)
    %275 = llvm.mul %273, %25 : i32 loc(#loc49)
    %276 = llvm.add %275, %29 : i32 loc(#loc49)
    %277 = llvm.mul %274, %26 : i32 loc(#loc49)
    %278 = llvm.add %276, %277 : i32 loc(#loc49)
    %279 = llvm.getelementptr inbounds %268[%278] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %280 = llvm.ptrtoint %279 : !llvm.ptr<3> to i32 loc(#loc49)
    %281 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %280 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %282 = llvm.extractvalue %281[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %283 = llvm.extractvalue %281[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %284 = llvm.extractvalue %281[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %285 = llvm.extractvalue %281[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %286 = llvm.xor %19, %269 : i32 loc(#loc49)
    %287 = llvm.xor %286, %271 : i32 loc(#loc49)
    %288 = llvm.xor %287, %92 : i32 loc(#loc49)
    %289 = llvm.mul %288, %25 : i32 loc(#loc49)
    %290 = llvm.add %289, %29 : i32 loc(#loc49)
    %291 = llvm.add %290, %277 : i32 loc(#loc49)
    %292 = llvm.getelementptr inbounds %268[%291] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %293 = llvm.ptrtoint %292 : !llvm.ptr<3> to i32 loc(#loc49)
    %294 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %293 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %295 = llvm.extractvalue %294[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %296 = llvm.extractvalue %294[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %297 = llvm.extractvalue %294[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %298 = llvm.extractvalue %294[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %299 = llvm.bitcast %282 : i32 to vector<1xf32> loc(#loc49)
    %300 = llvm.extractelement %299[%29 : i32] : vector<1xf32> loc(#loc49)
    %301 = llvm.bitcast %283 : i32 to vector<1xf32> loc(#loc49)
    %302 = llvm.extractelement %301[%29 : i32] : vector<1xf32> loc(#loc49)
    %303 = llvm.bitcast %284 : i32 to vector<1xf32> loc(#loc49)
    %304 = llvm.extractelement %303[%29 : i32] : vector<1xf32> loc(#loc49)
    %305 = llvm.bitcast %285 : i32 to vector<1xf32> loc(#loc49)
    %306 = llvm.extractelement %305[%29 : i32] : vector<1xf32> loc(#loc49)
    %307 = llvm.bitcast %295 : i32 to vector<1xf32> loc(#loc49)
    %308 = llvm.extractelement %307[%29 : i32] : vector<1xf32> loc(#loc49)
    %309 = llvm.bitcast %296 : i32 to vector<1xf32> loc(#loc49)
    %310 = llvm.extractelement %309[%29 : i32] : vector<1xf32> loc(#loc49)
    %311 = llvm.bitcast %297 : i32 to vector<1xf32> loc(#loc49)
    %312 = llvm.extractelement %311[%29 : i32] : vector<1xf32> loc(#loc49)
    %313 = llvm.bitcast %298 : i32 to vector<1xf32> loc(#loc49)
    %314 = llvm.extractelement %313[%29 : i32] : vector<1xf32> loc(#loc49)
    %315 = llvm.add %265, %237 : i32 loc(#loc46)
    %316 = llvm.add %315, %202 : i32 loc(#loc46)
    %317 = llvm.getelementptr %195[%316] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %318 = llvm.xor %121, %86 : i32 loc(#loc46)
    %319 = llvm.xor %318, %90 : i32 loc(#loc46)
    %320 = llvm.xor %319, %92 : i32 loc(#loc46)
    %321 = llvm.xor %320, %94 : i32 loc(#loc46)
    %322 = llvm.mul %321, %25 : i32 loc(#loc46)
    %323 = llvm.add %322, %29 : i32 loc(#loc46)
    %324 = llvm.mul %150, %27 : i32 loc(#loc46)
    %325 = llvm.add %323, %324 : i32 loc(#loc46)
    %326 = llvm.getelementptr inbounds %317[%325] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %327 = llvm.load %326 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %328 = llvm.extractelement %327[%29 : i32] : vector<1xf32> loc(#loc46)
    %329 = llvm.xor %30, %147 : i32 loc(#loc46)
    %330 = llvm.xor %329, %149 : i32 loc(#loc46)
    %331 = llvm.mul %330, %27 : i32 loc(#loc46)
    %332 = llvm.add %323, %331 : i32 loc(#loc46)
    %333 = llvm.getelementptr inbounds %317[%332] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %334 = llvm.load %333 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %335 = llvm.extractelement %334[%29 : i32] : vector<1xf32> loc(#loc46)
    %336 = llvm.xor %19, %147 : i32 loc(#loc46)
    %337 = llvm.xor %336, %149 : i32 loc(#loc46)
    %338 = llvm.mul %337, %27 : i32 loc(#loc46)
    %339 = llvm.add %323, %338 : i32 loc(#loc46)
    %340 = llvm.getelementptr inbounds %317[%339] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %341 = llvm.load %340 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %342 = llvm.extractelement %341[%29 : i32] : vector<1xf32> loc(#loc46)
    %343 = llvm.xor %8, %147 : i32 loc(#loc46)
    %344 = llvm.xor %343, %149 : i32 loc(#loc46)
    %345 = llvm.mul %344, %27 : i32 loc(#loc46)
    %346 = llvm.add %323, %345 : i32 loc(#loc46)
    %347 = llvm.getelementptr inbounds %317[%346] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %348 = llvm.load %347 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %349 = llvm.extractelement %348[%29 : i32] : vector<1xf32> loc(#loc46)
    %350 = llvm.xor %26, %118 : i32 loc(#loc46)
    %351 = llvm.xor %350, %120 : i32 loc(#loc46)
    %352 = llvm.xor %351, %86 : i32 loc(#loc46)
    %353 = llvm.xor %352, %90 : i32 loc(#loc46)
    %354 = llvm.xor %353, %92 : i32 loc(#loc46)
    %355 = llvm.xor %354, %94 : i32 loc(#loc46)
    %356 = llvm.mul %355, %25 : i32 loc(#loc46)
    %357 = llvm.add %356, %29 : i32 loc(#loc46)
    %358 = llvm.add %357, %324 : i32 loc(#loc46)
    %359 = llvm.getelementptr inbounds %317[%358] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %360 = llvm.load %359 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %361 = llvm.extractelement %360[%29 : i32] : vector<1xf32> loc(#loc46)
    %362 = llvm.add %357, %331 : i32 loc(#loc46)
    %363 = llvm.getelementptr inbounds %317[%362] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %364 = llvm.load %363 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %365 = llvm.extractelement %364[%29 : i32] : vector<1xf32> loc(#loc46)
    %366 = llvm.add %357, %338 : i32 loc(#loc46)
    %367 = llvm.getelementptr inbounds %317[%366] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %368 = llvm.load %367 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %369 = llvm.extractelement %368[%29 : i32] : vector<1xf32> loc(#loc46)
    %370 = llvm.add %357, %345 : i32 loc(#loc46)
    %371 = llvm.getelementptr inbounds %317[%370] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %372 = llvm.load %371 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %373 = llvm.extractelement %372[%29 : i32] : vector<1xf32> loc(#loc46)
    %374 = llvm.insertelement %300, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %375 = llvm.bitcast %374 : vector<1xf32> to i32 loc(#loc51)
    %376 = llvm.insertelement %302, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %377 = llvm.bitcast %376 : vector<1xf32> to i32 loc(#loc51)
    %378 = llvm.insertelement %304, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %379 = llvm.bitcast %378 : vector<1xf32> to i32 loc(#loc51)
    %380 = llvm.insertelement %306, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %381 = llvm.bitcast %380 : vector<1xf32> to i32 loc(#loc51)
    %382 = llvm.insertelement %308, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %383 = llvm.bitcast %382 : vector<1xf32> to i32 loc(#loc51)
    %384 = llvm.insertelement %310, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %385 = llvm.bitcast %384 : vector<1xf32> to i32 loc(#loc51)
    %386 = llvm.insertelement %312, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %387 = llvm.bitcast %386 : vector<1xf32> to i32 loc(#loc51)
    %388 = llvm.insertelement %314, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %389 = llvm.bitcast %388 : vector<1xf32> to i32 loc(#loc51)
    %390 = llvm.insertelement %328, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %391 = llvm.bitcast %390 : vector<1xf32> to i32 loc(#loc51)
    %392 = llvm.insertelement %335, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %393 = llvm.bitcast %392 : vector<1xf32> to i32 loc(#loc51)
    %394 = llvm.insertelement %342, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %395 = llvm.bitcast %394 : vector<1xf32> to i32 loc(#loc51)
    %396 = llvm.insertelement %349, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %397 = llvm.bitcast %396 : vector<1xf32> to i32 loc(#loc51)
    %398 = llvm.insertelement %361, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %399 = llvm.bitcast %398 : vector<1xf32> to i32 loc(#loc51)
    %400 = llvm.insertelement %365, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %401 = llvm.bitcast %400 : vector<1xf32> to i32 loc(#loc51)
    %402 = llvm.insertelement %369, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %403 = llvm.bitcast %402 : vector<1xf32> to i32 loc(#loc51)
    %404 = llvm.insertelement %373, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %405 = llvm.bitcast %404 : vector<1xf32> to i32 loc(#loc51)
    %406 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %407 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %408 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %409 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %410 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %411 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %412 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %413 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %414 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %406, %407, %408, %409, %375, %377, %379, %381, %391, %393 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %415 = llvm.extractvalue %414[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %416 = llvm.extractvalue %414[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %417 = llvm.extractvalue %414[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %418 = llvm.extractvalue %414[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %419 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %410, %411, %412, %413, %375, %377, %379, %381, %399, %401 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %420 = llvm.extractvalue %419[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %421 = llvm.extractvalue %419[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %422 = llvm.extractvalue %419[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %423 = llvm.extractvalue %419[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %424 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %415, %416, %417, %418, %383, %385, %387, %389, %395, %397 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %425 = llvm.extractvalue %424[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %426 = llvm.extractvalue %424[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %427 = llvm.extractvalue %424[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %428 = llvm.extractvalue %424[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %429 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %420, %421, %422, %423, %383, %385, %387, %389, %403, %405 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %430 = llvm.extractvalue %429[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %431 = llvm.extractvalue %429[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %432 = llvm.extractvalue %429[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %433 = llvm.extractvalue %429[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %434 = llvm.insertvalue %425, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %435 = llvm.insertvalue %426, %434[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %436 = llvm.insertvalue %427, %435[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %437 = llvm.insertvalue %428, %436[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %438 = llvm.insertvalue %430, %437[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %439 = llvm.insertvalue %431, %438[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %440 = llvm.insertvalue %432, %439[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %441 = llvm.insertvalue %433, %440[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %442 = llvm.extractvalue %254[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %443 = llvm.extractvalue %254[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %444 = llvm.extractvalue %254[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %445 = llvm.extractvalue %254[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %446 = llvm.getelementptr %442[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %447 = llvm.getelementptr %443[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %448 = llvm.getelementptr %444[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %449 = llvm.getelementptr %445[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %450 = llvm.insertvalue %446, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %451 = llvm.insertvalue %447, %450[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %452 = llvm.insertvalue %448, %451[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %453 = llvm.insertvalue %449, %452[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %454 = llvm.extractvalue %255[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %455 = llvm.extractvalue %255[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %456 = llvm.extractvalue %255[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %457 = llvm.extractvalue %255[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %458 = llvm.getelementptr %454[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %459 = llvm.getelementptr %455[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %460 = llvm.getelementptr %456[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %461 = llvm.getelementptr %457[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %462 = llvm.insertvalue %458, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %463 = llvm.insertvalue %459, %462[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %464 = llvm.insertvalue %460, %463[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %465 = llvm.insertvalue %461, %464[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %466 = llvm.add %256, %25 : i32 loc(#loc47)
    %467 = llvm.icmp "slt" %466, %25 : i32 loc(#loc47)
    %468 = llvm.select %467, %466, %29 : i1, i32 loc(#loc47)
    %469 = llvm.add %252, %25 : i32 loc(#loc47)
    %470 = llvm.mul %469, %26 : i32 loc(#loc54)
    %471 = llvm.sub %arg5, %470 : i32 loc(#loc55)
    %472 = llvm.icmp "slt" %156, %471 : i32 loc(#loc48)
    %473 = llvm.mul %468, %11 : i32 loc(#loc49)
    %474 = llvm.add %473, %29 : i32 loc(#loc49)
    %475 = llvm.add %474, %200 : i32 loc(#loc49)
    %476 = llvm.add %475, %202 : i32 loc(#loc49)
    %477 = llvm.getelementptr %12[%476] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %478 = llvm.and %260, %472 : i1 loc(#loc47)
    nvvm.barrier0 loc(#loc49)
    %479 = llvm.getelementptr inbounds %477[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %480 = llvm.getelementptr inbounds %477[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %481 = llvm.getelementptr inbounds %477[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %482 = llvm.getelementptr inbounds %477[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %483 = llvm.select %478, %30, %29 : i1, i32 loc(#loc49)
    %484 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %479, %446, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %485 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %480, %447, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %486 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %481, %448, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %487 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %482, %449, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %488 = llvm.icmp "slt" %178, %471 : i32 loc(#loc50)
    %489 = llvm.add %474, %237 : i32 loc(#loc46)
    %490 = llvm.add %489, %202 : i32 loc(#loc46)
    %491 = llvm.getelementptr %195[%490] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %492 = llvm.and %260, %488 : i1 loc(#loc47)
    %493 = llvm.getelementptr inbounds %491[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %494 = llvm.select %492, %26, %29 : i1, i32 loc(#loc46)
    %495 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %493, %458, %494 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%469, %441, %453, %465, %468, %263 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb3:  // pred: ^bb1
    nvvm.cp.async.wait.group 0 loc(#loc47)
    nvvm.barrier0 loc(#loc47)
    %496 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %497 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %498 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %499 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %500 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %501 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %502 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %503 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %504 = llvm.fptrunc %496 : f32 to f16 loc(#loc56)
    %505 = llvm.fptrunc %497 : f32 to f16 loc(#loc56)
    %506 = llvm.fptrunc %498 : f32 to f16 loc(#loc56)
    %507 = llvm.fptrunc %499 : f32 to f16 loc(#loc56)
    %508 = llvm.fptrunc %500 : f32 to f16 loc(#loc56)
    %509 = llvm.fptrunc %501 : f32 to f16 loc(#loc56)
    %510 = llvm.fptrunc %502 : f32 to f16 loc(#loc56)
    %511 = llvm.fptrunc %503 : f32 to f16 loc(#loc56)
    %512 = llvm.mul %arg8, %128 : i32 loc(#loc57)
    %513 = llvm.getelementptr %arg2[%512] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc58)
    %514 = llvm.getelementptr %513[%138] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc59)
    %515 = llvm.icmp "slt" %128, %arg3 : i32 loc(#loc60)
    %516 = llvm.icmp "slt" %138, %arg4 : i32 loc(#loc61)
    %517 = llvm.and %515, %516 : i1 loc(#loc62)
    %518 = llvm.select %101, %29, %20 : i1, i32 loc(#loc63)
    %519 = llvm.xor %29, %518 : i32 loc(#loc63)
    %520 = llvm.select %105, %29, %30 : i1, i32 loc(#loc63)
    %521 = llvm.xor %519, %520 : i32 loc(#loc63)
    %522 = llvm.select %85, %29, %27 : i1, i32 loc(#loc63)
    %523 = llvm.xor %521, %522 : i32 loc(#loc63)
    %524 = llvm.select %89, %29, %5 : i1, i32 loc(#loc63)
    %525 = llvm.xor %523, %524 : i32 loc(#loc63)
    %526 = llvm.select %65, %29, %10 : i1, i32 loc(#loc63)
    %527 = llvm.xor %525, %526 : i32 loc(#loc63)
    %528 = llvm.xor %527, %94 : i32 loc(#loc63)
    %529 = llvm.select %73, %29, %11 : i1, i32 loc(#loc63)
    %530 = llvm.xor %528, %529 : i32 loc(#loc63)
    %531 = llvm.xor %121, %522 : i32 loc(#loc63)
    %532 = llvm.xor %531, %524 : i32 loc(#loc63)
    %533 = llvm.xor %532, %526 : i32 loc(#loc63)
    %534 = llvm.select %69, %29, %9 : i1, i32 loc(#loc63)
    %535 = llvm.xor %533, %534 : i32 loc(#loc63)
    %536 = llvm.xor %535, %529 : i32 loc(#loc63)
    %537 = llvm.xor %530, %29 : i32 loc(#loc63)
    %538 = llvm.lshr %537, %16 : i32 loc(#loc63)
    %539 = llvm.shl %538, %17 : i32 loc(#loc63)
    %540 = llvm.add %539, %537 : i32 loc(#loc63)
    %541 = llvm.getelementptr inbounds %12[%540] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %542 = llvm.insertelement %504, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %543 = llvm.insertelement %505, %542[%25 : i32] : vector<2xf16> loc(#loc63)
    %544 = llvm.extractelement %543[%29 : i32] : vector<2xf16> loc(#loc63)
    %545 = llvm.extractelement %543[%25 : i32] : vector<2xf16> loc(#loc63)
    %546 = llvm.bitcast %544 : f16 to i16 loc(#loc63)
    %547 = llvm.bitcast %545 : f16 to i16 loc(#loc63)
    %548 = llvm.insertelement %546, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %549 = llvm.insertelement %547, %548[%25 : i32] : vector<2xi16> loc(#loc63)
    %550 = llvm.extractelement %549[%29 : i32] : vector<2xi16> loc(#loc63)
    %551 = llvm.extractelement %549[%25 : i32] : vector<2xi16> loc(#loc63)
    %552 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %541, %550, %551, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %553 = llvm.xor %530, %9 : i32 loc(#loc63)
    %554 = llvm.lshr %553, %16 : i32 loc(#loc63)
    %555 = llvm.shl %554, %17 : i32 loc(#loc63)
    %556 = llvm.add %555, %553 : i32 loc(#loc63)
    %557 = llvm.getelementptr inbounds %12[%556] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %558 = llvm.insertelement %506, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %559 = llvm.insertelement %507, %558[%25 : i32] : vector<2xf16> loc(#loc63)
    %560 = llvm.extractelement %559[%29 : i32] : vector<2xf16> loc(#loc63)
    %561 = llvm.extractelement %559[%25 : i32] : vector<2xf16> loc(#loc63)
    %562 = llvm.bitcast %560 : f16 to i16 loc(#loc63)
    %563 = llvm.bitcast %561 : f16 to i16 loc(#loc63)
    %564 = llvm.insertelement %562, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %565 = llvm.insertelement %563, %564[%25 : i32] : vector<2xi16> loc(#loc63)
    %566 = llvm.extractelement %565[%29 : i32] : vector<2xi16> loc(#loc63)
    %567 = llvm.extractelement %565[%25 : i32] : vector<2xi16> loc(#loc63)
    %568 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %557, %566, %567, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %569 = llvm.xor %530, %26 : i32 loc(#loc63)
    %570 = llvm.lshr %569, %16 : i32 loc(#loc63)
    %571 = llvm.shl %570, %17 : i32 loc(#loc63)
    %572 = llvm.add %571, %569 : i32 loc(#loc63)
    %573 = llvm.getelementptr inbounds %12[%572] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %574 = llvm.insertelement %508, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %575 = llvm.insertelement %509, %574[%25 : i32] : vector<2xf16> loc(#loc63)
    %576 = llvm.extractelement %575[%29 : i32] : vector<2xf16> loc(#loc63)
    %577 = llvm.extractelement %575[%25 : i32] : vector<2xf16> loc(#loc63)
    %578 = llvm.bitcast %576 : f16 to i16 loc(#loc63)
    %579 = llvm.bitcast %577 : f16 to i16 loc(#loc63)
    %580 = llvm.insertelement %578, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %581 = llvm.insertelement %579, %580[%25 : i32] : vector<2xi16> loc(#loc63)
    %582 = llvm.extractelement %581[%29 : i32] : vector<2xi16> loc(#loc63)
    %583 = llvm.extractelement %581[%25 : i32] : vector<2xi16> loc(#loc63)
    %584 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %573, %582, %583, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %585 = llvm.xor %530, %7 : i32 loc(#loc63)
    %586 = llvm.lshr %585, %16 : i32 loc(#loc63)
    %587 = llvm.shl %586, %17 : i32 loc(#loc63)
    %588 = llvm.add %587, %585 : i32 loc(#loc63)
    %589 = llvm.getelementptr inbounds %12[%588] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %590 = llvm.insertelement %510, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %591 = llvm.insertelement %511, %590[%25 : i32] : vector<2xf16> loc(#loc63)
    %592 = llvm.extractelement %591[%29 : i32] : vector<2xf16> loc(#loc63)
    %593 = llvm.extractelement %591[%25 : i32] : vector<2xf16> loc(#loc63)
    %594 = llvm.bitcast %592 : f16 to i16 loc(#loc63)
    %595 = llvm.bitcast %593 : f16 to i16 loc(#loc63)
    %596 = llvm.insertelement %594, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %597 = llvm.insertelement %595, %596[%25 : i32] : vector<2xi16> loc(#loc63)
    %598 = llvm.extractelement %597[%29 : i32] : vector<2xi16> loc(#loc63)
    %599 = llvm.extractelement %597[%25 : i32] : vector<2xi16> loc(#loc63)
    %600 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %589, %598, %599, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    nvvm.barrier0 loc(#loc63)
    %601 = llvm.xor %536, %29 : i32 loc(#loc63)
    %602 = llvm.lshr %601, %16 : i32 loc(#loc63)
    %603 = llvm.shl %602, %17 : i32 loc(#loc63)
    %604 = llvm.add %603, %601 : i32 loc(#loc63)
    %605 = llvm.getelementptr inbounds %12[%604] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %606 = llvm.load %605 : !llvm.ptr<3> -> vector<4xi32> loc(#loc63)
    %607 = llvm.extractelement %606[%29 : i32] : vector<4xi32> loc(#loc63)
    %608 = llvm.extractelement %606[%25 : i32] : vector<4xi32> loc(#loc63)
    %609 = llvm.extractelement %606[%20 : i32] : vector<4xi32> loc(#loc63)
    %610 = llvm.extractelement %606[%17 : i32] : vector<4xi32> loc(#loc63)
    %611 = llvm.insertelement %607, %2[%29 : i32] : vector<4xi32> loc(#loc63)
    %612 = llvm.insertelement %608, %611[%25 : i32] : vector<4xi32> loc(#loc63)
    %613 = llvm.insertelement %609, %612[%20 : i32] : vector<4xi32> loc(#loc63)
    %614 = llvm.insertelement %610, %613[%17 : i32] : vector<4xi32> loc(#loc63)
    %615 = llvm.extractelement %614[%29 : i32] : vector<4xi32> loc(#loc63)
    %616 = llvm.extractelement %614[%25 : i32] : vector<4xi32> loc(#loc63)
    %617 = llvm.extractelement %614[%20 : i32] : vector<4xi32> loc(#loc63)
    %618 = llvm.extractelement %614[%17 : i32] : vector<4xi32> loc(#loc63)
    %619 = llvm.bitcast %615 : i32 to vector<2xi16> loc(#loc63)
    %620 = llvm.extractelement %619[%29 : i32] : vector<2xi16> loc(#loc63)
    %621 = llvm.extractelement %619[%25 : i32] : vector<2xi16> loc(#loc63)
    %622 = llvm.bitcast %616 : i32 to vector<2xi16> loc(#loc63)
    %623 = llvm.extractelement %622[%29 : i32] : vector<2xi16> loc(#loc63)
    %624 = llvm.extractelement %622[%25 : i32] : vector<2xi16> loc(#loc63)
    %625 = llvm.bitcast %617 : i32 to vector<2xi16> loc(#loc63)
    %626 = llvm.extractelement %625[%29 : i32] : vector<2xi16> loc(#loc63)
    %627 = llvm.extractelement %625[%25 : i32] : vector<2xi16> loc(#loc63)
    %628 = llvm.bitcast %618 : i32 to vector<2xi16> loc(#loc63)
    %629 = llvm.extractelement %628[%29 : i32] : vector<2xi16> loc(#loc63)
    %630 = llvm.extractelement %628[%25 : i32] : vector<2xi16> loc(#loc63)
    %631 = llvm.insertelement %620, %1[%29 : i32] : vector<8xi16> loc(#loc63)
    %632 = llvm.insertelement %621, %631[%25 : i32] : vector<8xi16> loc(#loc63)
    %633 = llvm.insertelement %623, %632[%20 : i32] : vector<8xi16> loc(#loc63)
    %634 = llvm.insertelement %624, %633[%17 : i32] : vector<8xi16> loc(#loc63)
    %635 = llvm.insertelement %626, %634[%30 : i32] : vector<8xi16> loc(#loc63)
    %636 = llvm.insertelement %627, %635[%16 : i32] : vector<8xi16> loc(#loc63)
    %637 = llvm.insertelement %629, %636[%15 : i32] : vector<8xi16> loc(#loc63)
    %638 = llvm.insertelement %630, %637[%14 : i32] : vector<8xi16> loc(#loc63)
    %639 = llvm.extractelement %638[%29 : i32] : vector<8xi16> loc(#loc63)
    %640 = llvm.extractelement %638[%25 : i32] : vector<8xi16> loc(#loc63)
    %641 = llvm.extractelement %638[%20 : i32] : vector<8xi16> loc(#loc63)
    %642 = llvm.extractelement %638[%17 : i32] : vector<8xi16> loc(#loc63)
    %643 = llvm.extractelement %638[%30 : i32] : vector<8xi16> loc(#loc63)
    %644 = llvm.extractelement %638[%16 : i32] : vector<8xi16> loc(#loc63)
    %645 = llvm.extractelement %638[%15 : i32] : vector<8xi16> loc(#loc63)
    %646 = llvm.extractelement %638[%14 : i32] : vector<8xi16> loc(#loc63)
    %647 = llvm.bitcast %639 : i16 to f16 loc(#loc63)
    %648 = llvm.bitcast %640 : i16 to f16 loc(#loc63)
    %649 = llvm.bitcast %641 : i16 to f16 loc(#loc63)
    %650 = llvm.bitcast %642 : i16 to f16 loc(#loc63)
    %651 = llvm.bitcast %643 : i16 to f16 loc(#loc63)
    %652 = llvm.bitcast %644 : i16 to f16 loc(#loc63)
    %653 = llvm.bitcast %645 : i16 to f16 loc(#loc63)
    %654 = llvm.bitcast %646 : i16 to f16 loc(#loc63)
    %655 = llvm.insertelement %647, %0[%29 : i32] : vector<8xf16> loc(#loc63)
    %656 = llvm.insertelement %648, %655[%25 : i32] : vector<8xf16> loc(#loc63)
    %657 = llvm.insertelement %649, %656[%20 : i32] : vector<8xf16> loc(#loc63)
    %658 = llvm.insertelement %650, %657[%17 : i32] : vector<8xf16> loc(#loc63)
    %659 = llvm.insertelement %651, %658[%30 : i32] : vector<8xf16> loc(#loc63)
    %660 = llvm.insertelement %652, %659[%16 : i32] : vector<8xf16> loc(#loc63)
    %661 = llvm.insertelement %653, %660[%15 : i32] : vector<8xf16> loc(#loc63)
    %662 = llvm.insertelement %654, %661[%14 : i32] : vector<8xf16> loc(#loc63)
    %663 = llvm.extractelement %662[%29 : i32] : vector<8xf16> loc(#loc63)
    %664 = llvm.extractelement %662[%25 : i32] : vector<8xf16> loc(#loc63)
    %665 = llvm.extractelement %662[%20 : i32] : vector<8xf16> loc(#loc63)
    %666 = llvm.extractelement %662[%17 : i32] : vector<8xf16> loc(#loc63)
    %667 = llvm.extractelement %662[%30 : i32] : vector<8xf16> loc(#loc63)
    %668 = llvm.extractelement %662[%16 : i32] : vector<8xf16> loc(#loc63)
    %669 = llvm.extractelement %662[%15 : i32] : vector<8xf16> loc(#loc63)
    %670 = llvm.extractelement %662[%14 : i32] : vector<8xf16> loc(#loc63)
    %671 = llvm.insertelement %663, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %672 = llvm.insertelement %664, %671[%25 : i32] : vector<2xf16> loc(#loc63)
    %673 = llvm.bitcast %672 : vector<2xf16> to i32 loc(#loc63)
    %674 = llvm.insertelement %665, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %675 = llvm.insertelement %666, %674[%25 : i32] : vector<2xf16> loc(#loc63)
    %676 = llvm.bitcast %675 : vector<2xf16> to i32 loc(#loc63)
    %677 = llvm.insertelement %667, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %678 = llvm.insertelement %668, %677[%25 : i32] : vector<2xf16> loc(#loc63)
    %679 = llvm.bitcast %678 : vector<2xf16> to i32 loc(#loc63)
    %680 = llvm.insertelement %669, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %681 = llvm.insertelement %670, %680[%25 : i32] : vector<2xf16> loc(#loc63)
    %682 = llvm.bitcast %681 : vector<2xf16> to i32 loc(#loc63)
    %683 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$5 st.global.v4.b32 [ $4 + 0 ], { $0, $1, $2, $3 };", "r,r,r,r,l,b" %673, %676, %679, %682, %514, %517 : (i32, i32, i32, i32, !llvm.ptr<1>, i1) -> !llvm.void loc(#loc63)
    llvm.return loc(#loc64)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:41)
#loc37 = loc("examples/kernels/binary_ops.py":159:60)
#loc38 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":160:29)
#loc41 = loc("examples/kernels/binary_ops.py":160:40)
#loc42 = loc("examples/kernels/binary_ops.py":160:52)
#loc44 = loc("examples/kernels/binary_ops.py":168:33)
#loc45 = loc("examples/kernels/binary_ops.py":177:33)
#loc46 = loc("examples/kernels/binary_ops.py":172:20)
#loc48 = loc("examples/kernels/binary_ops.py":171:51)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:51)
#loc51 = loc("examples/kernels/binary_ops.py":174:35)
#loc52 = loc("examples/kernels/binary_ops.py":176:18)
#loc53 = loc("examples/kernels/binary_ops.py":177:18)
#loc54 = loc("examples/kernels/binary_ops.py":171:59)
#loc55 = loc("examples/kernels/binary_ops.py":171:55)
#loc56 = loc("examples/kernels/binary_ops.py":182:23)
#loc57 = loc("examples/kernels/binary_ops.py":188:33)
#loc58 = loc("examples/kernels/binary_ops.py":188:21)
#loc59 = loc("examples/kernels/binary_ops.py":188:52)
#loc60 = loc("examples/kernels/binary_ops.py":189:33)
#loc61 = loc("examples/kernels/binary_ops.py":189:58)
#loc62 = loc("examples/kernels/binary_ops.py":189:39)
#loc63 = loc("examples/kernels/binary_ops.py":190:21)
#loc64 = loc("examples/kernels/binary_ops.py":190:4)
#loc65 = loc(callsite(#loc3 at #loc4))
#loc66 = loc(callsite(#loc5 at #loc4))
#loc67 = loc(callsite(#loc3 at #loc6))
#loc68 = loc(callsite(#loc5 at #loc6))
#loc69 = loc(callsite(#loc3 at #loc44))
#loc70 = loc(callsite(#loc5 at #loc44))


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc39 = loc("examples/kernels/binary_ops.py":159:22)
#loc43 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
module attributes {ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @matmul_kernel(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg9: !llvm.ptr<1> loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.undef : vector<8xf16> loc(#loc1)
    %1 = llvm.mlir.undef : vector<8xi16> loc(#loc1)
    %2 = llvm.mlir.undef : vector<4xi32> loc(#loc1)
    %3 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %4 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %5 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.undef : vector<1xf32> loc(#loc1)
    %7 = llvm.mlir.constant(272 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.constant(256 : i32) : i32 loc(#loc1)
    %10 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(512 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %13 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc1)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(6 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %22 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc1)
    %23 = llvm.mlir.constant(15 : i32) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(31 : i32) : i32 loc(#loc1)
    %25 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %26 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %27 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %28 = llvm.mlir.constant(true) : i1 loc(#loc1)
    %29 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %30 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %31 = llvm.mlir.constant(-1 : i32) : i32 loc(#loc1)
    %32 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %33 = llvm.insertvalue %32, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %34 = llvm.insertvalue %32, %33[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %35 = llvm.insertvalue %32, %34[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %36 = llvm.insertvalue %32, %35[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %37 = llvm.insertvalue %32, %36[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %38 = llvm.insertvalue %32, %37[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %39 = llvm.insertvalue %32, %38[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %40 = llvm.insertvalue %32, %39[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %41 = llvm.call_intrinsic "llvm.nvvm.read.ptx.sreg.ctaid.x"() : () -> i32 loc(#loc2)
    %42 = llvm.add %arg3, %24 : i32 loc(#loc65)
    %43 = llvm.sdiv %42, %27 : i32 loc(#loc66)
    %44 = llvm.add %arg4, %24 : i32 loc(#loc67)
    %45 = llvm.sdiv %44, %27 : i32 loc(#loc68)
    %46 = llvm.mul %45, %30 : i32 loc(#loc7)
    %47 = llvm.sdiv %41, %46 : i32 loc(#loc8)
    %48 = llvm.mul %47, %30 : i32 loc(#loc9)
    %49 = llvm.sub %43, %48 : i32 loc(#loc10)
    %50 = llvm.intr.smin(%49, %30) : (i32, i32) -> i32 loc(#loc11)
    %51 = llvm.srem %41, %46 : i32 loc(#loc12)
    %52 = llvm.srem %51, %50 : i32 loc(#loc13)
    %53 = llvm.add %48, %52 : i32 loc(#loc14)
    %54 = llvm.sdiv %51, %50 : i32 loc(#loc15)
    %55 = llvm.icmp "sge" %53, %29 : i32 loc(#loc16)
    llvm.intr.assume %55 : i1 loc(#loc17)
    %56 = llvm.icmp "sge" %54, %29 : i32 loc(#loc18)
    llvm.intr.assume %56 : i1 loc(#loc19)
    %57 = llvm.icmp "sgt" %arg6, %29 : i32 loc(#loc20)
    llvm.intr.assume %57 : i1 loc(#loc21)
    llvm.intr.assume %28 : i1 loc(#loc22)
    llvm.intr.assume %28 : i1 loc(#loc23)
    %58 = llvm.icmp "sgt" %arg7, %29 : i32 loc(#loc24)
    llvm.intr.assume %58 : i1 loc(#loc25)
    %59 = llvm.icmp "sgt" %arg8, %29 : i32 loc(#loc26)
    llvm.intr.assume %59 : i1 loc(#loc27)
    llvm.intr.assume %28 : i1 loc(#loc28)
    %60 = llvm.mul %53, %27 : i32 loc(#loc29)
    %61 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc30)
    %62 = llvm.urem %61, %27 : i32 loc(#loc30)
    %63 = llvm.udiv %61, %27 : i32 loc(#loc30)
    %64 = llvm.and %62, %26 : i32 loc(#loc30)
    %65 = llvm.icmp "eq" %64, %29 : i32 loc(#loc30)
    %66 = llvm.select %65, %29, %25 : i1, i32 loc(#loc30)
    %67 = llvm.xor %29, %66 : i32 loc(#loc30)
    %68 = llvm.and %63, %25 : i32 loc(#loc30)
    %69 = llvm.icmp "eq" %68, %29 : i32 loc(#loc30)
    %70 = llvm.select %69, %29, %20 : i1, i32 loc(#loc30)
    %71 = llvm.xor %67, %70 : i32 loc(#loc30)
    %72 = llvm.and %63, %20 : i32 loc(#loc30)
    %73 = llvm.icmp "eq" %72, %29 : i32 loc(#loc30)
    %74 = llvm.select %73, %29, %30 : i1, i32 loc(#loc30)
    %75 = llvm.xor %71, %74 : i32 loc(#loc30)
    %76 = llvm.xor %75, %29 : i32 loc(#loc30)
    %77 = llvm.xor %75, %19 : i32 loc(#loc30)
    %78 = llvm.xor %75, %26 : i32 loc(#loc30)
    %79 = llvm.xor %75, %18 : i32 loc(#loc30)
    %80 = llvm.add %76, %21 : i32 loc(#loc30)
    %81 = llvm.add %77, %21 : i32 loc(#loc30)
    %82 = llvm.add %78, %21 : i32 loc(#loc30)
    %83 = llvm.add %79, %21 : i32 loc(#loc30)
    %84 = llvm.and %62, %30 : i32 loc(#loc30)
    %85 = llvm.icmp "eq" %84, %29 : i32 loc(#loc30)
    %86 = llvm.select %85, %29, %25 : i1, i32 loc(#loc30)
    %87 = llvm.xor %29, %86 : i32 loc(#loc30)
    %88 = llvm.and %62, %19 : i32 loc(#loc30)
    %89 = llvm.icmp "eq" %88, %29 : i32 loc(#loc30)
    %90 = llvm.select %89, %29, %20 : i1, i32 loc(#loc30)
    %91 = llvm.xor %87, %90 : i32 loc(#loc30)
    %92 = llvm.select %65, %29, %30 : i1, i32 loc(#loc30)
    %93 = llvm.xor %91, %92 : i32 loc(#loc30)
    %94 = llvm.select %69, %29, %19 : i1, i32 loc(#loc30)
    %95 = llvm.xor %93, %94 : i32 loc(#loc30)
    %96 = llvm.select %73, %29, %26 : i1, i32 loc(#loc30)
    %97 = llvm.xor %95, %96 : i32 loc(#loc30)
    %98 = llvm.xor %97, %29 : i32 loc(#loc30)
    %99 = llvm.add %98, %21 : i32 loc(#loc30)
    %100 = llvm.and %62, %25 : i32 loc(#loc30)
    %101 = llvm.icmp "eq" %100, %29 : i32 loc(#loc30)
    %102 = llvm.select %101, %29, %30 : i1, i32 loc(#loc30)
    %103 = llvm.xor %29, %102 : i32 loc(#loc30)
    %104 = llvm.and %62, %20 : i32 loc(#loc30)
    %105 = llvm.icmp "eq" %104, %29 : i32 loc(#loc30)
    %106 = llvm.select %105, %29, %19 : i1, i32 loc(#loc30)
    %107 = llvm.xor %103, %106 : i32 loc(#loc30)
    %108 = llvm.select %85, %29, %26 : i1, i32 loc(#loc30)
    %109 = llvm.xor %107, %108 : i32 loc(#loc30)
    %110 = llvm.xor %109, %29 : i32 loc(#loc30)
    %111 = llvm.xor %109, %25 : i32 loc(#loc30)
    %112 = llvm.xor %109, %20 : i32 loc(#loc30)
    %113 = llvm.xor %109, %17 : i32 loc(#loc30)
    %114 = llvm.add %110, %21 : i32 loc(#loc30)
    %115 = llvm.add %111, %21 : i32 loc(#loc30)
    %116 = llvm.add %112, %21 : i32 loc(#loc30)
    %117 = llvm.add %113, %21 : i32 loc(#loc30)
    %118 = llvm.select %101, %29, %19 : i1, i32 loc(#loc30)
    %119 = llvm.xor %29, %118 : i32 loc(#loc30)
    %120 = llvm.select %105, %29, %26 : i1, i32 loc(#loc30)
    %121 = llvm.xor %119, %120 : i32 loc(#loc30)
    %122 = llvm.xor %121, %29 : i32 loc(#loc30)
    %123 = llvm.add %122, %21 : i32 loc(#loc30)
    %124 = llvm.add %60, %80 : i32 loc(#loc31)
    %125 = llvm.add %60, %81 : i32 loc(#loc31)
    %126 = llvm.add %60, %82 : i32 loc(#loc31)
    %127 = llvm.add %60, %83 : i32 loc(#loc31)
    %128 = llvm.add %60, %99 : i32 loc(#loc31)
    %129 = llvm.srem %124, %arg3 : i32 loc(#loc32)
    %130 = llvm.srem %125, %arg3 : i32 loc(#loc32)
    %131 = llvm.srem %126, %arg3 : i32 loc(#loc32)
    %132 = llvm.srem %127, %arg3 : i32 loc(#loc32)
    %133 = llvm.mul %54, %27 : i32 loc(#loc33)
    %134 = llvm.add %133, %114 : i32 loc(#loc34)
    %135 = llvm.add %133, %115 : i32 loc(#loc34)
    %136 = llvm.add %133, %116 : i32 loc(#loc34)
    %137 = llvm.add %133, %117 : i32 loc(#loc34)
    %138 = llvm.add %133, %123 : i32 loc(#loc34)
    %139 = llvm.srem %134, %arg4 : i32 loc(#loc35)
    %140 = llvm.srem %135, %arg4 : i32 loc(#loc35)
    %141 = llvm.srem %136, %arg4 : i32 loc(#loc35)
    %142 = llvm.srem %137, %arg4 : i32 loc(#loc35)
    %143 = llvm.mul %129, %arg6 : i32 loc(#loc36)
    %144 = llvm.mul %130, %arg6 : i32 loc(#loc36)
    %145 = llvm.mul %131, %arg6 : i32 loc(#loc36)
    %146 = llvm.mul %132, %arg6 : i32 loc(#loc36)
    %147 = llvm.select %101, %29, %25 : i1, i32 loc(#loc37)
    %148 = llvm.xor %29, %147 : i32 loc(#loc37)
    %149 = llvm.select %105, %29, %20 : i1, i32 loc(#loc37)
    %150 = llvm.xor %148, %149 : i32 loc(#loc37)
    %151 = llvm.select %85, %29, %30 : i1, i32 loc(#loc37)
    %152 = llvm.xor %150, %151 : i32 loc(#loc37)
    %153 = llvm.select %89, %29, %19 : i1, i32 loc(#loc37)
    %154 = llvm.xor %152, %153 : i32 loc(#loc37)
    %155 = llvm.xor %154, %29 : i32 loc(#loc37)
    %156 = llvm.add %155, %21 : i32 loc(#loc37)
    %157 = llvm.add %143, %156 : i32 loc(#loc38)
    %158 = llvm.add %144, %156 : i32 loc(#loc38)
    %159 = llvm.add %145, %156 : i32 loc(#loc38)
    %160 = llvm.add %146, %156 : i32 loc(#loc38)
    %161 = llvm.getelementptr %arg0[%157] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %162 = llvm.getelementptr %arg0[%158] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %163 = llvm.getelementptr %arg0[%159] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %164 = llvm.getelementptr %arg0[%160] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %165 = llvm.insertvalue %161, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %166 = llvm.insertvalue %162, %165[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %167 = llvm.insertvalue %163, %166[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %168 = llvm.insertvalue %164, %167[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %169 = llvm.select %89, %29, %25 : i1, i32 loc(#loc40)
    %170 = llvm.xor %29, %169 : i32 loc(#loc40)
    %171 = llvm.select %65, %29, %20 : i1, i32 loc(#loc40)
    %172 = llvm.xor %170, %171 : i32 loc(#loc40)
    %173 = llvm.select %69, %29, %30 : i1, i32 loc(#loc40)
    %174 = llvm.xor %172, %173 : i32 loc(#loc40)
    %175 = llvm.select %73, %29, %19 : i1, i32 loc(#loc40)
    %176 = llvm.xor %174, %175 : i32 loc(#loc40)
    %177 = llvm.xor %176, %29 : i32 loc(#loc40)
    %178 = llvm.add %177, %21 : i32 loc(#loc40)
    %179 = llvm.mul %178, %arg7 : i32 loc(#loc41)
    %180 = llvm.add %179, %139 : i32 loc(#loc42)
    %181 = llvm.add %179, %140 : i32 loc(#loc42)
    %182 = llvm.add %179, %141 : i32 loc(#loc42)
    %183 = llvm.add %179, %142 : i32 loc(#loc42)
    %184 = llvm.getelementptr %arg1[%180] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %185 = llvm.getelementptr %arg1[%181] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %186 = llvm.getelementptr %arg1[%182] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %187 = llvm.getelementptr %arg1[%183] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %188 = llvm.insertvalue %184, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %189 = llvm.insertvalue %185, %188[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %190 = llvm.insertvalue %186, %189[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %191 = llvm.insertvalue %187, %190[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %192 = llvm.add %arg5, %23 : i32 loc(#loc69)
    %193 = llvm.sdiv %192, %26 : i32 loc(#loc70)
    %194 = llvm.mul %arg7, %26 : i32 loc(#loc45)
    %195 = llvm.getelementptr %12[2048] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc46)
    %196 = llvm.icmp "sgt" %193, %29 : i32 loc(#loc47)
    %197 = llvm.icmp "slt" %156, %arg5 : i32 loc(#loc48)
    %198 = llvm.mul %29, %11 : i32 loc(#loc49)
    %199 = llvm.add %198, %29 : i32 loc(#loc49)
    %200 = llvm.mul %29, %26 : i32 loc(#loc49)
    %201 = llvm.add %199, %200 : i32 loc(#loc49)
    %202 = llvm.mul %29, %25 : i32 loc(#loc49)
    %203 = llvm.add %201, %202 : i32 loc(#loc49)
    %204 = llvm.getelementptr %12[%203] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %205 = llvm.and %196, %197 : i1 loc(#loc47)
    %206 = llvm.xor %154, %173 : i32 loc(#loc49)
    %207 = llvm.xor %206, %175 : i32 loc(#loc49)
    %208 = llvm.mul %207, %25 : i32 loc(#loc49)
    %209 = llvm.add %208, %29 : i32 loc(#loc49)
    %210 = llvm.mul %75, %26 : i32 loc(#loc49)
    %211 = llvm.add %209, %210 : i32 loc(#loc49)
    %212 = llvm.getelementptr inbounds %204[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %213 = llvm.xor %19, %66 : i32 loc(#loc49)
    %214 = llvm.xor %213, %70 : i32 loc(#loc49)
    %215 = llvm.xor %214, %74 : i32 loc(#loc49)
    %216 = llvm.mul %215, %26 : i32 loc(#loc49)
    %217 = llvm.add %209, %216 : i32 loc(#loc49)
    %218 = llvm.getelementptr inbounds %204[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %219 = llvm.xor %26, %66 : i32 loc(#loc49)
    %220 = llvm.xor %219, %70 : i32 loc(#loc49)
    %221 = llvm.xor %220, %74 : i32 loc(#loc49)
    %222 = llvm.mul %221, %26 : i32 loc(#loc49)
    %223 = llvm.add %209, %222 : i32 loc(#loc49)
    %224 = llvm.getelementptr inbounds %204[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %225 = llvm.xor %18, %66 : i32 loc(#loc49)
    %226 = llvm.xor %225, %70 : i32 loc(#loc49)
    %227 = llvm.xor %226, %74 : i32 loc(#loc49)
    %228 = llvm.mul %227, %26 : i32 loc(#loc49)
    %229 = llvm.add %209, %228 : i32 loc(#loc49)
    %230 = llvm.getelementptr inbounds %204[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %231 = llvm.select %205, %30, %29 : i1, i32 loc(#loc49)
    %232 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %212, %161, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %233 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %218, %162, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %234 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %224, %163, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %235 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %230, %164, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %236 = llvm.icmp "slt" %178, %arg5 : i32 loc(#loc50)
    %237 = llvm.mul %29, %27 : i32 loc(#loc46)
    %238 = llvm.add %199, %237 : i32 loc(#loc46)
    %239 = llvm.add %238, %202 : i32 loc(#loc46)
    %240 = llvm.getelementptr %195[%239] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %241 = llvm.and %196, %236 : i1 loc(#loc47)
    %242 = llvm.xor %109, %153 : i32 loc(#loc46)
    %243 = llvm.select %65, %29, %26 : i1, i32 loc(#loc46)
    %244 = llvm.xor %242, %243 : i32 loc(#loc46)
    %245 = llvm.mul %244, %25 : i32 loc(#loc46)
    %246 = llvm.add %245, %29 : i32 loc(#loc46)
    %247 = llvm.mul %176, %27 : i32 loc(#loc46)
    %248 = llvm.add %246, %247 : i32 loc(#loc46)
    %249 = llvm.getelementptr inbounds %240[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %250 = llvm.select %241, %26, %29 : i1, i32 loc(#loc46)
    %251 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %249, %184, %250 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%29, %40, %168, %191, %29, %31 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb1(%252: i32 loc("examples/kernels/binary_ops.py":168:22), %253: !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(unknown), %254: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":159:22), %255: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":160:22), %256: i32 loc(unknown), %257: i32 loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %258 = llvm.icmp "slt" %252, %193 : i32 loc(#loc47)
    llvm.cond_br %258, ^bb2, ^bb3 loc(#loc47)
  ^bb2:  // pred: ^bb1
    %259 = llvm.sub %193, %25 : i32 loc(#loc47)
    %260 = llvm.icmp "slt" %252, %259 : i32 loc(#loc47)
    %261 = llvm.add %257, %25 : i32 loc(#loc47)
    %262 = llvm.icmp "slt" %261, %25 : i32 loc(#loc47)
    %263 = llvm.select %262, %261, %29 : i1, i32 loc(#loc47)
    nvvm.cp.async.wait.group 0 loc(#loc49)
    nvvm.barrier0 loc(#loc49)
    %264 = llvm.mul %263, %11 : i32 loc(#loc49)
    %265 = llvm.add %264, %29 : i32 loc(#loc49)
    %266 = llvm.add %265, %200 : i32 loc(#loc49)
    %267 = llvm.add %266, %202 : i32 loc(#loc49)
    %268 = llvm.getelementptr %12[%267] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %269 = llvm.select %105, %29, %30 : i1, i32 loc(#loc49)
    %270 = llvm.xor %29, %269 : i32 loc(#loc49)
    %271 = llvm.select %85, %29, %19 : i1, i32 loc(#loc49)
    %272 = llvm.xor %270, %271 : i32 loc(#loc49)
    %273 = llvm.xor %272, %92 : i32 loc(#loc49)
    %274 = llvm.xor %154, %96 : i32 loc(#loc49)
    %275 = llvm.mul %273, %25 : i32 loc(#loc49)
    %276 = llvm.add %275, %29 : i32 loc(#loc49)
    %277 = llvm.mul %274, %26 : i32 loc(#loc49)
    %278 = llvm.add %276, %277 : i32 loc(#loc49)
    %279 = llvm.getelementptr inbounds %268[%278] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %280 = llvm.ptrtoint %279 : !llvm.ptr<3> to i32 loc(#loc49)
    %281 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %280 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %282 = llvm.extractvalue %281[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %283 = llvm.extractvalue %281[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %284 = llvm.extractvalue %281[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %285 = llvm.extractvalue %281[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %286 = llvm.xor %19, %269 : i32 loc(#loc49)
    %287 = llvm.xor %286, %271 : i32 loc(#loc49)
    %288 = llvm.xor %287, %92 : i32 loc(#loc49)
    %289 = llvm.mul %288, %25 : i32 loc(#loc49)
    %290 = llvm.add %289, %29 : i32 loc(#loc49)
    %291 = llvm.add %290, %277 : i32 loc(#loc49)
    %292 = llvm.getelementptr inbounds %268[%291] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %293 = llvm.ptrtoint %292 : !llvm.ptr<3> to i32 loc(#loc49)
    %294 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %293 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %295 = llvm.extractvalue %294[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %296 = llvm.extractvalue %294[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %297 = llvm.extractvalue %294[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %298 = llvm.extractvalue %294[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %299 = llvm.bitcast %282 : i32 to vector<1xf32> loc(#loc49)
    %300 = llvm.extractelement %299[%29 : i32] : vector<1xf32> loc(#loc49)
    %301 = llvm.bitcast %283 : i32 to vector<1xf32> loc(#loc49)
    %302 = llvm.extractelement %301[%29 : i32] : vector<1xf32> loc(#loc49)
    %303 = llvm.bitcast %284 : i32 to vector<1xf32> loc(#loc49)
    %304 = llvm.extractelement %303[%29 : i32] : vector<1xf32> loc(#loc49)
    %305 = llvm.bitcast %285 : i32 to vector<1xf32> loc(#loc49)
    %306 = llvm.extractelement %305[%29 : i32] : vector<1xf32> loc(#loc49)
    %307 = llvm.bitcast %295 : i32 to vector<1xf32> loc(#loc49)
    %308 = llvm.extractelement %307[%29 : i32] : vector<1xf32> loc(#loc49)
    %309 = llvm.bitcast %296 : i32 to vector<1xf32> loc(#loc49)
    %310 = llvm.extractelement %309[%29 : i32] : vector<1xf32> loc(#loc49)
    %311 = llvm.bitcast %297 : i32 to vector<1xf32> loc(#loc49)
    %312 = llvm.extractelement %311[%29 : i32] : vector<1xf32> loc(#loc49)
    %313 = llvm.bitcast %298 : i32 to vector<1xf32> loc(#loc49)
    %314 = llvm.extractelement %313[%29 : i32] : vector<1xf32> loc(#loc49)
    %315 = llvm.add %265, %237 : i32 loc(#loc46)
    %316 = llvm.add %315, %202 : i32 loc(#loc46)
    %317 = llvm.getelementptr %195[%316] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %318 = llvm.xor %121, %86 : i32 loc(#loc46)
    %319 = llvm.xor %318, %90 : i32 loc(#loc46)
    %320 = llvm.xor %319, %92 : i32 loc(#loc46)
    %321 = llvm.xor %320, %94 : i32 loc(#loc46)
    %322 = llvm.mul %321, %25 : i32 loc(#loc46)
    %323 = llvm.add %322, %29 : i32 loc(#loc46)
    %324 = llvm.mul %150, %27 : i32 loc(#loc46)
    %325 = llvm.add %323, %324 : i32 loc(#loc46)
    %326 = llvm.getelementptr inbounds %317[%325] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %327 = llvm.load %326 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %328 = llvm.extractelement %327[%29 : i32] : vector<1xf32> loc(#loc46)
    %329 = llvm.xor %30, %147 : i32 loc(#loc46)
    %330 = llvm.xor %329, %149 : i32 loc(#loc46)
    %331 = llvm.mul %330, %27 : i32 loc(#loc46)
    %332 = llvm.add %323, %331 : i32 loc(#loc46)
    %333 = llvm.getelementptr inbounds %317[%332] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %334 = llvm.load %333 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %335 = llvm.extractelement %334[%29 : i32] : vector<1xf32> loc(#loc46)
    %336 = llvm.xor %19, %147 : i32 loc(#loc46)
    %337 = llvm.xor %336, %149 : i32 loc(#loc46)
    %338 = llvm.mul %337, %27 : i32 loc(#loc46)
    %339 = llvm.add %323, %338 : i32 loc(#loc46)
    %340 = llvm.getelementptr inbounds %317[%339] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %341 = llvm.load %340 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %342 = llvm.extractelement %341[%29 : i32] : vector<1xf32> loc(#loc46)
    %343 = llvm.xor %8, %147 : i32 loc(#loc46)
    %344 = llvm.xor %343, %149 : i32 loc(#loc46)
    %345 = llvm.mul %344, %27 : i32 loc(#loc46)
    %346 = llvm.add %323, %345 : i32 loc(#loc46)
    %347 = llvm.getelementptr inbounds %317[%346] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %348 = llvm.load %347 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %349 = llvm.extractelement %348[%29 : i32] : vector<1xf32> loc(#loc46)
    %350 = llvm.xor %26, %118 : i32 loc(#loc46)
    %351 = llvm.xor %350, %120 : i32 loc(#loc46)
    %352 = llvm.xor %351, %86 : i32 loc(#loc46)
    %353 = llvm.xor %352, %90 : i32 loc(#loc46)
    %354 = llvm.xor %353, %92 : i32 loc(#loc46)
    %355 = llvm.xor %354, %94 : i32 loc(#loc46)
    %356 = llvm.mul %355, %25 : i32 loc(#loc46)
    %357 = llvm.add %356, %29 : i32 loc(#loc46)
    %358 = llvm.add %357, %324 : i32 loc(#loc46)
    %359 = llvm.getelementptr inbounds %317[%358] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %360 = llvm.load %359 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %361 = llvm.extractelement %360[%29 : i32] : vector<1xf32> loc(#loc46)
    %362 = llvm.add %357, %331 : i32 loc(#loc46)
    %363 = llvm.getelementptr inbounds %317[%362] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %364 = llvm.load %363 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %365 = llvm.extractelement %364[%29 : i32] : vector<1xf32> loc(#loc46)
    %366 = llvm.add %357, %338 : i32 loc(#loc46)
    %367 = llvm.getelementptr inbounds %317[%366] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %368 = llvm.load %367 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %369 = llvm.extractelement %368[%29 : i32] : vector<1xf32> loc(#loc46)
    %370 = llvm.add %357, %345 : i32 loc(#loc46)
    %371 = llvm.getelementptr inbounds %317[%370] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %372 = llvm.load %371 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %373 = llvm.extractelement %372[%29 : i32] : vector<1xf32> loc(#loc46)
    %374 = llvm.insertelement %300, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %375 = llvm.bitcast %374 : vector<1xf32> to i32 loc(#loc51)
    %376 = llvm.insertelement %302, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %377 = llvm.bitcast %376 : vector<1xf32> to i32 loc(#loc51)
    %378 = llvm.insertelement %304, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %379 = llvm.bitcast %378 : vector<1xf32> to i32 loc(#loc51)
    %380 = llvm.insertelement %306, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %381 = llvm.bitcast %380 : vector<1xf32> to i32 loc(#loc51)
    %382 = llvm.insertelement %308, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %383 = llvm.bitcast %382 : vector<1xf32> to i32 loc(#loc51)
    %384 = llvm.insertelement %310, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %385 = llvm.bitcast %384 : vector<1xf32> to i32 loc(#loc51)
    %386 = llvm.insertelement %312, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %387 = llvm.bitcast %386 : vector<1xf32> to i32 loc(#loc51)
    %388 = llvm.insertelement %314, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %389 = llvm.bitcast %388 : vector<1xf32> to i32 loc(#loc51)
    %390 = llvm.insertelement %328, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %391 = llvm.bitcast %390 : vector<1xf32> to i32 loc(#loc51)
    %392 = llvm.insertelement %335, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %393 = llvm.bitcast %392 : vector<1xf32> to i32 loc(#loc51)
    %394 = llvm.insertelement %342, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %395 = llvm.bitcast %394 : vector<1xf32> to i32 loc(#loc51)
    %396 = llvm.insertelement %349, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %397 = llvm.bitcast %396 : vector<1xf32> to i32 loc(#loc51)
    %398 = llvm.insertelement %361, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %399 = llvm.bitcast %398 : vector<1xf32> to i32 loc(#loc51)
    %400 = llvm.insertelement %365, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %401 = llvm.bitcast %400 : vector<1xf32> to i32 loc(#loc51)
    %402 = llvm.insertelement %369, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %403 = llvm.bitcast %402 : vector<1xf32> to i32 loc(#loc51)
    %404 = llvm.insertelement %373, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %405 = llvm.bitcast %404 : vector<1xf32> to i32 loc(#loc51)
    %406 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %407 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %408 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %409 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %410 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %411 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %412 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %413 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %414 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %406, %407, %408, %409, %375, %377, %379, %381, %391, %393 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %415 = llvm.extractvalue %414[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %416 = llvm.extractvalue %414[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %417 = llvm.extractvalue %414[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %418 = llvm.extractvalue %414[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %419 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %410, %411, %412, %413, %375, %377, %379, %381, %399, %401 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %420 = llvm.extractvalue %419[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %421 = llvm.extractvalue %419[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %422 = llvm.extractvalue %419[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %423 = llvm.extractvalue %419[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %424 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %415, %416, %417, %418, %383, %385, %387, %389, %395, %397 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %425 = llvm.extractvalue %424[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %426 = llvm.extractvalue %424[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %427 = llvm.extractvalue %424[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %428 = llvm.extractvalue %424[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %429 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %420, %421, %422, %423, %383, %385, %387, %389, %403, %405 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %430 = llvm.extractvalue %429[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %431 = llvm.extractvalue %429[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %432 = llvm.extractvalue %429[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %433 = llvm.extractvalue %429[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %434 = llvm.insertvalue %425, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %435 = llvm.insertvalue %426, %434[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %436 = llvm.insertvalue %427, %435[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %437 = llvm.insertvalue %428, %436[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %438 = llvm.insertvalue %430, %437[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %439 = llvm.insertvalue %431, %438[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %440 = llvm.insertvalue %432, %439[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %441 = llvm.insertvalue %433, %440[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %442 = llvm.extractvalue %254[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %443 = llvm.extractvalue %254[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %444 = llvm.extractvalue %254[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %445 = llvm.extractvalue %254[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %446 = llvm.getelementptr %442[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %447 = llvm.getelementptr %443[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %448 = llvm.getelementptr %444[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %449 = llvm.getelementptr %445[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %450 = llvm.insertvalue %446, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %451 = llvm.insertvalue %447, %450[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %452 = llvm.insertvalue %448, %451[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %453 = llvm.insertvalue %449, %452[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %454 = llvm.extractvalue %255[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %455 = llvm.extractvalue %255[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %456 = llvm.extractvalue %255[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %457 = llvm.extractvalue %255[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %458 = llvm.getelementptr %454[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %459 = llvm.getelementptr %455[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %460 = llvm.getelementptr %456[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %461 = llvm.getelementptr %457[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %462 = llvm.insertvalue %458, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %463 = llvm.insertvalue %459, %462[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %464 = llvm.insertvalue %460, %463[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %465 = llvm.insertvalue %461, %464[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %466 = llvm.add %256, %25 : i32 loc(#loc47)
    %467 = llvm.icmp "slt" %466, %25 : i32 loc(#loc47)
    %468 = llvm.select %467, %466, %29 : i1, i32 loc(#loc47)
    %469 = llvm.add %252, %25 : i32 loc(#loc47)
    %470 = llvm.mul %469, %26 : i32 loc(#loc54)
    %471 = llvm.sub %arg5, %470 : i32 loc(#loc55)
    %472 = llvm.icmp "slt" %156, %471 : i32 loc(#loc48)
    %473 = llvm.mul %468, %11 : i32 loc(#loc49)
    %474 = llvm.add %473, %29 : i32 loc(#loc49)
    %475 = llvm.add %474, %200 : i32 loc(#loc49)
    %476 = llvm.add %475, %202 : i32 loc(#loc49)
    %477 = llvm.getelementptr %12[%476] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %478 = llvm.and %260, %472 : i1 loc(#loc47)
    nvvm.barrier0 loc(#loc49)
    %479 = llvm.getelementptr inbounds %477[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %480 = llvm.getelementptr inbounds %477[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %481 = llvm.getelementptr inbounds %477[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %482 = llvm.getelementptr inbounds %477[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %483 = llvm.select %478, %30, %29 : i1, i32 loc(#loc49)
    %484 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %479, %446, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %485 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %480, %447, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %486 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %481, %448, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %487 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %482, %449, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %488 = llvm.icmp "slt" %178, %471 : i32 loc(#loc50)
    %489 = llvm.add %474, %237 : i32 loc(#loc46)
    %490 = llvm.add %489, %202 : i32 loc(#loc46)
    %491 = llvm.getelementptr %195[%490] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %492 = llvm.and %260, %488 : i1 loc(#loc47)
    %493 = llvm.getelementptr inbounds %491[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %494 = llvm.select %492, %26, %29 : i1, i32 loc(#loc46)
    %495 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %493, %458, %494 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%469, %441, %453, %465, %468, %263 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb3:  // pred: ^bb1
    nvvm.cp.async.wait.group 0 loc(#loc47)
    nvvm.barrier0 loc(#loc47)
    %496 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %497 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %498 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %499 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %500 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %501 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %502 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %503 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %504 = llvm.fptrunc %496 : f32 to f16 loc(#loc56)
    %505 = llvm.fptrunc %497 : f32 to f16 loc(#loc56)
    %506 = llvm.fptrunc %498 : f32 to f16 loc(#loc56)
    %507 = llvm.fptrunc %499 : f32 to f16 loc(#loc56)
    %508 = llvm.fptrunc %500 : f32 to f16 loc(#loc56)
    %509 = llvm.fptrunc %501 : f32 to f16 loc(#loc56)
    %510 = llvm.fptrunc %502 : f32 to f16 loc(#loc56)
    %511 = llvm.fptrunc %503 : f32 to f16 loc(#loc56)
    %512 = llvm.mul %arg8, %128 : i32 loc(#loc57)
    %513 = llvm.getelementptr %arg2[%512] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc58)
    %514 = llvm.getelementptr %513[%138] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc59)
    %515 = llvm.icmp "slt" %128, %arg3 : i32 loc(#loc60)
    %516 = llvm.icmp "slt" %138, %arg4 : i32 loc(#loc61)
    %517 = llvm.and %515, %516 : i1 loc(#loc62)
    %518 = llvm.select %101, %29, %20 : i1, i32 loc(#loc63)
    %519 = llvm.xor %29, %518 : i32 loc(#loc63)
    %520 = llvm.select %105, %29, %30 : i1, i32 loc(#loc63)
    %521 = llvm.xor %519, %520 : i32 loc(#loc63)
    %522 = llvm.select %85, %29, %27 : i1, i32 loc(#loc63)
    %523 = llvm.xor %521, %522 : i32 loc(#loc63)
    %524 = llvm.select %89, %29, %5 : i1, i32 loc(#loc63)
    %525 = llvm.xor %523, %524 : i32 loc(#loc63)
    %526 = llvm.select %65, %29, %10 : i1, i32 loc(#loc63)
    %527 = llvm.xor %525, %526 : i32 loc(#loc63)
    %528 = llvm.xor %527, %94 : i32 loc(#loc63)
    %529 = llvm.select %73, %29, %11 : i1, i32 loc(#loc63)
    %530 = llvm.xor %528, %529 : i32 loc(#loc63)
    %531 = llvm.xor %121, %522 : i32 loc(#loc63)
    %532 = llvm.xor %531, %524 : i32 loc(#loc63)
    %533 = llvm.xor %532, %526 : i32 loc(#loc63)
    %534 = llvm.select %69, %29, %9 : i1, i32 loc(#loc63)
    %535 = llvm.xor %533, %534 : i32 loc(#loc63)
    %536 = llvm.xor %535, %529 : i32 loc(#loc63)
    %537 = llvm.xor %530, %29 : i32 loc(#loc63)
    %538 = llvm.lshr %537, %16 : i32 loc(#loc63)
    %539 = llvm.shl %538, %17 : i32 loc(#loc63)
    %540 = llvm.add %539, %537 : i32 loc(#loc63)
    %541 = llvm.getelementptr inbounds %12[%540] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %542 = llvm.insertelement %504, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %543 = llvm.insertelement %505, %542[%25 : i32] : vector<2xf16> loc(#loc63)
    %544 = llvm.extractelement %543[%29 : i32] : vector<2xf16> loc(#loc63)
    %545 = llvm.extractelement %543[%25 : i32] : vector<2xf16> loc(#loc63)
    %546 = llvm.bitcast %544 : f16 to i16 loc(#loc63)
    %547 = llvm.bitcast %545 : f16 to i16 loc(#loc63)
    %548 = llvm.insertelement %546, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %549 = llvm.insertelement %547, %548[%25 : i32] : vector<2xi16> loc(#loc63)
    %550 = llvm.extractelement %549[%29 : i32] : vector<2xi16> loc(#loc63)
    %551 = llvm.extractelement %549[%25 : i32] : vector<2xi16> loc(#loc63)
    %552 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %541, %550, %551, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %553 = llvm.xor %530, %9 : i32 loc(#loc63)
    %554 = llvm.lshr %553, %16 : i32 loc(#loc63)
    %555 = llvm.shl %554, %17 : i32 loc(#loc63)
    %556 = llvm.add %555, %553 : i32 loc(#loc63)
    %557 = llvm.getelementptr inbounds %12[%556] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %558 = llvm.insertelement %506, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %559 = llvm.insertelement %507, %558[%25 : i32] : vector<2xf16> loc(#loc63)
    %560 = llvm.extractelement %559[%29 : i32] : vector<2xf16> loc(#loc63)
    %561 = llvm.extractelement %559[%25 : i32] : vector<2xf16> loc(#loc63)
    %562 = llvm.bitcast %560 : f16 to i16 loc(#loc63)
    %563 = llvm.bitcast %561 : f16 to i16 loc(#loc63)
    %564 = llvm.insertelement %562, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %565 = llvm.insertelement %563, %564[%25 : i32] : vector<2xi16> loc(#loc63)
    %566 = llvm.extractelement %565[%29 : i32] : vector<2xi16> loc(#loc63)
    %567 = llvm.extractelement %565[%25 : i32] : vector<2xi16> loc(#loc63)
    %568 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %557, %566, %567, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %569 = llvm.xor %530, %26 : i32 loc(#loc63)
    %570 = llvm.lshr %569, %16 : i32 loc(#loc63)
    %571 = llvm.shl %570, %17 : i32 loc(#loc63)
    %572 = llvm.add %571, %569 : i32 loc(#loc63)
    %573 = llvm.getelementptr inbounds %12[%572] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %574 = llvm.insertelement %508, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %575 = llvm.insertelement %509, %574[%25 : i32] : vector<2xf16> loc(#loc63)
    %576 = llvm.extractelement %575[%29 : i32] : vector<2xf16> loc(#loc63)
    %577 = llvm.extractelement %575[%25 : i32] : vector<2xf16> loc(#loc63)
    %578 = llvm.bitcast %576 : f16 to i16 loc(#loc63)
    %579 = llvm.bitcast %577 : f16 to i16 loc(#loc63)
    %580 = llvm.insertelement %578, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %581 = llvm.insertelement %579, %580[%25 : i32] : vector<2xi16> loc(#loc63)
    %582 = llvm.extractelement %581[%29 : i32] : vector<2xi16> loc(#loc63)
    %583 = llvm.extractelement %581[%25 : i32] : vector<2xi16> loc(#loc63)
    %584 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %573, %582, %583, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %585 = llvm.xor %530, %7 : i32 loc(#loc63)
    %586 = llvm.lshr %585, %16 : i32 loc(#loc63)
    %587 = llvm.shl %586, %17 : i32 loc(#loc63)
    %588 = llvm.add %587, %585 : i32 loc(#loc63)
    %589 = llvm.getelementptr inbounds %12[%588] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %590 = llvm.insertelement %510, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %591 = llvm.insertelement %511, %590[%25 : i32] : vector<2xf16> loc(#loc63)
    %592 = llvm.extractelement %591[%29 : i32] : vector<2xf16> loc(#loc63)
    %593 = llvm.extractelement %591[%25 : i32] : vector<2xf16> loc(#loc63)
    %594 = llvm.bitcast %592 : f16 to i16 loc(#loc63)
    %595 = llvm.bitcast %593 : f16 to i16 loc(#loc63)
    %596 = llvm.insertelement %594, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %597 = llvm.insertelement %595, %596[%25 : i32] : vector<2xi16> loc(#loc63)
    %598 = llvm.extractelement %597[%29 : i32] : vector<2xi16> loc(#loc63)
    %599 = llvm.extractelement %597[%25 : i32] : vector<2xi16> loc(#loc63)
    %600 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %589, %598, %599, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    nvvm.barrier0 loc(#loc63)
    %601 = llvm.xor %536, %29 : i32 loc(#loc63)
    %602 = llvm.lshr %601, %16 : i32 loc(#loc63)
    %603 = llvm.shl %602, %17 : i32 loc(#loc63)
    %604 = llvm.add %603, %601 : i32 loc(#loc63)
    %605 = llvm.getelementptr inbounds %12[%604] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %606 = llvm.load %605 : !llvm.ptr<3> -> vector<4xi32> loc(#loc63)
    %607 = llvm.extractelement %606[%29 : i32] : vector<4xi32> loc(#loc63)
    %608 = llvm.extractelement %606[%25 : i32] : vector<4xi32> loc(#loc63)
    %609 = llvm.extractelement %606[%20 : i32] : vector<4xi32> loc(#loc63)
    %610 = llvm.extractelement %606[%17 : i32] : vector<4xi32> loc(#loc63)
    %611 = llvm.insertelement %607, %2[%29 : i32] : vector<4xi32> loc(#loc63)
    %612 = llvm.insertelement %608, %611[%25 : i32] : vector<4xi32> loc(#loc63)
    %613 = llvm.insertelement %609, %612[%20 : i32] : vector<4xi32> loc(#loc63)
    %614 = llvm.insertelement %610, %613[%17 : i32] : vector<4xi32> loc(#loc63)
    %615 = llvm.extractelement %614[%29 : i32] : vector<4xi32> loc(#loc63)
    %616 = llvm.extractelement %614[%25 : i32] : vector<4xi32> loc(#loc63)
    %617 = llvm.extractelement %614[%20 : i32] : vector<4xi32> loc(#loc63)
    %618 = llvm.extractelement %614[%17 : i32] : vector<4xi32> loc(#loc63)
    %619 = llvm.bitcast %615 : i32 to vector<2xi16> loc(#loc63)
    %620 = llvm.extractelement %619[%29 : i32] : vector<2xi16> loc(#loc63)
    %621 = llvm.extractelement %619[%25 : i32] : vector<2xi16> loc(#loc63)
    %622 = llvm.bitcast %616 : i32 to vector<2xi16> loc(#loc63)
    %623 = llvm.extractelement %622[%29 : i32] : vector<2xi16> loc(#loc63)
    %624 = llvm.extractelement %622[%25 : i32] : vector<2xi16> loc(#loc63)
    %625 = llvm.bitcast %617 : i32 to vector<2xi16> loc(#loc63)
    %626 = llvm.extractelement %625[%29 : i32] : vector<2xi16> loc(#loc63)
    %627 = llvm.extractelement %625[%25 : i32] : vector<2xi16> loc(#loc63)
    %628 = llvm.bitcast %618 : i32 to vector<2xi16> loc(#loc63)
    %629 = llvm.extractelement %628[%29 : i32] : vector<2xi16> loc(#loc63)
    %630 = llvm.extractelement %628[%25 : i32] : vector<2xi16> loc(#loc63)
    %631 = llvm.insertelement %620, %1[%29 : i32] : vector<8xi16> loc(#loc63)
    %632 = llvm.insertelement %621, %631[%25 : i32] : vector<8xi16> loc(#loc63)
    %633 = llvm.insertelement %623, %632[%20 : i32] : vector<8xi16> loc(#loc63)
    %634 = llvm.insertelement %624, %633[%17 : i32] : vector<8xi16> loc(#loc63)
    %635 = llvm.insertelement %626, %634[%30 : i32] : vector<8xi16> loc(#loc63)
    %636 = llvm.insertelement %627, %635[%16 : i32] : vector<8xi16> loc(#loc63)
    %637 = llvm.insertelement %629, %636[%15 : i32] : vector<8xi16> loc(#loc63)
    %638 = llvm.insertelement %630, %637[%14 : i32] : vector<8xi16> loc(#loc63)
    %639 = llvm.extractelement %638[%29 : i32] : vector<8xi16> loc(#loc63)
    %640 = llvm.extractelement %638[%25 : i32] : vector<8xi16> loc(#loc63)
    %641 = llvm.extractelement %638[%20 : i32] : vector<8xi16> loc(#loc63)
    %642 = llvm.extractelement %638[%17 : i32] : vector<8xi16> loc(#loc63)
    %643 = llvm.extractelement %638[%30 : i32] : vector<8xi16> loc(#loc63)
    %644 = llvm.extractelement %638[%16 : i32] : vector<8xi16> loc(#loc63)
    %645 = llvm.extractelement %638[%15 : i32] : vector<8xi16> loc(#loc63)
    %646 = llvm.extractelement %638[%14 : i32] : vector<8xi16> loc(#loc63)
    %647 = llvm.bitcast %639 : i16 to f16 loc(#loc63)
    %648 = llvm.bitcast %640 : i16 to f16 loc(#loc63)
    %649 = llvm.bitcast %641 : i16 to f16 loc(#loc63)
    %650 = llvm.bitcast %642 : i16 to f16 loc(#loc63)
    %651 = llvm.bitcast %643 : i16 to f16 loc(#loc63)
    %652 = llvm.bitcast %644 : i16 to f16 loc(#loc63)
    %653 = llvm.bitcast %645 : i16 to f16 loc(#loc63)
    %654 = llvm.bitcast %646 : i16 to f16 loc(#loc63)
    %655 = llvm.insertelement %647, %0[%29 : i32] : vector<8xf16> loc(#loc63)
    %656 = llvm.insertelement %648, %655[%25 : i32] : vector<8xf16> loc(#loc63)
    %657 = llvm.insertelement %649, %656[%20 : i32] : vector<8xf16> loc(#loc63)
    %658 = llvm.insertelement %650, %657[%17 : i32] : vector<8xf16> loc(#loc63)
    %659 = llvm.insertelement %651, %658[%30 : i32] : vector<8xf16> loc(#loc63)
    %660 = llvm.insertelement %652, %659[%16 : i32] : vector<8xf16> loc(#loc63)
    %661 = llvm.insertelement %653, %660[%15 : i32] : vector<8xf16> loc(#loc63)
    %662 = llvm.insertelement %654, %661[%14 : i32] : vector<8xf16> loc(#loc63)
    %663 = llvm.extractelement %662[%29 : i32] : vector<8xf16> loc(#loc63)
    %664 = llvm.extractelement %662[%25 : i32] : vector<8xf16> loc(#loc63)
    %665 = llvm.extractelement %662[%20 : i32] : vector<8xf16> loc(#loc63)
    %666 = llvm.extractelement %662[%17 : i32] : vector<8xf16> loc(#loc63)
    %667 = llvm.extractelement %662[%30 : i32] : vector<8xf16> loc(#loc63)
    %668 = llvm.extractelement %662[%16 : i32] : vector<8xf16> loc(#loc63)
    %669 = llvm.extractelement %662[%15 : i32] : vector<8xf16> loc(#loc63)
    %670 = llvm.extractelement %662[%14 : i32] : vector<8xf16> loc(#loc63)
    %671 = llvm.insertelement %663, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %672 = llvm.insertelement %664, %671[%25 : i32] : vector<2xf16> loc(#loc63)
    %673 = llvm.bitcast %672 : vector<2xf16> to i32 loc(#loc63)
    %674 = llvm.insertelement %665, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %675 = llvm.insertelement %666, %674[%25 : i32] : vector<2xf16> loc(#loc63)
    %676 = llvm.bitcast %675 : vector<2xf16> to i32 loc(#loc63)
    %677 = llvm.insertelement %667, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %678 = llvm.insertelement %668, %677[%25 : i32] : vector<2xf16> loc(#loc63)
    %679 = llvm.bitcast %678 : vector<2xf16> to i32 loc(#loc63)
    %680 = llvm.insertelement %669, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %681 = llvm.insertelement %670, %680[%25 : i32] : vector<2xf16> loc(#loc63)
    %682 = llvm.bitcast %681 : vector<2xf16> to i32 loc(#loc63)
    %683 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$5 st.global.v4.b32 [ $4 + 0 ], { $0, $1, $2, $3 };", "r,r,r,r,l,b" %673, %676, %679, %682, %514, %517 : (i32, i32, i32, i32, !llvm.ptr<1>, i1) -> !llvm.void loc(#loc63)
    llvm.return loc(#loc64)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:41)
#loc37 = loc("examples/kernels/binary_ops.py":159:60)
#loc38 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":160:29)
#loc41 = loc("examples/kernels/binary_ops.py":160:40)
#loc42 = loc("examples/kernels/binary_ops.py":160:52)
#loc44 = loc("examples/kernels/binary_ops.py":168:33)
#loc45 = loc("examples/kernels/binary_ops.py":177:33)
#loc46 = loc("examples/kernels/binary_ops.py":172:20)
#loc48 = loc("examples/kernels/binary_ops.py":171:51)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:51)
#loc51 = loc("examples/kernels/binary_ops.py":174:35)
#loc52 = loc("examples/kernels/binary_ops.py":176:18)
#loc53 = loc("examples/kernels/binary_ops.py":177:18)
#loc54 = loc("examples/kernels/binary_ops.py":171:59)
#loc55 = loc("examples/kernels/binary_ops.py":171:55)
#loc56 = loc("examples/kernels/binary_ops.py":182:23)
#loc57 = loc("examples/kernels/binary_ops.py":188:33)
#loc58 = loc("examples/kernels/binary_ops.py":188:21)
#loc59 = loc("examples/kernels/binary_ops.py":188:52)
#loc60 = loc("examples/kernels/binary_ops.py":189:33)
#loc61 = loc("examples/kernels/binary_ops.py":189:58)
#loc62 = loc("examples/kernels/binary_ops.py":189:39)
#loc63 = loc("examples/kernels/binary_ops.py":190:21)
#loc64 = loc("examples/kernels/binary_ops.py":190:4)
#loc65 = loc(callsite(#loc3 at #loc4))
#loc66 = loc(callsite(#loc5 at #loc4))
#loc67 = loc(callsite(#loc3 at #loc6))
#loc68 = loc(callsite(#loc5 at #loc6))
#loc69 = loc(callsite(#loc3 at #loc44))
#loc70 = loc(callsite(#loc5 at #loc44))


// -----// IR Dump Before SymbolDCE (symbol-dce) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc39 = loc("examples/kernels/binary_ops.py":159:22)
#loc43 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
module attributes {ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @matmul_kernel(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg9: !llvm.ptr<1> loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.undef : vector<8xf16> loc(#loc1)
    %1 = llvm.mlir.undef : vector<8xi16> loc(#loc1)
    %2 = llvm.mlir.undef : vector<4xi32> loc(#loc1)
    %3 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %4 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %5 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.undef : vector<1xf32> loc(#loc1)
    %7 = llvm.mlir.constant(272 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.constant(256 : i32) : i32 loc(#loc1)
    %10 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(512 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %13 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc1)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(6 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %22 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc1)
    %23 = llvm.mlir.constant(15 : i32) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(31 : i32) : i32 loc(#loc1)
    %25 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %26 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %27 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %28 = llvm.mlir.constant(true) : i1 loc(#loc1)
    %29 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %30 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %31 = llvm.mlir.constant(-1 : i32) : i32 loc(#loc1)
    %32 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %33 = llvm.insertvalue %32, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %34 = llvm.insertvalue %32, %33[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %35 = llvm.insertvalue %32, %34[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %36 = llvm.insertvalue %32, %35[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %37 = llvm.insertvalue %32, %36[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %38 = llvm.insertvalue %32, %37[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %39 = llvm.insertvalue %32, %38[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %40 = llvm.insertvalue %32, %39[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %41 = llvm.call_intrinsic "llvm.nvvm.read.ptx.sreg.ctaid.x"() : () -> i32 loc(#loc2)
    %42 = llvm.add %arg3, %24 : i32 loc(#loc65)
    %43 = llvm.sdiv %42, %27 : i32 loc(#loc66)
    %44 = llvm.add %arg4, %24 : i32 loc(#loc67)
    %45 = llvm.sdiv %44, %27 : i32 loc(#loc68)
    %46 = llvm.mul %45, %30 : i32 loc(#loc7)
    %47 = llvm.sdiv %41, %46 : i32 loc(#loc8)
    %48 = llvm.mul %47, %30 : i32 loc(#loc9)
    %49 = llvm.sub %43, %48 : i32 loc(#loc10)
    %50 = llvm.intr.smin(%49, %30) : (i32, i32) -> i32 loc(#loc11)
    %51 = llvm.srem %41, %46 : i32 loc(#loc12)
    %52 = llvm.srem %51, %50 : i32 loc(#loc13)
    %53 = llvm.add %48, %52 : i32 loc(#loc14)
    %54 = llvm.sdiv %51, %50 : i32 loc(#loc15)
    %55 = llvm.icmp "sge" %53, %29 : i32 loc(#loc16)
    llvm.intr.assume %55 : i1 loc(#loc17)
    %56 = llvm.icmp "sge" %54, %29 : i32 loc(#loc18)
    llvm.intr.assume %56 : i1 loc(#loc19)
    %57 = llvm.icmp "sgt" %arg6, %29 : i32 loc(#loc20)
    llvm.intr.assume %57 : i1 loc(#loc21)
    llvm.intr.assume %28 : i1 loc(#loc22)
    llvm.intr.assume %28 : i1 loc(#loc23)
    %58 = llvm.icmp "sgt" %arg7, %29 : i32 loc(#loc24)
    llvm.intr.assume %58 : i1 loc(#loc25)
    %59 = llvm.icmp "sgt" %arg8, %29 : i32 loc(#loc26)
    llvm.intr.assume %59 : i1 loc(#loc27)
    llvm.intr.assume %28 : i1 loc(#loc28)
    %60 = llvm.mul %53, %27 : i32 loc(#loc29)
    %61 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc30)
    %62 = llvm.urem %61, %27 : i32 loc(#loc30)
    %63 = llvm.udiv %61, %27 : i32 loc(#loc30)
    %64 = llvm.and %62, %26 : i32 loc(#loc30)
    %65 = llvm.icmp "eq" %64, %29 : i32 loc(#loc30)
    %66 = llvm.select %65, %29, %25 : i1, i32 loc(#loc30)
    %67 = llvm.xor %29, %66 : i32 loc(#loc30)
    %68 = llvm.and %63, %25 : i32 loc(#loc30)
    %69 = llvm.icmp "eq" %68, %29 : i32 loc(#loc30)
    %70 = llvm.select %69, %29, %20 : i1, i32 loc(#loc30)
    %71 = llvm.xor %67, %70 : i32 loc(#loc30)
    %72 = llvm.and %63, %20 : i32 loc(#loc30)
    %73 = llvm.icmp "eq" %72, %29 : i32 loc(#loc30)
    %74 = llvm.select %73, %29, %30 : i1, i32 loc(#loc30)
    %75 = llvm.xor %71, %74 : i32 loc(#loc30)
    %76 = llvm.xor %75, %29 : i32 loc(#loc30)
    %77 = llvm.xor %75, %19 : i32 loc(#loc30)
    %78 = llvm.xor %75, %26 : i32 loc(#loc30)
    %79 = llvm.xor %75, %18 : i32 loc(#loc30)
    %80 = llvm.add %76, %21 : i32 loc(#loc30)
    %81 = llvm.add %77, %21 : i32 loc(#loc30)
    %82 = llvm.add %78, %21 : i32 loc(#loc30)
    %83 = llvm.add %79, %21 : i32 loc(#loc30)
    %84 = llvm.and %62, %30 : i32 loc(#loc30)
    %85 = llvm.icmp "eq" %84, %29 : i32 loc(#loc30)
    %86 = llvm.select %85, %29, %25 : i1, i32 loc(#loc30)
    %87 = llvm.xor %29, %86 : i32 loc(#loc30)
    %88 = llvm.and %62, %19 : i32 loc(#loc30)
    %89 = llvm.icmp "eq" %88, %29 : i32 loc(#loc30)
    %90 = llvm.select %89, %29, %20 : i1, i32 loc(#loc30)
    %91 = llvm.xor %87, %90 : i32 loc(#loc30)
    %92 = llvm.select %65, %29, %30 : i1, i32 loc(#loc30)
    %93 = llvm.xor %91, %92 : i32 loc(#loc30)
    %94 = llvm.select %69, %29, %19 : i1, i32 loc(#loc30)
    %95 = llvm.xor %93, %94 : i32 loc(#loc30)
    %96 = llvm.select %73, %29, %26 : i1, i32 loc(#loc30)
    %97 = llvm.xor %95, %96 : i32 loc(#loc30)
    %98 = llvm.xor %97, %29 : i32 loc(#loc30)
    %99 = llvm.add %98, %21 : i32 loc(#loc30)
    %100 = llvm.and %62, %25 : i32 loc(#loc30)
    %101 = llvm.icmp "eq" %100, %29 : i32 loc(#loc30)
    %102 = llvm.select %101, %29, %30 : i1, i32 loc(#loc30)
    %103 = llvm.xor %29, %102 : i32 loc(#loc30)
    %104 = llvm.and %62, %20 : i32 loc(#loc30)
    %105 = llvm.icmp "eq" %104, %29 : i32 loc(#loc30)
    %106 = llvm.select %105, %29, %19 : i1, i32 loc(#loc30)
    %107 = llvm.xor %103, %106 : i32 loc(#loc30)
    %108 = llvm.select %85, %29, %26 : i1, i32 loc(#loc30)
    %109 = llvm.xor %107, %108 : i32 loc(#loc30)
    %110 = llvm.xor %109, %29 : i32 loc(#loc30)
    %111 = llvm.xor %109, %25 : i32 loc(#loc30)
    %112 = llvm.xor %109, %20 : i32 loc(#loc30)
    %113 = llvm.xor %109, %17 : i32 loc(#loc30)
    %114 = llvm.add %110, %21 : i32 loc(#loc30)
    %115 = llvm.add %111, %21 : i32 loc(#loc30)
    %116 = llvm.add %112, %21 : i32 loc(#loc30)
    %117 = llvm.add %113, %21 : i32 loc(#loc30)
    %118 = llvm.select %101, %29, %19 : i1, i32 loc(#loc30)
    %119 = llvm.xor %29, %118 : i32 loc(#loc30)
    %120 = llvm.select %105, %29, %26 : i1, i32 loc(#loc30)
    %121 = llvm.xor %119, %120 : i32 loc(#loc30)
    %122 = llvm.xor %121, %29 : i32 loc(#loc30)
    %123 = llvm.add %122, %21 : i32 loc(#loc30)
    %124 = llvm.add %60, %80 : i32 loc(#loc31)
    %125 = llvm.add %60, %81 : i32 loc(#loc31)
    %126 = llvm.add %60, %82 : i32 loc(#loc31)
    %127 = llvm.add %60, %83 : i32 loc(#loc31)
    %128 = llvm.add %60, %99 : i32 loc(#loc31)
    %129 = llvm.srem %124, %arg3 : i32 loc(#loc32)
    %130 = llvm.srem %125, %arg3 : i32 loc(#loc32)
    %131 = llvm.srem %126, %arg3 : i32 loc(#loc32)
    %132 = llvm.srem %127, %arg3 : i32 loc(#loc32)
    %133 = llvm.mul %54, %27 : i32 loc(#loc33)
    %134 = llvm.add %133, %114 : i32 loc(#loc34)
    %135 = llvm.add %133, %115 : i32 loc(#loc34)
    %136 = llvm.add %133, %116 : i32 loc(#loc34)
    %137 = llvm.add %133, %117 : i32 loc(#loc34)
    %138 = llvm.add %133, %123 : i32 loc(#loc34)
    %139 = llvm.srem %134, %arg4 : i32 loc(#loc35)
    %140 = llvm.srem %135, %arg4 : i32 loc(#loc35)
    %141 = llvm.srem %136, %arg4 : i32 loc(#loc35)
    %142 = llvm.srem %137, %arg4 : i32 loc(#loc35)
    %143 = llvm.mul %129, %arg6 : i32 loc(#loc36)
    %144 = llvm.mul %130, %arg6 : i32 loc(#loc36)
    %145 = llvm.mul %131, %arg6 : i32 loc(#loc36)
    %146 = llvm.mul %132, %arg6 : i32 loc(#loc36)
    %147 = llvm.select %101, %29, %25 : i1, i32 loc(#loc37)
    %148 = llvm.xor %29, %147 : i32 loc(#loc37)
    %149 = llvm.select %105, %29, %20 : i1, i32 loc(#loc37)
    %150 = llvm.xor %148, %149 : i32 loc(#loc37)
    %151 = llvm.select %85, %29, %30 : i1, i32 loc(#loc37)
    %152 = llvm.xor %150, %151 : i32 loc(#loc37)
    %153 = llvm.select %89, %29, %19 : i1, i32 loc(#loc37)
    %154 = llvm.xor %152, %153 : i32 loc(#loc37)
    %155 = llvm.xor %154, %29 : i32 loc(#loc37)
    %156 = llvm.add %155, %21 : i32 loc(#loc37)
    %157 = llvm.add %143, %156 : i32 loc(#loc38)
    %158 = llvm.add %144, %156 : i32 loc(#loc38)
    %159 = llvm.add %145, %156 : i32 loc(#loc38)
    %160 = llvm.add %146, %156 : i32 loc(#loc38)
    %161 = llvm.getelementptr %arg0[%157] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %162 = llvm.getelementptr %arg0[%158] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %163 = llvm.getelementptr %arg0[%159] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %164 = llvm.getelementptr %arg0[%160] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %165 = llvm.insertvalue %161, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %166 = llvm.insertvalue %162, %165[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %167 = llvm.insertvalue %163, %166[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %168 = llvm.insertvalue %164, %167[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %169 = llvm.select %89, %29, %25 : i1, i32 loc(#loc40)
    %170 = llvm.xor %29, %169 : i32 loc(#loc40)
    %171 = llvm.select %65, %29, %20 : i1, i32 loc(#loc40)
    %172 = llvm.xor %170, %171 : i32 loc(#loc40)
    %173 = llvm.select %69, %29, %30 : i1, i32 loc(#loc40)
    %174 = llvm.xor %172, %173 : i32 loc(#loc40)
    %175 = llvm.select %73, %29, %19 : i1, i32 loc(#loc40)
    %176 = llvm.xor %174, %175 : i32 loc(#loc40)
    %177 = llvm.xor %176, %29 : i32 loc(#loc40)
    %178 = llvm.add %177, %21 : i32 loc(#loc40)
    %179 = llvm.mul %178, %arg7 : i32 loc(#loc41)
    %180 = llvm.add %179, %139 : i32 loc(#loc42)
    %181 = llvm.add %179, %140 : i32 loc(#loc42)
    %182 = llvm.add %179, %141 : i32 loc(#loc42)
    %183 = llvm.add %179, %142 : i32 loc(#loc42)
    %184 = llvm.getelementptr %arg1[%180] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %185 = llvm.getelementptr %arg1[%181] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %186 = llvm.getelementptr %arg1[%182] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %187 = llvm.getelementptr %arg1[%183] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %188 = llvm.insertvalue %184, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %189 = llvm.insertvalue %185, %188[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %190 = llvm.insertvalue %186, %189[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %191 = llvm.insertvalue %187, %190[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %192 = llvm.add %arg5, %23 : i32 loc(#loc69)
    %193 = llvm.sdiv %192, %26 : i32 loc(#loc70)
    %194 = llvm.mul %arg7, %26 : i32 loc(#loc45)
    %195 = llvm.getelementptr %12[2048] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc46)
    %196 = llvm.icmp "sgt" %193, %29 : i32 loc(#loc47)
    %197 = llvm.icmp "slt" %156, %arg5 : i32 loc(#loc48)
    %198 = llvm.mul %29, %11 : i32 loc(#loc49)
    %199 = llvm.add %198, %29 : i32 loc(#loc49)
    %200 = llvm.mul %29, %26 : i32 loc(#loc49)
    %201 = llvm.add %199, %200 : i32 loc(#loc49)
    %202 = llvm.mul %29, %25 : i32 loc(#loc49)
    %203 = llvm.add %201, %202 : i32 loc(#loc49)
    %204 = llvm.getelementptr %12[%203] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %205 = llvm.and %196, %197 : i1 loc(#loc47)
    %206 = llvm.xor %154, %173 : i32 loc(#loc49)
    %207 = llvm.xor %206, %175 : i32 loc(#loc49)
    %208 = llvm.mul %207, %25 : i32 loc(#loc49)
    %209 = llvm.add %208, %29 : i32 loc(#loc49)
    %210 = llvm.mul %75, %26 : i32 loc(#loc49)
    %211 = llvm.add %209, %210 : i32 loc(#loc49)
    %212 = llvm.getelementptr inbounds %204[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %213 = llvm.xor %19, %66 : i32 loc(#loc49)
    %214 = llvm.xor %213, %70 : i32 loc(#loc49)
    %215 = llvm.xor %214, %74 : i32 loc(#loc49)
    %216 = llvm.mul %215, %26 : i32 loc(#loc49)
    %217 = llvm.add %209, %216 : i32 loc(#loc49)
    %218 = llvm.getelementptr inbounds %204[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %219 = llvm.xor %26, %66 : i32 loc(#loc49)
    %220 = llvm.xor %219, %70 : i32 loc(#loc49)
    %221 = llvm.xor %220, %74 : i32 loc(#loc49)
    %222 = llvm.mul %221, %26 : i32 loc(#loc49)
    %223 = llvm.add %209, %222 : i32 loc(#loc49)
    %224 = llvm.getelementptr inbounds %204[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %225 = llvm.xor %18, %66 : i32 loc(#loc49)
    %226 = llvm.xor %225, %70 : i32 loc(#loc49)
    %227 = llvm.xor %226, %74 : i32 loc(#loc49)
    %228 = llvm.mul %227, %26 : i32 loc(#loc49)
    %229 = llvm.add %209, %228 : i32 loc(#loc49)
    %230 = llvm.getelementptr inbounds %204[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %231 = llvm.select %205, %30, %29 : i1, i32 loc(#loc49)
    %232 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %212, %161, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %233 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %218, %162, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %234 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %224, %163, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %235 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %230, %164, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %236 = llvm.icmp "slt" %178, %arg5 : i32 loc(#loc50)
    %237 = llvm.mul %29, %27 : i32 loc(#loc46)
    %238 = llvm.add %199, %237 : i32 loc(#loc46)
    %239 = llvm.add %238, %202 : i32 loc(#loc46)
    %240 = llvm.getelementptr %195[%239] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %241 = llvm.and %196, %236 : i1 loc(#loc47)
    %242 = llvm.xor %109, %153 : i32 loc(#loc46)
    %243 = llvm.select %65, %29, %26 : i1, i32 loc(#loc46)
    %244 = llvm.xor %242, %243 : i32 loc(#loc46)
    %245 = llvm.mul %244, %25 : i32 loc(#loc46)
    %246 = llvm.add %245, %29 : i32 loc(#loc46)
    %247 = llvm.mul %176, %27 : i32 loc(#loc46)
    %248 = llvm.add %246, %247 : i32 loc(#loc46)
    %249 = llvm.getelementptr inbounds %240[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %250 = llvm.select %241, %26, %29 : i1, i32 loc(#loc46)
    %251 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %249, %184, %250 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%29, %40, %168, %191, %29, %31 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb1(%252: i32 loc("examples/kernels/binary_ops.py":168:22), %253: !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(unknown), %254: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":159:22), %255: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":160:22), %256: i32 loc(unknown), %257: i32 loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %258 = llvm.icmp "slt" %252, %193 : i32 loc(#loc47)
    llvm.cond_br %258, ^bb2, ^bb3 loc(#loc47)
  ^bb2:  // pred: ^bb1
    %259 = llvm.sub %193, %25 : i32 loc(#loc47)
    %260 = llvm.icmp "slt" %252, %259 : i32 loc(#loc47)
    %261 = llvm.add %257, %25 : i32 loc(#loc47)
    %262 = llvm.icmp "slt" %261, %25 : i32 loc(#loc47)
    %263 = llvm.select %262, %261, %29 : i1, i32 loc(#loc47)
    nvvm.cp.async.wait.group 0 loc(#loc49)
    nvvm.barrier0 loc(#loc49)
    %264 = llvm.mul %263, %11 : i32 loc(#loc49)
    %265 = llvm.add %264, %29 : i32 loc(#loc49)
    %266 = llvm.add %265, %200 : i32 loc(#loc49)
    %267 = llvm.add %266, %202 : i32 loc(#loc49)
    %268 = llvm.getelementptr %12[%267] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %269 = llvm.select %105, %29, %30 : i1, i32 loc(#loc49)
    %270 = llvm.xor %29, %269 : i32 loc(#loc49)
    %271 = llvm.select %85, %29, %19 : i1, i32 loc(#loc49)
    %272 = llvm.xor %270, %271 : i32 loc(#loc49)
    %273 = llvm.xor %272, %92 : i32 loc(#loc49)
    %274 = llvm.xor %154, %96 : i32 loc(#loc49)
    %275 = llvm.mul %273, %25 : i32 loc(#loc49)
    %276 = llvm.add %275, %29 : i32 loc(#loc49)
    %277 = llvm.mul %274, %26 : i32 loc(#loc49)
    %278 = llvm.add %276, %277 : i32 loc(#loc49)
    %279 = llvm.getelementptr inbounds %268[%278] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %280 = llvm.ptrtoint %279 : !llvm.ptr<3> to i32 loc(#loc49)
    %281 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %280 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %282 = llvm.extractvalue %281[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %283 = llvm.extractvalue %281[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %284 = llvm.extractvalue %281[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %285 = llvm.extractvalue %281[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %286 = llvm.xor %19, %269 : i32 loc(#loc49)
    %287 = llvm.xor %286, %271 : i32 loc(#loc49)
    %288 = llvm.xor %287, %92 : i32 loc(#loc49)
    %289 = llvm.mul %288, %25 : i32 loc(#loc49)
    %290 = llvm.add %289, %29 : i32 loc(#loc49)
    %291 = llvm.add %290, %277 : i32 loc(#loc49)
    %292 = llvm.getelementptr inbounds %268[%291] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %293 = llvm.ptrtoint %292 : !llvm.ptr<3> to i32 loc(#loc49)
    %294 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %293 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %295 = llvm.extractvalue %294[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %296 = llvm.extractvalue %294[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %297 = llvm.extractvalue %294[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %298 = llvm.extractvalue %294[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %299 = llvm.bitcast %282 : i32 to vector<1xf32> loc(#loc49)
    %300 = llvm.extractelement %299[%29 : i32] : vector<1xf32> loc(#loc49)
    %301 = llvm.bitcast %283 : i32 to vector<1xf32> loc(#loc49)
    %302 = llvm.extractelement %301[%29 : i32] : vector<1xf32> loc(#loc49)
    %303 = llvm.bitcast %284 : i32 to vector<1xf32> loc(#loc49)
    %304 = llvm.extractelement %303[%29 : i32] : vector<1xf32> loc(#loc49)
    %305 = llvm.bitcast %285 : i32 to vector<1xf32> loc(#loc49)
    %306 = llvm.extractelement %305[%29 : i32] : vector<1xf32> loc(#loc49)
    %307 = llvm.bitcast %295 : i32 to vector<1xf32> loc(#loc49)
    %308 = llvm.extractelement %307[%29 : i32] : vector<1xf32> loc(#loc49)
    %309 = llvm.bitcast %296 : i32 to vector<1xf32> loc(#loc49)
    %310 = llvm.extractelement %309[%29 : i32] : vector<1xf32> loc(#loc49)
    %311 = llvm.bitcast %297 : i32 to vector<1xf32> loc(#loc49)
    %312 = llvm.extractelement %311[%29 : i32] : vector<1xf32> loc(#loc49)
    %313 = llvm.bitcast %298 : i32 to vector<1xf32> loc(#loc49)
    %314 = llvm.extractelement %313[%29 : i32] : vector<1xf32> loc(#loc49)
    %315 = llvm.add %265, %237 : i32 loc(#loc46)
    %316 = llvm.add %315, %202 : i32 loc(#loc46)
    %317 = llvm.getelementptr %195[%316] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %318 = llvm.xor %121, %86 : i32 loc(#loc46)
    %319 = llvm.xor %318, %90 : i32 loc(#loc46)
    %320 = llvm.xor %319, %92 : i32 loc(#loc46)
    %321 = llvm.xor %320, %94 : i32 loc(#loc46)
    %322 = llvm.mul %321, %25 : i32 loc(#loc46)
    %323 = llvm.add %322, %29 : i32 loc(#loc46)
    %324 = llvm.mul %150, %27 : i32 loc(#loc46)
    %325 = llvm.add %323, %324 : i32 loc(#loc46)
    %326 = llvm.getelementptr inbounds %317[%325] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %327 = llvm.load %326 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %328 = llvm.extractelement %327[%29 : i32] : vector<1xf32> loc(#loc46)
    %329 = llvm.xor %30, %147 : i32 loc(#loc46)
    %330 = llvm.xor %329, %149 : i32 loc(#loc46)
    %331 = llvm.mul %330, %27 : i32 loc(#loc46)
    %332 = llvm.add %323, %331 : i32 loc(#loc46)
    %333 = llvm.getelementptr inbounds %317[%332] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %334 = llvm.load %333 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %335 = llvm.extractelement %334[%29 : i32] : vector<1xf32> loc(#loc46)
    %336 = llvm.xor %19, %147 : i32 loc(#loc46)
    %337 = llvm.xor %336, %149 : i32 loc(#loc46)
    %338 = llvm.mul %337, %27 : i32 loc(#loc46)
    %339 = llvm.add %323, %338 : i32 loc(#loc46)
    %340 = llvm.getelementptr inbounds %317[%339] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %341 = llvm.load %340 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %342 = llvm.extractelement %341[%29 : i32] : vector<1xf32> loc(#loc46)
    %343 = llvm.xor %8, %147 : i32 loc(#loc46)
    %344 = llvm.xor %343, %149 : i32 loc(#loc46)
    %345 = llvm.mul %344, %27 : i32 loc(#loc46)
    %346 = llvm.add %323, %345 : i32 loc(#loc46)
    %347 = llvm.getelementptr inbounds %317[%346] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %348 = llvm.load %347 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %349 = llvm.extractelement %348[%29 : i32] : vector<1xf32> loc(#loc46)
    %350 = llvm.xor %26, %118 : i32 loc(#loc46)
    %351 = llvm.xor %350, %120 : i32 loc(#loc46)
    %352 = llvm.xor %351, %86 : i32 loc(#loc46)
    %353 = llvm.xor %352, %90 : i32 loc(#loc46)
    %354 = llvm.xor %353, %92 : i32 loc(#loc46)
    %355 = llvm.xor %354, %94 : i32 loc(#loc46)
    %356 = llvm.mul %355, %25 : i32 loc(#loc46)
    %357 = llvm.add %356, %29 : i32 loc(#loc46)
    %358 = llvm.add %357, %324 : i32 loc(#loc46)
    %359 = llvm.getelementptr inbounds %317[%358] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %360 = llvm.load %359 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %361 = llvm.extractelement %360[%29 : i32] : vector<1xf32> loc(#loc46)
    %362 = llvm.add %357, %331 : i32 loc(#loc46)
    %363 = llvm.getelementptr inbounds %317[%362] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %364 = llvm.load %363 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %365 = llvm.extractelement %364[%29 : i32] : vector<1xf32> loc(#loc46)
    %366 = llvm.add %357, %338 : i32 loc(#loc46)
    %367 = llvm.getelementptr inbounds %317[%366] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %368 = llvm.load %367 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %369 = llvm.extractelement %368[%29 : i32] : vector<1xf32> loc(#loc46)
    %370 = llvm.add %357, %345 : i32 loc(#loc46)
    %371 = llvm.getelementptr inbounds %317[%370] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %372 = llvm.load %371 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %373 = llvm.extractelement %372[%29 : i32] : vector<1xf32> loc(#loc46)
    %374 = llvm.insertelement %300, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %375 = llvm.bitcast %374 : vector<1xf32> to i32 loc(#loc51)
    %376 = llvm.insertelement %302, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %377 = llvm.bitcast %376 : vector<1xf32> to i32 loc(#loc51)
    %378 = llvm.insertelement %304, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %379 = llvm.bitcast %378 : vector<1xf32> to i32 loc(#loc51)
    %380 = llvm.insertelement %306, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %381 = llvm.bitcast %380 : vector<1xf32> to i32 loc(#loc51)
    %382 = llvm.insertelement %308, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %383 = llvm.bitcast %382 : vector<1xf32> to i32 loc(#loc51)
    %384 = llvm.insertelement %310, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %385 = llvm.bitcast %384 : vector<1xf32> to i32 loc(#loc51)
    %386 = llvm.insertelement %312, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %387 = llvm.bitcast %386 : vector<1xf32> to i32 loc(#loc51)
    %388 = llvm.insertelement %314, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %389 = llvm.bitcast %388 : vector<1xf32> to i32 loc(#loc51)
    %390 = llvm.insertelement %328, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %391 = llvm.bitcast %390 : vector<1xf32> to i32 loc(#loc51)
    %392 = llvm.insertelement %335, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %393 = llvm.bitcast %392 : vector<1xf32> to i32 loc(#loc51)
    %394 = llvm.insertelement %342, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %395 = llvm.bitcast %394 : vector<1xf32> to i32 loc(#loc51)
    %396 = llvm.insertelement %349, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %397 = llvm.bitcast %396 : vector<1xf32> to i32 loc(#loc51)
    %398 = llvm.insertelement %361, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %399 = llvm.bitcast %398 : vector<1xf32> to i32 loc(#loc51)
    %400 = llvm.insertelement %365, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %401 = llvm.bitcast %400 : vector<1xf32> to i32 loc(#loc51)
    %402 = llvm.insertelement %369, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %403 = llvm.bitcast %402 : vector<1xf32> to i32 loc(#loc51)
    %404 = llvm.insertelement %373, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %405 = llvm.bitcast %404 : vector<1xf32> to i32 loc(#loc51)
    %406 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %407 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %408 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %409 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %410 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %411 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %412 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %413 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %414 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %406, %407, %408, %409, %375, %377, %379, %381, %391, %393 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %415 = llvm.extractvalue %414[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %416 = llvm.extractvalue %414[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %417 = llvm.extractvalue %414[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %418 = llvm.extractvalue %414[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %419 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %410, %411, %412, %413, %375, %377, %379, %381, %399, %401 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %420 = llvm.extractvalue %419[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %421 = llvm.extractvalue %419[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %422 = llvm.extractvalue %419[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %423 = llvm.extractvalue %419[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %424 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %415, %416, %417, %418, %383, %385, %387, %389, %395, %397 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %425 = llvm.extractvalue %424[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %426 = llvm.extractvalue %424[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %427 = llvm.extractvalue %424[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %428 = llvm.extractvalue %424[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %429 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %420, %421, %422, %423, %383, %385, %387, %389, %403, %405 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %430 = llvm.extractvalue %429[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %431 = llvm.extractvalue %429[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %432 = llvm.extractvalue %429[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %433 = llvm.extractvalue %429[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %434 = llvm.insertvalue %425, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %435 = llvm.insertvalue %426, %434[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %436 = llvm.insertvalue %427, %435[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %437 = llvm.insertvalue %428, %436[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %438 = llvm.insertvalue %430, %437[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %439 = llvm.insertvalue %431, %438[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %440 = llvm.insertvalue %432, %439[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %441 = llvm.insertvalue %433, %440[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %442 = llvm.extractvalue %254[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %443 = llvm.extractvalue %254[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %444 = llvm.extractvalue %254[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %445 = llvm.extractvalue %254[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %446 = llvm.getelementptr %442[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %447 = llvm.getelementptr %443[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %448 = llvm.getelementptr %444[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %449 = llvm.getelementptr %445[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %450 = llvm.insertvalue %446, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %451 = llvm.insertvalue %447, %450[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %452 = llvm.insertvalue %448, %451[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %453 = llvm.insertvalue %449, %452[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %454 = llvm.extractvalue %255[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %455 = llvm.extractvalue %255[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %456 = llvm.extractvalue %255[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %457 = llvm.extractvalue %255[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %458 = llvm.getelementptr %454[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %459 = llvm.getelementptr %455[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %460 = llvm.getelementptr %456[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %461 = llvm.getelementptr %457[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %462 = llvm.insertvalue %458, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %463 = llvm.insertvalue %459, %462[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %464 = llvm.insertvalue %460, %463[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %465 = llvm.insertvalue %461, %464[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %466 = llvm.add %256, %25 : i32 loc(#loc47)
    %467 = llvm.icmp "slt" %466, %25 : i32 loc(#loc47)
    %468 = llvm.select %467, %466, %29 : i1, i32 loc(#loc47)
    %469 = llvm.add %252, %25 : i32 loc(#loc47)
    %470 = llvm.mul %469, %26 : i32 loc(#loc54)
    %471 = llvm.sub %arg5, %470 : i32 loc(#loc55)
    %472 = llvm.icmp "slt" %156, %471 : i32 loc(#loc48)
    %473 = llvm.mul %468, %11 : i32 loc(#loc49)
    %474 = llvm.add %473, %29 : i32 loc(#loc49)
    %475 = llvm.add %474, %200 : i32 loc(#loc49)
    %476 = llvm.add %475, %202 : i32 loc(#loc49)
    %477 = llvm.getelementptr %12[%476] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %478 = llvm.and %260, %472 : i1 loc(#loc47)
    nvvm.barrier0 loc(#loc49)
    %479 = llvm.getelementptr inbounds %477[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %480 = llvm.getelementptr inbounds %477[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %481 = llvm.getelementptr inbounds %477[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %482 = llvm.getelementptr inbounds %477[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %483 = llvm.select %478, %30, %29 : i1, i32 loc(#loc49)
    %484 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %479, %446, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %485 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %480, %447, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %486 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %481, %448, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %487 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %482, %449, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %488 = llvm.icmp "slt" %178, %471 : i32 loc(#loc50)
    %489 = llvm.add %474, %237 : i32 loc(#loc46)
    %490 = llvm.add %489, %202 : i32 loc(#loc46)
    %491 = llvm.getelementptr %195[%490] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %492 = llvm.and %260, %488 : i1 loc(#loc47)
    %493 = llvm.getelementptr inbounds %491[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %494 = llvm.select %492, %26, %29 : i1, i32 loc(#loc46)
    %495 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %493, %458, %494 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%469, %441, %453, %465, %468, %263 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb3:  // pred: ^bb1
    nvvm.cp.async.wait.group 0 loc(#loc47)
    nvvm.barrier0 loc(#loc47)
    %496 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %497 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %498 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %499 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %500 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %501 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %502 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %503 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %504 = llvm.fptrunc %496 : f32 to f16 loc(#loc56)
    %505 = llvm.fptrunc %497 : f32 to f16 loc(#loc56)
    %506 = llvm.fptrunc %498 : f32 to f16 loc(#loc56)
    %507 = llvm.fptrunc %499 : f32 to f16 loc(#loc56)
    %508 = llvm.fptrunc %500 : f32 to f16 loc(#loc56)
    %509 = llvm.fptrunc %501 : f32 to f16 loc(#loc56)
    %510 = llvm.fptrunc %502 : f32 to f16 loc(#loc56)
    %511 = llvm.fptrunc %503 : f32 to f16 loc(#loc56)
    %512 = llvm.mul %arg8, %128 : i32 loc(#loc57)
    %513 = llvm.getelementptr %arg2[%512] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc58)
    %514 = llvm.getelementptr %513[%138] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc59)
    %515 = llvm.icmp "slt" %128, %arg3 : i32 loc(#loc60)
    %516 = llvm.icmp "slt" %138, %arg4 : i32 loc(#loc61)
    %517 = llvm.and %515, %516 : i1 loc(#loc62)
    %518 = llvm.select %101, %29, %20 : i1, i32 loc(#loc63)
    %519 = llvm.xor %29, %518 : i32 loc(#loc63)
    %520 = llvm.select %105, %29, %30 : i1, i32 loc(#loc63)
    %521 = llvm.xor %519, %520 : i32 loc(#loc63)
    %522 = llvm.select %85, %29, %27 : i1, i32 loc(#loc63)
    %523 = llvm.xor %521, %522 : i32 loc(#loc63)
    %524 = llvm.select %89, %29, %5 : i1, i32 loc(#loc63)
    %525 = llvm.xor %523, %524 : i32 loc(#loc63)
    %526 = llvm.select %65, %29, %10 : i1, i32 loc(#loc63)
    %527 = llvm.xor %525, %526 : i32 loc(#loc63)
    %528 = llvm.xor %527, %94 : i32 loc(#loc63)
    %529 = llvm.select %73, %29, %11 : i1, i32 loc(#loc63)
    %530 = llvm.xor %528, %529 : i32 loc(#loc63)
    %531 = llvm.xor %121, %522 : i32 loc(#loc63)
    %532 = llvm.xor %531, %524 : i32 loc(#loc63)
    %533 = llvm.xor %532, %526 : i32 loc(#loc63)
    %534 = llvm.select %69, %29, %9 : i1, i32 loc(#loc63)
    %535 = llvm.xor %533, %534 : i32 loc(#loc63)
    %536 = llvm.xor %535, %529 : i32 loc(#loc63)
    %537 = llvm.xor %530, %29 : i32 loc(#loc63)
    %538 = llvm.lshr %537, %16 : i32 loc(#loc63)
    %539 = llvm.shl %538, %17 : i32 loc(#loc63)
    %540 = llvm.add %539, %537 : i32 loc(#loc63)
    %541 = llvm.getelementptr inbounds %12[%540] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %542 = llvm.insertelement %504, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %543 = llvm.insertelement %505, %542[%25 : i32] : vector<2xf16> loc(#loc63)
    %544 = llvm.extractelement %543[%29 : i32] : vector<2xf16> loc(#loc63)
    %545 = llvm.extractelement %543[%25 : i32] : vector<2xf16> loc(#loc63)
    %546 = llvm.bitcast %544 : f16 to i16 loc(#loc63)
    %547 = llvm.bitcast %545 : f16 to i16 loc(#loc63)
    %548 = llvm.insertelement %546, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %549 = llvm.insertelement %547, %548[%25 : i32] : vector<2xi16> loc(#loc63)
    %550 = llvm.extractelement %549[%29 : i32] : vector<2xi16> loc(#loc63)
    %551 = llvm.extractelement %549[%25 : i32] : vector<2xi16> loc(#loc63)
    %552 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %541, %550, %551, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %553 = llvm.xor %530, %9 : i32 loc(#loc63)
    %554 = llvm.lshr %553, %16 : i32 loc(#loc63)
    %555 = llvm.shl %554, %17 : i32 loc(#loc63)
    %556 = llvm.add %555, %553 : i32 loc(#loc63)
    %557 = llvm.getelementptr inbounds %12[%556] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %558 = llvm.insertelement %506, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %559 = llvm.insertelement %507, %558[%25 : i32] : vector<2xf16> loc(#loc63)
    %560 = llvm.extractelement %559[%29 : i32] : vector<2xf16> loc(#loc63)
    %561 = llvm.extractelement %559[%25 : i32] : vector<2xf16> loc(#loc63)
    %562 = llvm.bitcast %560 : f16 to i16 loc(#loc63)
    %563 = llvm.bitcast %561 : f16 to i16 loc(#loc63)
    %564 = llvm.insertelement %562, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %565 = llvm.insertelement %563, %564[%25 : i32] : vector<2xi16> loc(#loc63)
    %566 = llvm.extractelement %565[%29 : i32] : vector<2xi16> loc(#loc63)
    %567 = llvm.extractelement %565[%25 : i32] : vector<2xi16> loc(#loc63)
    %568 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %557, %566, %567, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %569 = llvm.xor %530, %26 : i32 loc(#loc63)
    %570 = llvm.lshr %569, %16 : i32 loc(#loc63)
    %571 = llvm.shl %570, %17 : i32 loc(#loc63)
    %572 = llvm.add %571, %569 : i32 loc(#loc63)
    %573 = llvm.getelementptr inbounds %12[%572] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %574 = llvm.insertelement %508, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %575 = llvm.insertelement %509, %574[%25 : i32] : vector<2xf16> loc(#loc63)
    %576 = llvm.extractelement %575[%29 : i32] : vector<2xf16> loc(#loc63)
    %577 = llvm.extractelement %575[%25 : i32] : vector<2xf16> loc(#loc63)
    %578 = llvm.bitcast %576 : f16 to i16 loc(#loc63)
    %579 = llvm.bitcast %577 : f16 to i16 loc(#loc63)
    %580 = llvm.insertelement %578, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %581 = llvm.insertelement %579, %580[%25 : i32] : vector<2xi16> loc(#loc63)
    %582 = llvm.extractelement %581[%29 : i32] : vector<2xi16> loc(#loc63)
    %583 = llvm.extractelement %581[%25 : i32] : vector<2xi16> loc(#loc63)
    %584 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %573, %582, %583, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %585 = llvm.xor %530, %7 : i32 loc(#loc63)
    %586 = llvm.lshr %585, %16 : i32 loc(#loc63)
    %587 = llvm.shl %586, %17 : i32 loc(#loc63)
    %588 = llvm.add %587, %585 : i32 loc(#loc63)
    %589 = llvm.getelementptr inbounds %12[%588] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %590 = llvm.insertelement %510, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %591 = llvm.insertelement %511, %590[%25 : i32] : vector<2xf16> loc(#loc63)
    %592 = llvm.extractelement %591[%29 : i32] : vector<2xf16> loc(#loc63)
    %593 = llvm.extractelement %591[%25 : i32] : vector<2xf16> loc(#loc63)
    %594 = llvm.bitcast %592 : f16 to i16 loc(#loc63)
    %595 = llvm.bitcast %593 : f16 to i16 loc(#loc63)
    %596 = llvm.insertelement %594, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %597 = llvm.insertelement %595, %596[%25 : i32] : vector<2xi16> loc(#loc63)
    %598 = llvm.extractelement %597[%29 : i32] : vector<2xi16> loc(#loc63)
    %599 = llvm.extractelement %597[%25 : i32] : vector<2xi16> loc(#loc63)
    %600 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %589, %598, %599, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    nvvm.barrier0 loc(#loc63)
    %601 = llvm.xor %536, %29 : i32 loc(#loc63)
    %602 = llvm.lshr %601, %16 : i32 loc(#loc63)
    %603 = llvm.shl %602, %17 : i32 loc(#loc63)
    %604 = llvm.add %603, %601 : i32 loc(#loc63)
    %605 = llvm.getelementptr inbounds %12[%604] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %606 = llvm.load %605 : !llvm.ptr<3> -> vector<4xi32> loc(#loc63)
    %607 = llvm.extractelement %606[%29 : i32] : vector<4xi32> loc(#loc63)
    %608 = llvm.extractelement %606[%25 : i32] : vector<4xi32> loc(#loc63)
    %609 = llvm.extractelement %606[%20 : i32] : vector<4xi32> loc(#loc63)
    %610 = llvm.extractelement %606[%17 : i32] : vector<4xi32> loc(#loc63)
    %611 = llvm.insertelement %607, %2[%29 : i32] : vector<4xi32> loc(#loc63)
    %612 = llvm.insertelement %608, %611[%25 : i32] : vector<4xi32> loc(#loc63)
    %613 = llvm.insertelement %609, %612[%20 : i32] : vector<4xi32> loc(#loc63)
    %614 = llvm.insertelement %610, %613[%17 : i32] : vector<4xi32> loc(#loc63)
    %615 = llvm.extractelement %614[%29 : i32] : vector<4xi32> loc(#loc63)
    %616 = llvm.extractelement %614[%25 : i32] : vector<4xi32> loc(#loc63)
    %617 = llvm.extractelement %614[%20 : i32] : vector<4xi32> loc(#loc63)
    %618 = llvm.extractelement %614[%17 : i32] : vector<4xi32> loc(#loc63)
    %619 = llvm.bitcast %615 : i32 to vector<2xi16> loc(#loc63)
    %620 = llvm.extractelement %619[%29 : i32] : vector<2xi16> loc(#loc63)
    %621 = llvm.extractelement %619[%25 : i32] : vector<2xi16> loc(#loc63)
    %622 = llvm.bitcast %616 : i32 to vector<2xi16> loc(#loc63)
    %623 = llvm.extractelement %622[%29 : i32] : vector<2xi16> loc(#loc63)
    %624 = llvm.extractelement %622[%25 : i32] : vector<2xi16> loc(#loc63)
    %625 = llvm.bitcast %617 : i32 to vector<2xi16> loc(#loc63)
    %626 = llvm.extractelement %625[%29 : i32] : vector<2xi16> loc(#loc63)
    %627 = llvm.extractelement %625[%25 : i32] : vector<2xi16> loc(#loc63)
    %628 = llvm.bitcast %618 : i32 to vector<2xi16> loc(#loc63)
    %629 = llvm.extractelement %628[%29 : i32] : vector<2xi16> loc(#loc63)
    %630 = llvm.extractelement %628[%25 : i32] : vector<2xi16> loc(#loc63)
    %631 = llvm.insertelement %620, %1[%29 : i32] : vector<8xi16> loc(#loc63)
    %632 = llvm.insertelement %621, %631[%25 : i32] : vector<8xi16> loc(#loc63)
    %633 = llvm.insertelement %623, %632[%20 : i32] : vector<8xi16> loc(#loc63)
    %634 = llvm.insertelement %624, %633[%17 : i32] : vector<8xi16> loc(#loc63)
    %635 = llvm.insertelement %626, %634[%30 : i32] : vector<8xi16> loc(#loc63)
    %636 = llvm.insertelement %627, %635[%16 : i32] : vector<8xi16> loc(#loc63)
    %637 = llvm.insertelement %629, %636[%15 : i32] : vector<8xi16> loc(#loc63)
    %638 = llvm.insertelement %630, %637[%14 : i32] : vector<8xi16> loc(#loc63)
    %639 = llvm.extractelement %638[%29 : i32] : vector<8xi16> loc(#loc63)
    %640 = llvm.extractelement %638[%25 : i32] : vector<8xi16> loc(#loc63)
    %641 = llvm.extractelement %638[%20 : i32] : vector<8xi16> loc(#loc63)
    %642 = llvm.extractelement %638[%17 : i32] : vector<8xi16> loc(#loc63)
    %643 = llvm.extractelement %638[%30 : i32] : vector<8xi16> loc(#loc63)
    %644 = llvm.extractelement %638[%16 : i32] : vector<8xi16> loc(#loc63)
    %645 = llvm.extractelement %638[%15 : i32] : vector<8xi16> loc(#loc63)
    %646 = llvm.extractelement %638[%14 : i32] : vector<8xi16> loc(#loc63)
    %647 = llvm.bitcast %639 : i16 to f16 loc(#loc63)
    %648 = llvm.bitcast %640 : i16 to f16 loc(#loc63)
    %649 = llvm.bitcast %641 : i16 to f16 loc(#loc63)
    %650 = llvm.bitcast %642 : i16 to f16 loc(#loc63)
    %651 = llvm.bitcast %643 : i16 to f16 loc(#loc63)
    %652 = llvm.bitcast %644 : i16 to f16 loc(#loc63)
    %653 = llvm.bitcast %645 : i16 to f16 loc(#loc63)
    %654 = llvm.bitcast %646 : i16 to f16 loc(#loc63)
    %655 = llvm.insertelement %647, %0[%29 : i32] : vector<8xf16> loc(#loc63)
    %656 = llvm.insertelement %648, %655[%25 : i32] : vector<8xf16> loc(#loc63)
    %657 = llvm.insertelement %649, %656[%20 : i32] : vector<8xf16> loc(#loc63)
    %658 = llvm.insertelement %650, %657[%17 : i32] : vector<8xf16> loc(#loc63)
    %659 = llvm.insertelement %651, %658[%30 : i32] : vector<8xf16> loc(#loc63)
    %660 = llvm.insertelement %652, %659[%16 : i32] : vector<8xf16> loc(#loc63)
    %661 = llvm.insertelement %653, %660[%15 : i32] : vector<8xf16> loc(#loc63)
    %662 = llvm.insertelement %654, %661[%14 : i32] : vector<8xf16> loc(#loc63)
    %663 = llvm.extractelement %662[%29 : i32] : vector<8xf16> loc(#loc63)
    %664 = llvm.extractelement %662[%25 : i32] : vector<8xf16> loc(#loc63)
    %665 = llvm.extractelement %662[%20 : i32] : vector<8xf16> loc(#loc63)
    %666 = llvm.extractelement %662[%17 : i32] : vector<8xf16> loc(#loc63)
    %667 = llvm.extractelement %662[%30 : i32] : vector<8xf16> loc(#loc63)
    %668 = llvm.extractelement %662[%16 : i32] : vector<8xf16> loc(#loc63)
    %669 = llvm.extractelement %662[%15 : i32] : vector<8xf16> loc(#loc63)
    %670 = llvm.extractelement %662[%14 : i32] : vector<8xf16> loc(#loc63)
    %671 = llvm.insertelement %663, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %672 = llvm.insertelement %664, %671[%25 : i32] : vector<2xf16> loc(#loc63)
    %673 = llvm.bitcast %672 : vector<2xf16> to i32 loc(#loc63)
    %674 = llvm.insertelement %665, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %675 = llvm.insertelement %666, %674[%25 : i32] : vector<2xf16> loc(#loc63)
    %676 = llvm.bitcast %675 : vector<2xf16> to i32 loc(#loc63)
    %677 = llvm.insertelement %667, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %678 = llvm.insertelement %668, %677[%25 : i32] : vector<2xf16> loc(#loc63)
    %679 = llvm.bitcast %678 : vector<2xf16> to i32 loc(#loc63)
    %680 = llvm.insertelement %669, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %681 = llvm.insertelement %670, %680[%25 : i32] : vector<2xf16> loc(#loc63)
    %682 = llvm.bitcast %681 : vector<2xf16> to i32 loc(#loc63)
    %683 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$5 st.global.v4.b32 [ $4 + 0 ], { $0, $1, $2, $3 };", "r,r,r,r,l,b" %673, %676, %679, %682, %514, %517 : (i32, i32, i32, i32, !llvm.ptr<1>, i1) -> !llvm.void loc(#loc63)
    llvm.return loc(#loc64)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:41)
#loc37 = loc("examples/kernels/binary_ops.py":159:60)
#loc38 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":160:29)
#loc41 = loc("examples/kernels/binary_ops.py":160:40)
#loc42 = loc("examples/kernels/binary_ops.py":160:52)
#loc44 = loc("examples/kernels/binary_ops.py":168:33)
#loc45 = loc("examples/kernels/binary_ops.py":177:33)
#loc46 = loc("examples/kernels/binary_ops.py":172:20)
#loc48 = loc("examples/kernels/binary_ops.py":171:51)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:51)
#loc51 = loc("examples/kernels/binary_ops.py":174:35)
#loc52 = loc("examples/kernels/binary_ops.py":176:18)
#loc53 = loc("examples/kernels/binary_ops.py":177:18)
#loc54 = loc("examples/kernels/binary_ops.py":171:59)
#loc55 = loc("examples/kernels/binary_ops.py":171:55)
#loc56 = loc("examples/kernels/binary_ops.py":182:23)
#loc57 = loc("examples/kernels/binary_ops.py":188:33)
#loc58 = loc("examples/kernels/binary_ops.py":188:21)
#loc59 = loc("examples/kernels/binary_ops.py":188:52)
#loc60 = loc("examples/kernels/binary_ops.py":189:33)
#loc61 = loc("examples/kernels/binary_ops.py":189:58)
#loc62 = loc("examples/kernels/binary_ops.py":189:39)
#loc63 = loc("examples/kernels/binary_ops.py":190:21)
#loc64 = loc("examples/kernels/binary_ops.py":190:4)
#loc65 = loc(callsite(#loc3 at #loc4))
#loc66 = loc(callsite(#loc5 at #loc4))
#loc67 = loc(callsite(#loc3 at #loc6))
#loc68 = loc(callsite(#loc5 at #loc6))
#loc69 = loc(callsite(#loc3 at #loc44))
#loc70 = loc(callsite(#loc5 at #loc44))


// -----// IR Dump Before LLVMDIScope (enable-line-info) ('builtin.module' operation) //----- //
#loc = loc("examples/kernels/binary_ops.py":103:0)
#loc1 = loc(unknown)
#loc39 = loc("examples/kernels/binary_ops.py":159:22)
#loc43 = loc("examples/kernels/binary_ops.py":160:22)
#loc47 = loc("examples/kernels/binary_ops.py":168:22)
module attributes {ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.shared = 4096 : i32, ttg.target = "cuda:89", ttg.tensor_memory_size = 0 : i32, "ttg.threads-per-warp" = 32 : i32, "ttg.total-num-warps" = 4 : i32} {
  llvm.mlir.global external @global_smem() {addr_space = 3 : i32, alignment = 16 : i64} : !llvm.array<0 x i8> loc(#loc)
  llvm.func @matmul_kernel(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg4: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg5: i32 loc("examples/kernels/binary_ops.py":103:0), %arg6: i32 loc("examples/kernels/binary_ops.py":103:0), %arg7: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg8: i32 {tt.divisibility = 16 : i32} loc("examples/kernels/binary_ops.py":103:0), %arg9: !llvm.ptr<1> loc("examples/kernels/binary_ops.py":103:0)) attributes {noinline = false, nvvm.kernel = 1 : ui1, nvvm.reqntid = array<i32: 128>, ttg.global_scratch_memory_alignment = 1 : i32, ttg.global_scratch_memory_size = 0 : i32} {
    %0 = llvm.mlir.undef : vector<8xf16> loc(#loc1)
    %1 = llvm.mlir.undef : vector<8xi16> loc(#loc1)
    %2 = llvm.mlir.undef : vector<4xi32> loc(#loc1)
    %3 = llvm.mlir.undef : vector<2xi16> loc(#loc1)
    %4 = llvm.mlir.undef : vector<2xf16> loc(#loc1)
    %5 = llvm.mlir.constant(64 : i32) : i32 loc(#loc1)
    %6 = llvm.mlir.undef : vector<1xf32> loc(#loc1)
    %7 = llvm.mlir.constant(272 : i32) : i32 loc(#loc1)
    %8 = llvm.mlir.constant(12 : i32) : i32 loc(#loc1)
    %9 = llvm.mlir.constant(256 : i32) : i32 loc(#loc1)
    %10 = llvm.mlir.constant(128 : i32) : i32 loc(#loc1)
    %11 = llvm.mlir.constant(512 : i32) : i32 loc(#loc1)
    %12 = llvm.mlir.addressof @global_smem : !llvm.ptr<3> loc(#loc1)
    %13 = llvm.mlir.undef : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc(#loc1)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc1)
    %15 = llvm.mlir.constant(6 : i32) : i32 loc(#loc1)
    %16 = llvm.mlir.constant(5 : i32) : i32 loc(#loc1)
    %17 = llvm.mlir.constant(3 : i32) : i32 loc(#loc1)
    %18 = llvm.mlir.constant(24 : i32) : i32 loc(#loc1)
    %19 = llvm.mlir.constant(8 : i32) : i32 loc(#loc1)
    %20 = llvm.mlir.constant(2 : i32) : i32 loc(#loc1)
    %21 = llvm.mlir.constant(0 : index) : i32 loc(#loc1)
    %22 = llvm.mlir.undef : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(#loc1)
    %23 = llvm.mlir.constant(15 : i32) : i32 loc(#loc1)
    %24 = llvm.mlir.constant(31 : i32) : i32 loc(#loc1)
    %25 = llvm.mlir.constant(1 : i32) : i32 loc(#loc1)
    %26 = llvm.mlir.constant(16 : i32) : i32 loc(#loc1)
    %27 = llvm.mlir.constant(32 : i32) : i32 loc(#loc1)
    %28 = llvm.mlir.constant(true) : i1 loc(#loc1)
    %29 = llvm.mlir.constant(0 : i32) : i32 loc(#loc1)
    %30 = llvm.mlir.constant(4 : i32) : i32 loc(#loc1)
    %31 = llvm.mlir.constant(-1 : i32) : i32 loc(#loc1)
    %32 = llvm.mlir.constant(0.000000e+00 : f32) : f32 loc(#loc1)
    %33 = llvm.insertvalue %32, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %34 = llvm.insertvalue %32, %33[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %35 = llvm.insertvalue %32, %34[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %36 = llvm.insertvalue %32, %35[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %37 = llvm.insertvalue %32, %36[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %38 = llvm.insertvalue %32, %37[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %39 = llvm.insertvalue %32, %38[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %40 = llvm.insertvalue %32, %39[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc1)
    %41 = llvm.call_intrinsic "llvm.nvvm.read.ptx.sreg.ctaid.x"() : () -> i32 loc(#loc2)
    %42 = llvm.add %arg3, %24 : i32 loc(#loc65)
    %43 = llvm.sdiv %42, %27 : i32 loc(#loc66)
    %44 = llvm.add %arg4, %24 : i32 loc(#loc67)
    %45 = llvm.sdiv %44, %27 : i32 loc(#loc68)
    %46 = llvm.mul %45, %30 : i32 loc(#loc7)
    %47 = llvm.sdiv %41, %46 : i32 loc(#loc8)
    %48 = llvm.mul %47, %30 : i32 loc(#loc9)
    %49 = llvm.sub %43, %48 : i32 loc(#loc10)
    %50 = llvm.intr.smin(%49, %30) : (i32, i32) -> i32 loc(#loc11)
    %51 = llvm.srem %41, %46 : i32 loc(#loc12)
    %52 = llvm.srem %51, %50 : i32 loc(#loc13)
    %53 = llvm.add %48, %52 : i32 loc(#loc14)
    %54 = llvm.sdiv %51, %50 : i32 loc(#loc15)
    %55 = llvm.icmp "sge" %53, %29 : i32 loc(#loc16)
    llvm.intr.assume %55 : i1 loc(#loc17)
    %56 = llvm.icmp "sge" %54, %29 : i32 loc(#loc18)
    llvm.intr.assume %56 : i1 loc(#loc19)
    %57 = llvm.icmp "sgt" %arg6, %29 : i32 loc(#loc20)
    llvm.intr.assume %57 : i1 loc(#loc21)
    llvm.intr.assume %28 : i1 loc(#loc22)
    llvm.intr.assume %28 : i1 loc(#loc23)
    %58 = llvm.icmp "sgt" %arg7, %29 : i32 loc(#loc24)
    llvm.intr.assume %58 : i1 loc(#loc25)
    %59 = llvm.icmp "sgt" %arg8, %29 : i32 loc(#loc26)
    llvm.intr.assume %59 : i1 loc(#loc27)
    llvm.intr.assume %28 : i1 loc(#loc28)
    %60 = llvm.mul %53, %27 : i32 loc(#loc29)
    %61 = nvvm.read.ptx.sreg.tid.x : i32 loc(#loc30)
    %62 = llvm.urem %61, %27 : i32 loc(#loc30)
    %63 = llvm.udiv %61, %27 : i32 loc(#loc30)
    %64 = llvm.and %62, %26 : i32 loc(#loc30)
    %65 = llvm.icmp "eq" %64, %29 : i32 loc(#loc30)
    %66 = llvm.select %65, %29, %25 : i1, i32 loc(#loc30)
    %67 = llvm.xor %29, %66 : i32 loc(#loc30)
    %68 = llvm.and %63, %25 : i32 loc(#loc30)
    %69 = llvm.icmp "eq" %68, %29 : i32 loc(#loc30)
    %70 = llvm.select %69, %29, %20 : i1, i32 loc(#loc30)
    %71 = llvm.xor %67, %70 : i32 loc(#loc30)
    %72 = llvm.and %63, %20 : i32 loc(#loc30)
    %73 = llvm.icmp "eq" %72, %29 : i32 loc(#loc30)
    %74 = llvm.select %73, %29, %30 : i1, i32 loc(#loc30)
    %75 = llvm.xor %71, %74 : i32 loc(#loc30)
    %76 = llvm.xor %75, %29 : i32 loc(#loc30)
    %77 = llvm.xor %75, %19 : i32 loc(#loc30)
    %78 = llvm.xor %75, %26 : i32 loc(#loc30)
    %79 = llvm.xor %75, %18 : i32 loc(#loc30)
    %80 = llvm.add %76, %21 : i32 loc(#loc30)
    %81 = llvm.add %77, %21 : i32 loc(#loc30)
    %82 = llvm.add %78, %21 : i32 loc(#loc30)
    %83 = llvm.add %79, %21 : i32 loc(#loc30)
    %84 = llvm.and %62, %30 : i32 loc(#loc30)
    %85 = llvm.icmp "eq" %84, %29 : i32 loc(#loc30)
    %86 = llvm.select %85, %29, %25 : i1, i32 loc(#loc30)
    %87 = llvm.xor %29, %86 : i32 loc(#loc30)
    %88 = llvm.and %62, %19 : i32 loc(#loc30)
    %89 = llvm.icmp "eq" %88, %29 : i32 loc(#loc30)
    %90 = llvm.select %89, %29, %20 : i1, i32 loc(#loc30)
    %91 = llvm.xor %87, %90 : i32 loc(#loc30)
    %92 = llvm.select %65, %29, %30 : i1, i32 loc(#loc30)
    %93 = llvm.xor %91, %92 : i32 loc(#loc30)
    %94 = llvm.select %69, %29, %19 : i1, i32 loc(#loc30)
    %95 = llvm.xor %93, %94 : i32 loc(#loc30)
    %96 = llvm.select %73, %29, %26 : i1, i32 loc(#loc30)
    %97 = llvm.xor %95, %96 : i32 loc(#loc30)
    %98 = llvm.xor %97, %29 : i32 loc(#loc30)
    %99 = llvm.add %98, %21 : i32 loc(#loc30)
    %100 = llvm.and %62, %25 : i32 loc(#loc30)
    %101 = llvm.icmp "eq" %100, %29 : i32 loc(#loc30)
    %102 = llvm.select %101, %29, %30 : i1, i32 loc(#loc30)
    %103 = llvm.xor %29, %102 : i32 loc(#loc30)
    %104 = llvm.and %62, %20 : i32 loc(#loc30)
    %105 = llvm.icmp "eq" %104, %29 : i32 loc(#loc30)
    %106 = llvm.select %105, %29, %19 : i1, i32 loc(#loc30)
    %107 = llvm.xor %103, %106 : i32 loc(#loc30)
    %108 = llvm.select %85, %29, %26 : i1, i32 loc(#loc30)
    %109 = llvm.xor %107, %108 : i32 loc(#loc30)
    %110 = llvm.xor %109, %29 : i32 loc(#loc30)
    %111 = llvm.xor %109, %25 : i32 loc(#loc30)
    %112 = llvm.xor %109, %20 : i32 loc(#loc30)
    %113 = llvm.xor %109, %17 : i32 loc(#loc30)
    %114 = llvm.add %110, %21 : i32 loc(#loc30)
    %115 = llvm.add %111, %21 : i32 loc(#loc30)
    %116 = llvm.add %112, %21 : i32 loc(#loc30)
    %117 = llvm.add %113, %21 : i32 loc(#loc30)
    %118 = llvm.select %101, %29, %19 : i1, i32 loc(#loc30)
    %119 = llvm.xor %29, %118 : i32 loc(#loc30)
    %120 = llvm.select %105, %29, %26 : i1, i32 loc(#loc30)
    %121 = llvm.xor %119, %120 : i32 loc(#loc30)
    %122 = llvm.xor %121, %29 : i32 loc(#loc30)
    %123 = llvm.add %122, %21 : i32 loc(#loc30)
    %124 = llvm.add %60, %80 : i32 loc(#loc31)
    %125 = llvm.add %60, %81 : i32 loc(#loc31)
    %126 = llvm.add %60, %82 : i32 loc(#loc31)
    %127 = llvm.add %60, %83 : i32 loc(#loc31)
    %128 = llvm.add %60, %99 : i32 loc(#loc31)
    %129 = llvm.srem %124, %arg3 : i32 loc(#loc32)
    %130 = llvm.srem %125, %arg3 : i32 loc(#loc32)
    %131 = llvm.srem %126, %arg3 : i32 loc(#loc32)
    %132 = llvm.srem %127, %arg3 : i32 loc(#loc32)
    %133 = llvm.mul %54, %27 : i32 loc(#loc33)
    %134 = llvm.add %133, %114 : i32 loc(#loc34)
    %135 = llvm.add %133, %115 : i32 loc(#loc34)
    %136 = llvm.add %133, %116 : i32 loc(#loc34)
    %137 = llvm.add %133, %117 : i32 loc(#loc34)
    %138 = llvm.add %133, %123 : i32 loc(#loc34)
    %139 = llvm.srem %134, %arg4 : i32 loc(#loc35)
    %140 = llvm.srem %135, %arg4 : i32 loc(#loc35)
    %141 = llvm.srem %136, %arg4 : i32 loc(#loc35)
    %142 = llvm.srem %137, %arg4 : i32 loc(#loc35)
    %143 = llvm.mul %129, %arg6 : i32 loc(#loc36)
    %144 = llvm.mul %130, %arg6 : i32 loc(#loc36)
    %145 = llvm.mul %131, %arg6 : i32 loc(#loc36)
    %146 = llvm.mul %132, %arg6 : i32 loc(#loc36)
    %147 = llvm.select %101, %29, %25 : i1, i32 loc(#loc37)
    %148 = llvm.xor %29, %147 : i32 loc(#loc37)
    %149 = llvm.select %105, %29, %20 : i1, i32 loc(#loc37)
    %150 = llvm.xor %148, %149 : i32 loc(#loc37)
    %151 = llvm.select %85, %29, %30 : i1, i32 loc(#loc37)
    %152 = llvm.xor %150, %151 : i32 loc(#loc37)
    %153 = llvm.select %89, %29, %19 : i1, i32 loc(#loc37)
    %154 = llvm.xor %152, %153 : i32 loc(#loc37)
    %155 = llvm.xor %154, %29 : i32 loc(#loc37)
    %156 = llvm.add %155, %21 : i32 loc(#loc37)
    %157 = llvm.add %143, %156 : i32 loc(#loc38)
    %158 = llvm.add %144, %156 : i32 loc(#loc38)
    %159 = llvm.add %145, %156 : i32 loc(#loc38)
    %160 = llvm.add %146, %156 : i32 loc(#loc38)
    %161 = llvm.getelementptr %arg0[%157] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %162 = llvm.getelementptr %arg0[%158] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %163 = llvm.getelementptr %arg0[%159] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %164 = llvm.getelementptr %arg0[%160] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc39)
    %165 = llvm.insertvalue %161, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %166 = llvm.insertvalue %162, %165[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %167 = llvm.insertvalue %163, %166[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %168 = llvm.insertvalue %164, %167[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc39)
    %169 = llvm.select %89, %29, %25 : i1, i32 loc(#loc40)
    %170 = llvm.xor %29, %169 : i32 loc(#loc40)
    %171 = llvm.select %65, %29, %20 : i1, i32 loc(#loc40)
    %172 = llvm.xor %170, %171 : i32 loc(#loc40)
    %173 = llvm.select %69, %29, %30 : i1, i32 loc(#loc40)
    %174 = llvm.xor %172, %173 : i32 loc(#loc40)
    %175 = llvm.select %73, %29, %19 : i1, i32 loc(#loc40)
    %176 = llvm.xor %174, %175 : i32 loc(#loc40)
    %177 = llvm.xor %176, %29 : i32 loc(#loc40)
    %178 = llvm.add %177, %21 : i32 loc(#loc40)
    %179 = llvm.mul %178, %arg7 : i32 loc(#loc41)
    %180 = llvm.add %179, %139 : i32 loc(#loc42)
    %181 = llvm.add %179, %140 : i32 loc(#loc42)
    %182 = llvm.add %179, %141 : i32 loc(#loc42)
    %183 = llvm.add %179, %142 : i32 loc(#loc42)
    %184 = llvm.getelementptr %arg1[%180] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %185 = llvm.getelementptr %arg1[%181] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %186 = llvm.getelementptr %arg1[%182] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %187 = llvm.getelementptr %arg1[%183] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc43)
    %188 = llvm.insertvalue %184, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %189 = llvm.insertvalue %185, %188[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %190 = llvm.insertvalue %186, %189[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %191 = llvm.insertvalue %187, %190[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc43)
    %192 = llvm.add %arg5, %23 : i32 loc(#loc69)
    %193 = llvm.sdiv %192, %26 : i32 loc(#loc70)
    %194 = llvm.mul %arg7, %26 : i32 loc(#loc45)
    %195 = llvm.getelementptr %12[2048] : (!llvm.ptr<3>) -> !llvm.ptr<3>, i8 loc(#loc46)
    %196 = llvm.icmp "sgt" %193, %29 : i32 loc(#loc47)
    %197 = llvm.icmp "slt" %156, %arg5 : i32 loc(#loc48)
    %198 = llvm.mul %29, %11 : i32 loc(#loc49)
    %199 = llvm.add %198, %29 : i32 loc(#loc49)
    %200 = llvm.mul %29, %26 : i32 loc(#loc49)
    %201 = llvm.add %199, %200 : i32 loc(#loc49)
    %202 = llvm.mul %29, %25 : i32 loc(#loc49)
    %203 = llvm.add %201, %202 : i32 loc(#loc49)
    %204 = llvm.getelementptr %12[%203] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %205 = llvm.and %196, %197 : i1 loc(#loc47)
    %206 = llvm.xor %154, %173 : i32 loc(#loc49)
    %207 = llvm.xor %206, %175 : i32 loc(#loc49)
    %208 = llvm.mul %207, %25 : i32 loc(#loc49)
    %209 = llvm.add %208, %29 : i32 loc(#loc49)
    %210 = llvm.mul %75, %26 : i32 loc(#loc49)
    %211 = llvm.add %209, %210 : i32 loc(#loc49)
    %212 = llvm.getelementptr inbounds %204[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %213 = llvm.xor %19, %66 : i32 loc(#loc49)
    %214 = llvm.xor %213, %70 : i32 loc(#loc49)
    %215 = llvm.xor %214, %74 : i32 loc(#loc49)
    %216 = llvm.mul %215, %26 : i32 loc(#loc49)
    %217 = llvm.add %209, %216 : i32 loc(#loc49)
    %218 = llvm.getelementptr inbounds %204[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %219 = llvm.xor %26, %66 : i32 loc(#loc49)
    %220 = llvm.xor %219, %70 : i32 loc(#loc49)
    %221 = llvm.xor %220, %74 : i32 loc(#loc49)
    %222 = llvm.mul %221, %26 : i32 loc(#loc49)
    %223 = llvm.add %209, %222 : i32 loc(#loc49)
    %224 = llvm.getelementptr inbounds %204[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %225 = llvm.xor %18, %66 : i32 loc(#loc49)
    %226 = llvm.xor %225, %70 : i32 loc(#loc49)
    %227 = llvm.xor %226, %74 : i32 loc(#loc49)
    %228 = llvm.mul %227, %26 : i32 loc(#loc49)
    %229 = llvm.add %209, %228 : i32 loc(#loc49)
    %230 = llvm.getelementptr inbounds %204[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %231 = llvm.select %205, %30, %29 : i1, i32 loc(#loc49)
    %232 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %212, %161, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %233 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %218, %162, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %234 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %224, %163, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %235 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %230, %164, %231 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %236 = llvm.icmp "slt" %178, %arg5 : i32 loc(#loc50)
    %237 = llvm.mul %29, %27 : i32 loc(#loc46)
    %238 = llvm.add %199, %237 : i32 loc(#loc46)
    %239 = llvm.add %238, %202 : i32 loc(#loc46)
    %240 = llvm.getelementptr %195[%239] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %241 = llvm.and %196, %236 : i1 loc(#loc47)
    %242 = llvm.xor %109, %153 : i32 loc(#loc46)
    %243 = llvm.select %65, %29, %26 : i1, i32 loc(#loc46)
    %244 = llvm.xor %242, %243 : i32 loc(#loc46)
    %245 = llvm.mul %244, %25 : i32 loc(#loc46)
    %246 = llvm.add %245, %29 : i32 loc(#loc46)
    %247 = llvm.mul %176, %27 : i32 loc(#loc46)
    %248 = llvm.add %246, %247 : i32 loc(#loc46)
    %249 = llvm.getelementptr inbounds %240[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %250 = llvm.select %241, %26, %29 : i1, i32 loc(#loc46)
    %251 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %249, %184, %250 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%29, %40, %168, %191, %29, %31 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb1(%252: i32 loc("examples/kernels/binary_ops.py":168:22), %253: !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)> loc(unknown), %254: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":159:22), %255: !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)> loc("examples/kernels/binary_ops.py":160:22), %256: i32 loc(unknown), %257: i32 loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %258 = llvm.icmp "slt" %252, %193 : i32 loc(#loc47)
    llvm.cond_br %258, ^bb2, ^bb3 loc(#loc47)
  ^bb2:  // pred: ^bb1
    %259 = llvm.sub %193, %25 : i32 loc(#loc47)
    %260 = llvm.icmp "slt" %252, %259 : i32 loc(#loc47)
    %261 = llvm.add %257, %25 : i32 loc(#loc47)
    %262 = llvm.icmp "slt" %261, %25 : i32 loc(#loc47)
    %263 = llvm.select %262, %261, %29 : i1, i32 loc(#loc47)
    nvvm.cp.async.wait.group 0 loc(#loc49)
    nvvm.barrier0 loc(#loc49)
    %264 = llvm.mul %263, %11 : i32 loc(#loc49)
    %265 = llvm.add %264, %29 : i32 loc(#loc49)
    %266 = llvm.add %265, %200 : i32 loc(#loc49)
    %267 = llvm.add %266, %202 : i32 loc(#loc49)
    %268 = llvm.getelementptr %12[%267] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %269 = llvm.select %105, %29, %30 : i1, i32 loc(#loc49)
    %270 = llvm.xor %29, %269 : i32 loc(#loc49)
    %271 = llvm.select %85, %29, %19 : i1, i32 loc(#loc49)
    %272 = llvm.xor %270, %271 : i32 loc(#loc49)
    %273 = llvm.xor %272, %92 : i32 loc(#loc49)
    %274 = llvm.xor %154, %96 : i32 loc(#loc49)
    %275 = llvm.mul %273, %25 : i32 loc(#loc49)
    %276 = llvm.add %275, %29 : i32 loc(#loc49)
    %277 = llvm.mul %274, %26 : i32 loc(#loc49)
    %278 = llvm.add %276, %277 : i32 loc(#loc49)
    %279 = llvm.getelementptr inbounds %268[%278] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %280 = llvm.ptrtoint %279 : !llvm.ptr<3> to i32 loc(#loc49)
    %281 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %280 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %282 = llvm.extractvalue %281[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %283 = llvm.extractvalue %281[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %284 = llvm.extractvalue %281[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %285 = llvm.extractvalue %281[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %286 = llvm.xor %19, %269 : i32 loc(#loc49)
    %287 = llvm.xor %286, %271 : i32 loc(#loc49)
    %288 = llvm.xor %287, %92 : i32 loc(#loc49)
    %289 = llvm.mul %288, %25 : i32 loc(#loc49)
    %290 = llvm.add %289, %29 : i32 loc(#loc49)
    %291 = llvm.add %290, %277 : i32 loc(#loc49)
    %292 = llvm.getelementptr inbounds %268[%291] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %293 = llvm.ptrtoint %292 : !llvm.ptr<3> to i32 loc(#loc49)
    %294 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "ldmatrix.sync.aligned.m8n8.x4.shared.b16 {$0, $1, $2, $3}, [$4];", "=r,=r,=r,=r,r" %293 : (i32) -> !llvm.struct<(i32, i32, i32, i32)> loc(#loc49)
    %295 = llvm.extractvalue %294[0] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %296 = llvm.extractvalue %294[1] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %297 = llvm.extractvalue %294[2] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %298 = llvm.extractvalue %294[3] : !llvm.struct<(i32, i32, i32, i32)>  loc(#loc49)
    %299 = llvm.bitcast %282 : i32 to vector<1xf32> loc(#loc49)
    %300 = llvm.extractelement %299[%29 : i32] : vector<1xf32> loc(#loc49)
    %301 = llvm.bitcast %283 : i32 to vector<1xf32> loc(#loc49)
    %302 = llvm.extractelement %301[%29 : i32] : vector<1xf32> loc(#loc49)
    %303 = llvm.bitcast %284 : i32 to vector<1xf32> loc(#loc49)
    %304 = llvm.extractelement %303[%29 : i32] : vector<1xf32> loc(#loc49)
    %305 = llvm.bitcast %285 : i32 to vector<1xf32> loc(#loc49)
    %306 = llvm.extractelement %305[%29 : i32] : vector<1xf32> loc(#loc49)
    %307 = llvm.bitcast %295 : i32 to vector<1xf32> loc(#loc49)
    %308 = llvm.extractelement %307[%29 : i32] : vector<1xf32> loc(#loc49)
    %309 = llvm.bitcast %296 : i32 to vector<1xf32> loc(#loc49)
    %310 = llvm.extractelement %309[%29 : i32] : vector<1xf32> loc(#loc49)
    %311 = llvm.bitcast %297 : i32 to vector<1xf32> loc(#loc49)
    %312 = llvm.extractelement %311[%29 : i32] : vector<1xf32> loc(#loc49)
    %313 = llvm.bitcast %298 : i32 to vector<1xf32> loc(#loc49)
    %314 = llvm.extractelement %313[%29 : i32] : vector<1xf32> loc(#loc49)
    %315 = llvm.add %265, %237 : i32 loc(#loc46)
    %316 = llvm.add %315, %202 : i32 loc(#loc46)
    %317 = llvm.getelementptr %195[%316] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %318 = llvm.xor %121, %86 : i32 loc(#loc46)
    %319 = llvm.xor %318, %90 : i32 loc(#loc46)
    %320 = llvm.xor %319, %92 : i32 loc(#loc46)
    %321 = llvm.xor %320, %94 : i32 loc(#loc46)
    %322 = llvm.mul %321, %25 : i32 loc(#loc46)
    %323 = llvm.add %322, %29 : i32 loc(#loc46)
    %324 = llvm.mul %150, %27 : i32 loc(#loc46)
    %325 = llvm.add %323, %324 : i32 loc(#loc46)
    %326 = llvm.getelementptr inbounds %317[%325] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %327 = llvm.load %326 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %328 = llvm.extractelement %327[%29 : i32] : vector<1xf32> loc(#loc46)
    %329 = llvm.xor %30, %147 : i32 loc(#loc46)
    %330 = llvm.xor %329, %149 : i32 loc(#loc46)
    %331 = llvm.mul %330, %27 : i32 loc(#loc46)
    %332 = llvm.add %323, %331 : i32 loc(#loc46)
    %333 = llvm.getelementptr inbounds %317[%332] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %334 = llvm.load %333 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %335 = llvm.extractelement %334[%29 : i32] : vector<1xf32> loc(#loc46)
    %336 = llvm.xor %19, %147 : i32 loc(#loc46)
    %337 = llvm.xor %336, %149 : i32 loc(#loc46)
    %338 = llvm.mul %337, %27 : i32 loc(#loc46)
    %339 = llvm.add %323, %338 : i32 loc(#loc46)
    %340 = llvm.getelementptr inbounds %317[%339] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %341 = llvm.load %340 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %342 = llvm.extractelement %341[%29 : i32] : vector<1xf32> loc(#loc46)
    %343 = llvm.xor %8, %147 : i32 loc(#loc46)
    %344 = llvm.xor %343, %149 : i32 loc(#loc46)
    %345 = llvm.mul %344, %27 : i32 loc(#loc46)
    %346 = llvm.add %323, %345 : i32 loc(#loc46)
    %347 = llvm.getelementptr inbounds %317[%346] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %348 = llvm.load %347 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %349 = llvm.extractelement %348[%29 : i32] : vector<1xf32> loc(#loc46)
    %350 = llvm.xor %26, %118 : i32 loc(#loc46)
    %351 = llvm.xor %350, %120 : i32 loc(#loc46)
    %352 = llvm.xor %351, %86 : i32 loc(#loc46)
    %353 = llvm.xor %352, %90 : i32 loc(#loc46)
    %354 = llvm.xor %353, %92 : i32 loc(#loc46)
    %355 = llvm.xor %354, %94 : i32 loc(#loc46)
    %356 = llvm.mul %355, %25 : i32 loc(#loc46)
    %357 = llvm.add %356, %29 : i32 loc(#loc46)
    %358 = llvm.add %357, %324 : i32 loc(#loc46)
    %359 = llvm.getelementptr inbounds %317[%358] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %360 = llvm.load %359 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %361 = llvm.extractelement %360[%29 : i32] : vector<1xf32> loc(#loc46)
    %362 = llvm.add %357, %331 : i32 loc(#loc46)
    %363 = llvm.getelementptr inbounds %317[%362] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %364 = llvm.load %363 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %365 = llvm.extractelement %364[%29 : i32] : vector<1xf32> loc(#loc46)
    %366 = llvm.add %357, %338 : i32 loc(#loc46)
    %367 = llvm.getelementptr inbounds %317[%366] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %368 = llvm.load %367 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %369 = llvm.extractelement %368[%29 : i32] : vector<1xf32> loc(#loc46)
    %370 = llvm.add %357, %345 : i32 loc(#loc46)
    %371 = llvm.getelementptr inbounds %317[%370] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %372 = llvm.load %371 {alignment = 4 : i64} : !llvm.ptr<3> -> vector<1xf32> loc(#loc46)
    %373 = llvm.extractelement %372[%29 : i32] : vector<1xf32> loc(#loc46)
    %374 = llvm.insertelement %300, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %375 = llvm.bitcast %374 : vector<1xf32> to i32 loc(#loc51)
    %376 = llvm.insertelement %302, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %377 = llvm.bitcast %376 : vector<1xf32> to i32 loc(#loc51)
    %378 = llvm.insertelement %304, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %379 = llvm.bitcast %378 : vector<1xf32> to i32 loc(#loc51)
    %380 = llvm.insertelement %306, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %381 = llvm.bitcast %380 : vector<1xf32> to i32 loc(#loc51)
    %382 = llvm.insertelement %308, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %383 = llvm.bitcast %382 : vector<1xf32> to i32 loc(#loc51)
    %384 = llvm.insertelement %310, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %385 = llvm.bitcast %384 : vector<1xf32> to i32 loc(#loc51)
    %386 = llvm.insertelement %312, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %387 = llvm.bitcast %386 : vector<1xf32> to i32 loc(#loc51)
    %388 = llvm.insertelement %314, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %389 = llvm.bitcast %388 : vector<1xf32> to i32 loc(#loc51)
    %390 = llvm.insertelement %328, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %391 = llvm.bitcast %390 : vector<1xf32> to i32 loc(#loc51)
    %392 = llvm.insertelement %335, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %393 = llvm.bitcast %392 : vector<1xf32> to i32 loc(#loc51)
    %394 = llvm.insertelement %342, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %395 = llvm.bitcast %394 : vector<1xf32> to i32 loc(#loc51)
    %396 = llvm.insertelement %349, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %397 = llvm.bitcast %396 : vector<1xf32> to i32 loc(#loc51)
    %398 = llvm.insertelement %361, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %399 = llvm.bitcast %398 : vector<1xf32> to i32 loc(#loc51)
    %400 = llvm.insertelement %365, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %401 = llvm.bitcast %400 : vector<1xf32> to i32 loc(#loc51)
    %402 = llvm.insertelement %369, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %403 = llvm.bitcast %402 : vector<1xf32> to i32 loc(#loc51)
    %404 = llvm.insertelement %373, %6[%29 : i32] : vector<1xf32> loc(#loc51)
    %405 = llvm.bitcast %404 : vector<1xf32> to i32 loc(#loc51)
    %406 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %407 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %408 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %409 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %410 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %411 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %412 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %413 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %414 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %406, %407, %408, %409, %375, %377, %379, %381, %391, %393 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %415 = llvm.extractvalue %414[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %416 = llvm.extractvalue %414[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %417 = llvm.extractvalue %414[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %418 = llvm.extractvalue %414[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %419 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %410, %411, %412, %413, %375, %377, %379, %381, %399, %401 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %420 = llvm.extractvalue %419[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %421 = llvm.extractvalue %419[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %422 = llvm.extractvalue %419[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %423 = llvm.extractvalue %419[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %424 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %415, %416, %417, %418, %383, %385, %387, %389, %395, %397 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %425 = llvm.extractvalue %424[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %426 = llvm.extractvalue %424[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %427 = llvm.extractvalue %424[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %428 = llvm.extractvalue %424[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %429 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32 { $0, $1, $2, $3 }, { $8, $9, $10, $11 }, { $12, $13 }, { $4, $5, $6, $7 };", "=f,=f,=f,=f,0,1,2,3,r,r,r,r,r,r" %420, %421, %422, %423, %383, %385, %387, %389, %403, %405 : (f32, f32, f32, f32, i32, i32, i32, i32, i32, i32) -> !llvm.struct<(f32, f32, f32, f32)> loc(#loc51)
    %430 = llvm.extractvalue %429[0] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %431 = llvm.extractvalue %429[1] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %432 = llvm.extractvalue %429[2] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %433 = llvm.extractvalue %429[3] : !llvm.struct<(f32, f32, f32, f32)>  loc(#loc51)
    %434 = llvm.insertvalue %425, %22[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %435 = llvm.insertvalue %426, %434[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %436 = llvm.insertvalue %427, %435[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %437 = llvm.insertvalue %428, %436[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %438 = llvm.insertvalue %430, %437[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %439 = llvm.insertvalue %431, %438[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %440 = llvm.insertvalue %432, %439[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %441 = llvm.insertvalue %433, %440[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc51)
    %442 = llvm.extractvalue %254[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %443 = llvm.extractvalue %254[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %444 = llvm.extractvalue %254[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %445 = llvm.extractvalue %254[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %446 = llvm.getelementptr %442[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %447 = llvm.getelementptr %443[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %448 = llvm.getelementptr %444[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %449 = llvm.getelementptr %445[16] : (!llvm.ptr<1>) -> !llvm.ptr<1>, f32 loc(#loc52)
    %450 = llvm.insertvalue %446, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %451 = llvm.insertvalue %447, %450[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %452 = llvm.insertvalue %448, %451[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %453 = llvm.insertvalue %449, %452[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc52)
    %454 = llvm.extractvalue %255[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %455 = llvm.extractvalue %255[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %456 = llvm.extractvalue %255[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %457 = llvm.extractvalue %255[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %458 = llvm.getelementptr %454[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %459 = llvm.getelementptr %455[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %460 = llvm.getelementptr %456[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %461 = llvm.getelementptr %457[%194] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f32 loc(#loc53)
    %462 = llvm.insertvalue %458, %13[0] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %463 = llvm.insertvalue %459, %462[1] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %464 = llvm.insertvalue %460, %463[2] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %465 = llvm.insertvalue %461, %464[3] : !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>  loc(#loc53)
    %466 = llvm.add %256, %25 : i32 loc(#loc47)
    %467 = llvm.icmp "slt" %466, %25 : i32 loc(#loc47)
    %468 = llvm.select %467, %466, %29 : i1, i32 loc(#loc47)
    %469 = llvm.add %252, %25 : i32 loc(#loc47)
    %470 = llvm.mul %469, %26 : i32 loc(#loc54)
    %471 = llvm.sub %arg5, %470 : i32 loc(#loc55)
    %472 = llvm.icmp "slt" %156, %471 : i32 loc(#loc48)
    %473 = llvm.mul %468, %11 : i32 loc(#loc49)
    %474 = llvm.add %473, %29 : i32 loc(#loc49)
    %475 = llvm.add %474, %200 : i32 loc(#loc49)
    %476 = llvm.add %475, %202 : i32 loc(#loc49)
    %477 = llvm.getelementptr %12[%476] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %478 = llvm.and %260, %472 : i1 loc(#loc47)
    nvvm.barrier0 loc(#loc49)
    %479 = llvm.getelementptr inbounds %477[%211] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %480 = llvm.getelementptr inbounds %477[%217] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %481 = llvm.getelementptr inbounds %477[%223] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %482 = llvm.getelementptr inbounds %477[%229] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc49)
    %483 = llvm.select %478, %30, %29 : i1, i32 loc(#loc49)
    %484 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %479, %446, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %485 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %480, %447, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %486 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %481, %448, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    %487 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.ca.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x4, $2;", "r,l,r" %482, %449, %483 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc49)
    nvvm.cp.async.commit.group loc(#loc49)
    %488 = llvm.icmp "slt" %178, %471 : i32 loc(#loc50)
    %489 = llvm.add %474, %237 : i32 loc(#loc46)
    %490 = llvm.add %489, %202 : i32 loc(#loc46)
    %491 = llvm.getelementptr %195[%490] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %492 = llvm.and %260, %488 : i1 loc(#loc47)
    %493 = llvm.getelementptr inbounds %491[%248] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f32 loc(#loc46)
    %494 = llvm.select %492, %26, %29 : i1, i32 loc(#loc46)
    %495 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "cp.async.cg.shared.global [ $0 + 0 ], [ $1 + 0 ], 0x10, $2;", "r,l,r" %493, %458, %494 : (!llvm.ptr<3>, !llvm.ptr<1>, i32) -> !llvm.void loc(#loc46)
    nvvm.cp.async.commit.group loc(#loc46)
    llvm.br ^bb1(%469, %441, %453, %465, %468, %263 : i32, !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, !llvm.struct<(ptr<1>, ptr<1>, ptr<1>, ptr<1>)>, i32, i32) loc(#loc47)
  ^bb3:  // pred: ^bb1
    nvvm.cp.async.wait.group 0 loc(#loc47)
    nvvm.barrier0 loc(#loc47)
    %496 = llvm.extractvalue %253[0] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %497 = llvm.extractvalue %253[1] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %498 = llvm.extractvalue %253[2] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %499 = llvm.extractvalue %253[3] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %500 = llvm.extractvalue %253[4] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %501 = llvm.extractvalue %253[5] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %502 = llvm.extractvalue %253[6] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %503 = llvm.extractvalue %253[7] : !llvm.struct<(f32, f32, f32, f32, f32, f32, f32, f32)>  loc(#loc56)
    %504 = llvm.fptrunc %496 : f32 to f16 loc(#loc56)
    %505 = llvm.fptrunc %497 : f32 to f16 loc(#loc56)
    %506 = llvm.fptrunc %498 : f32 to f16 loc(#loc56)
    %507 = llvm.fptrunc %499 : f32 to f16 loc(#loc56)
    %508 = llvm.fptrunc %500 : f32 to f16 loc(#loc56)
    %509 = llvm.fptrunc %501 : f32 to f16 loc(#loc56)
    %510 = llvm.fptrunc %502 : f32 to f16 loc(#loc56)
    %511 = llvm.fptrunc %503 : f32 to f16 loc(#loc56)
    %512 = llvm.mul %arg8, %128 : i32 loc(#loc57)
    %513 = llvm.getelementptr %arg2[%512] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc58)
    %514 = llvm.getelementptr %513[%138] : (!llvm.ptr<1>, i32) -> !llvm.ptr<1>, f16 loc(#loc59)
    %515 = llvm.icmp "slt" %128, %arg3 : i32 loc(#loc60)
    %516 = llvm.icmp "slt" %138, %arg4 : i32 loc(#loc61)
    %517 = llvm.and %515, %516 : i1 loc(#loc62)
    %518 = llvm.select %101, %29, %20 : i1, i32 loc(#loc63)
    %519 = llvm.xor %29, %518 : i32 loc(#loc63)
    %520 = llvm.select %105, %29, %30 : i1, i32 loc(#loc63)
    %521 = llvm.xor %519, %520 : i32 loc(#loc63)
    %522 = llvm.select %85, %29, %27 : i1, i32 loc(#loc63)
    %523 = llvm.xor %521, %522 : i32 loc(#loc63)
    %524 = llvm.select %89, %29, %5 : i1, i32 loc(#loc63)
    %525 = llvm.xor %523, %524 : i32 loc(#loc63)
    %526 = llvm.select %65, %29, %10 : i1, i32 loc(#loc63)
    %527 = llvm.xor %525, %526 : i32 loc(#loc63)
    %528 = llvm.xor %527, %94 : i32 loc(#loc63)
    %529 = llvm.select %73, %29, %11 : i1, i32 loc(#loc63)
    %530 = llvm.xor %528, %529 : i32 loc(#loc63)
    %531 = llvm.xor %121, %522 : i32 loc(#loc63)
    %532 = llvm.xor %531, %524 : i32 loc(#loc63)
    %533 = llvm.xor %532, %526 : i32 loc(#loc63)
    %534 = llvm.select %69, %29, %9 : i1, i32 loc(#loc63)
    %535 = llvm.xor %533, %534 : i32 loc(#loc63)
    %536 = llvm.xor %535, %529 : i32 loc(#loc63)
    %537 = llvm.xor %530, %29 : i32 loc(#loc63)
    %538 = llvm.lshr %537, %16 : i32 loc(#loc63)
    %539 = llvm.shl %538, %17 : i32 loc(#loc63)
    %540 = llvm.add %539, %537 : i32 loc(#loc63)
    %541 = llvm.getelementptr inbounds %12[%540] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %542 = llvm.insertelement %504, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %543 = llvm.insertelement %505, %542[%25 : i32] : vector<2xf16> loc(#loc63)
    %544 = llvm.extractelement %543[%29 : i32] : vector<2xf16> loc(#loc63)
    %545 = llvm.extractelement %543[%25 : i32] : vector<2xf16> loc(#loc63)
    %546 = llvm.bitcast %544 : f16 to i16 loc(#loc63)
    %547 = llvm.bitcast %545 : f16 to i16 loc(#loc63)
    %548 = llvm.insertelement %546, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %549 = llvm.insertelement %547, %548[%25 : i32] : vector<2xi16> loc(#loc63)
    %550 = llvm.extractelement %549[%29 : i32] : vector<2xi16> loc(#loc63)
    %551 = llvm.extractelement %549[%25 : i32] : vector<2xi16> loc(#loc63)
    %552 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %541, %550, %551, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %553 = llvm.xor %530, %9 : i32 loc(#loc63)
    %554 = llvm.lshr %553, %16 : i32 loc(#loc63)
    %555 = llvm.shl %554, %17 : i32 loc(#loc63)
    %556 = llvm.add %555, %553 : i32 loc(#loc63)
    %557 = llvm.getelementptr inbounds %12[%556] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %558 = llvm.insertelement %506, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %559 = llvm.insertelement %507, %558[%25 : i32] : vector<2xf16> loc(#loc63)
    %560 = llvm.extractelement %559[%29 : i32] : vector<2xf16> loc(#loc63)
    %561 = llvm.extractelement %559[%25 : i32] : vector<2xf16> loc(#loc63)
    %562 = llvm.bitcast %560 : f16 to i16 loc(#loc63)
    %563 = llvm.bitcast %561 : f16 to i16 loc(#loc63)
    %564 = llvm.insertelement %562, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %565 = llvm.insertelement %563, %564[%25 : i32] : vector<2xi16> loc(#loc63)
    %566 = llvm.extractelement %565[%29 : i32] : vector<2xi16> loc(#loc63)
    %567 = llvm.extractelement %565[%25 : i32] : vector<2xi16> loc(#loc63)
    %568 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %557, %566, %567, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %569 = llvm.xor %530, %26 : i32 loc(#loc63)
    %570 = llvm.lshr %569, %16 : i32 loc(#loc63)
    %571 = llvm.shl %570, %17 : i32 loc(#loc63)
    %572 = llvm.add %571, %569 : i32 loc(#loc63)
    %573 = llvm.getelementptr inbounds %12[%572] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %574 = llvm.insertelement %508, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %575 = llvm.insertelement %509, %574[%25 : i32] : vector<2xf16> loc(#loc63)
    %576 = llvm.extractelement %575[%29 : i32] : vector<2xf16> loc(#loc63)
    %577 = llvm.extractelement %575[%25 : i32] : vector<2xf16> loc(#loc63)
    %578 = llvm.bitcast %576 : f16 to i16 loc(#loc63)
    %579 = llvm.bitcast %577 : f16 to i16 loc(#loc63)
    %580 = llvm.insertelement %578, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %581 = llvm.insertelement %579, %580[%25 : i32] : vector<2xi16> loc(#loc63)
    %582 = llvm.extractelement %581[%29 : i32] : vector<2xi16> loc(#loc63)
    %583 = llvm.extractelement %581[%25 : i32] : vector<2xi16> loc(#loc63)
    %584 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %573, %582, %583, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    %585 = llvm.xor %530, %7 : i32 loc(#loc63)
    %586 = llvm.lshr %585, %16 : i32 loc(#loc63)
    %587 = llvm.shl %586, %17 : i32 loc(#loc63)
    %588 = llvm.add %587, %585 : i32 loc(#loc63)
    %589 = llvm.getelementptr inbounds %12[%588] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %590 = llvm.insertelement %510, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %591 = llvm.insertelement %511, %590[%25 : i32] : vector<2xf16> loc(#loc63)
    %592 = llvm.extractelement %591[%29 : i32] : vector<2xf16> loc(#loc63)
    %593 = llvm.extractelement %591[%25 : i32] : vector<2xf16> loc(#loc63)
    %594 = llvm.bitcast %592 : f16 to i16 loc(#loc63)
    %595 = llvm.bitcast %593 : f16 to i16 loc(#loc63)
    %596 = llvm.insertelement %594, %3[%29 : i32] : vector<2xi16> loc(#loc63)
    %597 = llvm.insertelement %595, %596[%25 : i32] : vector<2xi16> loc(#loc63)
    %598 = llvm.extractelement %597[%29 : i32] : vector<2xi16> loc(#loc63)
    %599 = llvm.extractelement %597[%25 : i32] : vector<2xi16> loc(#loc63)
    %600 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$3 st.shared.v2.b16 [ $0 + 0 ], { $1, $2 };", "r,h,h,b" %589, %598, %599, %28 : (!llvm.ptr<3>, i16, i16, i1) -> !llvm.void loc(#loc63)
    nvvm.barrier0 loc(#loc63)
    %601 = llvm.xor %536, %29 : i32 loc(#loc63)
    %602 = llvm.lshr %601, %16 : i32 loc(#loc63)
    %603 = llvm.shl %602, %17 : i32 loc(#loc63)
    %604 = llvm.add %603, %601 : i32 loc(#loc63)
    %605 = llvm.getelementptr inbounds %12[%604] : (!llvm.ptr<3>, i32) -> !llvm.ptr<3>, f16 loc(#loc63)
    %606 = llvm.load %605 : !llvm.ptr<3> -> vector<4xi32> loc(#loc63)
    %607 = llvm.extractelement %606[%29 : i32] : vector<4xi32> loc(#loc63)
    %608 = llvm.extractelement %606[%25 : i32] : vector<4xi32> loc(#loc63)
    %609 = llvm.extractelement %606[%20 : i32] : vector<4xi32> loc(#loc63)
    %610 = llvm.extractelement %606[%17 : i32] : vector<4xi32> loc(#loc63)
    %611 = llvm.insertelement %607, %2[%29 : i32] : vector<4xi32> loc(#loc63)
    %612 = llvm.insertelement %608, %611[%25 : i32] : vector<4xi32> loc(#loc63)
    %613 = llvm.insertelement %609, %612[%20 : i32] : vector<4xi32> loc(#loc63)
    %614 = llvm.insertelement %610, %613[%17 : i32] : vector<4xi32> loc(#loc63)
    %615 = llvm.extractelement %614[%29 : i32] : vector<4xi32> loc(#loc63)
    %616 = llvm.extractelement %614[%25 : i32] : vector<4xi32> loc(#loc63)
    %617 = llvm.extractelement %614[%20 : i32] : vector<4xi32> loc(#loc63)
    %618 = llvm.extractelement %614[%17 : i32] : vector<4xi32> loc(#loc63)
    %619 = llvm.bitcast %615 : i32 to vector<2xi16> loc(#loc63)
    %620 = llvm.extractelement %619[%29 : i32] : vector<2xi16> loc(#loc63)
    %621 = llvm.extractelement %619[%25 : i32] : vector<2xi16> loc(#loc63)
    %622 = llvm.bitcast %616 : i32 to vector<2xi16> loc(#loc63)
    %623 = llvm.extractelement %622[%29 : i32] : vector<2xi16> loc(#loc63)
    %624 = llvm.extractelement %622[%25 : i32] : vector<2xi16> loc(#loc63)
    %625 = llvm.bitcast %617 : i32 to vector<2xi16> loc(#loc63)
    %626 = llvm.extractelement %625[%29 : i32] : vector<2xi16> loc(#loc63)
    %627 = llvm.extractelement %625[%25 : i32] : vector<2xi16> loc(#loc63)
    %628 = llvm.bitcast %618 : i32 to vector<2xi16> loc(#loc63)
    %629 = llvm.extractelement %628[%29 : i32] : vector<2xi16> loc(#loc63)
    %630 = llvm.extractelement %628[%25 : i32] : vector<2xi16> loc(#loc63)
    %631 = llvm.insertelement %620, %1[%29 : i32] : vector<8xi16> loc(#loc63)
    %632 = llvm.insertelement %621, %631[%25 : i32] : vector<8xi16> loc(#loc63)
    %633 = llvm.insertelement %623, %632[%20 : i32] : vector<8xi16> loc(#loc63)
    %634 = llvm.insertelement %624, %633[%17 : i32] : vector<8xi16> loc(#loc63)
    %635 = llvm.insertelement %626, %634[%30 : i32] : vector<8xi16> loc(#loc63)
    %636 = llvm.insertelement %627, %635[%16 : i32] : vector<8xi16> loc(#loc63)
    %637 = llvm.insertelement %629, %636[%15 : i32] : vector<8xi16> loc(#loc63)
    %638 = llvm.insertelement %630, %637[%14 : i32] : vector<8xi16> loc(#loc63)
    %639 = llvm.extractelement %638[%29 : i32] : vector<8xi16> loc(#loc63)
    %640 = llvm.extractelement %638[%25 : i32] : vector<8xi16> loc(#loc63)
    %641 = llvm.extractelement %638[%20 : i32] : vector<8xi16> loc(#loc63)
    %642 = llvm.extractelement %638[%17 : i32] : vector<8xi16> loc(#loc63)
    %643 = llvm.extractelement %638[%30 : i32] : vector<8xi16> loc(#loc63)
    %644 = llvm.extractelement %638[%16 : i32] : vector<8xi16> loc(#loc63)
    %645 = llvm.extractelement %638[%15 : i32] : vector<8xi16> loc(#loc63)
    %646 = llvm.extractelement %638[%14 : i32] : vector<8xi16> loc(#loc63)
    %647 = llvm.bitcast %639 : i16 to f16 loc(#loc63)
    %648 = llvm.bitcast %640 : i16 to f16 loc(#loc63)
    %649 = llvm.bitcast %641 : i16 to f16 loc(#loc63)
    %650 = llvm.bitcast %642 : i16 to f16 loc(#loc63)
    %651 = llvm.bitcast %643 : i16 to f16 loc(#loc63)
    %652 = llvm.bitcast %644 : i16 to f16 loc(#loc63)
    %653 = llvm.bitcast %645 : i16 to f16 loc(#loc63)
    %654 = llvm.bitcast %646 : i16 to f16 loc(#loc63)
    %655 = llvm.insertelement %647, %0[%29 : i32] : vector<8xf16> loc(#loc63)
    %656 = llvm.insertelement %648, %655[%25 : i32] : vector<8xf16> loc(#loc63)
    %657 = llvm.insertelement %649, %656[%20 : i32] : vector<8xf16> loc(#loc63)
    %658 = llvm.insertelement %650, %657[%17 : i32] : vector<8xf16> loc(#loc63)
    %659 = llvm.insertelement %651, %658[%30 : i32] : vector<8xf16> loc(#loc63)
    %660 = llvm.insertelement %652, %659[%16 : i32] : vector<8xf16> loc(#loc63)
    %661 = llvm.insertelement %653, %660[%15 : i32] : vector<8xf16> loc(#loc63)
    %662 = llvm.insertelement %654, %661[%14 : i32] : vector<8xf16> loc(#loc63)
    %663 = llvm.extractelement %662[%29 : i32] : vector<8xf16> loc(#loc63)
    %664 = llvm.extractelement %662[%25 : i32] : vector<8xf16> loc(#loc63)
    %665 = llvm.extractelement %662[%20 : i32] : vector<8xf16> loc(#loc63)
    %666 = llvm.extractelement %662[%17 : i32] : vector<8xf16> loc(#loc63)
    %667 = llvm.extractelement %662[%30 : i32] : vector<8xf16> loc(#loc63)
    %668 = llvm.extractelement %662[%16 : i32] : vector<8xf16> loc(#loc63)
    %669 = llvm.extractelement %662[%15 : i32] : vector<8xf16> loc(#loc63)
    %670 = llvm.extractelement %662[%14 : i32] : vector<8xf16> loc(#loc63)
    %671 = llvm.insertelement %663, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %672 = llvm.insertelement %664, %671[%25 : i32] : vector<2xf16> loc(#loc63)
    %673 = llvm.bitcast %672 : vector<2xf16> to i32 loc(#loc63)
    %674 = llvm.insertelement %665, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %675 = llvm.insertelement %666, %674[%25 : i32] : vector<2xf16> loc(#loc63)
    %676 = llvm.bitcast %675 : vector<2xf16> to i32 loc(#loc63)
    %677 = llvm.insertelement %667, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %678 = llvm.insertelement %668, %677[%25 : i32] : vector<2xf16> loc(#loc63)
    %679 = llvm.bitcast %678 : vector<2xf16> to i32 loc(#loc63)
    %680 = llvm.insertelement %669, %4[%29 : i32] : vector<2xf16> loc(#loc63)
    %681 = llvm.insertelement %670, %680[%25 : i32] : vector<2xf16> loc(#loc63)
    %682 = llvm.bitcast %681 : vector<2xf16> to i32 loc(#loc63)
    %683 = llvm.inline_asm has_side_effects asm_dialect = att operand_attrs = [] "@$5 st.global.v4.b32 [ $4 + 0 ], { $0, $1, $2, $3 };", "r,r,r,r,l,b" %673, %676, %679, %682, %514, %517 : (i32, i32, i32, i32, !llvm.ptr<1>, i1) -> !llvm.void loc(#loc63)
    llvm.return loc(#loc64)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("examples/kernels/binary_ops.py":126:24)
#loc3 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:22)
#loc4 = loc("examples/kernels/binary_ops.py":127:27)
#loc5 = loc("/home/ahmed/miniconda3/envs/torch-env/lib/python3.13/site-packages/triton/language/standard.py":40:28)
#loc6 = loc("examples/kernels/binary_ops.py":128:27)
#loc7 = loc("examples/kernels/binary_ops.py":129:38)
#loc8 = loc("examples/kernels/binary_ops.py":130:22)
#loc9 = loc("examples/kernels/binary_ops.py":131:29)
#loc10 = loc("examples/kernels/binary_ops.py":132:35)
#loc11 = loc("examples/kernels/binary_ops.py":132:48)
#loc12 = loc("examples/kernels/binary_ops.py":133:34)
#loc13 = loc("examples/kernels/binary_ops.py":133:54)
#loc14 = loc("examples/kernels/binary_ops.py":133:27)
#loc15 = loc("examples/kernels/binary_ops.py":134:40)
#loc16 = loc("examples/kernels/binary_ops.py":140:23)
#loc17 = loc("examples/kernels/binary_ops.py":140:14)
#loc18 = loc("examples/kernels/binary_ops.py":141:23)
#loc19 = loc("examples/kernels/binary_ops.py":141:14)
#loc20 = loc("examples/kernels/binary_ops.py":142:26)
#loc21 = loc("examples/kernels/binary_ops.py":142:14)
#loc22 = loc("examples/kernels/binary_ops.py":143:14)
#loc23 = loc("examples/kernels/binary_ops.py":144:14)
#loc24 = loc("examples/kernels/binary_ops.py":145:26)
#loc25 = loc("examples/kernels/binary_ops.py":145:14)
#loc26 = loc("examples/kernels/binary_ops.py":146:26)
#loc27 = loc("examples/kernels/binary_ops.py":146:14)
#loc28 = loc("examples/kernels/binary_ops.py":147:14)
#loc29 = loc("examples/kernels/binary_ops.py":156:23)
#loc30 = loc("examples/kernels/binary_ops.py":156:51)
#loc31 = loc("examples/kernels/binary_ops.py":156:38)
#loc32 = loc("examples/kernels/binary_ops.py":156:68)
#loc33 = loc("examples/kernels/binary_ops.py":157:23)
#loc34 = loc("examples/kernels/binary_ops.py":157:38)
#loc35 = loc("examples/kernels/binary_ops.py":157:68)
#loc36 = loc("examples/kernels/binary_ops.py":159:41)
#loc37 = loc("examples/kernels/binary_ops.py":159:60)
#loc38 = loc("examples/kernels/binary_ops.py":159:53)
#loc40 = loc("examples/kernels/binary_ops.py":160:29)
#loc41 = loc("examples/kernels/binary_ops.py":160:40)
#loc42 = loc("examples/kernels/binary_ops.py":160:52)
#loc44 = loc("examples/kernels/binary_ops.py":168:33)
#loc45 = loc("examples/kernels/binary_ops.py":177:33)
#loc46 = loc("examples/kernels/binary_ops.py":172:20)
#loc48 = loc("examples/kernels/binary_ops.py":171:51)
#loc49 = loc("examples/kernels/binary_ops.py":171:20)
#loc50 = loc("examples/kernels/binary_ops.py":172:51)
#loc51 = loc("examples/kernels/binary_ops.py":174:35)
#loc52 = loc("examples/kernels/binary_ops.py":176:18)
#loc53 = loc("examples/kernels/binary_ops.py":177:18)
#loc54 = loc("examples/kernels/binary_ops.py":171:59)
#loc55 = loc("examples/kernels/binary_ops.py":171:55)
#loc56 = loc("examples/kernels/binary_ops.py":182:23)
#loc57 = loc("examples/kernels/binary_ops.py":188:33)
#loc58 = loc("examples/kernels/binary_ops.py":188:21)
#loc59 = loc("examples/kernels/binary_ops.py":188:52)
#loc60 = loc("examples/kernels/binary_ops.py":189:33)
#loc61 = loc("examples/kernels/binary_ops.py":189:58)
#loc62 = loc("examples/kernels/binary_ops.py":189:39)
#loc63 = loc("examples/kernels/binary_ops.py":190:21)
#loc64 = loc("examples/kernels/binary_ops.py":190:4)
#loc65 = loc(callsite(#loc3 at #loc4))
#loc66 = loc(callsite(#loc5 at #loc4))
#loc67 = loc(callsite(#loc3 at #loc6))
#loc68 = loc(callsite(#loc5 at #loc6))
#loc69 = loc(callsite(#loc3 at #loc44))
#loc70 = loc(callsite(#loc5 at #loc44))


